<!doctype html><html lang=en><head><meta charset=utf-8><meta name=mobile-web-app-capable content="yes"><meta name=viewport content="width=device-width,initial-scale=1"><title>Makespan Minimization for Unrelated Parallel Machines with Maintenance Windows - Adam Drake
</title><meta name=description content="Adam Drake is an advisor to scale-up tech companies. He writes about ML/AI/crypto/data, leadership, and building tech teams."><link rel="shortcut icon" href=https://adamdrake.com/static/favicon.ico><link rel=authorization_endpoint href=https://indieauth.com/auth><link rel=token_endpoint href=https://tokens.indieauth.com/token><link rel=me href=https://github.com/adamdrake><link rel=stylesheet href=https://adamdrake.com/css/style.min.css crossorigin=anonymous media=screen><meta property="og:url" content="https://adamdrake.com/"><meta property="og:title" content="Adam Drake"><meta property="og:site_name" content="Adam Drake"><meta property="og:type" content="website"><meta property="og:description" content="Adam Drake is an advisor to scale-up tech companies. He writes about ML/AI/crypto/data, leadership, and building tech teams."><meta property="og:image" content="/static/images/twitter-card.jpg"><meta name=twitter:title content="Adam Drake"><meta name=twitter:description content="Adam Drake is an advisor to scale-up tech companies. He writes about ML/AI/crypto/data, leadership, and building tech teams."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/static/images/twitter-card.jpg"></head><body><header><section><div class="header flex row"><div class="header__item flex row"><a id=site__name href=https://adamdrake.com/>Adam Drake</a></div><div class="flex row"><nav aria-label="page menu" class="flex row"><ul role=menubar class="flex row"><li role=none><a class=sidebar-nav-itemmenu__item href=/ title>Latest</a></li><li role=none><a class=sidebar-nav-itemmenu__item href=/about.html title>About</a></li><li role=none><a class=sidebar-nav-itemmenu__item href=/cases.html title>Case Studies</a></li><li role=none><a class=sidebar-nav-itemmenu__item href=/contact.html title>Contact</a></li><li role=none><a class="sidebar-nav-item activemenu__item" href=/posts.html title=Posts>Posts</a></li><li role=none><a class=sidebar-nav-itemmenu__item href=/press.html title>Press</a></li><li><button class="subscribe subscribe-btn">
<a href=https://www.digitalmaneuver.com/#/portal>Subscribe to newsletter</a></button></li></ul></nav></div></div></section></header><main aria-role=main><section><ul id=feed__ul><li class="feed__li h-entry"><div class=feed__content><time class="hidden dt-published">2015-05-27 00:00:00 +0000 UTC</time><div class="flex properties__row"><div rel=author class="flex left p-author h-card hidden"><img class=u-photo src=https://adamdrake.com/static/images/adam_drake_240.jpg alt="Adam Drake" id=author-img><div><p rel=me class=p-name id=author-name>Adam Drake</p><p class=properties>May 27, 2015</p></div></div><div class="flex right properties"></div></div><article class="md p-summary e-content"><h1 class=p-name>Makespan Minimization for Unrelated Parallel Machines with Maintenance Windows</h1><p>It&rsquo;s a bit late, but last year during the Christmas break, <a href=https://kaggle.com>Kaggle</a> had a <a href=https://www.kaggle.com/c/helping-santas-helpers>very interesting competition</a> for the season. The story was that the toy list at Santa&rsquo;s workshop was long, and elves had to make all the toys, with some constraints on their productivity rating and rest intervals. This is an adaptation of the classic problem of minimizing makespan, though with additional constraints. A good leaderboard position could be achieved using offline methods since the entire list of toys was supplied in advance, but as usual I pursued online solutions for fun and speed.</p><p>The problem they described can be reformulated as online makespan optimization for unrelated parallel machines with maintenance windows. For the moment we&rsquo;ll just consider some basic approaches in the offline case, and I may write something else in the future which covers more online methods.</p><p>The inspiration for the proofs below and notation, as well as a broader overview of these topics, is found in lecture notes from a class Albert and Souza gave on Combinatorial Algorithms at Humboldt-Universität zu Berlin Institut für Informatik.</p><h1 id=problem-statement class=anchor-link><a href=#problem-statement>Problem statement</a></h1><p>Let&rsquo;s start by formalizing the problem a bit so we have a clear understanding of what&rsquo;s happening.</p><p>Assume we have a set of machines $M := \{1, \ldots, m\}$ and a set of jobs $J := \{1, \ldots, n\}$ where job $j \in J$ on machine $i \in M$ requires $p_{ij}$ time units for processing. Further, let $J_i$ be the set of all jobs processed on machine $i$ and $c_j$ be the time at which job $j$ is completed. Now define the <em>load</em> on machine $i$ as $\ell_i := \sum_{j \in J_i} p_{ij}$. Also note the starting time of machine $i$ before the start of job $j$ as $s_j$. The <em>makespan</em> is then equivalent to the maximum load $\ell_{max} = c_j = max_{i \in M} \ell_i$.</p><p>Our basic objective is to find an assignment of jobs such that the makespan is minimized.</p><p>Furthermore, assume that that we must produce items <em>without preemption</em>, which means once an item has begun production on a given machine that it must continue until completion on the same machine.</p><p>In addition to this, the competition also had further constraints on intervals in which machines could operate, and their productivity bonuses (or penalties) for operating at different times. We&rsquo;ll get to those later.</p><p>Also note that an algorithm is an $\alpha$-approximation for a problem if and only if for every instance of the problem the algorithm produces a solution which is within a factor $\alpha$ of the optimal solution. In our context we are dealing with minimization problems, so $\alpha \ge 1$ means that the solution found by the algorithm is at most $\alpha$ times the optimal solution.</p><p>For now, let&rsquo;s consider the most basic formulation of the problem in the offline environment where we are presented with the complete job list.</p><h1 id=base-case-identical-parallel-machines class=anchor-link><a href=#base-case-identical-parallel-machines>Base case: Identical Parallel Machines</a></h1><p>In this case, the machines are identical so the production cost/time of an item is the same regardless of which machine produces the item. This basic formulation is known to be NP-Hard, even for two machines. We can examine two approaches to this problem, the basic List Scheduling heuristic and next the Sorted List Scheduling/Least Processing Time (LPT) heuristic.</p><h2 id=list-scheduling class=anchor-link><a href=#list-scheduling>List Scheduling</a></h2><p>This is approach is straightforward. Take the set of jobs $J$ in any order, and for each job $j \in J$ allocate the job to the machine $i \in M$ which has the smallest load $\ell_i$.</p><p>THEOREM: The List Scheduling algorithm is a 2-approximation for makespan scheduling on identical parallel machines.</p><p>PROOF: Let $T_{OPT}$ be the optimal makespan for a given instance of the problem. We can show that $s_j \le T_{OPT}$ for all $j \in J$. The implication then is that $c_j = s_j + p_j \le T_{OPT} + p_j \le 2 \cdot T_{OPT}$ for all $j \in J$ since it is necessarily true that for all $j \in J$ we have that $p_j \le T_{OPT}$.</p><p>By way of contradiction, assume there exists some $s_j \gt T_{OPT}$. Then the load on machine $i$ before the assignment of job $j$ is $\ell_i \gt T_{OPT}$ for all $i \in M$. Then all jobs $J^\prime \subseteq J$ scheduled before $j$ by the algorithm have total processing time $\sum_{j^\prime \in J^\prime}p_{j^\prime} \gt m \cdot T_{OPT}$. However, since the optimum schedule finishes all jobs $J$ at time $T_{OPT}$ we knows that $\sum_{j \in J} p_j \le m \cdot T_{OPT}$, a contradiction leading to the conclusion that the List Scheduling algorithm must start all jobs such that for all $j \in J$ we have $s_j \le T_{OPT}.$ $\blacksquare$</p><h2 id=sorted-list-scheduling class=anchor-link><a href=#sorted-list-scheduling>Sorted List Scheduling</a></h2><p>This algorithms is similar to the one above, except that instead of simply taking the set of jobs $J$ in any order, we sort them in decreasing order by length.</p><p>THEOREM: The Sorted List Scheduling algorithm is a $3/2$-approximation for makespan scheduling on identical parallel machines.</p><p>PROOF: Let $T_{OPT}$ be the optimal makespan for a given instance of the problem. Then partition the jobs into a set of <em>large</em> jobs $J_L = \{j \in J \colon p_j \gt \frac{T_{OPT}}{2} \}$ and a set of <em>small</em> jobs $J_S = J - J_L$. Now notice that $|J_L| \le m$. Assume by way of contradiction that there are more than $m$ such jobs, then in any schedule (including the optimal one) there must be at least two such jobs scheduled on the same machine. Since the length a large job is more than $\frac{T_{OPT}}{2}$ this contradicts that $T_{OPT}$ is the optimal makespan.</p><p>Since there are at most $m$ large jobs and the algorithm schedules them first and on individual machines, we know that $\forall j \in J_L, c_j \le T_{OPT}$. Therefore, if a job completes later than $T_{OPT}$ it must be a small job with length at most $\frac{T_{OPT}}{2}$. Since all jobs start not later than $T_{OPT}$ we have that $\forall j \in J_S, c_j \le T_{OPT} + p_j \le \frac{3}{2} \cdot T_{OPT}$. $\blacksquare$</p><h1 id=extended-case-unrelated-parallel-machines class=anchor-link><a href=#extended-case-unrelated-parallel-machines>Extended case: Unrelated Parallel Machines</a></h1><p>This case is the same as before, except that machines may not have the same rates of production. This means that a given job $j$ the processing time may be different depending on which machine processes the job, and $p_{ij}$ denotes the processing time for job $j$ on machine $i$.</p><p>The basic approach for this case is to relax the integer programming constraints to linear ones, use binary search to find a smallest feasible solution to the linear program, and then round to obtain the integer programming solution.</p><p>The range for the binary search is established by first greedily scheduling each job on the machine with the smallest load $\ell_i$. If $\alpha$ is the makespan of such a schedule, then the range for binary search is $[ \frac{\alpha}{m}, \alpha ]$.</p><p>Though this approach is more complicated, it can be shown that this is also a 2-approximation for the problem of makespan minimization on unrelated parallel machines.</p><p>The above examples are appropriate for the offline version of the problem where the list of items for production is known in advance, but does not touch at all upon the online case where the makespan must be optimized in a more streaming fashion.</p><h1 id=additional-problem-constraints class=anchor-link><a href=#additional-problem-constraints>Additional problem constraints</a></h1><p>In the competition as designed, there were more constraints on the problem, notably that elves can only work during certain hours, with penalties incurred for time spend working outside these ours and increases in productivity for time spent working within those hours. This can be considered equivalent to the concept of maintenance windows for machines.</p><h1 id=the-winning-solution class=anchor-link><a href=#the-winning-solution>The winning solution</a></h1><p>The winners of the competition posted <a href=https://www.kaggle.com/c/helping-santas-helpers/discussion/12441>posted a writeup</a> <a href=https://storage.googleapis.com/kaggle-forum-message-attachments/63756/1971/writeup.pdf>(PDF)</a> of their solution with lots of depth and explanation. They used a combination of techniques in addition to some observations about the data. Definitely recommend reading for further details.</p><a class=hidden href=https://brid.gy/publish/mastodon></a><a class=hidden href=https://brid.gy/publish/twitter></a><a class=hidden href=https://fed.brid.gy/></a><data class=p-bridgy-omit-link value=false></data></article></div><div id=webmentions></div></li></ul></section></main><hr><footer class="flex col"><section class="footer-bio content"><p><strong>Adam Drake</strong> leads technical business transformations in global and multi-cultural environments. He has a passion for helping companies become more productive by improving internal leadership capabilities, and accelerating product development through technology and data architecture guidance. Adam has served as a White House Presidential Innovation Fellow and is an IEEE Senior Member.</p></section><button class="subscribe subscribe-btn">
<a href=https://www.digitalmaneuver.com/#/portal>Subscribe to newsletter</a></button><div class=social-icons><a rel=me href=https://github.com/adamdrake title=GitHub><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></div></footer></body></html>