<!doctype html><html lang=en><head><meta charset=utf-8><meta name=mobile-web-app-capable content="yes"><meta name=viewport content="width=device-width,initial-scale=1"><title>Redis Performance Triage Handbook - Adam Drake</title><meta name=description content="Adam Drake is an advisor to scale-up tech companies. He writes about ML/AI, leadership, and building tech teams."><link rel="shortcut icon" href=https://adamdrake.com/static/favicon.ico><link rel=authorization_endpoint href=https://indieauth.com/auth><link rel=token_endpoint href=https://tokens.indieauth.com/token><link rel=me href=https://github.com/adamdrake><link rel=stylesheet href=https://adamdrake.com/css/style.min.css crossorigin=anonymous media=screen><meta property="og:url" content="https://adamdrake.com/"><meta property="og:title" content="Adam Drake"><meta property="og:site_name" content="Adam Drake"><meta property="og:type" content="website"><meta property="og:description" content="Adam Drake is an advisor to scale-up tech companies. He writes about ML/AI, leadership, and building tech teams."><meta property="og:image" content="/static/images/twitter-card.jpg"><meta name=twitter:title content="Adam Drake"><meta name=twitter:description content="Adam Drake is an advisor to scale-up tech companies. He writes about ML/AI, leadership, and building tech teams."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/static/images/twitter-card.jpg"></head><body><header><section><div class="header flex row"><div class="header__item flex row"><a id=site__name href=https://adamdrake.com/>Adam Drake</a></div><div class="flex row"><nav aria-label="page menu" class="flex row"><ul role=menubar class="flex row"><li role=none><a class=sidebar-nav-itemmenu__item href=/ title>Latest</a></li><li role=none><a class=sidebar-nav-itemmenu__item href=/about.html title>About</a></li><li role=none><a class=sidebar-nav-itemmenu__item href=/cases.html title>Case Studies</a></li><li role=none><a class=sidebar-nav-itemmenu__item href=/contact.html title>Contact</a></li><li role=none><a class="sidebar-nav-item activemenu__item" href=/posts.html title=Posts>Posts</a></li><li role=none><a class=sidebar-nav-itemmenu__item href=/press.html title>Press</a></li><li><button class="subscribe subscribe-btn">
<a href=https://www.digitalmaneuver.com/#/portal>Subscribe to newsletter</a></button></li></ul></nav></div></div></section></header><main aria-role=main><section><ul id=feed__ul><li class="feed__li h-entry"><div class=feed__content><time class="hidden dt-published">2017-05-15 00:00:00 +0000 UTC</time><div class="flex properties__row"><div rel=author class="flex left p-author h-card"><img class=u-photo src=https://adamdrake.com/static/images/adam_drake_240.jpg alt="Adam Drake" id=author-img><div><p rel=me class=p-name id=author-name>Adam Drake</p><p class=properties>May 15, 2017</p></div></div><div class="flex right properties"></div></div><article class="md p-summary e-content"><h2 class=p-name>Redis Performance Triage Handbook</h2><h1 id=intro class=anchor-link><a href=#intro>Intro</a></h1><p>I do a lot of work with growth-stage startups, and many of them use <a href=https://redis.io>Redis</a> for all sorts of things. Sometimes as a key/value store for caching, sometimes as a message queue, sometimes as a pub/sub message broker, etc. Redis is a great tool, with great performance, when used properly. However, I&rsquo;ve often seen cases where it is not used with good performance in mind, often to the detriment of system uptime and customer satisfaction. High-performance, customer-facing products literally go down for hours per day due to relatively subtle or seemingly innocent misuses of Redis.</p><h1 id=redis-overview class=anchor-link><a href=#redis-overview>Redis Overview</a></h1><p>I won&rsquo;t go into too much detail about the particulars of Redis commands and capabilities here, since the assumption is that you already know those things and are wanting to make sure you either use them properly, or you have some kind of performance problem which requires correction.</p><p>From a performance perspective, it&rsquo;s important to note some things about Redis. The foremost of these is that it is single-threaded.</p><p>Redis is single-threaded, by design (with small exception for background IO). If you run it on a machine with more than one hyperthread, all of the additional CPUs/cores/hyperthreads will be wasted. One Redis instance will run commands on one hyperthread (AKA AWS vCPU), no matter how many are present in the machine. If you need more performance, you will have to run multiple Redis instances, one per hyperthread, on different ports. If you run multiple Redis commands and some are faster than others, then all the commands will be blocked while each slow command is being run.</p><p>If you are using Redis on Amazon Web Services ElastiCache, this single-threaded nature means that using any AWS ElastiCache instances which have multiple vCPUs makes no sense from a CPU perspective. Your Redis will not use them (though Memcached will). Those larger ElastiCache instances are only useful for Redis if you need the additional memory space.</p><h1 id=performance-triage class=anchor-link><a href=#performance-triage>Performance triage</a></h1><h2 id=look-at-slowlog class=anchor-link><a href=#look-at-slowlog>Look at <code>SLOWLOG</code>.</a></h2><p>This will tell you which commands are taking a lot of time to run, and therefore blocking all the other commands. Remember, Redis only does <strong>one</strong> thing at a time. If you find some slow-running commands here, track them down in your code and see if there are ways to speed them up. Also note any appearance of <code>evalsha</code>, which denotes a LUA script. While using LUA inside Redis is fine in theory, and gives some nice functionality akin to stored procedures, it can be a performance problem. Consider the code below from the <a href=https://github.com/Automattic/kue/blob/master/lib/kue.js#L263>kue.js Javascript library</a>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#66d9ef>var</span> <span style=color:#a6e22e>script</span> <span style=color:#f92672>=</span>
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;local msg = redis.call( &#34;keys&#34;, &#34;&#39;</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>prefix</span> <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;:jobs:*:inactive&#34; )\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        local need_fix = 0\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        for i,v in ipairs(msg) do\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          local queue = redis.call( &#34;zcard&#34;, v )\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          local jt = string.match(v, &#34;&#39;</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>prefix</span> <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;:jobs:(.*):inactive&#34;)\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          local pending = redis.call( &#34;LLEN&#34;, &#34;&#39;</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>prefix</span> <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;:&#34; .. jt .. &#34;:jobs&#34; )\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          if queue &gt; pending then\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            need_fix = need_fix + 1\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            for j=1,(queue-pending) do\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>              redis.call( &#34;lpush&#34;, &#34;&#39;</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>prefix</span> <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;:&#34;..jt..&#34;:jobs&#34;, 1 )\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            end\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>          end\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        end\n\
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        return need_fix&#39;</span>;
</span></span></code></pre></div><p>This code can potentially be very slow, since it uses the <code>KEYS</code> command (among other things). Which leads us to&mldr;</p><h2 id=no-keys-command-ever class=anchor-link><a href=#no-keys-command-ever>No <code>KEYS</code> command. Ever.</a></h2><p>Even the Redis site says this is for <a href=https://redis.io/topics/benchmarks>debugging only</a>. This command stops the server while the keyspace is scanned for matches, which can take a really long time.</p><blockquote><p>Warning: consider <code>KEYS</code> as a command that should only be used in production environments with extreme care. It may ruin performance when it is executed against large databases. This command is intended for debugging and special operations, such as changing your keyspace layout. Don&rsquo;t use KEYS in your regular application code. If you&rsquo;re looking for a way to find keys in a subset of your keyspace, consider using <code>SCAN</code> or sets.</p></blockquote><p>Instead of <code>KEYS</code>, use <code>SCAN</code>, which like all the Redis commands has <a href=https://redis.io/topics/benchmarks>good documentation</a>.</p><h2 id=dont-open-a-new-connection-for-every-command class=anchor-link><a href=#dont-open-a-new-connection-for-every-command>Don&rsquo;t open a new connection for every command.</a></h2><p>In Redis, establishing a new connection and tearing it down again is expensive. If you are opening a new connection for every command then you might be wasting 95% of your performance doing so. Keeping the connection alive and issuing commands over a persistent connection, in my local tests, is about <strong>25 times faster</strong> than opening a new connection for each request. If you want to check for this on your current Redis instance, check the <code>total_connections_received</code> value in your <code>INFO</code> output. If it is high, then your application(s) might be opening a new connection for every request, and thus wasting a ton of capacity.</p><p>In the tests below, the <code>-k 0</code> flag means do not keep the connection alive (i.e., start a new connection for each command).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ redis-benchmark -k <span style=color:#ae81ff>0</span> -t get,set -q
</span></span><span style=display:flex><span>WARNING: keepalive disabled, you probably need <span style=color:#e6db74>&#39;echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse&#39;</span> <span style=color:#66d9ef>for</span> Linux and <span style=color:#e6db74>&#39;sudo sysctl -w net.inet.tcp.msl=1000&#39;</span> <span style=color:#66d9ef>for</span> Mac OS X in order to use a lot of clients/requests
</span></span><span style=display:flex><span>SET: 8142.00 requests per second
</span></span><span style=display:flex><span>GET: 7230.14 requests per second
</span></span></code></pre></div><p>We can see the huge performance increase if we change the benchmark and reuse the connections.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ redis-benchmark -k <span style=color:#ae81ff>1</span> -t get,set -q
</span></span><span style=display:flex><span>SET: 198807.16 requests per second
</span></span><span style=display:flex><span>GET: 193423.59 requests per second
</span></span></code></pre></div><p>P.S. - If you haven&rsquo;t used <code>redis-benchmark</code> before, now is a good time to <a href=https://redis.io/topics/benchmarks>check it out</a>.</p><h2 id=use-variadic-versions-of-commands-instead-of-using-set-in-a-loop-for-example class=anchor-link><a href=#use-variadic-versions-of-commands-instead-of-using-set-in-a-loop-for-example>Use variadic versions of commands instead of using <code>SET</code> in a loop, for example.</a></h2><p>If you have a list of key/value pairs you need to set, or some other operation you need to do repeatedly, use the variadic version of the command if it exists. Looping over a list and issuing 100 <code>SET</code> commands is a lot slower than using a single <code>MSET</code> with 100 key/value pairs. This slowness can compound if you are opening and closing a new connection for every command, which should not be the case if you are reusing connections as in the previous step. Check out the example with <code>SET</code> versus <code>MSET</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ redis-benchmark -q -t set,mset
</span></span><span style=display:flex><span>SET: 158730.16 requests per second
</span></span><span style=display:flex><span>MSET <span style=color:#f92672>(</span><span style=color:#ae81ff>10</span> keys<span style=color:#f92672>)</span>: 178253.12 requests per second
</span></span></code></pre></div><p>This gets even more impressive if we use pipelining&mldr;</p><h2 id=pipeline-your-commands class=anchor-link><a href=#pipeline-your-commands>Pipeline your commands.</a></h2><p>In cases where you want to further improve performance, or cannot use variadic commands, Redis supports pipelining, which lets you send a big batch of commands all at once. Doing this can dramatically speed up the number of commands your Redis instance can execute every second. Check out the below examples comparing zero pipelining to pipelining 75 commands.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ redis-benchmark -k <span style=color:#ae81ff>1</span> -t get,set -q -P <span style=color:#ae81ff>75</span>
</span></span><span style=display:flex><span>SET: 1587301.50 requests per second
</span></span><span style=display:flex><span>GET: 2127659.75 requests per secondh
</span></span></code></pre></div><p>This is a speedup of almost <strong>300 times</strong> over the first benchmark with no connection keepalive. Pipelining can make a massive difference in throughput on your Redis if it is appropriate for your application.</p><p>Now check out the performance when we use connection keepalive, and use a variadic command for setting key/value pairs, and use pipelining.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ redis-benchmark -q -P <span style=color:#ae81ff>75</span> -t set,mset
</span></span><span style=display:flex><span>SET: 1754386.00 requests per second
</span></span><span style=display:flex><span>MSET <span style=color:#f92672>(</span><span style=color:#ae81ff>10</span> keys<span style=color:#f92672>)</span>: 387596.91 requests per second
</span></span></code></pre></div><p>Since <code>MSET</code> is sending 10 keys per request, and doing about 400,000 requests per second, we&rsquo;re setting about 4 million keys, compared to about 2 million for the non-variadic version. Now we are <strong>500 times</strong> faster than the initial version.</p><h2 id=provide-expiration-for-a-key-along-with-the-set-command-not-as-a-separate-expire-command class=anchor-link><a href=#provide-expiration-for-a-key-along-with-the-set-command-not-as-a-separate-expire-command>Provide expiration for a key along with the <code>SET</code> command, not as a separate <code>EXPIRE</code> command.</a></h2><p>Because Redis is single-threaded, every unneccessary command is a waste and is blocking other commands. You can provide an expiration time/TTL in your <code>SET</code> command, so issuing a <code>SET</code>, followed immediately by an <code>EXPIRE</code> is a waste. Avoid using separate <code>EXPIRE</code> commands if at all possible.</p><h2 id=use-blocking-pushpop-commands-where-appropriate class=anchor-link><a href=#use-blocking-pushpop-commands-where-appropriate>Use blocking push/pop commands, where appropriate.</a></h2><p>Redis can work well as a basic queing system, but you don&rsquo;t want to tax the system for no reason by repeatedly checking the queue to see if there are items present. Instead, on the client, use the blocking version of push and pop like <code>BLPUSH</code> and <code>BLPOP</code>, respectively. This way the client will wait to do the operation instead of just issuing the standard command over and over again. This is a common mistake when building a worker to push queue items, and results in high CPU usage on the client system in addition to a lot of commands issued on the Redis instance for no reason. You should probably provide a timeout for the operation as well, unless you want to block forever.</p><h2 id=dont-use-multiple-databases class=anchor-link><a href=#dont-use-multiple-databases>Don&rsquo;t use multiple databases.</a></h2><p>Remember that due to the single-threaded nature of Redis, if one command is running, the next one is blocked. If you use multiple databases inside the same Redis instance, then you are requiring the use of the <code>SELECT</code> command to choose which database you want. There are other issues surrounding using multiple databases in Redis, and even Salvatore himself has said it isn&rsquo;t a good idea and is a feature <a href=https://groups.google.com/forum/#!topic/redis-db/vS5wX8X4Cjg>he wishes he could remove</a>. If you&rsquo;re using multiple databases, you&rsquo;re probably just better off having a prefix in your keyspace to represent the different sets of data.</p><h2 id=dont-send-an-auth-command-with-an-empty-string class=anchor-link><a href=#dont-send-an-auth-command-with-an-empty-string>Don&rsquo;t send an <code>AUTH</code> command with an empty string.</a></h2><p>As with the <code>SELECT</code>, taking up CPU cycles with an <code>AUTH</code> command is not a good idea. If you don&rsquo;t have any password on your Redis instance, make sure your code and/or the Redis library you are using is not sending an <code>AUTH ""</code> to the Redis server.</p><h2 id=if-memory-usage-is-getting-consistently-high-scan-your-keyspace class=anchor-link><a href=#if-memory-usage-is-getting-consistently-high-scan-your-keyspace>If memory usage is getting consistently high, <code>SCAN</code> your keyspace.</a></h2><p>Redis generally handles key expiration very well, but sometimes it can be necessary to do a manual <code>SCAN</code> through the keyspace in order to expire keys. I wouldn&rsquo;t do this as a matter of course since eviction seems to work well in current versions of Redis, but I do know of some customers using ElastiCache Redis instances on AWS that have to do this in order to keep their memory usage under control. The expiration of keys in Redis is quite good in general.</p><blockquote><p><strong>How Redis expires keys:</strong></p></blockquote><blockquote><p>Redis keys are expired in two ways: a passive way, and an active way. A key is passively expired simply when some client tries to access it, and the key is found to be timed out. Of course, this is not a complete solution as there are expired keys that will never be accessed again. To address this, Redis periodically tests a few keys at random among keys with an expire set. All the keys that are expired are deleted from the keyspace. Specifically, this is what Redis does 10 times per second:</p><ol><li>Test 20 random keys from the set of keys with an associated expire.</li><li>Delete all the keys found expired.</li><li>If more than 25% of keys were expired, start again from step 1.</li></ol><p>This is a trivial probabilistic algorithm. Basically, the assumption is that our sample is representative of the whole key space. We continue to expire keys until the percentage of keys that are likely to be expired is under 25%. This means that at any given moment the maximum amount of keys already expired that are using memory is at most equal to the maximum amount of write operations per second divided by 4.</p></blockquote><h1 id=fin class=anchor-link><a href=#fin>Fin</a></h1><p>Above are some areas to examine if your Redis instance isn&rsquo;t performing well. In general, you should be getting many thousands - if not millions - of commands from your Redis instance. Chances are that your application/site isn&rsquo;t that busy, so you should be able to use Redis as your data structure server throughout your growth cycle. If you do happen to need additional Redis instances with some kind of load balancing or sharding, consider setting up <a href=https://github.com/twitter/twemproxy>twemproxy</a>.</p><a class=hidden href=https://brid.gy/publish/mastodon></a><a class=hidden href=https://brid.gy/publish/twitter></a><a class=hidden href=https://fed.brid.gy/></a><data class=p-bridgy-omit-link value=false></data></article></div><div id=webmentions></div></li></ul></section></main><hr><footer class="flex col"><section class="footer-bio content"><p><strong>Adam Drake</strong> leads technical business transformations in global and multi-cultural environments. He has a passion for helping companies become more productive by improving internal leadership capabilities, and accelerating product development through technology and data architecture guidance. Adam has served as a White House Presidential Innovation Fellow and is an IEEE Senior Member.</p></section><button class="subscribe subscribe-btn">
<a href=https://www.digitalmaneuver.com/#/portal>Subscribe to newsletter</a></button><div class=social-icons><a rel=me href=https://github.com/adamdrake title=GitHub><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></div></footer></body></html>