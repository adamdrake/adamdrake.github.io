<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on Adam Drake</title><link>https://adamdrake.com/posts.html</link><description>Read the latest Posts on Adam Drake</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 16 Aug 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://adamdrake.com/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>An Unreasonably Deep Dive Into Project Euler Problem 4</title><link>https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-4.html</link><pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate><guid>https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-4.html</guid><description>&lt;h1 id="or-how-to-make-your-solution-8000x-faster-with-math-and-short-circuit-evaluation" class="anchor-link">&lt;a href="#or-how-to-make-your-solution-8000x-faster-with-math-and-short-circuit-evaluation">Or: How to make your solution 8000x faster with math and short-circuit evaluation.&lt;/a>&lt;/h1>
&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>It has been a couple of years since my last Project Eueler effort, &lt;a href="https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-3.html">An Unreasonably Deep Dive into Project Euler Problem 3&lt;/a>, and since I&amp;rsquo;ve also been wanting to do more work with Rust recently, I thought it would be a good opportunity to do both things at once by doing Project Euler problem 4 in Rust instead of my default of Go as before.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="or-how-to-make-your-solution-8000x-faster-with-math-and-short-circuit-evaluation" class="anchor-link"><a href="#or-how-to-make-your-solution-8000x-faster-with-math-and-short-circuit-evaluation">Or: How to make your solution 8000x faster with math and short-circuit evaluation.</a></h1>

<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>It has been a couple of years since my last Project Eueler effort, <a href="https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-3.html">An Unreasonably Deep Dive into Project Euler Problem 3</a>, and since I&rsquo;ve also been wanting to do more work with Rust recently, I thought it would be a good opportunity to do both things at once by doing Project Euler problem 4 in Rust instead of my default of Go as before.</p>

<h1 id="problem-statement" class="anchor-link"><a href="#problem-statement">Problem Statement</a></h1>
<blockquote>
<p>A palindromic number reads the same both ways. The largest palindrome made from the product of two 2-digit numbers is 9009 = 91 Ã— 99.</p>
<p>Find the largest palindrome made from the product of two 3-digit numbers.</p>
</blockquote>
<p>The general approach to the solution will be to find a working version first (as always), then focus on making it faster by reducing the search space.  Along the way, there are a couple of programming techniques we can employ for great speedups as well.</p>
<p>All of this results in the final version being about <em>8000x faster</em> than the naive version.</p>
<p>For the full code, see <a href="https://github.com/adamdrake/projecteuler">the github repository</a>.</p>

<h1 id="helper-functions" class="anchor-link"><a href="#helper-functions">Helper function(s)</a></h1>
<p>To start with, we will need a function that tells us if a number is palindromic.  This is not the most efficient way to write this helper function, but it works.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// We will need a helper function to determine if a number is palindromic
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// is_palindromic_v1() will convert the number to a string, reverse the string, and compare that with the
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// string representation of the number.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">is_palindromic_v1</span>(i: <span style="color:#66d9ef">i32</span>) -&gt; <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> i.to_string().chars().rev().collect::<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span>() <span style="color:#f92672">==</span> i.to_string();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="v0---time-required-102000000ns" class="anchor-link"><a href="#v0---time-required-102000000ns">v0() - time required: ~102,000,000ns</a></h1>
<p>As a naive/brute-force first version, let&rsquo;s just multiply all three-digit numbers, check each time if the product is palindromic, keep it if it is, and continue that process until we have checked all products of three-digit numbers.</p>
<p>This is slow but it works.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// v0() is the naive attempt: multiply three-digit numbers.  When a palindromic number is found,
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// if it&#39;s larger than the most recent palindromic number found then keep it.  Iterate until the end 999.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">v0</span>() -&gt; <span style="color:#66d9ef">i32</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> res <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> j <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">let</span> prod <span style="color:#f92672">=</span> i <span style="color:#f92672">*</span> j;
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> is_palindromic_v1(prod) <span style="color:#f92672">&amp;&amp;</span> prod <span style="color:#f92672">&gt;</span> res {
</span></span><span style="display:flex;"><span>                res <span style="color:#f92672">=</span> prod;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> res;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="v1---time-required-7300000ns-14x-speedup-from-v0" class="anchor-link"><a href="#v1---time-required-7300000ns-14x-speedup-from-v0">v1() - time required: 7,300,000ns (~14x speedup from v0())</a></h1>
<p>This isn&rsquo;t really an algorithm change, but it is a slight change in the code that makes a massive performance difference.  We are taking advantage of the <a href="https://en.wikipedia.org/wiki/Short-circuit_evaluation">Short-circuit evaluation</a> present in Rust.  This means that for a given sequence of arguments chained together with certain operators, like <code>&amp;&amp;</code>, the evaluation will take place from left to right and will terminate as soon as possible.  This prevents the remaining elements in the sequence from being evaluated unnecessarily.  In our case, that makes a big difference since we are iterating through many numbers and therefore would be executing <code>is_palindromic_v1()</code> many times.  Since <code>prod &gt; res</code> has a much lower computational cost than <code>is_palindromic_v1(prod)</code> and since <code>prod &gt; res</code> happens sufficiently frequently, this cuts down runtime by a factor of 14.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// v1(): FUN FACT - Rust has short-circuit evaluation.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">v1</span>() -&gt; <span style="color:#66d9ef">i32</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> res <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> j <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">let</span> prod <span style="color:#f92672">=</span> i <span style="color:#f92672">*</span> j;
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Note that this order changed.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#75715e">// Consequently, the right-hand side of the &amp;&amp; is only evaluated if needed.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#75715e">// This is important since string casting and reversing is so slow and the search
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#75715e">// space is so large.  Many languages have short-circuit/lazy evaluation.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#75715e">// This matters less as we start restricting the search space.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#66d9ef">if</span> prod <span style="color:#f92672">&gt;</span> res <span style="color:#f92672">&amp;&amp;</span> is_palindromic_v1(prod) {
</span></span><span style="display:flex;"><span>                res <span style="color:#f92672">=</span> prod;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> res;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="v2---time-required-1800000ns-57x-speedup-from-v0" class="anchor-link"><a href="#v2---time-required-1800000ns-57x-speedup-from-v0">v2() - time required: ~1,800,000ns (~57x speedup from v0())</a></h1>
<p>If you think about it, starting at the lower end of the range and iterating all the way to the higher end does not make very much sense when looking for the largest product.  The chances that the largest product will come from the lower end of the range are very small, so we should start the iteration from the large numbers and work our way down instead.  This results in a much smaller search space since we break out as soon as we find the large palindromic number.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// v2(): Start from the biggest numbers, which makes a lot more sense.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">v2</span>() -&gt; <span style="color:#66d9ef">i32</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> res <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#66d9ef">in</span> (<span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span>).rev() {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> j <span style="color:#66d9ef">in</span> (<span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span>).rev() {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">let</span> prod <span style="color:#f92672">=</span> i <span style="color:#f92672">*</span> j;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> prod <span style="color:#f92672">&gt;</span> res <span style="color:#f92672">&amp;&amp;</span> is_palindromic_v1(prod) {
</span></span><span style="display:flex;"><span>                res <span style="color:#f92672">=</span> prod;
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> res;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="v3---time-required-1050000ns-97x-speedup-from-v0" class="anchor-link"><a href="#v3---time-required-1050000ns-97x-speedup-from-v0">v3() - time required: ~1,050,000ns (~97x speedup from v0())</a></h1>
<p>Now we start to take advantage of some convenient math.  Since we are multiplying two numbers, and multiplication is a <a href="https://en.wikipedia.org/wiki/Transitive_relation">commutative binary operation</a>, we know that we do not need to check <code>p * q</code> and <code>q * p</code> since they are the same.  So if we get to a point in the evaluation where our product is less than the result we would currently return then we can also skip checking any smaller numbers that would come after that on the inner loop.  This additional restriction of the search space gives us even more speedup.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// v3(): Now stop if result is greater than current product.  If you
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// are multiplying and the product is smaller than the current number, you won&#39;t be
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// able to get around the fact that p * q = q * p, so you can stop.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">v3</span>() -&gt; <span style="color:#66d9ef">i32</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> res <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#66d9ef">in</span> (<span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span>).rev() {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> j <span style="color:#66d9ef">in</span> (<span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span>).rev() {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">let</span> prod <span style="color:#f92672">=</span> i <span style="color:#f92672">*</span> j;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> prod <span style="color:#f92672">&gt;</span> res <span style="color:#f92672">&amp;&amp;</span> is_palindromic_v1(prod) {
</span></span><span style="display:flex;"><span>                res <span style="color:#f92672">=</span> prod;
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>            } <span style="color:#66d9ef">else</span> <span style="color:#66d9ef">if</span> res <span style="color:#f92672">&gt;</span> prod {
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> res;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="v4---time-required-195000ns-517x-speedup-from-v0" class="anchor-link"><a href="#v4---time-required-195000ns-517x-speedup-from-v0">v4() - time required: ~195,000ns (~517x speedup from v0())</a></h1>
<p>Now we can reduce search space a little more by examining the general shape of our palindromic number in question, and doing some factoring.  This leads us to the conclusion that we don&rsquo;t need to check every factor, but only cases where one of the factors is divisible by 11.  For details, see the code comment below.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// v4(): Note that the number is probably 6 digits, i.e. abccba = p * q where each letter is some number between 1 and 9
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// then we can rewrite as a * 100000 + b * 10000 + c * 1000 + c * 100 + b * 10 + a * 1 = p * q
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// which we can rewrite as a * 100001 + b * 10010 + c * 1100 = p * q
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// which can be factored to 11 * (a * 9091 + b * 910 + c * 100) = p * q
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// therefore p * q must be divisible by 11
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// therefore either p or q must be divisible by 11.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Since p or q must be divisible by 11, just start the iteration at 990 because it is
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// the largest possible number in the given range that is also divisible by 11 and
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// work our way down in steps of 11.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">v4</span>() -&gt; <span style="color:#66d9ef">i32</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> res <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#66d9ef">in</span> (<span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">990</span>).rev().step_by(<span style="color:#ae81ff">11</span>) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> j <span style="color:#66d9ef">in</span> (<span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span>).rev() {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">let</span> prod <span style="color:#f92672">=</span> i <span style="color:#f92672">*</span> j;
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> prod <span style="color:#f92672">&gt;</span> res <span style="color:#f92672">&amp;&amp;</span> is_palindromic_v1(prod) {
</span></span><span style="display:flex;"><span>                res <span style="color:#f92672">=</span> prod;
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>            } <span style="color:#66d9ef">else</span> <span style="color:#66d9ef">if</span> res <span style="color:#f92672">&gt;</span> prod {
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> res;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="aside-finding-palindromic-integers" class="anchor-link"><a href="#aside-finding-palindromic-integers">Aside: finding palindromic integers</a></h1>
<p>Our naive helper function for checking palindromic integers is convenient but inefficient.</p>
<p>It has to cast our integer to a string, reverse that string to make a new string, and then compare that to another string-casted version of our original integer.</p>
<p>Fortunately, there is a much faster way to determine if an integer is palindromic.  We can just continually divide the original number by 10 and append the remainder on the right side of a new number each time to construct the reverse of the original number.  If the new number and the original number match, then the number is palindromic.</p>
<p>This version is a ~16x speedup over the version that uses string reversal and comparison.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// is_palindromic_v2() will build up a new number `reverse` by shifting `reverse` one decimal place
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// and adding the 10s place of the candidate number until no places are left in the candidate
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// number.  In this way, `reverse` is constructed as the sequence of successive tens place numbers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// from the original candidate number.  This version is ~16x faster than is_palindromic_v1().
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">is_palindromic_v2</span>(i: <span style="color:#66d9ef">i32</span>) -&gt; <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> reversed <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> number <span style="color:#f92672">=</span> i;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> number <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>        reversed <span style="color:#f92672">=</span> reversed <span style="color:#f92672">*</span> <span style="color:#ae81ff">10</span> <span style="color:#f92672">+</span> number <span style="color:#f92672">%</span> <span style="color:#ae81ff">10</span>;
</span></span><span style="display:flex;"><span>        number <span style="color:#f92672">=</span> number <span style="color:#f92672">/</span> <span style="color:#ae81ff">10</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> reversed <span style="color:#f92672">==</span> i <span style="color:#f92672">||</span> i <span style="color:#f92672">==</span> number <span style="color:#f92672">/</span> <span style="color:#ae81ff">10</span>;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="v5---time-required-13000ns-8000x-speedup-from-v0" class="anchor-link"><a href="#v5---time-required-13000ns-8000x-speedup-from-v0">v5() - time required: ~13,000ns (~8000x speedup from v0())</a></h1>
<p>This version loops 1627 times, a ~500x reduction from <code>v0()</code> and <code>v1()</code>.  The ~500x overall reduction in search space, the short-circuit evaluation change, plus the ~16x reduction due to the improved method of palindromic number checking is what gets us to the ~8000x reduction relative to the initial version.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// v5(): Get rid of the slow string reversing and use the numerical palindrome helper function.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">v5</span>() -&gt; <span style="color:#66d9ef">i32</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> res <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#66d9ef">in</span> (<span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">990</span>).rev().step_by(<span style="color:#ae81ff">11</span>) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> j <span style="color:#66d9ef">in</span> (<span style="color:#ae81ff">100</span><span style="color:#f92672">..=</span><span style="color:#ae81ff">999</span>).rev() {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">let</span> prod <span style="color:#f92672">=</span> i <span style="color:#f92672">*</span> j;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> prod <span style="color:#f92672">&gt;</span> res <span style="color:#f92672">&amp;&amp;</span> is_palindromic_v2(prod) {
</span></span><span style="display:flex;"><span>                res <span style="color:#f92672">=</span> prod;
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>            } <span style="color:#66d9ef">else</span> <span style="color:#66d9ef">if</span> res <span style="color:#f92672">&gt;</span> prod {
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> res;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="summary" class="anchor-link"><a href="#summary">Summary</a></h1>
<p>While there are still some performance gains likely to be had, they would probably be nominal and require extensive effort.  By simply pursuing our general problem solving strategy of reducing the search space, combined with a couple of domain knowledge improvements in the form of taking advantage of short-circuit evaluation and a different helper function to check if a number is palindromic, we were able to get an approximately <em>8000x</em> speedup over the original naive version.</p>
 ]]></content:encoded></item><item><title>Digital Maneuver</title><link>https://adamdrake.com/digital-maneuver.html</link><pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate><guid>https://adamdrake.com/digital-maneuver.html</guid><description>&lt;h1 id="bluf-a-newsletter" class="anchor-link">&lt;a href="#bluf-a-newsletter">BLUF: A Newsletter&lt;/a>&lt;/h1>
&lt;p>Digital Maneuver is the ability to quickly build or modify software applications or systems in order to gain a decisive advantage over a competitor. I&amp;rsquo;ve spent decades helping organizations increase their digital maneuverability and have recently created the &lt;a href="https://digitalmaneuver.com">Digital Maneuver newsletter&lt;/a> in order to distribute some of these ideas and other curated content to people who are interested in achieving that in their teams. If you want to learn more ways to deliver software faster in your organization, &lt;a href="https://digitalmaneuver.com">sign up here&lt;/a>.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="bluf-a-newsletter" class="anchor-link"><a href="#bluf-a-newsletter">BLUF: A Newsletter</a></h1>
<p>Digital Maneuver is the ability to quickly build or modify software applications or systems in order to gain a decisive advantage over a competitor.  I&rsquo;ve spent decades helping organizations increase their digital maneuverability and have recently created the <a href="https://digitalmaneuver.com">Digital Maneuver newsletter</a> in order to distribute some of these ideas and other curated content to people who are interested in achieving that in their teams.  If you want to learn more ways to deliver software faster in your organization, <a href="https://digitalmaneuver.com">sign up here</a>.</p>

<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>As Marc Andreesson wrote back in 2011, <a href="https://a16z.com/2011/08/20/why-software-is-eating-the-world/">Software is Eating the World</a>.  More and more of what we used to do in hardware, or used to do with people, is being done by software.  This means that in order to be effective, any organization, whether private sector or public, tiny tech startup or large defense or intelligence agency, is going to have to become good at adapting to technological change by becoming good at building and deploying software.</p>
<p>What does <em>good</em> mean in this context?  Sun Tzu said that speed is the essence of conflict, and I would extend that to say speed is the essence of competition.  Therefore, I would define being <em>good</em> at software as being able to build and deploy software solutions more quickly than your competitor or adversary, given the same level of quality and reliability.</p>
<p>In addition, software has become more commoditized and easier to build in the last 20 years.  More of what we do in software development now is related to some form of stitching together business process logic and making systems talk to each other rather than implementing some particularly technical thing from scratch.  The rise of open source software over the last 20 years has aided this immensely. Organizations are able to reuse solutions to a variety of subproblems instead of starting from zero every time.</p>
<p>Because it is so much faster and easier to create software to solve problems, much software that is built now is almost throwaway software.  It is easy to create, may solve a small problem or process, and may be disposed of when that process or problem no longer exists.  This means that organizations that have heavy processes relating to software development are at a distinct disadvantage because the process originally designed to reduce waste on exquisite software projects has itself become the primary cost and time driver in those software projects.  These processes have become precisely the thing they were designed to prevent.  This is especially true in government and Department of Defense situations, as referenced by the <a href="https://www.hqmc.marines.mil/Portals/142/Docs/%2038th%20Commandant's%20Planning%20Guidance_2019.pdf">Commandant&rsquo;s Planning Guidance</a> released by General Berger, which specifically calls out the Authority to Operate (ATO) process as a critical problem and risk.</p>
<p>Thankfully, many great thinkers have already pondered the problem of adaptability and agility in a broad sense, especially as it relates to military endeavors.  Thinkers like John Boyd and William Lind have written and spoken at length about the concept of maneuver warfare and how being able to cycle through an Observe-Orient-Decide-Act (OODA) loop faster than your competitor is the decisive advantage.  The same is true not only in the physical world, but in the virtual world as well.  I will refer to this as <em>Digital Maneuver</em>.</p>

<h1 id="digital-maneuver" class="anchor-link"><a href="#digital-maneuver">Digital Maneuver</a></h1>
<p>Digital Maneuver is the ability to quickly build or modify software applications or systems in order to gain a decisive advantage over a competitor.</p>
<p>Framed in this way, Digital Maneuver is not broadly a new concept since every private-sector company understands the importance of being able to innovate and adapt more quickly than the competition.  What is somewhat different is the consideration that techniques and tactics that typically apply to maneuver warfare in physical space are equally applicable when building software for users in cyberspace.</p>
<p>Mission Command is a good example of this.  The same doctrine that encourages military organizations to provide clear intent of leadership and rely on actual doers for determining how to solve a given problem applies just as equally to software development projects.  An equivalent amount of autonomy and empowerment is required for a software development team as is required for a combat team on the ground or in the air.</p>
<p>It may be argued that large organizations like the military know how to do this in the physical world, but in the world of software the tendency of these organizations is to centralize software development teams the same way the Greeks employed their phalanxes, and unsurprisingly, with the same results.  The same organizations that espouse maneuver warfare seem to also be those most eager to repeat the mistakes of the past.</p>
<p>Digital Maneuver requires a highly evolved capacity to issue and execute mission-type orders, because the people who are issuing the orders (almost) never have the understanding to even begin to prescribe the details of execution.  However, many senior leaders do not have a background in software and therefore do not weigh the perspectives of technical experts as high as they must in order to create change in the organization and succeed at delivering software more quickly.</p>
<p><a href="https://www.marines.mil/Portals/1/Publications/MCDP%201-3%20Tactics.pdf">Marine Corps Doctrinal Publication 1-3: Tactics, page 25</a> states very clearly that &ldquo;The first requirement of a commander is to understand the situation.&rdquo;  This is excellent advice in any organizational endeavor.  However, at the moment, there are essentially zero senior leaders in large public-sector organizations that understand how to do software development.  The same is true in many large private-sector organizations (though to a lesser extent due to market forces).  This, however, does not dissuade these leaders from making uninformed decisions about organizational and technology policy based on their intuition.  Further, these senior leaders also do not have any competent staff to advise them appropriately.  In other words, the people least qualified to make technology decisions are the ones tasked with doing it and they tend to underweight advice from outside competent experts.  The onus is on us to demonstrate by small and consistent successes that further trust in and autonomy for technical experts is required.  We must do a better job of leading up.</p>

<h1 id="now-what" class="anchor-link"><a href="#now-what">Now what</a></h1>
<p>The <a href="https://digitalmaneuver.com">Digital Maneuver newsletter</a> will cover a variety of topics with original and curated content.</p>
<p>Things in scope include:</p>
<ul>
<li>What is Digital Span of Control?</li>
<li>Freedom vs. Focus and adding constraints to digital maneuvers and tactics</li>
<li>Offensive and defense operations in cyberspace, and cybersecurity more generally</li>
<li>What does Digital Maneuver look like at the strategic, operational, and tactical levels?</li>
<li>How are private and public-sector organizations improving digital maneuverability?</li>
</ul>

<h1 id="subscribe" class="anchor-link"><a href="#subscribe">Subscribe</a></h1>
<p>If you want to learn more about these and other topics, <a href="https://digitalmaneuver.com">subscribe now</a>.</p>

<h1 id="ps---a-playbook" class="anchor-link"><a href="#ps---a-playbook">P.S. - A playbook</a></h1>
<p>As part of this effort, I have also started creating <a href="https://playbook.digitalmaneuver.com">the Digital Maneuver playbook</a>.  This is open source (CC0 licensed) content on topics or <em>plays</em> that organizations can use to deliver software value to users faster.</p>
 ]]></content:encoded></item><item><title>Developing your AI BS detector (v2)</title><link>https://adamdrake.com/developing-your-ai-bs-detector-v2.html</link><pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate><guid>https://adamdrake.com/developing-your-ai-bs-detector-v2.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>In April 2018 I gave a lecture at an event in Toronto which I titled &lt;a href="https://adamdrake.com/developing-your-ai-bs-detector.html">&lt;em>Developing Your AI BS Detector&lt;/em>.&lt;/a>. That event was designed to be a discussion around &amp;ldquo;Rational AI in the Enterprise&amp;rdquo; and I&amp;rsquo;ve found that since then others have been interested in hosting a version of the lecture as well.&lt;/p>
&lt;p>Recently, I updated the slides a bit and changed the focus of the lecture somewhat to make it more clear and accessible. I had a great opportunity to give version 2 of this lecture to a group organized by Army Futures Command.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>In April 2018 I gave a lecture at an event in Toronto which I titled <a href="https://adamdrake.com/developing-your-ai-bs-detector.html"><em>Developing Your AI BS Detector</em>.</a>.  That event was designed to be a discussion around &ldquo;Rational AI in the Enterprise&rdquo; and I&rsquo;ve found that since then others have been interested in hosting a version of the lecture as well.</p>
<p>Recently, I updated the slides a bit and changed the focus of the lecture somewhat to make it more clear and accessible.  I had a great opportunity to give version 2 of this lecture to a group organized by Army Futures Command.</p>
<p>As I usually do for my lectures, below are some of the slide headings or titles along with an overview of the material I spoke about for that particular slide.</p>
<p>You can also <a href="https://adamdrake.com/static/talks/drake-adam-20190318-afc-developing-your-ai-bs-detector.html">download the slides</a> if you find that helpful.</p>

<h1 id="overview" class="anchor-link"><a href="#overview">Overview</a></h1>
<p>The purpose of the lecture is really to help people understand what kinds of things might be red flags for AI-related projects, and to sharpen their skills at recognizing when AI might be getting thrown around as a manipulation tactic.</p>

<h1 id="definitions" class="anchor-link"><a href="#definitions">Definitions</a></h1>
<ul>
<li>AI is a field of study, not a thing.</li>
<li>AI is computers minimizing a cost function.</li>
</ul>
<p>Or as my own modification of Tesler&rsquo;s Theorem (AI is whatever hasn&rsquo;t been done yet):</p>
<ul>
<li>AI is a set of tools that do not exist <em>YET</em> for solving problems that have not been solved <em>YET</em>.</li>
</ul>
<p>Once one of those conditions are violated, people do not regard the thing as AI anymore.</p>
<p>Before getting too far into a lecture it&rsquo;s important to get all the definitions settled.  AI can  be considered more of a field of study than a thing that is somehow acquired.</p>
<p>If a technology already exists then usually people do not consider that technology to be AI.  Consider things like Siri or some of the various Google products.  Many of those were absolutely considered to be AI only a few years before they became standard products and household names.</p>
<p>As technology is developed, or even the tools to create the technology are developed, we usually cease thinking of the tools and the thing as futuristic and in the case of AI that means we do not consider the thing to be AI once it has been built.</p>
<p>Tesler&rsquo;s theorem states the concept thusly: &ldquo;AI is whatever hasn&rsquo;t been done yet&rdquo;</p>

<h1 id="ai--task-automation" class="anchor-link"><a href="#ai--task-automation">AI = task automation</a></h1>
<p>A good way to think about AI as it relates to the current product and solution offerings is to think in terms of task automation.  In other words, if I had this AI thing, what tasks would I use it for?  What current activities are humans engaging in that, if they had sufficiently advanced technology, the human would no longer do?  This useless work can be called <em>toil</em> and is precisely the kind of activity that AI will be able to largely eliminate.</p>
<p>Some people become very nervous or defensive when considering the task automation aspects of AI, and this is unavoidable.  However, that should not prevent honest people from having honest conversations about the topic of task automation.  The goal, after all, is to automate away portions of work that do not require human effort or intervention, thus freeing the person in question to engage in more important and valuable pursuits.  Those who would be concerned about having their job automated away often do not see themselves as being able to contribute in other ways, or see that their sole value is in their process knowledge.  As a leader, it is your role to help them understand that while they are valuable in their current role, they could also add much more value if the repetitive tasks of their current role no longer required their attention.</p>

<h1 id="red-flags" class="anchor-link"><a href="#red-flags">RED FLAGS</a></h1>
<p>There are a few major red flags when talking about AI.  The top few that I see can be loosely grouped into two main groups: <em>anthropomorphizing</em> and <em>selling</em>.</p>
<ul>
<li>
<p>Anthropomorphizing</p>
<blockquote>
<p>The question of whether Machines Can Think is about as relevant as the questions of whether Submarines Can Swim.  &ndash; Dijkstra, EWD898, 1984</p>
</blockquote>
<p>The quote above from Dijkstra perfectly illustrates the risk in humans anthropomorphizing technology.  By making it seem like the machine is doing something that a human does, we make the machine something to which you can relate, something more exciting, and those who play this horrible trick often use the resulting failures of intuition to swindle non-savvy consumers.</p>
<p>It is much easier for a sales and marketing person for some AI vendor to sell magical technology if they can leave out any real explanation for how the technology works and instead focus on exploiting people&rsquo;s intuitive understanding of concepts like <em>thinking</em> machines and so on.  I once sat in on a pitch from a vendor who was trying to convince people that he had created machine learning systems that exhibited creativity due to him inducing stress and anxiety in the mind of the machine.  All he really did was introduce some random perturbations in the weight vector of his machine learning algorithm.  It was academically criminal, and thankfully I was able to ask probing questions in the sales pitch that revealed the vendor for the fraud that he was.</p>
<p>If someone is anthropomorphizing the technology, run away.  They are probably lying to you.</p>
</li>
<li>
<p>Selling</p>
<p>Consider an Anomaly Detection AI that someone is trying to get you to purchase in order to solve your particular problem.  They tell you that it is a 100% proprietary solution that nobody else has (i.e., it is not built on open-source).  They say that the system has been proven in production, developed in the real world and tunable for your application, and it is extremely scalable.  So scalable in fact that it can handle 2.3 billion calculations per node, per day, and can be parallelized across many nodes for even further scalability.</p>
<p>That might sound like a reasonable and interesting sales pitch if you are receiving it from a vendor, or if you are a VC and are getting such a pitch from a potential portfolio company, but the code below satisfies all the criteria listed in the text above.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isFraud</span>(<span style="color:#a6e22e">ccIsForeign</span> <span style="color:#66d9ef">bool</span>, <span style="color:#a6e22e">amount</span> <span style="color:#66d9ef">float64</span>, <span style="color:#a6e22e">transactionsToday</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">ccIsForeign</span> <span style="color:#f92672">&amp;&amp;</span> <span style="color:#a6e22e">amount</span> &gt; <span style="color:#ae81ff">1000</span> <span style="color:#f92672">&amp;&amp;</span> <span style="color:#a6e22e">transactionsToday</span> &gt; <span style="color:#ae81ff">5</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>That code is reasonably similar to a fraud detection system I found in a company I once advised.  You could make an argument that it is an expert/rules-based system, and therefore could be considered a type of AI.  The system also worked rather well, and despite spending millions of a dollars on a data science team in order to try to address the fraud problem by more sophisticated means, they did not find any improvement.</p>
<p>If someone is trying to sell you some kind of advanced AI solution to a problem, it&rsquo;s a good idea to confirm that what they are selling is actually advanced technology.  Even more important, however, is the fact that said technology should actually improve upon the solution currently in place.  Paying money for an expensive and complex solution that performs no better than the current solution is foolish and unnecessary.</p>
</li>
<li>
<p>Cost or proprietary technology</p>
<p>FACTS: State-of-the-art AI/ML frameworks are open source and therefore cost zero dollars, accessing and preparing data is probably 95% (or more) of the work, and there is no cost associated with the technical tools required to do state-of-the-art machine learning.</p>
<p>Therefore, if someone is claiming that they have some kind of magical proprietary technology then they are misleading you for two main reasons.  First, their technology is almost certainly the same open source stuff everyone else is using.  Since the open source systems are the best you can get in most cases, any proprietary solution offers only a marginal improvement over the current freely-available standard if it offers any improvement at all.</p>
<p>Second, and more importantly, even if they have a fantastic machine learning solution they will still need access to the underlying systems and data, which must be connected and cleaned, in order to feed the algorithms themselves.  Herein lies the problem!  Most work in machine learning and data science, from a practical perspective, involves all the janitorial work of acquiring data from multiple sources, cleaning it up, normalizing it, tying together disparate systems and data sets, and so on.  The company selling you the machine learning system is going to make the bulk of their money off of you by charging you to do all of this cleanup and integration work.  In other words, the vendor is going to make their money by being the technological equivalent of a maid.</p>
<p>Don&rsquo;t be swindled by a vendor.  If your systems and data are not set up to appropriately use a system internally anyway, you will not be able to make use of whatever machine learning or AI stuff they are trying to sell you.  Before reaching for AI or machine learning, you will have to get your technological house in order, and there is no need to pay a vendor a disgusting amount of money to attempt to do that for you.  Especially since they will likely fail due to lack of domain knowledge compared to your own staff.</p>
</li>
<li>
<p>Patents</p>
<p>In the realm of technological advancement, patents really do not make much sense.  First of all, you cannot patent an algorithm, so that rules out truly patenting most machine learning or AI approaches.  Second, the top machine learning and AI research is, as mentioned above, free and open source.  Research papers are published, and competition write-ups are created, in order to tell the rest of the research community how the start of the art is evolving.  This information is almost always freely available, to anyone interested to look.</p>
<p>Furthermore, when a system is patented, it becomes public.  In my experience, companies who have interesting approaches to machine learning and AI problems never patent such things for the precise reason that then all of their competitors would also be aware of the approach.  Therefore, the most interesting machine learning and AI applications are usually kept private as trade secrets.</p>
<p>In other words, if something in this field is patented then it is some twist on research that is already available to the public.  Therefore, the only reason to pay the cost of the patent is to try to capitalize on the fact that there is a misunderstanding of the value of a patent among the buyers or users of the technology.</p>
<p>Lastly, a bit of information that is not often well known is that in the larger companies the researchers are paid bonuses for patents that they are able to get granted to the company.  The researcher gets money and something else to put on their resume, the company gets more marketing material to add to their dubious claims of how technologically advanced they are, and the potential customer gets swindled by overpaying for technology that is probably already open source.</p>
<p>If someone is invoking some kind of patent list to support why their solution is valuable, run away.</p>
</li>
</ul>

<h1 id="separating-wheat-from-chaff" class="anchor-link"><a href="#separating-wheat-from-chaff">Separating wheat from chaff</a></h1>
<p>The questions below are part of the set of questions I ask when trying to evaluate if a project team, startup, or other organization is actually doing something interesting in the field of AI and machine learning, or if they are just trying to capitalize on the current hype surrounding the field.</p>

<h2 id="what-specific-problem-are-you-solving" class="anchor-link"><a href="#what-specific-problem-are-you-solving">What specific problem are you solving?</a></h2>
<p>The goal of this question is to understand if they are solving an actual problem, or if they see AI as a solution in search of a problem.  Furthermore, it is an opportunity for the person to demonstrate understanding of the actual organization issue they are trying to address.</p>

<h2 id="what-is-the-most-naive-solution--did-you-try-that" class="anchor-link"><a href="#what-is-the-most-naive-solution--did-you-try-that">What is the most naive solution?  Did you try that?</a></h2>
<p>If the previous question demonstrates an understanding of the business problem and not just someone who is trying to hawk their AI wares, then the next logical question is whether or not they tried the most simple or naive solution to the problem.  Often in business cases, the simple solution is perfectly adequate, cheap, and allows for time and money to be spent on solving other difficult problems that do not lend themselves to the simple solutions.  Verify that the simple solution has been explored and found to be unacceptable before proceeding with more elaborate solutions.</p>

<h2 id="what-about-the-next-most-naive-solution" class="anchor-link"><a href="#what-about-the-next-most-naive-solution">What about the next-most-naive solution?</a></h2>
<p>As above, verify that the simpler solutions have been tried.  You might not be able to do time series forecasting with some linear regression approach, but you might be able to get it done just fine with some basic smoothing methods.</p>

<h2 id="why-is-what-youre-doing-considered-ai" class="anchor-link"><a href="#why-is-what-youre-doing-considered-ai">Why is what you&rsquo;re doing considered AI?</a></h2>
<p>This is a fun question because it serves to sanity check the understanding of the person selling the AI solution.  It refocuses the conversation on the technology, after having talked about the actual business problem for some time, and sets things up for the next question.</p>

<h2 id="are-you-using-a-framework" class="anchor-link"><a href="#are-you-using-a-framework">Are you using a framework?</a></h2>
<p>If so, why is your solution special?
If not, explain why you aren&rsquo;t wasting time.</p>
<p>This question, and the follow up questions above, are something of a trick question.  There is almost no way to answer this question without exposing the fact that most of the state of the art AI stuff is free and open source, and therefore being built with largely the same few frameworks or that the person or organization in question has eschewed the state of the art in order to try to build something proprietary and on their own which probably came at great expense and marginal benefit, if any.</p>

<h1 id="heilmeier-catechism" class="anchor-link"><a href="#heilmeier-catechism">Heilmeier Catechism</a></h1>
<p>As it turns out, these questions were in some sense formulated by George H. Heilmeier, who was the DARPA Director from 1975 to 1977.  The Heilmeier Catechism is as follows.</p>
<ul>
<li>What are you trying to do?  Articulate your objectives using absolutely no jargon.</li>
<li>How is it done today, and what are the limits of the current practice?</li>
<li>What is new in your approach and why do you think it will be successful?</li>
<li>Who cares? If you are successful, what difference will it make?</li>
<li>What are the risks?</li>
<li>How much will it cost?</li>
<li>How long will it take?</li>
<li>What are the mid-term and final &ldquo;exams&rdquo; to check for successful?</li>
</ul>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>There is a lot of hype surrounding the topic of AI at the moment, and unfortunately there are many vendors, project/program managers, and others who are more than happy to attempt to use the current hype as a way to bolster their resumes or bank accounts.</p>
<p>It is critical when evaluating possible AI solutions to problems that pragmatism is maintained as paramount and the focus on the actual problem is not lost.  If that effort is successful, then it is often the case that some kind of AI solution isn&rsquo;t really needed at all.  Rather, a simple solution using known methods that allows the organization to solve the problem adequately and move on to the next problem is almost always the most beneficial.</p>
<p>When someone is trying to sell you AI, <em>be suspicious</em>.</p>
 ]]></content:encoded></item><item><title>Technical is tactical</title><link>https://adamdrake.com/technical-is-tactical.html</link><pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate><guid>https://adamdrake.com/technical-is-tactical.html</guid><description>&lt;h1 id="intro-levels-of-war" class="anchor-link">&lt;a href="#intro-levels-of-war">Intro: levels of war&lt;/a>&lt;/h1>
&lt;p>The US Department of the Army publishes a Field Manual called &lt;em>Operations&lt;/em> (FM 3-0), a doctrinal guide for conducting military operations. In it, three levels of war are described. They are:&lt;/p>
&lt;ol>
&lt;li>The strategic level (such as national policy)&lt;/li>
&lt;li>The operational level (such as campaigns and major operations)&lt;/li>
&lt;li>The tactical level (including battles and small-unit actions)&lt;/li>
&lt;/ol>
&lt;p>At the strategic level, national interests and policy inform national and multinational military objectives, and global plans for achieving those objectives are developed.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="intro-levels-of-war" class="anchor-link"><a href="#intro-levels-of-war">Intro: levels of war</a></h1>
<p>The US Department of the Army publishes a Field Manual called <em>Operations</em> (FM 3-0), a doctrinal guide for conducting military operations. In it, three levels of war are described. They are:</p>
<ol>
<li>The strategic level (such as national policy)</li>
<li>The operational level (such as campaigns and major operations)</li>
<li>The tactical level (including battles and small-unit actions)</li>
</ol>
<p>At the strategic level, national interests and policy inform national and multinational military objectives, and global plans for achieving those objectives are developed.</p>
<p>The operational level consists of major operations conducted by commanders in order to achieve the strategic objectives. These commanders determine how and when to position and employ their resources in order to create favourable conditions for tactical actions.</p>
<p>At the tactical level, short-term actions with defined goals are conducted in order to support and bring about the objectives of the major operation.</p>
<p>Each level is meant to clarify the relationship between strategy, operational approach, and tactical actions in military operations. They describe levels of responsibility and planning when it comes to solving large-scale problems, and though each has a very different scope, it is inextricably linked with the others.</p>

<h1 id="levels-of-business" class="anchor-link"><a href="#levels-of-business">Levels of business</a></h1>
<p>Military operations have many parallels to running a company, especially at the operational and tactical levels.</p>
<p>Like campaign commanders, those responsible for the operational aspects of a company are tasked with creating favourable conditions for the company&rsquo;s success. Company operations center on the concepts of people and process.</p>
<p><em>People</em> can be thought of as the aggregation and interaction of individuals, such as with organizational structure. The framework governing this aggregation and the protocol for these interactions is what we call <em>process</em>, such as the interactions between organizational components of a broader organization.</p>
<p>The tactical actions of a company, by contrast, center on day-to-day actions that support the organization&rsquo;s larger goals or seek to remove pain points. Tactical actions seem urgent, and are at front of mind of those working in the company. They are a vital part of furthering long-term success, however, they do not in themselves achieve a company&rsquo;s larger operational objectives.</p>
<p>These different levels of approaching problems are important for those in decision-making roles to keep in mind. Often, when a company encounters problems, management or technical leaders will try and address the painful symptoms, rather than solve the underlying issue. All too often, it&rsquo;s easy to scapegoat technology and tooling, and squander time on its selection and/or modification. Either the inefficacy of present tooling or the perceived lack of any tooling at all is blamed as the cause of the problem, and the company is easily seduced by the lure of implementing shiny new technological &ldquo;solutions.&rdquo;</p>
<p>In reality, the problems companies typically face are almost never technical.</p>
<p>Most identified pain points are not the actual problem, but symptoms of the underlying issue. The true problems are often rooted in people and process, not technology.</p>
<p>Attempting to address problems rooted in people and process with technical solutions is attempting to solve an organizational issue with a tactical solution. At best, a tactical maneuver may remove short-term pain, but overall has a minimal and temporary positive effect on organizational improvement. It does little to advance mid-term and long-term strategic objectives.</p>
<p>In other words, technical is tactical.</p>

<h1 id="understanding-the-costs-involved" class="anchor-link"><a href="#understanding-the-costs-involved">Understanding the costs involved</a></h1>
<p>A band-aid technical solution can seem to be an appealing, sometimes necessary, quick fix.  The lure of a quick technical solution is especially strong when it involves sexy new technologies or tools. Often, however, objective costs for implementing these &ldquo;quick&rdquo; fixes are not properly considered and weighed against the alleged benefits.</p>
<p>Technical solutions present a variety of costs in order to select, configure, customize, and implement them. Besides initial purchase or development, companies must consider costs associated with user training, software maintenance, and support for troubleshooting any issues that may arise. When long-term maintenance costs are considered alongside short-term acquisition costs, the ticket price of a new technical band-aid may be far too high, making it a less appealing solution when it comes to treating a symptom.</p>

<h1 id="avoiding-the-firefighting-culture" class="anchor-link"><a href="#avoiding-the-firefighting-culture">Avoiding the firefighting culture</a></h1>
<p>To try and solve pain points rooted in people and process with technological band-aids is to constantly pursue a (often short-sighted) local optima. Colloquially, this is often known as <em>firefighting</em>. Companies that aren&rsquo;t aware of this pitfall unfortunately develop a firefighting culture, and spend their resources putting out small fires instead of solving the underlying issues. Technical teams that engage in this behavior may seem very busy, and may even be very good at putting out the fires that arise. However, they are not able to be very productive as they end up solving the same problems over and over. They&rsquo;ve mastered the tactical solutions to their technical problems, but fail to consider the broader, operational, point of view.</p>
<p>I saw a clear example of this situation years ago. It affected a reporting and data access group within a company I was advising. The team had very high levels of proficiency with a tool that allowed them to provide reports via web interface to others in the business.</p>
<p>Since this team was so effective at building reports, they built many hundreds of them. These reports depended on a specific database structure, and for certain pieces of data to be present within that database structure. This dependency was choking technological progress in the company because the software involved could not easily be modified without compromising the reporting system.</p>
<p>The team had become very good at firefighting with their technical solution of building the reports, but as a result were crippling the evolution of the company&rsquo;s underlying data infrastructure. The many hundreds of small, tactical fixes that the team had made created a lot of historical baggage. There had been little consideration for the strategic impacts of the tactical wins.</p>
<p>Upon closer examination of the underlying problems, it became clear that:</p>
<ol>
<li>No monitoring of the report usage logs was being performed</li>
<li>No usage analysis resulting from the above was ever performed</li>
<li>None of the reports had ever been deleted as a result</li>
</ol>
<p>Once the usage history was examined, it became obvious that more than 95% of the reports had not been used in months, and that most of the reports had only been used once, presumably either as a test or by the requestor. Thus it was a straightforward decision to stop producing these useless reports, and instead provide training and access for company employees to examine the relevant data on their own. The data and reporting team could then focus on solving more important business problems, allowing the company to improve its development and feature release capability for its users. By examining the underlying issue, it was possible to fix the organizational problem at its root instead of pursuing band-aid tactical solutions.</p>

<h1 id="finding-the-underlying-problem" class="anchor-link"><a href="#finding-the-underlying-problem">Finding the underlying problem</a></h1>
<p>There are two main ways a company can determine if it is addressing a symptom or the true underlying problem. One is to follow a framework for examining the issue, and the other is to break down a pain point into its constituent parts.</p>

<h2 id="using-a-framework" class="anchor-link"><a href="#using-a-framework">Using a framework</a></h2>
<p>A company can use a framework to identify root causes of problems, such as the <em>5 Whys</em> framework. In this methodology, we examine a problem by answering the question of why it exists. For example,</p>
<p>Q: Why do I have heartburn?
A: Because I had a spicy nachos and whisky for lunch.</p>
<p>To get to the root of the issue, we repeatedly ask why the above answer exists until we reach the root cause. Here is a continuation of our example:</p>
<p>Q: Why did I have spicy chili nachos and whisky for lunch?
A: Because that&rsquo;s all that was available at the nearest restaurant.</p>
<p>Q: Why did I have to get lunch at the nearest restaurant?
A: Because I was short on time and didn&rsquo;t pack a healthy lunch.</p>
<p>Q: Why did I not pack my lunch?
A: Because I snoozed my alarm this morning and I got out of bed later than usual.</p>
<p>Q: Why did I snooze my alarm this morning?
A: Because I stayed up playing video games and went to bed late at night.</p>
<p>In our somewhat contrived but nonetheless familiar example, we&rsquo;ve used the 5 Whys framework to identify the root cause of our heartburn pain point. Now we understand that this pain point can be solved by not staying up too late, getting up on time, and packing a healthy lunch. Furthermore, we have not only identified a likely cause of the heartburn issue, but a likely cause of many other issues as well. By addressing a single underlying cause, we get the solution to many painful symptoms for free.</p>
<p>Ultimately, the methodology is unimportant compared to the company&rsquo;s willingness to recognize the root causes of the issue. Some objectivity is necessary in order to see where effort is being expended on something other than the underlying problem.</p>

<h2 id="breaking-it-down" class="anchor-link"><a href="#breaking-it-down">Breaking it down</a></h2>
<p>It is often possible to break down a pain point into its constituent parts. With this approach, we can determine if we can solve a different or simpler problem to achieve the same benefit.</p>
<p>I once advised a company that was having trouble scaling to handle increased demand on their technical systems for Southeast Asian operations. This trouble manifested in problems with their backend servers when handling API requests. The technical team had informed the company&rsquo;s executives that the performance issues were caused by the programming language used to build the high-traffic portion of their technology platform, and that in order to rewrite large parts of the the system in a new language and fix the issues, a freeze on feature development would be necessary for several months.</p>
<p>Since feature freezes and large system rewrites are almost never a good option from a technical standpoint (because you should <a href="https://adamdrake.com/always-be-shipping.html">Always Be Shipping</a>), it was necessary to break down the issues further and determine if there was a simpler way to achieve a solution. With this in mind, I investigated the overall system architecture to identify individual components that may have been posing scalability problems. I examined each component to identify some common performance-killing design mistakes, and then together with the technical team, we prioritized those areas for modifications.</p>
<p>The work to improve the performance of the problem components took a matter of days to complete, and without any feature freezes or major rewrites in a new programming language. This largely relieved the persistent performance issues. However, this was only the tactical solution to this company&rsquo;s problem.</p>
<p>The real issue in this example was still not addressed - namely, how the technology platform got into such a state of poor performance in the first place. In order to solve this company&rsquo;s pain points at the true root of the problem, I had to further break down its constituent parts.</p>
<p>Unsurprisingly, the real issues were largely organizational. There was a lack of appropriate onboarding and knowledge transfer processes in place when it came to hiring developers, as well as a lack of adequate training on the foundations of performance-focused application and database development. Additionally, there were no adequate processes in place for non-functional or performance testing during feature development.</p>
<p>Through breaking down the problem, we were able to determine that the true cause of the company&rsquo;s issues was rooted in inadequate education and training. Even if the technical team had successfully done a system overhaul in a new programming language, the real cause of the company&rsquo;s technical problems would not have been addressed, and likely would have worsened.</p>
<p>Never hesitate to break down a problem in order to determine if you can solve a different or simpler problem to yield the same (or greater) effect. Some objective examination in this area may help your company to work smart, instead of working hard.</p>

<h1 id="summary" class="anchor-link"><a href="#summary">Summary</a></h1>
<p>If you find yourself in a situation where you are proposing a technical solution to a problem, or someone is proposing a technical solution to you, it is worthwhile to consider whether or not you are solving the actual problem or simply addressing a symptom of a greater underlying issue.  Based on my experience working with organizations of varying sizes, levels of technical maturity, and in different geographical locations, I can say unequivocally that the technical symptoms are almost always trivial to identify and address.  However, that approach is only part of the solution.</p>
<p>A tactical, technical band-aid simply buys you time that you can use to solve the root organizational human problem.  In order to ensure the problem is actually solved, it is necessary to understand the underlying systemic effects that have led to the experience of the painful symptoms.  Hint: the organizational solutions to those root causes are almost always related to improving ineffective leadership capabilities.</p>
<p>If you find yourself on the sending or receiving end of a technical solution, just repeat this mantra: technical is tactical.</p>
 ]]></content:encoded></item><item><title>Novel Results Considered Harmful</title><link>https://adamdrake.com/novel-results-considered-harmful.html</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/novel-results-considered-harmful.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>&lt;a href="https://www.comm.utoronto.ca/~rsadve/">Ravi Adve&lt;/a> from University of Toronto graciously invited me to give a public lecture at the university earlier this summer. I was very grateful for the opportunity.&lt;/p>
&lt;p>The university&amp;rsquo;s facilities were fantastic, and Ravi did a wonderful job organizing everything. The audience was engaging and asked thoughtful questions, and the attendance was much higher than I had anticipated for a Tuesday morning lecture in the middle of summer! There was great representation from multiple departments, including Electrical and Computer Engineering, Computer Science, and Mathematics.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p><a href="https://www.comm.utoronto.ca/~rsadve/">Ravi Adve</a> from University of Toronto graciously invited me to give a public lecture at the university earlier this summer.  I was very grateful for the opportunity.</p>
<p>The university&rsquo;s facilities were fantastic, and Ravi did a wonderful job organizing everything.  The audience was engaging and asked thoughtful questions, and the attendance was much higher than I had anticipated for a Tuesday morning lecture in the middle of summer!  There was great representation from multiple departments, including Electrical and Computer Engineering, Computer Science, and Mathematics.</p>
<p>Many thanks again to Ravi and University of Toronto for hosting me.  Below are some main points from my slides along with brief thoughts on each.</p>
<p>The <a href="/static/talks/DRAKE-adam-20180710-novel-results-considered-harmful.html">slides</a> are also available for download.</p>

<h2 id="goal-of-the-talk" class="anchor-link"><a href="#goal-of-the-talk">Goal of the talk</a></h2>
<p>My primary goal for this lecture was to emphasize the distinction between techniques or developments that are useful, and those that are simply novel.  Additionally, I wanted to pose a question to the audience: what should we do in academic-like environments when results that are novel are valued much more highly than results that are useful?</p>
<p>In order to illustrate this distinction, I started with some definitions, then gave some examples.</p>
<p>Novel results are a requirement for attaining journal publishing, but often useless in cases where business problems need to be solved.  Novelty is also something that can be abused in the form of a novel technology solution that is useful in some specific areas, but is often just a solution searching for a problem (looking at you, blockchain&hellip;).  How to handle this fact is still an open question in my mind.  I would also say that practitioners misunderstand the academic publishing system, leading to the implementation and large-scale deployment of some of these novel results.  This implementation on production systems of such results usually does more harm than good, hence Novel Results Considered Harmful.</p>

<h1 id="ai-vs-ia" class="anchor-link"><a href="#ai-vs-ia">AI vs. IA</a></h1>
<p>There is a huge amount of hype right now surrounding Artificial Intelligence (AI), however, I would advocate placing focus instead on Intelligence Amplification (IA).  The basis of IA is that humans are the focus of systems, and that we should explore ways to make humans more productive by amplifying human intelligence.  Instead of some nebulous definition (colloquially, AI) of a machine engaging in some type of cognition to solve problems, IA takes the form of automation and/or providing access to more information in concrete and measurable steps.</p>
<p>Viewing problem solving through the lens of IA is a great way to add immediate and incremental value to endeavors that humans are engaging in right now.  The best-known example of IA in common use is probably Google.  How much more are you able to accomplish with Google than without it?  Do you consider Google&rsquo;s search product to be AI?  If not, why not?  By developing technology that aids humans in this way, we&rsquo;re able to add business value at a much faster rate, with lower risk.</p>
<p>There&rsquo;s a big difference between no automation and mediocre automation, and comparatively zero difference between mediocre automation and better-than-mediocre automation.  Go for the big gains in human output!</p>

<h1 id="novel-vs-useful" class="anchor-link"><a href="#novel-vs-useful">Novel vs. Useful</a></h1>
<p>Academic journals are the vehicles by which researchers advance their careers.  A general requirement for publication in an academic journal is that the work must contain a <em>novel result</em>, where <em>novel</em> is taken to mean new and interesting.</p>
<p>The problem is that something being new and interesting does not, by itself, mean that the thing is <em>useful</em>.  In terms of solving real-world business problems, the usefulness of an approach or technique matters much more than how new or interesting it is.  In fact, most business problems requiring technical solutions are best solved using techniques that most technologists would consider old and boring.</p>
<p>This misalignment of incentives causes problems for technologists who read academic journals.  It misleads them to think that the novel, state-of-the-art result is the thing they should build.  Instead, technologists should be building the most useful thing possible that solves the problem at hand, under the current time and materials constraints.</p>

<h1 id="douglas-engelbart-and-moad" class="anchor-link"><a href="#douglas-engelbart-and-moad">Douglas Engelbart and MOAD</a></h1>
<p>I like to ask audiences if they know of Douglas Engelbart.  Most people don&rsquo;t, which is unfortunate since his lab was a great example of what can be accomplished with the goal of Intelligence Amplification.  Probably the most notable result of their efforts was the Mother of All Demos (MOAD) which, in a single demonstration, showcased:</p>
<ul>
<li>Windows</li>
<li>Hypertext</li>
<li>Graphics</li>
<li>Video conferencing</li>
<li>The computer mouse</li>
<li>Word Processing</li>
<li>Dynamic file linking</li>
<li>Revision control</li>
<li>Real-time collaborative editing (like Google Docs)</li>
</ul>
<p>&hellip;in <em>1969</em>.</p>
<p>Engelbart&rsquo;s lab and the MOAD are a great example of what happens when we focus on amplifying the intelligence of humans, rather than creating some kind of general machine intelligence.</p>

<h1 id="kaggle-often-novel--rarely-useful" class="anchor-link"><a href="#kaggle-often-novel--rarely-useful">Kaggle: Often novel.  Rarely useful.</a></h1>
<p>Kaggle is a great example of a place where novel results abound, but useful results or approaches are not rewarded.  Some years ago, I worked on a Kaggle competition.  My solution had an accuracy within one or two percentage points of the winning solution.  My standing? I came in at 453rd place.</p>
<p>For reference, my solution was modified logistic regression with improvements as described in Google&rsquo;s paper <a href="https://ai.google/research/pubs/pub41159">&ldquo;Ad Click Prediction: a View from the Trenches&rdquo;</a>.  It had extremely high performance in the range of ~380,000 transactions per second on my laptop.  It&rsquo;s a model that is well understood, and easily deployable on even a modest virtual server.  It was also an online algorithm, so there was very little needed in the way of training time/steps.</p>
<p>By contrast, the winning solution used an ensemble of 20 separate Field-Aware Factorization Machine (FFM) models.  I won&rsquo;t go into the details in this article, but feel free to explore FFMs and ensemble techniques if you like.</p>
<p>Such a difference in solution complexity, in order to achieve an improvement of one or two percentage points, is endemic on platforms like Kaggle.  It&rsquo;s a great place to explore solutions and different problem areas, but it can train people to do nearly the opposite of what they should do if they want to add maximal value to a business.</p>

<h1 id="sorting" class="anchor-link"><a href="#sorting">Sorting</a></h1>
<p>If Google calls you for an interview, they&rsquo;ll probably ask you about a sorting algorithm (probably quicksort) and the time complexity thereof.  Why do they ask about quicksort?  It&rsquo;s certainly useful, but it&rsquo;s not always the best option.  The Linux kernel uses merge sort in the <a href="https://github.com/torvalds/linux/blob/7876320f88802b22d4e2daf7eb027dd14175a0f8/lib/list_sort.c#L88"><code>list_sort</code></a> function for sorting linked lists, for example.</p>
<p>Timsort is one of, if not the, most widely-used sorting algorithms and is essentially a combination of merge sort and insertion sort.  It&rsquo;s extremely useful, but not necessarily novel or academic.  In fact, I don&rsquo;t know that a paper has ever been written on it, though it did incorporate some results from other papers.  While Timsort works well and is thus extremely useful, it might be considered too <em>derivative</em>, and therefore not novel enough, to be a big paper in a prestigious journal.</p>
<p>Even if there has been a publication focusing on Timsort, the fact that it&rsquo;s not commonly known despite its obvious usefulness is interesting.</p>

<h1 id="typical-problems-in-machine-learning" class="anchor-link"><a href="#typical-problems-in-machine-learning">Typical problems in machine learning</a></h1>
<p>Beyond the common grouping of machine learning tasks into areas like classification or regression, there are a few areas where businesses typically apply machine learning techniques:</p>
<ul>
<li>counting (how many sales happened yesterday)</li>
<li>binary classification (e.g., will a user click on this)</li>
<li>time series forecasting (e.g., what is our expected sales, demand, etc.)</li>
<li>customer segmentation (e.g., churn prediction, personas, etc.)</li>
</ul>
<p>In each of these areas, there are well-studied, high-performance, interpretable algorithms that can be used.  These approaches, like logistic regression and online stochastic gradient descent, have extremely high success relative to their difficulty of implementation and support.  Such algorithms are extremely useful.</p>
<p>However, most of the focus these days is on things like deep learning, and AI (whatever people define that to be).  These approaches are more novel.</p>
<p>While deep learning at least has a more specific definition, it suffers from very high training complexity and low interpretability relative to the usefulness of the models generated.  In some cases, deep learning approaches can be very effective and the tradeoffs make sense, but this is not the norm.</p>

<h1 id="scalability-but-at-what-cost" class="anchor-link"><a href="#scalability-but-at-what-cost">Scalability, but at what COST?</a></h1>
<p>Often in academic papers and industry alike, horizontal scalability is touted as a benefit of a given algorithm or system architecture.  This capability to scale horizontally is often used to justify the development of a novel approach to solving a problem.  This is especially true among papers touting a new approach to distributed computation.  However, advocates for distributed approaches to data processing rarely compare their designs and systems with what could easily be achieved by a standard single-threaded solution on one machine.  I&rsquo;ve done similar comparisons in the past, showing that <a href="https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html">Command-line Tools can be 235x Faster than your Hadoop Cluster</a>, or expanding on these thoughts in my lecture <a href="https://adamdrake.com/big-data-small-machine.html">Big Data, Small Machine</a>.</p>
<p>Frank McSherry does a great job of examining the tradeoffs between distributed processing and performance costs in his paper <a href="http://www.frankmcsherry.org/graph/scalability/cost/2015/01/15/COST.html">&ldquo;Scalability!  But at what COST?&rdquo;</a> where COST is an acronym for &ldquo;Configuration that Outperforms a Single Thread.&rdquo;  In many cases, there is NO distributed computational platform (Hadoop, Spark, etc.) that will outperform a simple, single-threaded implementation running on a laptop.  With more voices like Frank&rsquo;s in the data community, we can prevent people from reaching for heavy tooling simply because it&rsquo;s novel.  Heavy tooling costs more, not only for maintenance, but for processing as well, and in many cases is completely unnecessary.  For example, at the time of this article you can spin up an instance on AWS EC2 with 12 TB (yes, Terabytes) of RAM.  Is your working set larger than 12TB?  Is your total data processing volume larger than 12TB?  Do you have more than 12TB of data to deal with in your organization?  Probably not.  If not, why do you need anything distributed?</p>
<p>You could argue that this is simply another way of saying <em>use the right tool for the job</em>, and you&rsquo;d be right.  Yet, it&rsquo;s amazing how many people want to use a different tool just for the novelty of it, instead of deriving similar excitement from coming up with the best solution for the problem at hand.</p>

<h1 id="hogwild" class="anchor-link"><a href="#hogwild">HOGWILD!</a></h1>
<p>As an extension of the point above, consider the paper from Niu, Recht, et al.: <a href="https://people.eecs.berkeley.edu/%7Ebrecht/papers/hogwildTR.pdf">&ldquo;HOGWILD! A Lock-Free Approach to Parallelizing Stochastic Gradient Descent&rdquo;</a>.</p>
<p>I mentioned above that many real-world problems are very amenable to logistic regression and SGD.  Sometimes, people think they need more performance than their LR/SGD approach can provide.  Sometimes they think they need to use a cluster of machines for their ML task.  Interestingly, in some cases, you can achieve an <em>order or magnitude</em> higher performance on a single multicore machine just from a simple change to your code!</p>
<p>I demonstrate this in my lecture <a href="https://adamdrake.com/big-data-small-machine.html">Big Data, Small Machine</a>, wherein a processing rate of 366,000 records per second is achieved on my modest laptop.  It&rsquo;s almost never the case that people need to handle that kind of request volume, even in high-growth startups.</p>
<p>Given that we have great tools and techniques for high-performance data processing that do not require complicated distributed systems, why do people insist on using such data processing frameworks?  My conjecture is that, generally, they simply enjoy the novelty of the tool more than solving the actual problem in the best possible way.  Additionally, blaming the current tooling and claiming that new tooling will help solve the problem may be a way to avoid taking responsibility for the current state of affairs.</p>

<h1 id="application-edge-analytics" class="anchor-link"><a href="#application-edge-analytics">Application: Edge Analytics</a></h1>
<p>In the future, I think edge analytics will become more common due to factors such as data privacy concerns, bandwidth limitations, and processing limitations.  In the latter case, we can benefit a lot by imposing constraints on ourselves for model size, training time, and power usage.</p>
<p>Consider &ldquo;Resource-efficient Machine Learning in 2KB RAM for the Internet of Things&rdquo;, Kunmar et al. 2017.  This might be a paper that nicely combines novelty and usefulness.</p>
<p>I expect a great deal of additional developments in the area of efficient tools and techniques that can allow us to do on-device machine learning.  This will be critical for future developments in edge analytics, and also allow for much better privacy and control when it comes to things like training machine learning models directly on your phone instead of sending data into some cloud service.  This is a very exciting area.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>From a technical perspective, perhaps the most common failure mode I see in the startups I advise is a completely avoidable one.  It&rsquo;s the mistake of over-engineering by implementing novel algorithms and systems encountered in journals, or on the technical blogs of large software companies.  The propagation of these solutions, most of which are wholly inappropriate for the needs of most companies, seems to be largely related to their novelty rather than their usefulness.</p>
<p>This is plain to see in the proliferation of companies that have labeled themselves with <em>AI</em> over the last few years.  These companies are using the ambiguity, novelty, and hopefulness associated with the term in order to try to advance their business interests.  The AI terminology (usually) has nothing to do with the products and services they offer to customers.</p>
<p>Our industry, and especially growth-stage startups therein, need to focus on ways technology can add practical value to the problems that most concern or absorb the time of humans.  Eliminating time sinks is critically important, but under-appreciated, and sits in the shadow of AI-as-marketing-term.</p>
<p>As a better, more practical way to make humans smarter and more productive, let us instead focus on IA: Intelligence Amplification.</p>
 ]]></content:encoded></item><item><title>Always Be Shipping</title><link>https://adamdrake.com/always-be-shipping.html</link><pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/always-be-shipping.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>Sometimes when I&amp;rsquo;m advising startups the topic of a &lt;em>feature freeze&lt;/em> comes up in a variety of contexts. The context I&amp;rsquo;m referring to is one in which technical debt, poor architecture decisions, and other related issues, have accumulated in a system to the point that it has become seemingly unmanageable. The situation has allegedly become so dire that all new development of features for the business must stop in order to dedicate all developer time and energy to cleaning up the mess. This cleaning up process, which the technical staff often referred to as &lt;em>refactoring&lt;/em>, is claimed to require so much effort that no other work can take place.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>Sometimes when I&rsquo;m advising startups the topic of a <em>feature freeze</em> comes up in a variety of contexts.  The context I&rsquo;m referring to is one in which technical debt, poor architecture decisions, and other related issues, have accumulated in a system to the point that it has become seemingly unmanageable.  The situation has allegedly become so dire that all new development of features for the business must stop in order to dedicate all developer time and energy to cleaning up the mess.  This cleaning up process, which the technical staff often referred to as <em>refactoring</em>, is claimed to require so much effort that no other work can take place.</p>
<p>The feature freeze, in this context, is the equivalent of declaring technological bankruptcy.  However, unlike a situation where bankruptcy is declared and an entity is able to renegotiate obligations in order to become stronger, this form of technical bankruptcy almost always leaves the technical leadership with less political capital than they had when they started, not to mention the resulting non-existent level of trust from the business.</p>
<p>A feature freeze is a bad idea.  It doesn&rsquo;t address the root problem of doing development for the business alongside maintenance work for the systems.  It gives the wrong impression of priorities for the business.  For yourself as a technology leader, it creates a deep political hole for you to dig yourself out of.</p>
<p>Therefore, you should always be shipping. You should always be shipping code, features, services, and every metric of value you deliver to the business.  There may be times when more valuable output is produced, and times when the output lessens, but you must Always Be Shipping!</p>

<h1 id="liar-liar-pants-on-fire" class="anchor-link"><a href="#liar-liar-pants-on-fire">Liar liar pants on fire</a></h1>
<p>Usually when a technology group tries to make the case to the business for a freeze on new feature development so they can work on system maintenance, they hold that it&rsquo;s simply not practical to continue developing on the current system.  This is almost always a lie, and the business knows it.  At the very least, if it isn&rsquo;t a conscious lie, it calls into question the judgment and competence of the technology leader advocating for the feature freeze.</p>
<p>The reasoning is pretty straightforward.  In theory, if you left the system alone, it could probably keep doing more or less what it&rsquo;s doing right now with only minimal maintenance.  With that in mind, any additional work on the system has to be split between grooming the current system to make it more maintainable and extensible, or developing new features.  If it is literally impossible to develop new features on the system, it would probably also be impossible to continue operating it since that would mean that 100% of developer time is currently allocated to maintenance alone.  While this can happen, it is extremely rare, by definition, in products and systems recently developed.  They simply haven&rsquo;t reached a stage of maturity where maintenance becomes the primary focus or concern.</p>
<p>Therefore, if you say that no new feature development can take place, chances are that you&rsquo;re lying, or at the very least, giving people the impression that you aren&rsquo;t sufficiently competent to be leading the engineering efforts in your organization.</p>
<p>Instead of claiming that additional features cannot be developed due to maintenance burdens meeting or exceeding 100% of development capacity, which is probably not the case, it would be more advantageous to manage the relationship between your team and the business.  Make it clear to the business that there are times when the team will have higher output, and times when it will have lower output, but progress towards shipping things to customers will always move forward.</p>
<p>Fun note: This is the team-level version of developing a <a href="https://en.wikipedia.org/wiki/Non-blocking_algorithm#Lock-freedom">lock-free algorithm</a> since, although some things might take longer than others, progress is always made.  When you&rsquo;re designing your software development process as an organization, think about it like a lock-free algorithm.</p>

<h1 id="perception-is-reality" class="anchor-link"><a href="#perception-is-reality">Perception is reality</a></h1>
<p>A feature freeze negatively affects the relationship between the technical teams and the business teams of an organization.  During the period in which no business-relevant output is forthcoming from the technology organization, the rest of the business will grow increasingly hostile toward, and will continually question the value provided by, the technology group.  This makes sense because, after all, technical naval-gazing does not generally provide value to the customers and therefore the business.</p>
<p>This perception builds, and the technology leadership keeps defending the lack of features in favor of systems improvement.  However, the situation quickly reaches a point where no amount of systems improvement can undo the perception from the business that the technology group just isn&rsquo;t very productive or useful.  That&rsquo;s a very bad political and cultural situation indeed.</p>
<p>This becomes even more problematic when we consider the effect of things like the <a href="https://en.wikipedia.org/wiki/Availability_heuristic">availability heuristic</a> as a cognitive bias.  This means that people place irrationally high value on recent information when reaching their conclusions, and if the recent information they have in their brain is that the technology team doesn&rsquo;t produce very much output for the business, then that perception is their reality.</p>
<p>What you did for the business a year ago matters little.  What have you done for the business <strong>lately</strong>?</p>

<h1 id="care-and-feeding-of-a-technology-platform" class="anchor-link"><a href="#care-and-feeding-of-a-technology-platform">Care and feeding of a technology platform</a></h1>
<p>Paying off technical debt and keeping things in good order is a result of a culture of responsibility and good development practices.  It is not in any way a result of some singular effort to improve things.</p>
<p>Think of your codebase, platform, module, etc. as a garden.  Gardens require constant attention in order to function optimally.  Weeds have to be removed, seeds planted, crops harvested, and flora and fauna relocated.  Because this happens continuously, it is completely unreasonable to expect, for example, that you can remove weeds from the garden once and they will never return.  Nobody expects that.  It&rsquo;s just preposterous.</p>
<p>Likewise, a codebase is always becoming more chaotic.  I am absolutely convinced that the <a href="https://en.wikipedia.org/wiki/Second_law_of_thermodynamics">Second Law of Thermodynamics</a> applies to software projects.  The entropy of a codebase never decreases!  If you do not invest your energy in keeping the code high-quality, it will devolve into chaos that is progressively more difficult to maintain.</p>
<p>Since this maintenance requires a process, doing a feature freeze to clean up your systems does not fix the actual problem.  Instead, it&rsquo;s necessary to redesign your development process, set expectations, and communicate responsibilities.  Developers, team leads, and architects must understand that they must continuously make small improvements to the platform and perform maintenance efforts.  It isn&rsquo;t something you can do all at once, so it doesn&rsquo;t make sense to try to fix it all at once.</p>

<h1 id="what-do" class="anchor-link"><a href="#what-do">What do?</a></h1>
<p>So what <strong>should</strong> we do in a situation where we have a mass of things to fix in the codebase, and a huge backlog of product features to build?</p>
<p>First, take a good look in the mirror and fix the cultural and process deficiencies that allowed this situation to develop and become problematic in the first place.  If people aren&rsquo;t writing quality code, if the test coverage is insufficient, if code reviews aren&rsquo;t taking place, all of those cultural and process-related problems must first be addressed.  This step does not, in any way, require a freeze on new feature development.  There is no need to inconvenience the business to make this happen.</p>
<p>Second, use these cultural and process changes to produce higher quality code not just for the features currently in development, but also to generally improve the future quality of your team&rsquo;s output.  Add another step to a developer&rsquo;s work wherein they improve a test, or refactor a module or class, or do some other small thing that measurably improves the quality of the code.  This step would not require a feature freeze or inconvenience the business, either.</p>
<p>Just keep improving things as you go.  Fix the process deficiencies and make developers aware that higher quality output is expected and required.</p>

<h1 id="what-not-to-do" class="anchor-link"><a href="#what-not-to-do">What NOT to do</a></h1>
<p>Do not do a complete and one-shot rewrite of any system.  This is almost always a bad idea, it&rsquo;s a nuclear option, and I can&rsquo;t recall ever having seen it succeed with any established system.  If you want to rebuild parts of the system in the process of implementing the cultural and process changes mentioned above, that can work very well (and it&rsquo;s what I typically recommend).  Definitely don&rsquo;t go the route of trying to do a feature freeze in order to do a system rewrite.  It&rsquo;s the worst possible path for all involved.</p>
<p>Most importantly, <strong>do not negotiate feature vs. maintenance development effort percentages!</strong>  It is not advantageous to have this topic come up as a result of touting the new process and culture of the development team to the business.  In fact, you should not discuss your team&rsquo;s new process and culture with the business as some kind of selling point.  Doing so will only result in the question of how much time you are spending on these new quality efforts compared to feature development.  No matter how much time you report, the business will want you to lower it.</p>
<p>The business doesn&rsquo;t understand that time spent on maintenance is not <strong>wasted</strong> time, it is <strong>invested</strong> time.  To them, you are simply taking time away from developing features, and features are what attract and retain customers.  From their perspective, you are moving feature development time that pays off now, to platform investment time which might pay off in the future in some sort of ambiguous way they cannot quantify.  The logic isn&rsquo;t incorrect, but it is an oversimplification.  I&rsquo;ve never seen a business organization that really understands the value of higher quality code.  In almost every case, even if the leaders of the business support efforts to improve code quality, the product owners, scrum masters, or other project whip-crackers will always try to get you to sacrifice quality in order to ship faster.  Quality is your responsibility, because the business types don&rsquo;t get rewarded when quality is high nor punished when it is low.  They get recognized and achieve advancement by shipping things, and the quality issues usually don&rsquo;t turn up until later.  As a technologist, that means you&rsquo;ll be holding the bag for low-quality software what was shipped quickly.</p>
<p>Therefore, avoid rolling out the above changes to culture and process as though they&rsquo;re some kind of new initiative from technology leadership.  Without any kind of grand announcement, the business will start to benefit from faster development speed and lower maintenance issues as the code quality gradually improves.  If you try to tout these initiatives, they will, perhaps paradoxically, be more likely to fail.  Just do the right thing without trying to obtain credit or to use the efforts as a buffer or excuse for not delivering as quickly as the business wants.  Down that path lies much pain.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>More than the fact that it isn&rsquo;t necessary to stop shipping in order to do maintenance work, it&rsquo;s outright detrimental to your system, team, perception as a leader, and your relationship with the business organization. Instead, adopt a process and culture of continuous improvement while continuously shipping, and you&rsquo;ll be supporting the business as well as your team with sustainable, long-term strategies.</p>
<p>Just as with a fruitful garden, your processes and systems require a measured but consistent amount of care and upkeep. Make that upkeep is one focus of your team&rsquo;s efforts rather than bulldozing the garden in a misguided attempt to not spend future time on maintenance.  Not spending time on maintenance is, after all, what got you considering a feature freeze in the first place.</p>
 ]]></content:encoded></item><item><title>Leaders Eat Last</title><link>https://adamdrake.com/leaders-eat-last.html</link><pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/leaders-eat-last.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>When leading teams, one of the most important things to keep in mind is to lead from a perspective of wanting the team to grow and improve in order to achieve a higher goal. The biggest part of that is taking care of the people on the team. This can mean things people may typically think of, like supporting and encouraging someone on your team while they pursue their career goals. It can also mean things people typically don&amp;rsquo;t think of, like firing someone from the team when they aren&amp;rsquo;t performing since you must continue to look out for the team&amp;rsquo;s overall welfare and advancement.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>When leading teams, one of the most important things to keep in mind is to lead from a perspective of wanting the team to grow and improve in order to achieve a higher goal.  The biggest part of that is taking care of the people on the team.  This can mean things people may typically think of, like supporting and encouraging someone on your team while they pursue their career goals.  It can also mean things people typically don&rsquo;t think of, like firing someone from the team when they aren&rsquo;t performing since you must continue to look out for the team&rsquo;s overall welfare and advancement.</p>
<p>It&rsquo;s not unusual for companies to offer to reserve a conference room for me to use as an office and meeting room during a site visit.  While this is a very kind gesture, I always decline such an offer for a wide variety of reasons.</p>
<p>First, conference rooms are always in high demand.  Executives blocking an entire room for an extended period for an external advisor is more than just an administrative task.  It gives the indication that the advisor is more important than the other people who may need that conference room.  This does not serve the purpose of helping the advisor to become accepted by and to rapidly develop a rapport with employees.  It&rsquo;s almost like an auditor were visiting, and that isn&rsquo;t conducive to the kinds of site visits I find most beneficial.</p>
<p>Second, it&rsquo;s simply not practical to expect employees to speak openly in a more formal setting.  It&rsquo;s great for the executives to spread the word that I&rsquo;ll be in the office, but I avoid having them give me any special treatment that wouldn&rsquo;t also be afforded to any employee.  In fact, I typically have all of my introductory discussions with people outside of the office entirely, if it is possible to do so.</p>
<p>The biggest, and arguably most important, reason I decline to have a conference room reserved is that it directly contradicts my leadership philosophy.</p>

<h1 id="put-yourself-before-others" class="anchor-link"><a href="#put-yourself-before-others">Put yourself before others</a></h1>
<p>The term <em>servant leadership</em> gets thrown around a lot these days, but from my observations it&rsquo;s more talked about than acted out.  Some people will go through the motions with selfish intentions, and with predictable results.</p>
<p>If people know that you genuinely have their welfare at heart, and you will do what you can to support their efforts and advancement, that probably does more than anything else to build trust.  You don&rsquo;t have to be right all the time, but if you&rsquo;re knowledgeable about the job and you genuinely look out for people&rsquo;s welfare, they will usually respect, trust, and follow you as a leader.</p>
<p>However, you must really want that kind of situation.  You must <em>walk the walk</em>, so to speak.  You must genuinely want to sacrifice your own comfort for the betterment of the people on the team and the team itself.  You must live this at all times.</p>
<p>I don&rsquo;t mean that you should never seize opportunities to improve yourself if you are a leader.  In fact, far from it!  Improving yourself and your situation may be an ideal way to provide a better environment for the team.  If you have more political capital with management, you can lobby more effectively for budget and raises.  If you are more prominent in groups in your industry, you can attract more business in order to support and grow your team.  But you should ask yourself, objectively, if the benefits of an action are driven more by selfishness or or by a desire to be a better leader for the team.</p>

<h1 id="concrete-examples" class="anchor-link"><a href="#concrete-examples">Concrete Examples</a></h1>
<p>There are many ways you can put yourself before the team, and these are some that I employ or have employed on a regular basis over the years.  The goal of doing these things is not just to be seen doing them in order to make a statement.  The goal is to make sure that your people have what they need, and that you are always allocating resources in a way that most benefits the team and the people on it.  Usually, this allocation means giving little or nothing to yourself.  Your reward is the improvement of the people and the team.</p>
<p>To start with, leaders eat last.  Whenever there is a company function or event, do not stand in line for food.  Do not make your way to the kitchen area when some free-food type of email comes into your inbox.  Let everyone else go first, and you can take what is left (if anything).  If nothing is left, go hungry.  This isn&rsquo;t to say you should not be present at social functions or events where food is served, but if you&rsquo;re at a company function and there&rsquo;s a line, just wait until the line has passed through before you start taking things.  Or, at least wait until the line has finished growing and then you can stand at the back.</p>
<p>Most departments have a fixed budget, if any at all, for conferences and travel.  If you can send someone else to a conference or event instead of going yourself, then do that.  There may be cases where you need to go to conferences in order to increase business or support for the team, and that&rsquo;s fine.  But if you&rsquo;re going to a conference to present some kind of work or result, could it make more sense to send someone from the team to present their results instead?  Who will benefit more from the experience?  Whose career will reap a bigger benefit?  Would you really get more out of presenting the team&rsquo;s work than someone on the team would get from doing the presentation?  Also, allowing someone else to go in your stead is a great way to groom and support potential future leaders of the team.  Don&rsquo;t be selfish with the conference and travel budget.</p>
<p>Does your company offer referrals or recruiting bonuses?  Usually, companies don&rsquo;t pay the referral bonuses to someone hired directly in your department, but you may be entitled to the same referral bonus as any other employee for referring someone who is hired into another department.  If you hire someone from your network (and if you&rsquo;re a senior leader, you probably do this often when working with a company), instead of taking the referral bonus for a new hire, consider asking if you can allocate it to a bonus or bonuses for people on your team.  If not, see if you can use that money in a different way for the betterment of your team.  It could supplement a conference, a training and education budget, or even just fund some team or department events.  Find ways to redirect that referral money away from yourself and towards your team.</p>
<p>Sometimes companies fall on hard times and cash flow becomes an issue.  This is especially true in startups where funding processes may be ongoing.  It may become necessary to choose between keeping the lights on and making payroll.  In this case, consider halting some or all of your salary before having to do the same to a person or people on your team.  If you&rsquo;re a very senior leader, it may be the case that your salary is triple, or more, the average salary of your team.  If that&rsquo;s the case, halting your salary for a period could lead to being able to avoid laying off multiple people from the team.  Furthermore, if you are a leader with no family to support, consider the personal and family situations of the people on your team.  If most of the people on your team have families to support, then who needs the money more?  Lastly, if a temporary reduction in salary isn&rsquo;t an option, make it clear to the leadership of the company that if people have to be laid off, that you should be the first to go before any of your team.  If you&rsquo;ve been doing a good job as a leader, your team is already lean and you&rsquo;ve ensured there is someone who is primed and ready to take your place as a team lead.  If people have to get cut, volunteer to be the first and communicate that desire to higher management.</p>
<p>Most technology departments have some kind of on-call or support system and process in place for critical systems.  If you are a technical person, you should be doing regular on-call shifts just like everyone else.  This assumes, of course, that you have sufficient technical ability to handle any problems that arise and that you wouldn&rsquo;t create more problems for the team than you&rsquo;d solve.  This also gives you a chance to actually live out the policies and procedures for the on-call rotation.  If, as a leader, when you are prescribing and setting policy, you demonstrate that you are willing to roll up your sleeves and experience the results of your process decisions firsthand, the team is far more likely to trust you.</p>
<p>If you have a kitchen area in your company or office, keep the dishes washed and the trash serviced.  I don&rsquo;t care if you have cleaning staff that do this as well.  I don&rsquo;t care if you can rationalize that your time is worth more than their time and therefore you should leave messes for them to clean up because it&rsquo;s a better use of company funds.  That&rsquo;s short-term thinking.  If you did that, you&rsquo;d be building horrible long-term habits, not to mention showing everyone who notices that you don&rsquo;t mind having other people clean up after you and deal with your problems.  Always clean the dishes and take out the trash.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>Even if you think your ideas are great, and even if they are in actuality, it&rsquo;s impossible to get people to trust and follow you if you do not genuinely have their best interests at heart.  The best way to demonstrate that fact is through your actions.</p>
<p>So clean up messes in the kitchen, redirect funding to people on your team, and always, <strong>always</strong> eat last.</p>
 ]]></content:encoded></item><item><title>Artificial Intelligence and The Heilmeier Catechism</title><link>https://adamdrake.com/artificial-intelligence-and-the-heilmeier-catechism.html</link><pubDate>Mon, 11 Jun 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/artificial-intelligence-and-the-heilmeier-catechism.html</guid><description>&lt;p>As part of my advising work, I encounter a plethora of companies. Most of these companies want to begin, improve, or continue initiatives surrounding Artificial Intelligence (AI), Machine Learning, Data Science, Data Analytics, or other such labels applied to a project wherein data is used to accomplish some business objectives.&lt;/p>
&lt;p>The difficulty is that these labels often serve to obfuscate the true nature of the project in order to make it sound more exciting, and to entice funding from those with the power to grant it. This is a travesty of the greatest degree. This practice intentionally belies the point of the project in the first place, which is not to engage in some AI research, but to build something valuable for the customer and therefore the business.&lt;/p></description><content:encoded><![CDATA[ <p>As part of my advising work, I encounter a plethora of companies.  Most of these companies want to begin, improve, or continue initiatives surrounding Artificial Intelligence (AI), Machine Learning, Data Science, Data Analytics, or other such labels applied to a project wherein data is used to accomplish some business objectives.</p>
<p>The difficulty is that these labels often serve to obfuscate the true nature of the project in order to make it sound more exciting, and to entice funding from those with the power to grant it.  This is a travesty of the greatest degree.  This practice intentionally belies the point of the project in the first place, which is not to engage in some AI research, but to build something valuable for the customer and therefore the business.</p>
<p>Therefore, I and other pragmatic data professionals spend a lot of our time doing what is commonly referred to as <em>expectation management</em>.  In other words, I spend a lot of time trying to bring people back to reality and undoing the detrimental effects of other people&rsquo;s lies.</p>
<p>This is part and parcel of doing technology work in a rapidly advancing field.  In fact, having to clean up after this constant assault on opinions by scheisters was a task well handled by George Heilmeier, who ran <a href="https://www.darpa.mil">DARPA</a> from 1975 to 1977.</p>
<p>Heilmeier employed a catechism very similar to the one I use, as outlined in my talk <a href="/developing-your-ai-bs-detector.html">Developing Your AI BS Detector</a>.  In the talk, I define some questions to ask in order to extract the true business value of a proposed AI project or investment.  I could have instead given a lecture on the Heilmeier Catechism.  Let&rsquo;s go over what that is, exactly.</p>

<h1 id="the-heilmeier-catechism" class="anchor-link"><a href="#the-heilmeier-catechism">The Heilmeier Catechism</a></h1>
<p>When Heilmeier was running DARPA, he had to have a way to evaluate research programs that seemed promising and decide which ones should get funding.  In order to do this, he developed a series of questions designed to provide critical information.  These guiding questions are known as the <a href="https://www.darpa.mil/work-with-us/heilmeier-catechism">Heilmeier Catechism</a>.</p>
<blockquote>
<p>DARPA operates on the principle that generating big rewards requires taking big risks. But how does the Agency determine what risks are worth taking?</p>
<p>George H. Heilmeier, a former DARPA director (1975-1977), crafted a set of questions known as the &ldquo;Heilmeier Catechism&rdquo; to help Agency officials think through and evaluate proposed research programs.</p>
<ol>
<li>What are you trying to do? Articulate your objectives using absolutely no jargon.</li>
<li>How is it done today, and what are the limits of current practice?</li>
<li>What is new in your approach and why do you think it will be successful?</li>
<li>Who cares? If you are successful, what difference will it make?</li>
<li>What are the risks?</li>
<li>How much will it cost?</li>
<li>How long will it take?</li>
<li>What are the mid-term and final â€œexamsâ€ to check for success?</li>
</ol>
</blockquote>
<p>Taken together, this set of questions should be very effective in separating wheat from chaff in the calculus of allocating time, money, and people to a certain project or portfolio of projects.  I take some issue with questions 6 and 7 since, by definition, if you&rsquo;re building something new that has not been built before, it is impossible to know with precision how long it will take or how much it will cost.  However, research organizations (and any high-output organization for that matter) have employed Agile-like work practices since the beginning. I&rsquo;m confident, in the modern context, that points 6 and 7 can be evaluated on an ongoing basis.</p>
<p>I think the first 4 questions are critical when evaluating a project that is pitched as having an AI focus.  The reason, as mentioned in my BS Detector article, is that the AI part is usually the <em>least important</em> part of the project.  It&rsquo;s often not even a critical component.  Usually, it&rsquo;s thrown on top purely as an attempt to differentiate from competitors in the funding or business development process.  This is harmful because the inflated expectations resulting from the differentiation must eventually be addressed.</p>
<p>In fact, employing only the first question of the Heilmeier Catechism would likely suffice.  If you&rsquo;re using AI or other Machine Learning jargon to describe what you&rsquo;re doing, or if what you&rsquo;re doing doesn&rsquo;t sound interesting without it, then perhaps you should reconsider what you&rsquo;re doing in the first place.</p>
<p>The main goal of any effort, or to use the German phrasing, the <em>Schwerpunkt</em>, is to build something valuable for customers who are willing to pay for it.  Customers don&rsquo;t care if the thing they&rsquo;re paying for is AI or not.  They just want their problem solved.</p>
<p>In the same vein, if you are considering projects for funding or allocation of people and resources generally, perhaps it&rsquo;ll be helpful to employ some or all of the Heilmeir Catechism.  You may be able to determine who is actually building something amazing, and who is simply putting the proverbial lipstick on a pig.</p>
 ]]></content:encoded></item><item><title>Speak with Confidence</title><link>https://adamdrake.com/speak-with-confidence.html</link><pubDate>Sat, 09 Jun 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/speak-with-confidence.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>When I&amp;rsquo;m asked to spend some time with a startup to help them continue their growth trajectory, by far the most common issues I help to solve are problems relating to leadership. Specifically, I&amp;rsquo;m usually asked by the investors and/or executive team to work very closely with the technology leadership in order to help them improve their output. The best way to improve output is to improve leadership skills.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>When I&rsquo;m asked to spend some time with a startup to help them continue their growth trajectory, by far the most common issues I help to solve are problems relating to leadership.  Specifically, I&rsquo;m usually asked by the investors and/or executive team to work very closely with the technology leadership in order to help them improve their output.  The best way to improve output is to improve leadership skills.</p>
<p>Verbal communication is a topic that frequently needs addressing.  It encompasses a variety of things including tact, the ability to explain technical topics to a non-technical audience, and language barriers when international teams are involved.  However, the one aspect of verbal communication that is likely the easiest to improve is how to <strong>speak with confidence</strong>.  <a href="/on-confidence.html">I&rsquo;ve written about confidence before</a>, but that was in the more general case.  In this article, I&rsquo;ll specifically address speaking with confidence.</p>
<p>If you speak in a way that gives the impression that you are unsure of yourself and meek, then that&rsquo;s almost always what people will believe.  It makes no difference what you say, or how amazing your ideas are.  If you cannot communicate those ideas and intentions clearly, with clarity and confidence, then you will always be subjected to additional scrutiny.  I can only assume, based on my own observations, that if you don&rsquo;t seem confident in what you&rsquo;re saying, you will fail to inspire confidence in others.</p>
<p>With that in mind, I frequently find myself coaching leaders on how to speak more clearly and confidently.  This pays off in so many ways, especially for those who have to give regular status updates or participate in weekly or monthly meetings with other executives and leaders.  Additionally, the difficulty of being able to project confidence through speech seems to be a particularly prevalent trait among technical people.</p>
<p>The good news is that speaking with confidence is a skill that can be <strong>learned</strong>.  It requires practice, but there are a few things you can do in order to dramatically improve the confidence you project when speaking.</p>

<h1 id="know-what-youre-talking-about" class="anchor-link"><a href="#know-what-youre-talking-about">Know what you&rsquo;re talking about</a></h1>
<p>First, know what you&rsquo;re talking about!  Be very precise in your speech, and do not equivocate when you are explaining something or answering questions.</p>
<p>How confidently do you respond to the question &ldquo;What is your name?&rdquo; or &ldquo;What is your date of birth?&rdquo;  Probably very confidently, because you are 100% sure of the factual answer.  While you&rsquo;re not always able to be 100% sure of the facts, and often discussions may involve only opinions, the confidence derived from precise and careful speech is beneficial to apply to speech in general.</p>
<p>Be precise in how you answer technical questions, especially when they are posed by non-technical people.  Non-technical people are already often suspicious of technical answers to questions, since they have no real way to judge the veracity of the response.  Therefore, speak slowly, deliberately, and honestly.  If you don&rsquo;t know something, say that you do not know, but that you can find out.</p>
<p>The same idea can apply to having technical discussions with teams.  If you don&rsquo;t understand something someone is talking about, stop them and say so, and ask them to please explain further.  Counterintuitively, an admission of not knowing and requesting further explanation is, in itself, an act of confidence and will generally be perceived as such.</p>
<p>Be precise.  Know what you&rsquo;re talking about, ask about what you don&rsquo;t understand, and don&rsquo;t talk about what you don&rsquo;t know.</p>

<h1 id="breathe" class="anchor-link"><a href="#breathe">Breathe</a></h1>
<p>Breathing is one of the major problems often had by people who struggle with confident speaking.  Take very deep breaths when you speak.  Ensure that you inhale enough air using your diaphragm in order to project your voice throughout the entire room.</p>
<p>Speak slowly enough so that you can speak calmly.  If you&rsquo;re unable to take full and deep breaths at a leisurely pace, you&rsquo;re probably speaking too quickly.</p>
<p>If you need some additional practice on breathing with your diaphragm, here&rsquo;s an exercise I&rsquo;ve suggested to technical people I&rsquo;ve mentored in the past.</p>
<ol>
<li>Lie down on your back, and place an object with some heft on your stomach (a heavy book will do).</li>
<li>Breathe in such a way that your stomach pushes the object up.</li>
<li>Breathe in as deeply as you can, raising the object as much as you can with your stomach.</li>
</ol>
<p>Practicing in this way for 5 minutes every few days will likely improve your ability to take deep and calm breaths with your diaphragm.</p>

<h1 id="project" class="anchor-link"><a href="#project">Project</a></h1>
<p>Once you are careful about only authoritatively discussing things you really know about, and you have developed your breathing such that you can be consciously aware of taking full and controlled breaths with your diaphragm, the next step is to be able to project your voice into rooms of varying sizes.</p>
<p>This may not seem terribly important, but if people in a spacious conference room can&rsquo;t hear you, they will assume that you simply do not have the capability to speak up and be heard.  In a sense, they&rsquo;re right, since you never trained yourself to do exactly that.  Note that the goal isn&rsquo;t to speak loudly just for the sake of it, or to speak over others, but rather to ensure that you are speaking at a volume that allows everyone in the room to easily hear what you are saying.</p>
<p>An easy fix for improving how well you project your voice is to have conversations with someone in a comically large space.  You&rsquo;ll need a partner to help you practice this one.  I&rsquo;ve used this technique to help people numerous times, and it works almost instantly.  An ideal space is a conference room with collapsable dividing walls that allow the space to be used as larger room.  The exercise is straightforward: you and your practice partner stand on opposite sides of the space, much further apart than you would normally be, and have a conversation.  Get into the practice of taking deep breaths with your diaphragm, and using those full breaths to project your voice to your practice partner.</p>
<p>Most people become comfortable speaking a larger space very quickly with this approach, assuming they don&rsquo;t take themselves too seriously and are actually willing to try it.  If you don&rsquo;t have a large conference room, a long hallway or other big and empty space works just as well.  Just be careful not to disturb anyone with your new and amazingly-powerful voice!</p>

<h1 id="bonus-round-rehearse" class="anchor-link"><a href="#bonus-round-rehearse">Bonus round: Rehearse!</a></h1>
<p>This one sounds obvious, but it&rsquo;s actually rarely done!</p>
<p>If you are being mindful of the topics you&rsquo;re speaking about, and you&rsquo;ve got the breath work down, and you&rsquo;ve learned to project your voice into larger spaces, then you can probably talk about a variety of things in all sorts of settings, and speak with confidence.</p>
<p>However, for those who have to give regular updates to more senior executives and board members, or represent their organization at public events, the added nervousness can often make speaking with confidence more difficult.  In that case, rehearse!</p>
<p>The critical thing about rehearsing is that you can&rsquo;t just run through a lecture or status report in your head.  You have to actually use your voice, and move your mouth, and hear yourself speak.  You have to use all the muscles you&rsquo;d normally use for breathing and speaking.  While visualization is important and useful for other reasons, you can&rsquo;t only imagine giving your lecture in your mind.</p>
<p>You don&rsquo;t need a partner to do this one, although one can be helpful to ensure you&rsquo;re not speaking too quickly and that the points you want to make are clear.</p>
<p>When I&rsquo;m doing this exercise with a leader I&rsquo;m supporting, not only do I have them do it in large room so that they can project, but I also interrupt them, ask questions (sometimes the same ones repeatedly), and do other things that would expose them to the added stress that is typical in a meeting situation.  In other words, I act like a belligerent executive or board member.  The goal is to provide a rehearsal that is more stressful than the actual thing, so that when they present their information in the meeting they can do so very confidently.  This stress inoculation is extremely useful in all contexts, not just for improving speaking, but perhaps that&rsquo;s a topic for another article.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>When you are in a leadership role and are the authority on a variety of topics, having the knowledge is only part of the role.  You also must communicate that knowledge, and interact with people in a way that does not give them the impression that you are unsure of yourself and your direction.  If you are unsure of something, say so, confidently!  Then people will know that even if you don&rsquo;t know what to do, you <strong>know</strong> you don&rsquo;t know what to do.</p>
<p>I&rsquo;ve helped many leaders, especially technology leaders, speak more confidently and it has always improved their leadership presence and ability.  If you have difficulties speaking with confidence, it is almost certainly hampering your abilities to take on a larger leadership role.  So be honest with yourself, take responsibility for your future development, and work on the things you need to improve in order to become a better leader.</p>
 ]]></content:encoded></item><item><title>Don't Categorize, Prioritize!</title><link>https://adamdrake.com/dont-categorize-prioritize.html</link><pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/dont-categorize-prioritize.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>When I begin an advising engagement with a client, one of the first things I try to understand is what their top priorities are as an organization. This seems like an obvious step, but there is a subtle difference between what most people &lt;strong>say&lt;/strong> are priorities, and what they actually &lt;strong>do&lt;/strong> when they think they&amp;rsquo;re setting priorities. This is because people say they &lt;strong>prioritize&lt;/strong>, but they actually &lt;strong>categorize.&lt;/strong>&lt;/p>
&lt;p>When most people think of prioritizing, they group things into categories such as &lt;em>important&lt;/em>, &lt;em>urgent level 1&lt;/em>, &lt;em>urgent level 2&lt;/em>, &lt;em>blocker&lt;/em>, &lt;em>Q3&lt;/em>, and so on. It&amp;rsquo;s likely that they include multiple items in those categories. In other words, they &lt;strong>cluster&lt;/strong> tasks instead of &lt;strong>prioritizing&lt;/strong> tasks.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>When I begin an advising engagement with a client, one of the first things I try to understand is what their top priorities are as an organization.  This seems like an obvious step, but there is a subtle difference between what most people <strong>say</strong> are priorities, and what they actually <strong>do</strong> when they think they&rsquo;re setting priorities.  This is because people say they <strong>prioritize</strong>, but they actually <strong>categorize.</strong></p>
<p>When most people think of prioritizing, they group things into categories such as <em>important</em>, <em>urgent level 1</em>, <em>urgent level 2</em>, <em>blocker</em>, <em>Q3</em>, and so on.  It&rsquo;s likely that they include multiple items in those categories.  In other words, they <strong>cluster</strong> tasks instead of <strong>prioritizing</strong> tasks.</p>
<p>To truly prioritize a set of tasks or initiatives, you assign each one an importance score such that the scores are <a href="https://en.wikipedia.org/wiki/Monotonic_function">monotonic</a>.  The key point here is that no two items can share the same importance.  Another way to consider prioritization is that we are forming a <a href="https://en.wikipedia.org/wiki/Total_order#Strict_total_order">strict total order</a> on the tasks to be completed.</p>
<p>What this means is that no two items can have the same importance.  Ever.</p>
<p>A priortization forms a strict ordering, and can therefore be used as a work queue.  You simply focus on the most important thing until it is completed, and then move on to the next most important thing.  This removes any ambiguity about which objectives need attention in an organization, and enhances unity of effort.</p>
<p>Why is prioritization instead of general categorization so important?  Prioritization provides three major advantages:</p>
<ol>
<li>Clear objectives and importance</li>
<li>Unity of effort</li>
<li>Focus</li>
</ol>
<p>I start emphasizing having a clear order of priorities very early in my engagements.  This helps to both clarify and obtain mutual understanding with my clients, and to start helping them to think in terms of priorities instead of sets of tasks that all must be accomplished.  Most people who don&rsquo;t realize they&rsquo;re not actually prioritizing tasks experience bewilderment and frustration when team performance seems to be lacking.</p>
<p>Executives and other high-level leaders have a lot of difficulty with setting clear priorities because of the abstracted view they have of the work being done.  If you&rsquo;re a leader, you might be responsible for five different teams.  From your perspective, you might then feel you can work on five things in parallel, and thus up to five things can all share the same priority.  This is false, because it assumes there are no dependencies of any kind between the areas of work being done, which is almost never true in practice.</p>
<p>What we&rsquo;re really talking about in this case is a teams-version of Amdahl&rsquo;s law.</p>

<h1 id="amdahls-law-for-leaders" class="anchor-link"><a href="#amdahls-law-for-leaders">Amdahl&rsquo;s law for leaders</a></h1>
<p>Amdahl&rsquo;s law as applied to <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law#Parallel_programs">parallel work</a> allows you to calculate the speedup that can be obtained from paralellizing tasks, instead of doing them one-by-one.  Many people familiar with this concept often still forget that not all tasks are embarrasingly parallel, and therefore you have to account for the dependencies in these calculations.</p>
<p>In other words, you can work on tasks in parallel, but you&rsquo;ll only achieve a speedup on the tasks that are completely isolated from all other tasks.  If you have ten tasks, and three of them are totally independent of all others (including each other), then even having ten teams work on those ten tasks will only enable them to be finished about 40% more quickly!  Too few leaders consider this.</p>
<p>Additionally, having pieces of work that are completely isolated from all other pieces of work is almost never the case in software development.  It&rsquo;s something people have tried to work around with a variety of technical solutions, most recently microservices. (You can read more about my stance on that in, spoiler alert, <a href="https://adamdrake.com/enough-with-the-microservices.html">Enough with the Microservices</a>!)  Microservices usually don&rsquo;t solve problems of dependencies across teams as well as, or in the ways that, people hope.</p>

<h1 id="clear-objectives-and-importance" class="anchor-link"><a href="#clear-objectives-and-importance">Clear objectives and importance</a></h1>
<p>If you want teams to be able to work well together, they have to know which areas of work are more important.  This is covered in more detail in <a href="https://adamdrake.com/three-things-your-people-need-to-know.html">Three Things your People Need To Know</a> and <a href="https://adamdrake.com/command-and-control.html">Command and Control</a>.</p>
<p>Assigning labels or categories to tasks might be useful as an initial clustering step, when there are a large number of things to be done and the ordering among the entire set of items is not yet clear.  Unfortunately, many executives stop after the clustering is complete.  They feel their work is done, but in fact it has only started.  Leaders need to finish the job, and make sure that every task, item, objective, initiative, or place where effort is focused, is clearly ranked among the other possible places to focus effort.  If you do not do this, then as a leader you are not giving people the guidance and context necessary for them to be productive.</p>

<h1 id="unity-of-effort" class="anchor-link"><a href="#unity-of-effort">Unity of effort</a></h1>
<p>When you think in terms of a <strong>queue</strong> (priorities) instead of <strong>buckets</strong> (categories), people immediately understand which things are more important and which are less important.  This is critical in software projects because it is often the case that parts of the system are dependent and therefore cannot be worked on in isolation.  This is related to the concept of <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">Essential Complexity</a> as defined by Fred Brooks in &ldquo;No Silver Bullet&rdquo;.  Speaking of which, you have made &ldquo;No Silver Bullet&rdquo; required reading in your teams, right?</p>
<p>Since it is inevitable that some work will be spread across teams, it is also the case that the teams need to know who is working on the most important thing so that they can subordinate their work if the need arises.  In a high-performing technology department, teams do not exist in vacuums and must support each other.  In order to do this, everyone needs to have a <strong>very</strong> clear understanding of what the most important priority for the company/team is <strong>right now</strong>.  Otherwise, people on a team may not have incentive to stop what they are doing and help another team.</p>
<p>Also, as a preemptive comment, having dependencies between teams is not a demonstration of poor technical leadership.  Having <strong>too much</strong> dependency between teams can be, and we should always seek to minimize such dependencies to the extent which we can, but we cannot rid ourselves of them entirely.</p>
<p>Since dependencies between teams will always exist, and support will always be required, having clear priorities is essential if you want to have unity of effort among your software teams.</p>

<h1 id="focus" class="anchor-link"><a href="#focus">Focus</a></h1>
<p>Especially in the growth-stage companies I typically work with, there is no time to spend working on non-essential features or functionality.  The company and market are growing rapidly, and the development teams are potentially understaffed.  For these and many other reasons, one of the most important commodities that startups have is focus.</p>
<p>If you want people and teams to be focused on company priorities, then those priorities must be set and clearly communicated.  People make many small decisions throughout the day about how to allocate their time and effort.  They also have to constantly decide whether to allocate their effort and attention to what they&rsquo;re currently working on, or drop their current task to handle a request for assistance from their colleague.  These many small decisions tax an individual team member&rsquo;s focus.</p>
<p>If the entire company does not understand the priorities, how the priorities are allocated to the teams, and what part of a particular priority they are working on at that moment, it&rsquo;s difficult or impossible for team members to make a rational decision about where to place their focus.  Priority-driven focus, on the other hand, can dramatically increase a team&rsquo;s output.</p>

<h1 id="common-question-i-have-five-teams-cant-i-have-five-tasks-of-the-same-priority" class="anchor-link"><a href="#common-question-i-have-five-teams-cant-i-have-five-tasks-of-the-same-priority">Common question: I have five teams, can&rsquo;t I have five tasks of the same priority?</a></h1>
<p>In summary, no.  You can work on multiple things at once, but that doesn&rsquo;t mean each one has the same priority.  The point is that one thing <strong>must</strong> be understood to be more important than all others.</p>
<p>Consider the following. If there are two teams working on two different priorities, and they need support from another part of the organization, which one gets the support first?  Clearly it should be the team working on the higher priority objective.  However, as is often the case in struggling startups, all objectives are categorized as <em>important</em> or <em>urgent</em> or <em>high priority</em> and therefore it is literally impossible for supporting teams to distinguish how to allocate their time and energy.</p>
<p>Also, refer back to the section on Amdahl&rsquo;s law above.  Even if you allocated your five objectives to five teams, you won&rsquo;t get the speedup you&rsquo;re hoping for unless all five objectives are completely independent of each other (hint: they never are).</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>When planning work for yourself and your teams, are you really assigning priorities to the work, or are you just grouping things together into categories?  This is a critical difference that a lot of startup leaders don&rsquo;t fully appreciate, and one that absolutely must be addressed as the company is scaling.</p>
<p>Without a clear understanding of what the priorities are, the people in your company and on your team(s) will not be able to prioritize their own work.  This leads to more confusion, slower delivery, and frustration on the part of the employees.</p>
<p>If you want to increase your output and make sure your teams are working together in a mutually-supportive way, you <strong>must</strong> prioritize tasks.  Customers don&rsquo;t care about how many projects you start, or how many you have running in parallel, they only care how many you deliver to <strong>them</strong>.  If you can truly prioritize your work, then, as one of my great mentors <a href="https://twitter.com/mmelas74">Marco Melas</a> is fond of saying, you can &ldquo;Stop starting, and start finishing!&rdquo;</p>
 ]]></content:encoded></item><item><title>Three Things Your People Need To Know</title><link>https://adamdrake.com/three-things-your-people-need-to-know.html</link><pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/three-things-your-people-need-to-know.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>As part of my work with scale-up companies, a critical component of the process I follow during an on-site visit is having interviews and discussions with a variety of people. I have these discussions with everyone at the company, not just the CEO and CTO with whom I most often closely work. People who are lower on the organizational chart often know more than the executive team about what is actually going on in the company. In most cases, they know a great deal more. They have a front-line view, on the ground, every day.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>As part of my work with scale-up companies, a critical component of the process I follow during an on-site visit is having interviews and discussions with a variety of people.  I have these discussions with everyone at the company, not just the CEO and CTO with whom I most often closely work.  People who are lower on the organizational chart often know more than the executive team about what is actually going on in the company.  In most cases, they know a great deal more.  They have a front-line view, on the ground, every day.</p>
<p>When I&rsquo;m engaged by a client, there is only a very limited time to unearth the realities of the current state of the organization&rsquo;s functions so that we can begin making improvements as quickly as possible.  As one client put it, &ldquo;Adam is like an emergency room doctor and world-class athletic coach during his engagements.&rdquo;  When a company knows there&rsquo;s a problem that needs fixing, it&rsquo;s crucial to get to the root of it quickly.</p>
<p>In order to be effective in a limited time, it&rsquo;s critical to talk with the front-line people.  These folks are usually the best way for me to take the pulse of the organization, and especially to see how far removed the understanding of the executive team is from the realities experienced by the broader group.  The bigger the gap between the understanding of the executives and the realities in the teams, the bigger the challenge of developing unity of purpose.  Without unity of purpose, there is no strategic progress.</p>
<p>Here are the three main questions I ask in my discussions in order to assess the severity of this gap.  Since I&rsquo;m an external advisor, I can be forgiven for not knowing these things, and people genuinely try to give me honest and helpful answers.</p>
<ol>
<li>What is the company mission?</li>
<li>How is your team contributing to the mission?</li>
<li>How does the work you&rsquo;re doing today contribute to the mission?</li>
</ol>
<p>As shocking as it might sound, it&rsquo;s very common for me to talk with people at a company who are not able to answer any of these questions.  At best, they often try to answer the first question with some platitude they&rsquo;ve heard from HR or the CEO at the last all-hands meeting.  Even when people do provide answers, they are rarely consistent from one person to another.  This demonstrates a remarkable lack of alignment and unity of purpose among people supposedly working together towards a common goal.</p>
<p>If you, as a leader, want people in the organization to make progress towards objectives in a way that makes them feel valued and increase their loyalty and effectiveness, then you <strong>must</strong> ensure that you are creating an environment where the answers to those three questions are clear, concise, and consistent across your organization.</p>
<p>If you yourself do not know the answers to those three questions, it&rsquo;s high time that you pause and reflect on how well your superiors have communicated things to you.  Moreover, if you don&rsquo;t know answers to questions like how your work supports the overall copmany goals then you should consider that you likely haven&rsquo;t taken the initiative and personal responsibility necessary to ask your superiors what you&rsquo;re supposed to do and why it&rsquo;s important.  If you yourself don&rsquo;t have this information, you should question why anyone else down the organizational chain should have the answers that you do not.  These are useful questions to pose both to yourself and your team.</p>
<p>If you haven&rsquo;t read my article on <a href="https://adamdrake.com/command-and-control.html">Command and Control</a>, you may benefit from taking a little detour to do that.  I&rsquo;ll build upon some of those concepts here.</p>

<h1 id="messaging-and-communication" class="anchor-link"><a href="#messaging-and-communication">Messaging and communication</a></h1>
<p>Before we talk about the three questions specifically, we have to talk about how to frame and communicate missions at various levels.  Thankfully, this work has already been done for us over hundreds of years, most recently and notably in the form of <em>auftragstaktik</em>.  From the <a href="https://adamdrake.com/command-and-control.html">Command and Control article</a>:</p>
<blockquote>
<p>Literally â€œmission tacticsâ€, auftragstaktik is a system for providing direction and vision for achieving objectives. It was originally developed and applied with great success in the Prussian military, an organization renowned for its efficiency, innovativeness, and adaptability. It is such an effective approach that it is still in use today, although in the US and UK itâ€™s now called mission command instead.</p>
<p>Modern startups which reach a scale beyond which a couple of co-founders can manage are always striving for autonomy, innovation, and progress among their teams, and auftragstaktik is a great way to go about that.</p>
</blockquote>
<p>The general idea is that instead of telling people <strong>what</strong> to do, you communicate the <strong>goal</strong> you want to achieve and <strong>why</strong> you want to achieve it.  You also communicate the <strong>minimal set of constraints</strong> that their solution must follow.  Then you leave them, as a team, to tell you <strong>how</strong> they plan to achieve the objective.  That&rsquo;s mission command, in a nutshell.</p>
<p>With this perspective on communication when it comes to planning objectives, let&rsquo;s consider the implications of the three questions and their importance to the broader company mission.</p>

<h1 id="what-is-the-company-mission" class="anchor-link"><a href="#what-is-the-company-mission">What is the company mission?</a></h1>
<p>In order to feel any ownership of their work, people in your organization require a fundamental understanding of the essential reasons for the existence of your company.  While that might sound rather philosophical, it&rsquo;s the right frame of mind to occupy if you&rsquo;ve never precisely formulated your company&rsquo;s mission before.</p>
<p>Your company has no inherent right to survive and thrive.  What sort of concrete contribution is it going to make in order to justify its own continued existence?</p>
<p>If you can come up with a satisfactory answer to that question, then there&rsquo;s a decent chance that answer is your company&rsquo;s mission.  You must formulate this mission statement clearly and concisely.  Everyone in your organization should be able to understand it and commit it to memory.  The longer and more confusing it is, the harder it will be for people to remember.</p>
<p>If people don&rsquo;t know what the company mission is, then by definition they can&rsquo;t know the top-level goal to which their efforts are tied.  Also, a company mission based on a lame business metric like <em>increase shareholder value</em> will never inspire your teams.  I&rsquo;ve said it on numerous occasions but it&rsquo;s worth repeating: <strong>nobody</strong> gets out of bed in the morning, when they&rsquo;re exhausted, to go to work and increase shareholder value.  Nobody.</p>
<p>If you can communicate the company&rsquo;s mission in a clear and concise way, people can keep it in mind at all times.  That leaves no ambiguity about why the company mission is important, and you&rsquo;ll be well on your way to having a high-performing team.</p>

<h1 id="how-is-your-team-contributing-to-the-mission" class="anchor-link"><a href="#how-is-your-team-contributing-to-the-mission">How is your team contributing to the mission?</a></h1>
<p>Once a strong company mission exists, it&rsquo;s time to figure out how each of the subordinate units and teams within the company are going to mutually support each other in order to make progress towards accomplishing the mission.</p>
<p>If the teams themselves don&rsquo;t have a clear understanding of the objectives to achieve in support of the mission, then the employees on the teams will not have a clear understanding of their importance and their role in the overall mission, either.</p>
<p>I have seen some rare cases of a team leader who comes up with their own mission for the team in companies that have a weak or non-existent overall mission. While this is a well-intentioned effort to keep the people on their team engaged and productive, it&rsquo;s a shortsighted solution.  Eventually, team members realize that their goals seem meaningless within the broader organization.  This leads them to optimize their personal growth in their current role, not with the desire to contribute to the organization, but to seek meaning and promotion elsewhere.  Forming a team-level mission in the absence of a company-level one is a stopgap measure, and is really only effective if the team leader uses it to secure some time so that they can work with their direct supervisor(s) on better crafting the overall company mission.</p>
<p>Without a team-level mission, employees will not feel that their personal efforts and investment are tied to the betterment of the broader organization.  As mentioned earlier, the choice of how to this team-level mission is allocated to individuals on the team in collaboration with their team lead.  This gives the team more ownership over their roles and creates investment in the mission.</p>

<h1 id="how-does-the-work-youre-doing-today-contribute-to-the-company-mission" class="anchor-link"><a href="#how-does-the-work-youre-doing-today-contribute-to-the-company-mission">How does the work you&rsquo;re doing today contribute to the company mission?</a></h1>
<p>This is where the rubber really meets the road, so to speak.  This question encompasses many important concepts when it comes to the level of engagement your team members feel.  Does the work you are doing today actually matter?  Why?  If you disappeared right now and didn&rsquo;t do your job, would anybody notice?  What is your existential purpose in this organization?  Why should you invest your limited energy and time in this group?  If people can&rsquo;t really answer these questions with conviction, then their days at the company are numbered.  People need to understand very clearly how they are a part of something bigger than themselves.</p>
<p>If someone is doing work and they don&rsquo;t know why they&rsquo;re doing it, not only will they probably not do a very good job, but they also don&rsquo;t have the context needed in order to consider doing things in a different, possibly better, way.  Your employees encounter hundreds of tiny little decisions and obstacles every day.  If they are to operate autonomously and find their way around those obstacles without constantly requiring guidance from superiors, then they must have the context they need in order to exercise good judgment.  If you never give them that context, they never have the opportunity.  This is a direct cause of a common complaint I hear from managers that their employees &ldquo;do not show initiative.&rdquo;  It&rsquo;s hard to show initiative when it isn&rsquo;t really clear what is to be done.</p>
<p>As a leader, it&rsquo;s absolutely critical that the front-line people understand how their literal daily work influences and contributes to the broader mission.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>The people who often provide the best perspective on the realities of an organization are the people actually on the ground, doing the work.  In the case of technology companies I often advise, that usually means the developers.  Working with systems and writing code on a daily basis gives this group the most valuable perspectives on many issues.</p>
<p>It&rsquo;s true that executives and leaders at various levels are great sources of information when it comes to interpersonal relationships and team dynamics.  However, if I have to find out why systems are unstable, or aren&rsquo;t performing well enough, or features aren&rsquo;t shipping fast enough, or one of many other commonly-reported ailments of a growth-stage startup, then it&rsquo;s imperative for me to talk with people who are knee-deep in the code.  Furthermore, it&rsquo;s imperative to be able to understand, on a deep technical level, what kind of work they&rsquo;re doing.  This aids both in being able to recommend improvements, and in being able to detect when people might be lying, exaggerating, or making excuses to cover up a lack of superior performance.  Without these important conversations, getting to the root of an issue is much more difficult and time consuming.</p>
<p>Ask yourself what the company mission is.  Ask yourself what your team&rsquo;s mission is and how it supports the company mission.  Ask yourself how your work today supports both missions.  If you are able to answer those questions, you are well on your way to being honest about whether or not you know what you&rsquo;re doing as a leader.</p>
<p>Likewise, if you ask your team those three questions and discover that they can&rsquo;t answer them, then you as a leader have some work to do on communication and how you explain and prioritize work.</p>
<p>These three questions are arguably my most important tool in rapidly understanding the workings of an organization, determining the level and severity of gaps in understanding between leadership and front-line team members, and formulating a plan to close those gaps.</p>
<p>Communicate with your people often.  Ask questions of your superiors often.  Always make sure you and every person you are leading knows the answer to these three questions.  They are vital to your organization&rsquo;s success.</p>
 ]]></content:encoded></item><item><title>Scalable Machine Learning with Fully Anonymized Data</title><link>https://adamdrake.com/scalable-machine-learning-with-fully-anonymized-data.html</link><pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/scalable-machine-learning-with-fully-anonymized-data.html</guid><description>&lt;p>&lt;em>Note: This article will likely be revised and expanded before being submitted for review and publication. At the moment it is missing critical sections, that will be added later. If we have suggestions for improvement, please send them to me directly.&lt;/em>&lt;/p>
&lt;h1 id="abstract" class="anchor-link">&lt;a href="#abstract">Abstract&lt;/a>&lt;/h1>
&lt;p>In this article I will discuss the well-known technique of feature hashing, but with the modification of performing the hashing step on the client-side before sending data to a server or daemon performing model training and prediction. By using this approach, we can ensure that the system performing the training cannot have any knowledge of the underlying data being received, since the learning takes place only using the hashed representation of the data. Since the hash values are not reversible, this approach allows for data to be shared across business units and regulatory jurisdictions while maintaining privacy and security. Additionally, this approach has well-documented scalability properties, and in our testing can perform model fitting and classification tasks at a rate of over 350,000 records per second on a commodity laptop.&lt;/p></description><content:encoded><![CDATA[ <p><em>Note: This article will likely be revised and expanded before being submitted for review and publication.  At the moment it is missing critical sections, that will be added later.  If we have suggestions for improvement, please send them to me directly.</em></p>

<h1 id="abstract" class="anchor-link"><a href="#abstract">Abstract</a></h1>
<p>In this article I will discuss the well-known technique of feature hashing, but with the modification of performing the hashing step on the client-side before sending data to a server or daemon performing model training and prediction.  By using this approach, we can ensure that the system performing the training cannot have any knowledge of the underlying data being received, since the learning takes place only using the hashed representation of the data.  Since the hash values are not reversible, this approach allows for data to be shared across business units and regulatory jurisdictions while maintaining privacy and security.  Additionally, this approach has well-documented scalability properties, and in our testing can perform model fitting and classification tasks at a rate of over 350,000 records per second on a commodity laptop.</p>

<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>Sharing data between entities for any reason, including for the purposes of doing machine learning, presents a variety of ethical, organizational, and legal issues.  Depending on the informed consent of the user, producer, or owner of the data, some of the data may not be shareable outside of the unit that has permission to collect it.  Inside an organization there are often a variety of reasons why data cannot be shared between different business units, subsidiaries, or teams.  Lastly, there are often legal frameworks such as the <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=uriserv:OJ.L_.2016.119.01.0001.01.ENG&amp;toc=OJ:L:2016:119:TOC">General Data Protection Regulation</a> (GDPR) in the EU that prevent certain entities from sharing data with others or from sending that data to other countries.  Similarly, in Indonesia, regulations limit and make difficult the <a href="https://uk.practicallaw.thomsonreuters.com/4-583-2387?transitionType=Default&amp;contextData=(sc.Default)&amp;firstPage=true&amp;bhcp=1">transfer of data out of the country</a>.  For this reason, it is necessary to consider methods of performing machine learning in situations where the underlying data cannot be shared or accessed by the party actually training the models.</p>
<p>Consider a company headquarters in the EU, with a subsidiary or affiliate in Indonesia.  The company is quite large and has a centralized Data Science department located in its EU office.  The Indonesia office produces valuable data that must be analyzed and can be used for predictions, but they do not have the staff with the background or requisite skills in machine learning or computing to perform such an analysis.  Due to regulatory constraints, the data on the systems in Indonesia cannot be sent to the existing EU systems for data ingestion and model training.</p>
<p>We start with the realization that entities are often hashing parts of data sets in order to provide some level of protection and compliance, but often this partial hashing is ineffective.  This is due to problems such as data leakage and being able to brute-force original data from partially anonymized data sets.  A memorable example of the latter is the Netflix Prize competition, wherein researchers were able to cross reference non-anonymized portions of data from Netflix with publicly-available data in order to uniquely identify users.  They covered their approach in the paper <a href="https://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf">Robust De-anonymization of Large Sparse Datasets</a>.</p>
<p>The so-called <em>hashing trick</em> is an established way of processing data as part of training a machine learning model.  The typical motivation for using the technique is a reduction in memory requirements or the ability to perform stateless feature extraction.  The commonly cited disadvantages of this approach, namely, that the hashing is not reversible and therefore the model cannot be interpreted by feature values alone, can be turned to an advantage in the case where we do not want any such interpretation to take place at all.  While feature hashing is ideally suited to categorical features, it also empirically works well on continuous features.</p>
<p>In order to accomplish our goal of machine learning on fully anonymized data, we apply the hashing portion of the hashing trick on a separate system from the system ingesting the training examples.  We then build the model and calculate predictions.  The effect of this is that the system processing the data actually knows nothing about it.  This includes zero knowledge of the feature names or label names and what they represent.  The processing system only receives a list of integers and a label of 0 or 1.  By decoupling the hashing step from the training system, we obtain the following benefits:</p>
<ul>
<li>We can produce a model with the same accuracy as if it were trained on non-anonymized data.</li>
<li>We reduce or eliminate the possibility of recovering the underlying data from the hashed training examples.</li>
</ul>

<h1 id="sharing-is-caring" class="anchor-link"><a href="#sharing-is-caring">Sharing is caring</a></h1>
<p>The problem of acquiring data for training machine learning models in a way that fits both ethical and legal standards is not new.  However, recent changes in public perception after scandals and data breaches involving companies like <a href="https://www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.html">Cambridge Analytica and Facebook</a>, <a href="https://www.ftc.gov/equifax-data-breach">Equifax</a>, and others, have caused both individuals and regulatory agencies to examine the problem more closely.</p>
<p>In Europe, this close examination has been going on for an even longer period of time, and has started to have tangible, and many would argue hugely beneficial, effects in the form of the <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=uriserv:OJ.L_.2016.119.01.0001.01.ENG&amp;toc=OJ:L:2016:119:TOC">General Data Protection Regulation</a> (GDPR).</p>
<p>With the growing awareness that collecting and sharing data is perhaps at least as much of a liability as a benefit, more work needs to be done to determine ways to safely share data.  Data must pass between organizational units or regulatory environments in a way that is compatible with data protection legislation and also takes care to protect the privacy of those who supply the data.</p>
<p>This problem of data transfer and sharing can even take place between two different units of the same company.  This was the case for one of my clients who had global offices, including some in Indonesia.  They wanted to have their fraud detection work done in the EU, but could not move data out of their Indonesian subsidiary due to the data regulations in that country.</p>
<p>For reasons such as these, there is critical need for a method of training machine learning models without access to any of the underlying data.</p>

<h1 id="rehashing-old-techniques" class="anchor-link"><a href="#rehashing-old-techniques">Rehashing old techniques</a></h1>

<h2 id="hash-functions-and-feature-hashing" class="anchor-link"><a href="#hash-functions-and-feature-hashing">Hash functions and feature hashing</a></h2>
<p>For our purposes, a <em>hash function</em> is a function that receives input data of varying size and produces output of a fixed size, with the additional properties that the output values are relatively resistant to collisions and computationally difficult to invert.  In other words, if we hash someone&rsquo;s name, we should receive some value that a) isn&rsquo;t likely to be a value we would get from hashing a different name and b) cannot be reversed in order to obtain the name that was supplied as input to the hash function.  Common hash functions include cryptographic hash functions such as MD5, SHA-1, and SHA-256.  Cryptographic hash functions are designed in such a way that it is especially difficult to recover the original data by reversing the hash.  For our purposes, cryptographic hash functions are not required.  While they do have security benefits, they also come with additional computational costs.</p>
<p>As an example of turning a feature name and feature value into an integer representation of the underlying data, we might have a feature in our data like <em>firstName</em> that has a value of <em>Adam</em>.  We can concatenate these two values and hash the result in order to obtain an integer representation of this unique feature name and feature value combination.  This would map something like <em>firstName-Adam</em> to the resulting integer <em>620516</em>.</p>
<p>Now we have a reasonably unique integer representing our particular feature name and value combination.  If we were also using a machine learning model that has a weight vector on a per-feature basis, then we could use this integer as the index to refer to that particular weight in the weight vector. We could then modify weights as appropriate as part of, for example, building a logistic regression model.</p>
<p>Taken together, this technique of applying a hash function to incoming features in order to go directly to their corresponding location in an array of weights is referred to as <em>feature hashing</em> or <em>the hashing trick</em>.</p>
<p>Additionally, since this process can be performed on individual records, and does not depend on any records that come before or after in the data set, it is ideally suited to a process that benefits from stateless feature extraction like Online Stochastic Gradient Descent (OSGD).  Because the feature extraction process is stateless, it takes trivial effort to parallelize, resulting in extremely high-performing systems.  For more detail on performance, see <a href="https://people.eecs.berkeley.edu/%7Ebrecht/papers/hogwildTR.pdf">HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent</a>.</p>
<p>Feature hashing is usually done on the same machine where the model is being trained, and the hashing is often part of the step wherein the weights of the model are updated.  However, feature hashing is a completely discrete step and could be performed on a separate machine before the data is supplied to the machine where the model training is taking place!</p>
<p>Furthermore, as conclusively demonstrated in the paper <a href="https://arxiv.org/abs/0902.2206">Feature Hashing for Large Scale Multitask Learning</a>, even if features are hashed and collisions are not expected, their presence is in most cases negligible on the resulting accuracy of the model, especially in multi-class classification scenarios.  For this reason, using the hashed representation of the data does not result in an appreciable decrease in the effectiveness of our machine learning model.</p>

<h2 id="old-dogs-and-new-tricks" class="anchor-link"><a href="#old-dogs-and-new-tricks">Old dogs and new tricks</a></h2>
<p>Consider the example in the previous section about two business units, Company A and Company B.  Both entities belong to the same company, but exist in different regulatory jurisdictions.  Company A does data collection, but B has all of the analytics expertise and actually builds the models that detect fraud in the data collected by Company A.</p>
<p>By using the approach we outlined above, Company A can simply provide to Company B the hashed representation of the data along with a label like <em>0</em> or <em>1</em> (in the case of a binary classification problem).  This allows Company B to do all the same machine learning work, model training, and so on, but without ever receiving any of the non-anonymized data.</p>
<p>Another way to accomplish the same goal would be for Company B to provide an API that accepts hashed data plus a label indicating its class.  The API request would then be fed to the model for learning.  Additionally, the API can expose an endpoint where Company A can provide only the hashed features and obtain a prediction of the resulting class membership.</p>

<h1 id="related-work" class="anchor-link"><a href="#related-work">Related work</a></h1>
<p>Fully hashing data on the client side is not the only approach to the problem of securely sharing data for use and processing by others.  There are other techniques that can provide better security protections, and still other approaches that do not anonymize the data per se, but rather add specific and small amount of variation to the data so as to make it difficult to attribute to one individual.</p>
<p><a href="https://arxiv.org/abs/1508.06574">Homomorphic Encryption for Statistical Machine Learning</a> is one such promising approach.  In a homomorphic encryption scenario, operations are performed on the data after it has been encrypted and without needing to do any decryption of any kind.  The benefit here is that the data processor never sees any unencrypted data, and the encryption approaches used could be more secure than anonymizing the data with a hash function.  However, the drawback is that performing operations on homomorphically-encrypted data can be very slow.  The linked paper describes one example in which multiplication operations are limited to approximately 50 per second.  Unfortunately, this performance limitation makes the approach unusable at this time.</p>
<p><a href="https://link.springer.com/chapter/10.1007%2F11681878_14">Differential Privacy</a> is another interesting approach to the question of obtaining data in a privacy-friendly way.  In this approach, data is queried from some kind of repository.  The response from the repository has some amount of random noise produced by a chosen distribution.  In this way, the data returned are, in some sense, lower resolution than their original representation.  While differential privacy approaches are an interesting method for making progress on the problem of preserving privacy while still sharing data, they do not fully anonymize the data as does our decoupled hashing approach.</p>
<p>Mohassel and Zhang present an approach in their paper <a href="https://ieeexplore.ieee.org/document/7958569/">SecureML: A System for Scalable Privacy-Preserving Machine Learning</a> that uses a specially-designed communication protocol to share data between two actors.  However, this approach requires coordination between the parties in terms of data processing and availability that our approach does not.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>The problems of sharing data between regulatory frameworks and the ethical use and privacy protection of data provided by users are becoming increasingly common problems in today&rsquo;s technology companies.  By making use of feature hashing techniques and decoupling the hashing and training components of a machine learning system, we can provide hashed, and therefore totally anonymized, data to a third party for the training of machine learning models.  The third party need have no knowledge of what the underlying data is or what it represents, to the great benefit of the privacy and security of our end users.</p>
 ]]></content:encoded></item><item><title>Big Data, Small Machine</title><link>https://adamdrake.com/big-data-small-machine.html</link><pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/big-data-small-machine.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>I was honored to be invited by &lt;a href="https://www.meetup.com/DevTOEvents/events/250716245/">DevTO&lt;/a> to give a talk at their May meetup. The organizers were keen to have someone speak about high-performance machine learning, and I was happy to oblige.&lt;/p>
&lt;p>The general thesis of the talk is that, for the purposes of machine learning, setting up large compute clusters is wholly unnecessary. Furthermore, it should generally be considered harmful as those efforts are extremely time consuming and detract from solving the actual machine learning problem at hand.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>I was honored to be invited by <a href="https://www.meetup.com/DevTOEvents/events/250716245/">DevTO</a> to give a talk at their May meetup.  The organizers were keen to have someone speak about high-performance machine learning, and I was happy to oblige.</p>
<p>The general thesis of the talk is that, for the purposes of machine learning, setting up large compute clusters is wholly unnecessary.  Furthermore, it should generally be considered harmful as those efforts are extremely time consuming and detract from solving the actual machine learning problem at hand.</p>
<p>To illustrate the point, I showed an online learning approach to binary classification problems using logistic regression with adaptive learning rates.  While some might dismiss this approach as too simplistic or ineffective, consider that it is not very different from what Google was (is?) using for some of their online advertising prediction systems.  This was described in the wonderful paper <a href="https://www.eecs.tufts.edu/%7Edsculley/papers/ad-click-prediction.pdf">Ad Click Prediction: a View from the Trenches</a>.</p>
<p>As in previous summaries of my lectures, I&rsquo;ll reference select slides by section header and provide the explanation that went along with the slide, including some elaboration I may not have had time for in the lecture itself.</p>

<h1 id="claims" class="anchor-link"><a href="#claims">Claims</a></h1>
<p>In my lecture I made a few general claims:</p>
<ul>
<li>RAM in machines used to process data is growing more quickly than the data itself</li>
<li>There are many techniques for dealing with so-called <em>Big Data</em> and none of which involve clusters or heavy data infrastructure components like Kafka, Hadoop, Spark, and so on</li>
<li>One machine is fine for machine learning tasks, i.e., actually training ML models</li>
</ul>

<h1 id="step-0-more-ram" class="anchor-link"><a href="#step-0-more-ram">Step 0: More RAM</a></h1>
<p>If you have a data set that is too big to fit into memory, you can consider getting access to more memory.</p>
<p>We know from <a href="https://www.kdnuggets.com/2015/11/big-ram-big-data-size-datasets.html">other articles</a> and surveys done by KDnuggets that the size of data sets people actually analyze seems to be growing at around 20% per year.  Additionally, this data tells us that most analytics professionals deal with data sets that are below 100GB or so in size.</p>
<p>We also know from looking at historical RAM availability on EC2 instances (just as an example) that the yearly increase in RAM on these instances is faster than the 20% yearly increase in data set size.</p>
<table>
  <thead>
      <tr>
          <th>Year</th>
          <th>Type</th>
          <th>RAM (GiB)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>2007</td>
          <td>m1.xlarge</td>
          <td>15</td>
      </tr>
      <tr>
          <td>2009</td>
          <td>m2.4xlarge</td>
          <td>68</td>
      </tr>
      <tr>
          <td>2012</td>
          <td>hs1.8xlarge</td>
          <td>117</td>
      </tr>
      <tr>
          <td>2014</td>
          <td>r3.8xlarge</td>
          <td>244</td>
      </tr>
      <tr>
          <td>2016</td>
          <td>x1.32xlarge</td>
          <td>1952</td>
      </tr>
      <tr>
          <td>2017/8</td>
          <td>x1e.32xlarge</td>
          <td>3904</td>
      </tr>
  </tbody>
</table>
<p>So for a lot of people, a single AWS instance circa 2012 would have been sufficient to perform all the necessary work for a machine learning task.  Nevermind of course, that the currently available high memory instances provide <strong>4TB</strong> of RAM, which is far more than the data set sizes most analytics professionals deal with.</p>
<p>Lastly, note that Tyan makes a motherboard which can currently accomodate 12.3TB of RAM, which is up from 6TB around 2016.</p>
<p>When all this is taken together, most people can do all the analytics and machine learning tasks they need to do on a single machine with adequate memory.  This completely obviates the need for infrastructure like Hadoop, Spark, and so on for training machine learning models (though they may have their place in preprocessing).</p>

<h1 id="step-1-sampling" class="anchor-link"><a href="#step-1-sampling">Step 1: Sampling</a></h1>
<p>Consider though that perhaps you still have too much data to fit into RAM, or you simply want to train your model more quickly with approximately the same level of accuracy.  In that case, just don&rsquo;t use all the available training data!</p>
<p>In the last years, it has somehow become fashionable to completely ignore centuries of mathematical and statistical progress and instead insist that, in order to make a useful model, all data must be analyzed.  This perspective became even more generally accepted in the last decade or so, and especially after Halevy, Norvig, and Periera published <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf">The Unreasonable Effectiveness of Data</a> (PDF).</p>
<p>Truths to having a larger training set notwithstanding, just because a larger data set for training may yield better results does not mean that using the larger training set yields <strong>significantly</strong> better results.  Often, the marginal increase in performance of a machine learning model from adding additional data is just not worth the additional annoyance of having to deal with the more complicated methods and infrastructure components that may be required to use all of the data.</p>
<p>More data might beat better algorithms, as the saying goes, but perhaps not by much.</p>
<p>This problem is particularly clear in the online advertising space and predicting clicks on advertisements.  It is not unusual to display an advertisement 10,000 times in order to achieve just 20 clicks.  In other words, approximately 99.8% of the data set will be views of ads that do not result in a click.</p>
<p>With a data set that has such biased class distribution, you could probably randomly eliminate 90% of the views and still have a similar performance from your classifier.  In other words, if you had 100GB of training data, you would only have to bother with processing 10GB instead.  This of course requires nothing particularly special in terms of hardware, and can be completed on many modern laptops.</p>

<h1 id="what-if-sampling-doesnt-work--try-streaming" class="anchor-link"><a href="#what-if-sampling-doesnt-work--try-streaming">What if sampling doesn&rsquo;t work?  Try streaming!</a></h1>
<p>There might be cases when sampling isn&rsquo;t an option, or won&rsquo;t work for some reason, and the data is too large to fit into RAM.</p>
<p>In other words, we will transform the problem from a batch-based approach of training a model on a set of data to an online-based approach where our model is learning as it receives data from a stream.  Think about it like building a system that takes requests to feed the model learning information, or obtain a prediction, instead of a model that takes in a large chunk of data in order to calculate model weights.  In doing this, we also change from a focus of how much data our model can handle at one time, to how many Requests Per Second (RPS) our system is capable of handling.  Higher RPS means we can handle more data, in less time.</p>
<p>To think in terms of streams with machine learning models, we need three basic things:</p>
<ol>
<li>A data source that can emit requests/events</li>
<li>A method of stateless feature extraction, so that obtaining features doesn&rsquo;t depend on other requests in the (potentially infinite) stream</li>
<li>A machine learning model that supports incremental learning</li>
</ol>

<h2 id="data-source" class="anchor-link"><a href="#data-source">Data Source</a></h2>
<p>If we have a large file, we can simply read it in one record/request at a time.  A simple way of doing this with a generator in Python might look something like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">getRequest</span>(path, numFeatures):
</span></span><span style="display:flex;"><span>    count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, line <span style="color:#f92672">in</span> enumerate(open(path)):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> i <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># do whatever you want at initialization</span>
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span>] <span style="color:#f92672">*</span> numFeatures <span style="color:#75715e"># So we don&#39;t need to create a new x every time</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> t, feat  <span style="color:#f92672">in</span> enumerate(line<span style="color:#f92672">.</span>strip()<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;,&#39;</span>)):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> t <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                y <span style="color:#f92672">=</span> feat <span style="color:#75715e"># assuming first position in request is some kind of label</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># do something with the features</span>
</span></span><span style="display:flex;"><span>                x[m] <span style="color:#f92672">=</span> feat
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">yield</span> (count, x, y)
</span></span></code></pre></div><p>Or alternatively, if we are using Pandas we can simply pass in the <code>chunksize</code> parameter to a method like <code>read_csv()</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>reader <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;blah.csv&#39;</span>, chunksize<span style="color:#f92672">=</span><span style="color:#ae81ff">10000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> chunk <span style="color:#f92672">in</span> reader:
</span></span><span style="display:flex;"><span>    doSomething(chunk)
</span></span></code></pre></div><p>That covers the need to transform a file that is too large to fit into memory into a stream of data we can easily process.</p>

<h2 id="stateless-feature-extraction" class="anchor-link"><a href="#stateless-feature-extraction">Stateless Feature Extraction</a></h2>
<p>Hello, hashing trick!</p>
<p>This slide was a bit difficult to fully explain given the time constraints of the lecture and density of the information.  The short version is that we will convert a request into an array of integers by concatenating each feature name and value in the request, and then taking a hash of that result.</p>
<p>For example, if the feature is <code>firstName</code> and the value is <code>Adam</code> then we would hash <code>firstNameAdam</code> and obtain some number, say <code>18445008</code>.  This number will then serve as the index for that particular feature name/feature value combination in our array of weights in our model.  This allows us to do a few extremely important things in a large-scale/sparse learning scenario:</p>
<ol>
<li>We do not need to know the features in advance, since a feature name/value combination always reliably hashes to the same weight</li>
<li>By deciding how many weights (<code>modelWeights</code>) we want our model to have up front, likely dictated by our RAM constraints, we can control RAM usage very precisely by simply taking the hash modulo the number of weights <code>18445008 % modelWeights</code>.</li>
<li>Since we are not storing any mappings between features and values and so on, we can save a lot of additional RAM.  We can simply adjust weights in the model by going to the resulting index in the weights array directly from the hash.</li>
</ol>
<p>With the above in mind, the <em>hashing trick</em> is a very important and useful tool when data is large but RAM is in tight supply.  This is equally true on smaller systems like embedded devices, which will become increasingly popular as analytics tasks are more distributed.  Embedded devices also typically do not have nearly as much RAM as a large EC2 instance.  If you only have an embedded device with 10MB of RAM to spare, you can simply limit the number of weights in your model accordingly.  It&rsquo;s amazing how accurate a model you can produce if you are using 32 bit floats and have 4MB of memory available.</p>

<h2 id="incremental-learning" class="anchor-link"><a href="#incremental-learning">Incremental Learning</a></h2>
<p>Once we have the stream and the hashing trick on hand (if needed) we can provide the features to our model <code>N</code> request at a time, or even one request at a time, as long as the model is one that supports incremental learning.  There are many such models available in scikit-learn, but here we will just use our own in the form of logistic regression with adaptive learning rates.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Turn the request into a list of hash values</span>
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span>]  <span style="color:#75715e"># 0 is the index of the bias term</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> key, value <span style="color:#f92672">in</span> request<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    index <span style="color:#f92672">=</span> int(value <span style="color:#f92672">+</span> key[<span style="color:#ae81ff">1</span>:], <span style="color:#ae81ff">16</span>) <span style="color:#f92672">%</span> D
</span></span><span style="display:flex;"><span>    x<span style="color:#f92672">.</span>append(index)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get the prediction for the given request (now transformed to hash values)</span>
</span></span><span style="display:flex;"><span>wTx <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> x:  <span style="color:#75715e"># do wTx</span>
</span></span><span style="display:flex;"><span>    wTx <span style="color:#f92672">+=</span> w[i] <span style="color:#75715e"># w[i] * x[i], but if i in x we got x[i] = 1.</span>
</span></span><span style="display:flex;"><span>p <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.</span> <span style="color:#f92672">/</span> (<span style="color:#ae81ff">1.</span> <span style="color:#f92672">+</span> exp(<span style="color:#f92672">-</span>max(min(wTx, <span style="color:#ae81ff">20.</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">20.</span>)))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Update the loss</span>
</span></span><span style="display:flex;"><span>p <span style="color:#f92672">=</span> max(min(p, <span style="color:#ae81ff">1.</span> <span style="color:#f92672">-</span> <span style="color:#ae81ff">10e-12</span>), <span style="color:#ae81ff">10e-12</span>)
</span></span><span style="display:flex;"><span>loss <span style="color:#f92672">+=</span> <span style="color:#f92672">-</span>log(p) <span style="color:#66d9ef">if</span> y <span style="color:#f92672">==</span> <span style="color:#ae81ff">1.</span> <span style="color:#66d9ef">else</span> <span style="color:#f92672">-</span>log(<span style="color:#ae81ff">1.</span> <span style="color:#f92672">-</span> p)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Update the weights</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> x:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># alpha / (sqrt(n) + 1) is the adaptive learning rate heuristic</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># (p - y) * x[i] is the current gradient</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># note that in our case, if i in x then x[i] = 1</span>
</span></span><span style="display:flex;"><span>    w[i] <span style="color:#f92672">-=</span> (p <span style="color:#f92672">-</span> y) <span style="color:#f92672">*</span> alpha <span style="color:#f92672">/</span> (sqrt(n[i]) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1.</span>)
</span></span><span style="display:flex;"><span>    n[i] <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1.</span>
</span></span></code></pre></div><p>To the best of my recollection, this code was originally provided by tinrtgu on the Kaggle forums some years ago, and it&rsquo;s a great example of how to do machine learning with limited RAM.</p>

<h1 id="performance" class="anchor-link"><a href="#performance">Performance</a></h1>

<h2 id="v1" class="anchor-link"><a href="#v1">V1</a></h2>
<p>In testing on my laptop with some old data, I was able to use the above code to train a model at a rate of ~20,000 RPS.  This is respectable, and there are few people who have to deal with online machine learning systems that have to handle more load than that.  However, that&rsquo;s usually the kind of situation that causes companies to contact me for technical help, so I explored further.</p>

<h2 id="v2" class="anchor-link"><a href="#v2">V2</a></h2>
<p>What&rsquo;s the first thing someone should do when CPython isn&rsquo;t fast enough?  Try PyPy!</p>
<p>Simply by running the script with PyPy instead of the regular CPython interpreter, I got a performance increase of 3.5x (74,000 RPS vs 20,000 RPS).</p>
<p>I cannot overemphasize how important this step is if your company uses Python in your data processing activities and things are too slow.  You may be able to speed them up dramatically without making a single modification to your code, thus allowing you to work on other important business problems.  If your Python is too slow, TRY PYPY!</p>

<h2 id="v3" class="anchor-link"><a href="#v3">V3</a></h2>
<p>One problem with Python in these scenarios is that Python is single-threaded by default and therefore will not avail itself of additional processor cores on the machine.  We&rsquo;d really like to use all cores, and just place some locks around the critical weight arrays so as to prevent non-atomic modifications by multiple threads or processes.</p>
<p>However, due to the Global Interpreter Lock (GIL) in CPython, only a single Python <strong>thread</strong> can execute bytecode at any given time.  Because of that, we have to spawn multiple processes using the <code>multiprocessing</code> library.  In this scenario, each process is essentially running its own copy of the Python interpreter.  Then you can do things like use a <code>RawArray</code> from <code>multiprocessing.sharedctypes</code> if you want to have multiple processes operate on a single chunk of memory.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> multiprocessing.sharedctypes <span style="color:#f92672">import</span> RawArray
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> multiprocessing <span style="color:#f92672">import</span> Process
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> random
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">incr</span>(arr, i):
</span></span><span style="display:flex;"><span>    time<span style="color:#f92672">.</span>sleep(random<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">4</span>))
</span></span><span style="display:flex;"><span>    arr[i] <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>    print(arr[:])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>arr <span style="color:#f92672">=</span> RawArray(<span style="color:#e6db74">&#39;d&#39;</span>, <span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>procs <span style="color:#f92672">=</span> [Process(target<span style="color:#f92672">=</span>incr, args<span style="color:#f92672">=</span>(arr,i)) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> procs:
</span></span><span style="display:flex;"><span>    p<span style="color:#f92672">.</span>start()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> procs:
</span></span><span style="display:flex;"><span>    p<span style="color:#f92672">.</span>join()
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;&#39;&#39;</span>
</span></span></code></pre></div><p>In practice, the standard way to handle this would be to place the requests we want to process into a work queue, and then have multiple worker processes pull from the queue and do all the processing tasks from the code in the Incremental Learning section above.  This looks something like the following.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> multiprocessing <span style="color:#f92672">import</span> Queue
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>procs <span style="color:#f92672">=</span> [Process(target<span style="color:#f92672">=</span>worker, args<span style="color:#f92672">=</span>(q, w, n, D, alpha, loss, count,)) \
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">4</span>)]
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> procs:
</span></span><span style="display:flex;"><span>    p<span style="color:#f92672">.</span>start()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> t, row <span style="color:#f92672">in</span> enumerate(DictReader(open(train))):
</span></span><span style="display:flex;"><span>    q<span style="color:#f92672">.</span>put(row)
</span></span></code></pre></div>
<h3 id="bad-news" class="anchor-link"><a href="#bad-news">Bad news&hellip;</a></h3>
<p>Unfortunately, the code above is actually <strong>slower</strong> than the single-threaded version.  Why, you ask?</p>
<p>
<img class="enclosure" src="/static/talks/DRAKE-adam-20180528-devto-python-multiproc-call-graph.png" alt="Call graph"  />
</p>
<p>If we have a look at the call graph above, we can see that we&rsquo;re spending about 64% of the run time waiting to acquire access to the queue.  This is a common issue in multi-threaded programming, and while it could be potentially, partially, ameliorated by doing things like putting more than one request in the queue at a time (i.e., using a mini-batch approach), the fact is that we&rsquo;re having to do a lot of gymnastics to make Python faster at this point.  For such a small program, maybe Python isn&rsquo;t the best tool for the job.</p>

<h2 id="v4---hello-go" class="anchor-link"><a href="#v4---hello-go">V4 - Hello Go!</a></h2>
<p>Thankfully, Go is a pretty straightforward language, and also reasonably fast.  For a program like this, it could be a good fit.  We can easily port the Python version of the code over to Go.  Besides the braces, it looks about the same.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span>  <span style="color:#75715e">// Hash the request values
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">request</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">hashResult</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">hash</span>([]byte(<span style="color:#a6e22e">fields</span>[<span style="color:#a6e22e">i</span>] <span style="color:#f92672">+</span> <span style="color:#a6e22e">v</span>)) <span style="color:#f92672">%</span> int(<span style="color:#a6e22e">D</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">x</span>[<span style="color:#a6e22e">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] = int(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Abs</span>(float64(<span style="color:#a6e22e">hashResult</span>)))
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Get the prediction for the given request (now transformed to hash values)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">wTx</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">x</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">wTx</span> <span style="color:#f92672">+=</span> (<span style="color:#f92672">*</span><span style="color:#a6e22e">w</span>)[<span style="color:#a6e22e">v</span>]
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">p</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> (<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">+</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Exp</span>(<span style="color:#f92672">-</span><span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Max</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Min</span>(<span style="color:#a6e22e">wTx</span>, <span style="color:#ae81ff">20.0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">20.0</span>)))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Update the loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">p</span> = <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Max</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Min</span>(<span style="color:#a6e22e">p</span>, <span style="color:#ae81ff">1.</span><span style="color:#f92672">-</span><span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Pow</span>(<span style="color:#ae81ff">10</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">12</span>)), <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Pow</span>(<span style="color:#ae81ff">10</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">12</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">y</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">*</span><span style="color:#a6e22e">loss</span> <span style="color:#f92672">+=</span> <span style="color:#f92672">-</span><span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Log</span>(<span style="color:#a6e22e">p</span>)
</span></span><span style="display:flex;"><span>    } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">*</span><span style="color:#a6e22e">loss</span> <span style="color:#f92672">+=</span> <span style="color:#f92672">-</span><span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Log</span>(<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">-</span> <span style="color:#a6e22e">p</span>)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Update the weights
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">x</span> {
</span></span><span style="display:flex;"><span>        (<span style="color:#f92672">*</span><span style="color:#a6e22e">w</span>)[<span style="color:#a6e22e">v</span>] = (<span style="color:#f92672">*</span><span style="color:#a6e22e">w</span>)[<span style="color:#a6e22e">v</span>] <span style="color:#f92672">-</span> (<span style="color:#a6e22e">p</span><span style="color:#f92672">-</span>float64(<span style="color:#a6e22e">y</span>))<span style="color:#f92672">*</span><span style="color:#a6e22e">alpha</span><span style="color:#f92672">/</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Sqrt</span>((<span style="color:#f92672">*</span><span style="color:#a6e22e">n</span>)[<span style="color:#a6e22e">v</span>])<span style="color:#f92672">+</span><span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#f92672">*</span><span style="color:#a6e22e">n</span>)[<span style="color:#a6e22e">v</span>]<span style="color:#f92672">++</span>
</span></span><span style="display:flex;"><span>    }
</span></span></code></pre></div><p>This port of the model runs at 186,000 RPS, which is about a <strong>9x</strong> speedup over the CPython version!  For most companies or purposes, we could simply stop here since most of the time anything more than an order of magnitude speedup isn&rsquo;t required before moving on to the next bottleneck.  However, we can still do better!</p>

<h1 id="v5---multicore" class="anchor-link"><a href="#v5---multicore">V5 - Multicore!</a></h1>
<p>Now we&rsquo;re getting somewhere.</p>
<p>Since we&rsquo;re using Go instead of CPython, it&rsquo;s now trivial to run our code across all of our processor cores.  We simple wrap the code above in a function called <code>worker</code> and then we spawn multiple workers which consume our input and do the processing.  We also make sure to use a <code>sync.Mutex</code> to lock the shared memory so as to prevent multiple processes writing from memory or corrupting things.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#ae81ff">5</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">wg</span>.<span style="color:#a6e22e">Add</span>(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">go</span> <span style="color:#a6e22e">worker</span>(<span style="color:#a6e22e">input</span>, <span style="color:#a6e22e">fields</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">w</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">n</span>, <span style="color:#a6e22e">D</span>, <span style="color:#a6e22e">alpha</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">loss</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">count</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">wg</span>, <span style="color:#a6e22e">mutex</span>)
</span></span><span style="display:flex;"><span>    }
</span></span></code></pre></div><p>This gets us further improvement, with the resulting processing speed being 253,000 RPS.</p>

<h2 id="more-efficient-locking" class="anchor-link"><a href="#more-efficient-locking">More efficient locking?</a></h2>
<p>The Go version of our code is much faster than our original CPython version (and the PyPy) version, which makes sense as it is a faster language in general and is also using multiple CPU cores.  However, we&rsquo;re still being slowed down due to the workers having to wait to acquire locks before they can update the weights in our model.</p>
<p>It&rsquo;s definitely worth asking how to make that faster, and there are certainly ways to go about that.  One example could be round-robin updates as described in this <a href="https://papers.nips.cc/paper/3888-slow-learners-are-fast.pdf">NIPS paper</a>.</p>
<p>However, it could also be worth asking a different question.</p>

<h2 id="what-if-we-just-ditch-the-locks" class="anchor-link"><a href="#what-if-we-just-ditch-the-locks">What if we just ditch the locks?</a></h2>
<p>This is the question examined in the paper <a href="https://arxiv.org/abs/1106.5730">HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent</a>.</p>
<p>The short answer is that when you are dealing with sparse data, as we are in this case, you can just remove the locks and let your processes run hog wild on the memory (hence the name) without any issues.  In fact, any collisions or erroneous updates that do happen seem to add a kind of smoothing effect, resulting in the models performing better than predicted!</p>
<p>So what happens to our code if we remove the locks from the workers?</p>

<h2 id="v6---hogwild" class="anchor-link"><a href="#v6---hogwild">V6 - HOGWILD!</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;fmt&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;hash/fnv&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;math&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;strings&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;sync&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;time&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fstream</span> <span style="color:#e6db74">&#34;github.com/adamdrake/gofstream&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">hash</span>(<span style="color:#a6e22e">s</span> []<span style="color:#66d9ef">byte</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">h</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">fnv</span>.<span style="color:#a6e22e">New64a</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">h</span>.<span style="color:#a6e22e">Write</span>(<span style="color:#a6e22e">s</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> int(<span style="color:#a6e22e">h</span>.<span style="color:#a6e22e">Sum64</span>())
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">worker</span>(<span style="color:#a6e22e">recs</span> <span style="color:#66d9ef">chan</span> <span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">fields</span> []<span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">w</span>, <span style="color:#a6e22e">n</span> <span style="color:#f92672">*</span>[]<span style="color:#66d9ef">float64</span>, <span style="color:#a6e22e">D</span>, <span style="color:#a6e22e">alpha</span> <span style="color:#66d9ef">float64</span>, <span style="color:#a6e22e">loss</span> <span style="color:#f92672">*</span><span style="color:#66d9ef">float64</span>, <span style="color:#a6e22e">count</span> <span style="color:#f92672">*</span><span style="color:#66d9ef">int</span>, <span style="color:#a6e22e">wg</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">sync</span>.<span style="color:#a6e22e">WaitGroup</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">defer</span> <span style="color:#a6e22e">wg</span>.<span style="color:#a6e22e">Done</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">r</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">recs</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">request</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">strings</span>.<span style="color:#a6e22e">Split</span>(<span style="color:#a6e22e">r</span>, <span style="color:#e6db74">&#34;,&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#f92672">*</span><span style="color:#a6e22e">count</span><span style="color:#f92672">++</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">y</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">request</span>[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;1&#34;</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">y</span> = <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">request</span> = <span style="color:#a6e22e">request</span>[<span style="color:#ae81ff">2</span>:]             <span style="color:#75715e">// ignore label and id
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		<span style="color:#a6e22e">x</span> <span style="color:#f92672">:=</span> make([]<span style="color:#66d9ef">int</span>, len(<span style="color:#a6e22e">request</span>)<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>) <span style="color:#75715e">// need length plus one for zero at front
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		<span style="color:#a6e22e">x</span>[<span style="color:#ae81ff">0</span>] = <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">request</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">hashResult</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">hash</span>([]byte(<span style="color:#a6e22e">fields</span>[<span style="color:#a6e22e">i</span>]<span style="color:#f92672">+</span><span style="color:#a6e22e">v</span>)) <span style="color:#f92672">%</span> int(<span style="color:#a6e22e">D</span>)
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">x</span>[<span style="color:#a6e22e">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>] = int(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Abs</span>(float64(<span style="color:#a6e22e">hashResult</span>)))
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">// Get the prediction for the given request (now transformed to hash values)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		<span style="color:#a6e22e">wTx</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">x</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">wTx</span> <span style="color:#f92672">+=</span> (<span style="color:#f92672">*</span><span style="color:#a6e22e">w</span>)[<span style="color:#a6e22e">v</span>]
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">p</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> (<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">+</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Exp</span>(<span style="color:#f92672">-</span><span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Max</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Min</span>(<span style="color:#a6e22e">wTx</span>, <span style="color:#ae81ff">20.0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">20.0</span>)))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">// Update the loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		<span style="color:#a6e22e">p</span> = <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Max</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Min</span>(<span style="color:#a6e22e">p</span>, <span style="color:#ae81ff">1.</span><span style="color:#f92672">-</span><span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Pow</span>(<span style="color:#ae81ff">10</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">12</span>)), <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Pow</span>(<span style="color:#ae81ff">10</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">12</span>))
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">y</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">*</span><span style="color:#a6e22e">loss</span> <span style="color:#f92672">+=</span> <span style="color:#f92672">-</span><span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Log</span>(<span style="color:#a6e22e">p</span>)
</span></span><span style="display:flex;"><span>		} <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#f92672">*</span><span style="color:#a6e22e">loss</span> <span style="color:#f92672">+=</span> <span style="color:#f92672">-</span><span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Log</span>(<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">-</span> <span style="color:#a6e22e">p</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">// Update the weights
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">x</span> {
</span></span><span style="display:flex;"><span>			(<span style="color:#f92672">*</span><span style="color:#a6e22e">w</span>)[<span style="color:#a6e22e">v</span>] = (<span style="color:#f92672">*</span><span style="color:#a6e22e">w</span>)[<span style="color:#a6e22e">v</span>] <span style="color:#f92672">-</span> (<span style="color:#a6e22e">p</span><span style="color:#f92672">-</span>float64(<span style="color:#a6e22e">y</span>))<span style="color:#f92672">*</span><span style="color:#a6e22e">alpha</span><span style="color:#f92672">/</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Sqrt</span>((<span style="color:#f92672">*</span><span style="color:#a6e22e">n</span>)[<span style="color:#a6e22e">v</span>])<span style="color:#f92672">+</span><span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>			(<span style="color:#f92672">*</span><span style="color:#a6e22e">n</span>)[<span style="color:#a6e22e">v</span>]<span style="color:#f92672">++</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">start</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">time</span>.<span style="color:#a6e22e">Now</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">D</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Pow</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">20</span>) <span style="color:#75715e">// number of weights use for learning
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#a6e22e">alpha</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0.1</span>         <span style="color:#75715e">// learning rate for sgd optimization
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#a6e22e">w</span> <span style="color:#f92672">:=</span> make([]<span style="color:#66d9ef">float64</span>, int(<span style="color:#a6e22e">D</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">n</span> <span style="color:#f92672">:=</span> make([]<span style="color:#66d9ef">float64</span>, int(<span style="color:#a6e22e">D</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">loss</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">count</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">data</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">fstream</span>.<span style="color:#a6e22e">New</span>(<span style="color:#e6db74">&#34;../train.csv&#34;</span>, <span style="color:#ae81ff">10000</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fields</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">strings</span>.<span style="color:#a6e22e">Split</span>(<span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">data</span>, <span style="color:#e6db74">&#34;,&#34;</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">wg</span> <span style="color:#a6e22e">sync</span>.<span style="color:#a6e22e">WaitGroup</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#ae81ff">5</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">wg</span>.<span style="color:#a6e22e">Add</span>(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">go</span> <span style="color:#a6e22e">worker</span>(<span style="color:#a6e22e">data</span>, <span style="color:#a6e22e">fields</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">w</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">n</span>, <span style="color:#a6e22e">D</span>, <span style="color:#a6e22e">alpha</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">loss</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">count</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">wg</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">wg</span>.<span style="color:#a6e22e">Wait</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Println</span>(<span style="color:#e6db74">&#34;Run time is&#34;</span>, <span style="color:#a6e22e">time</span>.<span style="color:#a6e22e">Since</span>(<span style="color:#a6e22e">start</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Println</span>(<span style="color:#e6db74">&#34;loss&#34;</span>, <span style="color:#a6e22e">loss</span><span style="color:#f92672">/</span>float64(<span style="color:#a6e22e">count</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Println</span>(<span style="color:#e6db74">&#34;RPS&#34;</span>, float64(<span style="color:#a6e22e">count</span>)<span style="color:#f92672">/</span><span style="color:#a6e22e">time</span>.<span style="color:#a6e22e">Since</span>(<span style="color:#a6e22e">start</span>).<span style="color:#a6e22e">Seconds</span>())
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The code above gets us to 366,000 RPS on my laptop, which has an <strong>18x</strong> speedup over the CPython version.  The Go code is also not optimized, and could pretty easily be made even faster.</p>
<p>As a side node, the solution above is not completely lock-free, as there is still locking going on from the buffered channel <code>data</code>.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>There has been quite a bit of hype surrounding <em>Big Data</em> and the tooling required to deal with it, largely from companies whose entire business model revolves around selling you the tools to processes larger data sets.  However, in many cases those tools are completely unnecessary and harmful to the focus and priorities of your development teams, not to mention your budget.  As an example, see a previous article of mine where I did a quick demonstration of how simple command-line tools on a laptop <a href="/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html">can be 235x faster than a Hadoop cluster</a>.</p>
<p>What we&rsquo;ve really done above is transform a batch-oriented machine learning problem into a streaming/online learning problem.  This provides us with much more flexibility in terms of how much memory is required to achieve the objective (in this case, binary classification) and is wholly independent of input data size.  Transforming problems like this into stream-based problems is a very valuable technique.</p>
<p>In this article we&rsquo;ve seen that it&rsquo;s relatively easy to deal with data sets larger than your RAM, or in fact infinitely large.  Using these techniques, you can probably process the data at a rate limited only by the read speed of your SSD!</p>
 ]]></content:encoded></item><item><title>Hello, Recruiter!</title><link>https://adamdrake.com/hello-recruiter.html</link><pubDate>Fri, 11 May 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/hello-recruiter.html</guid><description>&lt;p>Hello Recruiter!&lt;/p>
&lt;p>Thank you very much for your message and your consideration.&lt;/p>
&lt;p>In order for me to consider the role more fully and determine if a call is warranted, would you please provide more information? Please send over a JD/role description including the following:&lt;/p>
&lt;ul>
&lt;li>The specific company that is hiring&lt;/li>
&lt;li>How they see the role and its associated responsibilities fitting into the future of the company&lt;/li>
&lt;li>Composition, size, and working style of the current team&lt;/li>
&lt;li>Reporting line for the role (up to Board/investors and two levels down)&lt;/li>
&lt;li>Compensation details, including a breakdown between fixed/variable cash and options/equity/bonus, if any&lt;/li>
&lt;li>Any additional information that you think would be relevant in considering if the role is a good fit&lt;/li>
&lt;/ul>
&lt;p>I&amp;rsquo;m happy to consider the above information and determine if the role is a good fit for me. If it isn&amp;rsquo;t, perhaps it&amp;rsquo;s a good fit for someone in my network and I can make the requisite introductions.&lt;/p></description><content:encoded><![CDATA[ <p>Hello Recruiter!</p>
<p>Thank you very much for your message and your consideration.</p>
<p>In order for me to consider the role more fully and determine if a call is warranted, would you please provide more information?  Please send over a JD/role description including the following:</p>
<ul>
<li>The specific company that is hiring</li>
<li>How they see the role and its associated responsibilities fitting into the future of the company</li>
<li>Composition, size, and working style of the current team</li>
<li>Reporting line for the role (up to Board/investors and two levels down)</li>
<li>Compensation details, including a breakdown between fixed/variable cash and options/equity/bonus, if any</li>
<li>Any additional information that you think would be relevant in considering if the role is a good fit</li>
</ul>
<p>I&rsquo;m happy to consider the above information and determine if the role is a good fit for me.  If it isn&rsquo;t, perhaps it&rsquo;s a good fit for someone in my network and I can make the requisite introductions.</p>
<p>I appreciate that you may not want to share the above information for a variety of reasons, in which case I do not wish to put myself in consideration for the role and I wish you all the best in finding a great candidate.</p>
<p>Thank you again for considering me for the role, and I hope to hear from you soon!</p>
 ]]></content:encoded></item><item><title>Developing Your AI BS Detector</title><link>https://adamdrake.com/developing-your-ai-bs-detector.html</link><pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/developing-your-ai-bs-detector.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>I gave a talk at MaRS on this topic. The event was put on by Steve O&amp;rsquo;Neil and his team, who all did an excellent job. The venue was packed to standing-room only with a fantastic audience of 300-400 people.&lt;/p>
&lt;p>The goal of the event was to have a discussion around &amp;ldquo;Rational AI in the Enterprise.&amp;rdquo; I think all of the speakers did a wonderful job of honoring the topic. We wanted to present the facts as they are, on the ground, in real-world projects and situations.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>I gave a talk at MaRS on this topic.  The event was put on by Steve O&rsquo;Neil and his team, who all did an excellent job.  The venue was packed to standing-room only with a fantastic audience of 300-400 people.</p>
<p>The goal of the event was to have a discussion around &ldquo;Rational AI in the Enterprise.&rdquo;  I think all of the speakers did a wonderful job of honoring the topic.  We wanted to present the facts as they are, on the ground, in real-world projects and situations.</p>
<p>My talk was aimed at a mixed audience of technologists, investors, and executives.  The goal was to instill a sense of skepticism when considering if and when a given business problem dictates an AI solution, and also to instill some confidence when it comes to having a conversation with someone pitching an AI solution to a business problem.</p>
<p>If you want to skip ahead, you can <a href="/static/talks/DRAKE-adam-20180405-rational-ai.html">download the slides</a> directly.  I will be referencing selected slides by section below.</p>
<p>
<img class="enclosure" src="/static/talks/DRAKE-adam-20180405-rational-ai.jpg" alt="On stage at MaRS"  />
</p>

<h1 id="overview" class="anchor-link"><a href="#overview">Overview</a></h1>
<p>The plan for the talk is to first provide some of my background in order to share the ways in which my experiences have shaped my perspectives on AI as a topic.  Then, I&rsquo;ll give an example of a pitch for a fraud detection AI that I developed specifically for this talk.  In closing, I&rsquo;ll discuss some ways to separate wheat from chaff when it comes to AI projects and solutions.</p>

<h1 id="background" class="anchor-link"><a href="#background">Background</a></h1>
<p>My career has spanned a wide range of technical and leadership roles over a variety of industries, including e-commerce, financial services, and healthcare.  (I expanded further on this during the talk, but you can see my <a href="/about.html">About page</a> for more details.)</p>

<h1 id="ai-for-fraud-detection" class="anchor-link"><a href="#ai-for-fraud-detection">AI for fraud detection</a></h1>
<p>This is an example of a fraud detection AI solution I had developed for the lecture.  I explained the problem domain as fraud detection for e-commerce or other electronic transaction services.  I also described my &ldquo;co-founder,&rdquo; who is someone I&rsquo;ve worked with for many years on a variety of projects and who is, in their own right, an amazing technologist with an extensive background in high-performance machine learning from an applied perspective.  My co-founder is also classically trained in theoretical computer science.  The goal of this section was to communicate that the founding team is credible and enticing from an investment perspective.</p>

<h1 id="our-ai" class="anchor-link"><a href="#our-ai">Our AI</a></h1>
<p>This slide describes some facts about the AI solution my co-founder and I developed.  All of the items on this slide are true.  The system is proprietary, for performance reasons.  It is also proven in real-world applications, since I&rsquo;ve helped advising clients who have been using similar systems to great success.  Lastly, the system is extremely high performance and very scalable.  The system can handle all the traffic on VisaNet for about $20 per month in operational costs.</p>
<p>The goal of this slide was to provide sufficient buzzword bingo, and reference exciting tools and technologies.</p>
<p>The system is shown on the next slide (yes, it fits on a slide).</p>

<h1 id="next-slide" class="anchor-link"><a href="#next-slide">(next slide)</a></h1>
<p>This slide is the code for the system, of which the main part is only the following 6 lines.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isFraud</span>(<span style="color:#a6e22e">ccIsForeign</span> <span style="color:#66d9ef">bool</span>, <span style="color:#a6e22e">amount</span> <span style="color:#66d9ef">float64</span>, <span style="color:#a6e22e">transactionsToday</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">ccIsForeign</span> <span style="color:#f92672">&amp;&amp;</span> <span style="color:#a6e22e">amount</span> &gt; <span style="color:#ae81ff">1000</span> <span style="color:#f92672">&amp;&amp;</span> <span style="color:#a6e22e">transactionsToday</span> &gt; <span style="color:#ae81ff">5</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The point of this slide is to show that although my claims were all factually correct, viewing only the code for the AI system in question would not get anyone excited from an investment perspective.  The AI solution and my mock-pitch were constructed purely to demonstrate how people can be taken in by AI hype.</p>

<h1 id="ai-is-a-pursuit-not-a-thing" class="anchor-link"><a href="#ai-is-a-pursuit-not-a-thing">AI is a PURSUIT, not a THING</a></h1>
<p>AI, in practical terms, is the pursuit of human-level intelligence by machines.  It isn&rsquo;t a single thing you build, or a product, or a solution of some kind.  It is the process of trying to build increasingly smarter systems in order to free up the time and energy of humans to focus on more important and rewarding aspects of existence.</p>

<h1 id="ai-is-forever-a-set-of-tools-that-dont-exist-yet-for-solving-problems-that-arent-solved-yet" class="anchor-link"><a href="#ai-is-forever-a-set-of-tools-that-dont-exist-yet-for-solving-problems-that-arent-solved-yet">AI is forever a set of tools that don&rsquo;t exist YET, for solving problems that aren&rsquo;t solved YET</a></h1>
<p>This is a different take on the classic statement that &ldquo;AI is whatever hasn&rsquo;t been done yet.&rdquo;  Though the idea of a technology may be considered AI, once that technology is realized, people stop calling it AI.  There are countless examples of this, such as optical character recognition, facial recognition, chess playing, and many more.  These things aren&rsquo;t really considered to be AI anymore, they&rsquo;re just things your smartphone can do.</p>
<p>This is an important point because it completely disarms claims by any technology team or company trying to sell you an AI solution to a business problem.  They might have a solution, but calling it AI is just window dressing.  It&rsquo;s probably just a good solution to a business problem.</p>

<h1 id="ai-is-done-to-the-extent-it-is-done-at-all-by-research-teams-not-product-teams" class="anchor-link"><a href="#ai-is-done-to-the-extent-it-is-done-at-all-by-research-teams-not-product-teams">AI is done, to the extent it is done at all, by research teams not product teams</a></h1>
<p>Since AI is the pursuit of technology capable of a more advanced level of intelligence, it is almost by definition a research activity.  This makes it an endeavour wholly unsuited to almost every growth-stage startup, or large enterprise, excepting the few that have an actual research department.</p>
<p>A team at a growth-stage tech startup that is working on building a product is generally not building any AI which hasn&rsquo;t been built already.  They are, or they should be, using established tools, frameworks, algorithms, and other proven knowledge in order to build a product to satisfy a customer demand.  Efforts to advance the current state of AI research are simply a distraction for a startup that builds products.  AI isn&rsquo;t necessary in order for the startup to provide a great experience and tons of value for customers.</p>

<h1 id="next-slide-1" class="anchor-link"><a href="#next-slide-1">(next slide)</a></h1>
<p>This slide is a list of some things I&rsquo;ve seen during my career in tech thus far.  They&rsquo;ve all had similar hype trains associated with them.  Some have now gone out of fashion.</p>
<p>The thing to note is that these buzzwords are extremely vague, and seem to be getting more vague as time progresses.  While Business Intelligence efforts seemed to have a rather concrete scope (including creating reporting systems and aggregating data in order to allow humans to make better decisions), AI by contrast is almost completely nebulous.  It will accomplish everything, solve everything, and advance everything, resulting in some utopian or dystopian future.  Vague claims are a dead giveaway that the hype is out of control.</p>

<h1 id="an-anecdote-on-fraud-ai-and-rules-based-systems" class="anchor-link"><a href="#an-anecdote-on-fraud-ai-and-rules-based-systems">An anecdote on fraud, AI, and rules-based systems</a></h1>
<p>I was once contacted by a venture capital firm who asked me to pay a visit to one of their portfolio companies.  They wanted me to help the company make some progress on scaling their technical team, and to provide guidance on some particularly difficult technical problems they were trying to solve.  Along the way, I spoke with one of the executives who was very keen on improving their fraud detection system.</p>
<p>The executive was convinced that their current system, designed around rules for flagging transactions that were likely fraudulent, was archaic, and that they needed some AI and Data Science to achieve more effective fraud detection.  With that in mind, the executive had approved a budget for hiring an entire Data Science team, and that team had now been on site for the last four months working on the problem of developing this new and wonderful system.</p>
<p>I went to speak with the team in question and asked them how they were progressing.  The news was not good.  Unfortunately, they were having difficulties in improving the accuracy of the fraud detection system they were building.  They had tried numerous algorithms, data preprocessing techniques, and other strategies.  They were simply stuck, and the pressure from the executive to produce a new Data Science and AI-based fraud detection system was getting worse.</p>
<p>I asked them what they were using for training data for the new system.</p>
<p>They said they were using the labeled output data from the current rules-based system. /facepalm&hellip;</p>
<p>Of course the new system wouldn&rsquo;t be any more accurate!  In fact, it wouldn&rsquo;t even be as good as the current rules-based system, since any machine learning approach to that problem is only emulating the output of the rules-based system in the first place.</p>
<p>The executive seemed to think that a rules-based system was horribly outdated and that AI was needed.  He seemed to be unaware that many (most?) of the AI systems handling things like fraud detection or credit risk decisions are rules-based.  The executive completely bought into the hype surrounding AI, and it cost the company a large sum of time and money that would have been much better spent elsewhere.</p>

<h1 id="some-bs-detector-questions" class="anchor-link"><a href="#some-bs-detector-questions">Some BS Detector questions</a></h1>

<h2 id="what-specific-problem-are-you-solving" class="anchor-link"><a href="#what-specific-problem-are-you-solving">What specific problem are you solving?</a></h2>
<p>This is usually the first question I ask in a variety of situations, because it is often the case that people start trying to solve a problem before they have fully specified what it is they want to solve.  When dealing with a nebulous or poorly-specified problem, it is often the case that people try to solve it with a nebulous approach, like &ldquo;building an AI.&rdquo;</p>
<p>In order to guard against this, and also to facilitate the rest of the discussion, it&rsquo;s important to have a clear understanding about what the problem actually is.  Additionally, once the problem has been specified, it&rsquo;s almost always revealed to be a business problem with known effective solutions rather than something requiring a new and novel technical approach.  These business problems, and the companies who solve them, are almost always built on domain expertise, a professional network, focused objectives, and persistence - not AI magic.</p>

<h2 id="what-is-the-most-naive-solution--did-you-try-that" class="anchor-link"><a href="#what-is-the-most-naive-solution--did-you-try-that">What is the most naive solution?  Did you try that?</a></h2>
<p>Once the problem has been clearly specified, it&rsquo;s best to try the simplest or most naive solution first.  If that isn&rsquo;t possible, there should be a good reason.  Most technical problems that growth-stage startups need to solve are well addressed by textbook solutions.  There are often three or more ways to solve these common technical problems that are known, easy to implement and maintain, and proven to work across a wide variety of scalability phases.</p>
<p>As an example, if you&rsquo;re doing some kind of bin packing or knapsack problem, you can consider greedy heuristics, dynamic programming, and least-cost branch and bound.  Those tools enable coverage of different sizes of data sets, and you can make intelligent decisions on the important of accuracy versus runtime performance.  Developing some kind of AI packing prediction system is wholly unnecessary.</p>

<h2 id="what-about-the-next-most-naive" class="anchor-link"><a href="#what-about-the-next-most-naive">What about the next-most-naive?</a></h2>
<p>Sometimes people will deliberately attempt the most naive solution with full knowledge that it will fail, simply so they can justify using or building the more exciting and fancy AI solution.  A company can save a lot of time and money by instead considering the next-most-naive solution.</p>
<p>As mentioned above, many problems have solutions that work well across a wide variety of scalability stages.  In the knapsack problem example, you can solve for small item sets relatively quickly and optimally with a dynamic programming approach.  If you have more data and the dynamic programming solution is no longer appropriate, the answer is not to leap to some AI-based solution for knapsack problems, but rather to consider the next-most-naive solution.</p>

<h2 id="why-is-what-youre-doing-considered-ai" class="anchor-link"><a href="#why-is-what-youre-doing-considered-ai">Why is what you&rsquo;re doing considered AI?</a></h2>
<p>This is, intentionally, a bit of a trick question.  If someone is trying to sell you on investing in a project or company and they&rsquo;re playing up the AI aspect of it, ask them why the whole thing is considered AI in the first place.  If they&rsquo;re solving a valuable business problem, and happen to be using some new and interesting technology to do it, it&rsquo;s potentially an interesting investment.  However, if they just like the idea of AI and are using it as a solution in search of a problem, then that&rsquo;s probably a very dangerous investment and should be avoided.</p>

<h2 id="are-you-using-a-framework" class="anchor-link"><a href="#are-you-using-a-framework">Are you using a framework?</a></h2>
<ul>
<li>
<p>If so, why is your solutions defensible?</p>
</li>
<li>
<p>If not, explain why you aren&rsquo;t wasting time?</p>
</li>
</ul>
<p>As above, this one is also somewhat of a trick question.  Recall that AI is done, to the extent it is done at all, by research teams.  A product team at a growth-stage startup or a development team in a larger organization probably isn&rsquo;t outfitted to be focusing on advancing the forefront of human knowledge in AI.  Therefore, they should probably be using existing frameworks and tooling, allowing them to spend valuable time solving necessary customer and business problems in a manner that is efficient to operate and maintain.  Building a custom AI framework takes time and resources away from those goals, but is often touted as a selling point when the person doing the touting is trying to play up how novel their solution is.</p>
<p>Lastly, some companies will make the argument that because they&rsquo;re using an AI framework to solve business problem X, that their solution is valuable because of the AI component.  WRONG!  The solution must be valuable in its own right!  The customers who want business problem X solved do not care about the manner in which it is solved, so long as the solution works and is maintainable.  The business problem is what is important, not the fact that an AI framework was used to solve it.</p>

<h1 id="when-you-hear-ai-be-suspicious" class="anchor-link"><a href="#when-you-hear-ai-be-suspicious">When you hear AI, be suspicious.</a></h1>
<p>Above all, be suspicious.  When someone says AI, they may be solving a very important problem&hellip; or they may just want your money.</p>
 ]]></content:encoded></item><item><title>Serverless with Lambda, API Gateway, and Go</title><link>https://adamdrake.com/serverless-with-lambda-api-gateway-and-go.html</link><pubDate>Sun, 11 Feb 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/serverless-with-lambda-api-gateway-and-go.html</guid><description>&lt;h1 id="intro" class="anchor-link">&lt;a href="#intro">Intro&lt;/a>&lt;/h1>
&lt;p>Some time ago I made &lt;a href="https://tinysite.adamdrake.com">TinySite&lt;/a> and I wrote an article about building the &lt;a href="https://adamdrake.com/the-biggest-smallest-website.html">Biggest Smallest Website&lt;/a>. As part of that work, I also built &lt;a href="https://compresstest.com">CompressTest&lt;/a> in order to provide some insight on size of data post-compression for a few of the compress methods in the Go standard library.&lt;/p>
&lt;p>Those services were running on EC2 instances via Elastic Beanstalk, and while the cost wasn&amp;rsquo;t great, I have other side projects which, like those, require few resources and therefore result in EC2 instances which are mostly idling. Ditto for the Elastic Load Balancers which are part and parcel of an Elastic Beanstalk setup. That money is wasted, and in the case of CompressTest, since it is CPU-intensive, I had to have the setup in Elastic Beanstalk such that it could auto-scale in the event that the site ends up on Hacker News or another aggregator which results in high traffic loads. What I wanted was a system that didn&amp;rsquo;t really cost anything if it wasn&amp;rsquo;t being used, but that could scale up at a moment&amp;rsquo;s notice to whatever load happened to come in.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="intro" class="anchor-link"><a href="#intro">Intro</a></h1>
<p>Some time ago I made <a href="https://tinysite.adamdrake.com">TinySite</a> and I wrote an article about building the <a href="/the-biggest-smallest-website.html">Biggest Smallest Website</a>.  As part of that work, I also built <a href="https://compresstest.com">CompressTest</a> in order to provide some insight on size of data post-compression for a few of the compress methods in the Go standard library.</p>
<p>Those services were running on EC2 instances via Elastic Beanstalk, and while the cost wasn&rsquo;t great, I have other side projects which, like those, require few resources and therefore result in EC2 instances which are mostly idling.  Ditto for the Elastic Load Balancers which are part and parcel of an Elastic Beanstalk setup.  That money is wasted, and in the case of CompressTest, since it is CPU-intensive, I had to have the setup in Elastic Beanstalk such that it could auto-scale in the event that the site ends up on Hacker News or another aggregator which results in high traffic loads.  What I wanted was a system that didn&rsquo;t really cost anything if it wasn&rsquo;t being used, but that could scale up at a moment&rsquo;s notice to whatever load happened to come in.</p>
<p>New serverless approaches, like AWS API Gateway and AWS Lambda, provide a cheap, fast-scaling option for a relatively low-traffic service without strict performance and latency requirements.</p>

<h1 id="elastic-beanstalk---old-and-busted" class="anchor-link"><a href="#elastic-beanstalk---old-and-busted">Elastic Beanstalk - Old and busted</a></h1>
<p>Elastic Beanstalk works great, but requires at least one Elastic Load Balancer and one EC2 instance to form a functioning environment.  Additionally, scale-up time is determined by triggers that start or stop instances.  This means that having additional capacity on hand might take five minutes for something like an average CPU usage alarm to trigger, and then another few minutes for instances to come online.  If you need further instances, they will have to wait for the duration of whatever cool-down period you have configured (say three to five minutes), before initiating startup of additional instances.  This may not be so bad for larger services where there are sustained requests over time and where the traffic scales up relatively smoothly throughout the day, but it&rsquo;s not great for traffic that could come in large bursts, as in the situation I want to address.</p>
<p>Elastic Beanstalk is also not great for side projects, since the minimum cost to have the infrastructure running is around $25 USD per month.  This isn&rsquo;t going to break the bank for a single side project, but it does start to add up when you have many of them.</p>
<p>Considering the above, you might wonder about abstracting the load balancers and servers away entirely, and worry only about executing functions in your application.  Enter AWS API Gateway and Lambda.</p>

<h1 id="serverless---new-hotness" class="anchor-link"><a href="#serverless---new-hotness">Serverless - New Hotness</a></h1>
<p>Serverless has been a thing for a few years, but most of the systems I work with are high-performance (making it too expensive) and low latency (making it impossible to use due to calling overhead).  Those two points, combined with vendor lock-in issues, are why I typically don&rsquo;t recommend the serverless approach for my advising clients.  However, in this case it makes a lot of sense.  You only pay for what you use, and there isn&rsquo;t really any such thing as idling servers because there are no servers (from a billing and administration standpoint).  You pay for API Gateway on a per-request basis, and Lambda on a per-invocation basis, so the unused capacity problem goes away.</p>
<p>Requests to the API first hit API Gateway, which proxies requests to other systems - in this case, a function running on AWS Lambda.  Lambda handles execution and scaling and, as long as each request doesn&rsquo;t run for too long, it ends up being far cheaper than having instance(s) that idle for most of the time.  Currently, everyone is eligible for the free tier of Lambda, regardless of how long you&rsquo;ve been an AWS customer.  The free tier gets you one million function invocations per month.  API Gateway costs $3.50 per million function calls, plus data transfer costs (in this case, they&rsquo;re effectively zero).  In other words, instead of having a nano EC2 instance running TinySite (for roughly $5 per month) and an EB environment for CompressTest (for $25 per month), plus other instances for my other projects, I can run all the same services for pretty close to free.</p>

<h2 id="api-gateway" class="anchor-link"><a href="#api-gateway">API Gateway</a></h2>
<p>API Gateway has a small cost, but as mentioned it&rsquo;s only $3.50 per million API requests.  For a side project like this, getting multiple millions of API requests per month is unlikely, so $3.50 is a reasonable approximation of the total cost.</p>
<p>In the case of CompressTest, I set up a <code>POST</code> endpoint on API Gateway which forwards the requests to a Lambda function. The Lambda function processes the request and responds to API Gateway, which then passes the response back to the user.  There&rsquo;s a slight complication: in my testing, using API Gateway with Lambda means that even if you set up CORS headers on API Gateway, they will not be included in any response.  Therefore, if you need CORS headers, make sure you set them in the response your function sends back to API Gateway.  API Gateway will use whatever headers you set, with the exception of some reserved headers.  I create the response object and set the headers immediately just to be on the safe side:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">compressHandler</span>(<span style="color:#a6e22e">ctx</span> <span style="color:#a6e22e">context</span>.<span style="color:#a6e22e">Context</span>, <span style="color:#a6e22e">request</span> <span style="color:#a6e22e">events</span>.<span style="color:#a6e22e">APIGatewayProxyRequest</span>) (<span style="color:#a6e22e">events</span>.<span style="color:#a6e22e">APIGatewayProxyResponse</span>, <span style="color:#66d9ef">error</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// Let&#39;s create the response we&#39;ll eventually send, being sure to have CORS headers in place
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#a6e22e">resp</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">events</span>.<span style="color:#a6e22e">APIGatewayProxyResponse</span>{<span style="color:#a6e22e">Headers</span>: make(<span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">string</span>)}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">resp</span>.<span style="color:#a6e22e">Headers</span>[<span style="color:#e6db74">&#34;Access-Control-Allow-Origin&#34;</span>] = <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// Remainder of the handler below...
</span></span></span></code></pre></div><p>Another complication is that API Gateway likes to assume everything is JSON, and neither CompressTest nor TinySite deal strictly with JSON or even UTF-8 data.  CompressTest receives <code>multipart/form-data</code>, and TinySite responds with compressed data, which may contain arbitrary bytes.  AWS API Gateway can handle binary media types as long as you set the Content-Type values in the settings for the endpoint, but I found it to be difficult/unreliable.  The basic flow is that API Gateway receives the request and base64 encodes it.  It then passes the request on to the Lambda function, which decodes it back to bytes to perform the operations defined in the handler.  The resulting response is sent as-is if possible, or if it contains binary data it is base64 encoded before being sent to API Gateway.  If the Content-Type header supplied by the Lambda function matches that which was specified in the settings in API Gateway, then API Gateway will base64 decode the response body before forwarding it on to the client.  Additionally, I used the command line utility to set the <code>CONVERT_TO_BINARY</code> flag on egress as part of the process of trying to get it working.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>aws apigateway update-integration-response <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--rest-api-id XXXXXX <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--resource-id XXXXXX <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--http-method GET <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--status-code <span style="color:#ae81ff">200</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>--patch-operations <span style="color:#e6db74">&#39;[{&#34;op&#34; : &#34;replace&#34;, &#34;path&#34; : &#34;/contentHandling&#34;, &#34;value&#34; : &#34;CONVERT_TO_BINARY&#34;}]&#39;</span>
</span></span></code></pre></div><p>In the end, it all works, but it wasn&rsquo;t trivial to set up since there are so many knobs to turn.  I&rsquo;m not sure why API Gateway requires a string response instead of just bytes, but oh well.  Lastly, it does not seem to be totally clear which changes to API Gateway require the API to be redeployed, and which take effect without redeployment.  When in doubt, redeploy the API.</p>

<h2 id="lambda" class="anchor-link"><a href="#lambda">Lambda</a></h2>
<p>This part wasn&rsquo;t very difficult in either case.  In the case of Go and receiving events from API Gateway, you are receiving an <code>APIGatewayProxyRequest</code> with a structure like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#75715e">// APIGatewayProxyRequest contains data coming from the API Gateway proxy
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">type</span> <span style="color:#a6e22e">APIGatewayProxyRequest</span> <span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">Resource</span>              <span style="color:#66d9ef">string</span>                        <span style="color:#e6db74">`json:&#34;resource&#34;`</span> <span style="color:#75715e">// The resource path defined in API Gateway
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#a6e22e">Path</span>                  <span style="color:#66d9ef">string</span>                        <span style="color:#e6db74">`json:&#34;path&#34;`</span>     <span style="color:#75715e">// The url path for the caller
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#a6e22e">HTTPMethod</span>            <span style="color:#66d9ef">string</span>                        <span style="color:#e6db74">`json:&#34;httpMethod&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">Headers</span>               <span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">string</span>             <span style="color:#e6db74">`json:&#34;headers&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">QueryStringParameters</span> <span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">string</span>             <span style="color:#e6db74">`json:&#34;queryStringParameters&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">PathParameters</span>        <span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">string</span>             <span style="color:#e6db74">`json:&#34;pathParameters&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">StageVariables</span>        <span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">string</span>             <span style="color:#e6db74">`json:&#34;stageVariables&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">RequestContext</span>        <span style="color:#a6e22e">APIGatewayProxyRequestContext</span> <span style="color:#e6db74">`json:&#34;requestContext&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">Body</span>                  <span style="color:#66d9ef">string</span>                        <span style="color:#e6db74">`json:&#34;body&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">IsBase64Encoded</span>       <span style="color:#66d9ef">bool</span>                          <span style="color:#e6db74">`json:&#34;isBase64Encoded,omitempty&#34;`</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>and you construct an <code>APIGatewayProxyResponse</code> which looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#75715e">// APIGatewayProxyResponse configures the response to be returned by API Gateway for the request
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">type</span> <span style="color:#a6e22e">APIGatewayProxyResponse</span> <span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">StatusCode</span>      <span style="color:#66d9ef">int</span>               <span style="color:#e6db74">`json:&#34;statusCode&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">Headers</span>         <span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">string</span> <span style="color:#e6db74">`json:&#34;headers&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">Body</span>            <span style="color:#66d9ef">string</span>            <span style="color:#e6db74">`json:&#34;body&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">IsBase64Encoded</span> <span style="color:#66d9ef">bool</span>              <span style="color:#e6db74">`json:&#34;isBase64Encoded,omitempty&#34;`</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>IsBase64Encoded</code> field is used to differentiate between string data and raw bytes (compressed things, images, etc.) which have been base64 encoded, as mentioned in the section on API Gateway.</p>
<p>For CompressTest I just used the <code>APIGatewayProxyRequest</code> to build a <code>net/http.Request</code>, and then I used all the same code I had for the HTTP handler before.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">compressHandler</span>(<span style="color:#a6e22e">ctx</span> <span style="color:#a6e22e">context</span>.<span style="color:#a6e22e">Context</span>, <span style="color:#a6e22e">request</span> <span style="color:#a6e22e">events</span>.<span style="color:#a6e22e">APIGatewayProxyRequest</span>) (<span style="color:#a6e22e">events</span>.<span style="color:#a6e22e">APIGatewayProxyResponse</span>, <span style="color:#66d9ef">error</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// Let&#39;s create the response we&#39;ll eventually send, being sure to have CORS headers in place
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#a6e22e">resp</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">events</span>.<span style="color:#a6e22e">APIGatewayProxyResponse</span>{<span style="color:#a6e22e">Headers</span>: make(<span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">string</span>)}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">resp</span>.<span style="color:#a6e22e">Headers</span>[<span style="color:#e6db74">&#34;Access-Control-Allow-Origin&#34;</span>] = <span style="color:#e6db74">&#34;*&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">r</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">Request</span>{}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">Header</span> = make(<span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>][]<span style="color:#66d9ef">string</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">request</span>.<span style="color:#a6e22e">Headers</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">k</span> <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;content-type&#34;</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">k</span> <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;Content-Type&#34;</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">Header</span>.<span style="color:#a6e22e">Set</span>(<span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// NOTE: API Gateway is set up with */* as binary media type, so all APIGatewayProxyRequests will be base64 encoded
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#a6e22e">body</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">base64</span>.<span style="color:#a6e22e">StdEncoding</span>.<span style="color:#a6e22e">DecodeString</span>(<span style="color:#a6e22e">request</span>.<span style="color:#a6e22e">Body</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">Body</span> = <span style="color:#a6e22e">ioutil</span>.<span style="color:#a6e22e">NopCloser</span>(<span style="color:#a6e22e">bytes</span>.<span style="color:#a6e22e">NewBuffer</span>(<span style="color:#a6e22e">body</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">resp</span>.<span style="color:#a6e22e">StatusCode</span> = <span style="color:#ae81ff">403</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">resp</span>.<span style="color:#a6e22e">Body</span> = <span style="color:#e6db74">&#34;Could not read request body&#34;</span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">resp</span>, <span style="color:#66d9ef">nil</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">r</span>.<span style="color:#a6e22e">ParseMultipartForm</span>(<span style="color:#a6e22e">maxRequestBodySize</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// Handling the request continues...
</span></span></span></code></pre></div><p>Instead of taking an <code>http.Request</code> and an <code>http.ResponseWriter</code> I just take the context and <code>APIGatewayProxyRequest</code> and return the relevant <code>APIGatewayProxyResponse</code>.  The other trick is setting the body, which for an HTTP Request requires a <code>Close()</code> method.  However, if you try to <code>.Close()</code> in Lambda you&rsquo;ll get a nil pointer exception, since there isn&rsquo;t really an HTTP request there.  Therefore, use the <code>ioutil.NopCloser</code> to wrap the reader, thus satisfying the <code>ReadCloser</code> interface expected on the <code>net/http</code> side when the form is parsed.</p>
<p>Also note how the Content-Type header is being set.  Firefox will send the lower case version, and some tools like curl will send the title-case version, so it&rsquo;s important to check both cases.  I probably could have also hard-coded this to <code>multipart/form-data</code> but in addition to being poor form it would also result in the boundary separator not being known, since it is specified in that header.  This would result in the body of the HTTP request being impossible (or at least unreasonably difficult) to process.</p>
<p>Because CompressTest receives binary data, API Gateway will, as mentioned, forward the request body to our Lambda function after base64 encoding it.  Therefore, we have to decode it first, and then process the request as normal.</p>
<p>In the case of TinySite, the only real change required was to set the <code>IsBase64Encoded</code> flag in the response.  In fact, the whole handler for TinySite is only a few lines of code.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">tinysite</span>() (<span style="color:#a6e22e">events</span>.<span style="color:#a6e22e">APIGatewayProxyResponse</span>, <span style="color:#66d9ef">error</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">buf</span> <span style="color:#a6e22e">bytes</span>.<span style="color:#a6e22e">Buffer</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">zw</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">flate</span>.<span style="color:#a6e22e">NewWriter</span>(<span style="color:#f92672">&amp;</span><span style="color:#a6e22e">buf</span>, <span style="color:#a6e22e">flate</span>.<span style="color:#a6e22e">BestCompression</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">_</span> = <span style="color:#a6e22e">zw</span>.<span style="color:#a6e22e">Write</span>([]byte(<span style="color:#a6e22e">resp</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">zw</span>.<span style="color:#a6e22e">Close</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">compressedBody</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">buf</span>.<span style="color:#a6e22e">Next</span>(<span style="color:#a6e22e">buf</span>.<span style="color:#a6e22e">Len</span>())
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">resp</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">events</span>.<span style="color:#a6e22e">APIGatewayProxyResponse</span>{<span style="color:#a6e22e">StatusCode</span>: <span style="color:#ae81ff">200</span>, <span style="color:#a6e22e">Body</span>: <span style="color:#a6e22e">base64</span>.<span style="color:#a6e22e">StdEncoding</span>.<span style="color:#a6e22e">EncodeToString</span>(<span style="color:#a6e22e">compressedBody</span>), <span style="color:#a6e22e">IsBase64Encoded</span>: <span style="color:#66d9ef">true</span>}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">resp</span>.<span style="color:#a6e22e">Headers</span> = make(<span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">string</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">resp</span>.<span style="color:#a6e22e">Headers</span>[<span style="color:#e6db74">&#34;Content-Type&#34;</span>] = <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">resp</span>.<span style="color:#a6e22e">Headers</span>[<span style="color:#e6db74">&#34;Content-Encoding&#34;</span>] = <span style="color:#e6db74">&#34;deflate&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">resp</span>, <span style="color:#66d9ef">nil</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Note as well that if the <code>Content-Type</code> header is not set, then API Gateway will automatically set it to <code>application/json</code>, which we do not want.  The content type is inferred by the client in this case, and it is not required in the HTTP spec to send <code>text/html</code> as one might suspect.  By sending an empty string as the <code>Content-Type</code> we can ensure that it is not set by API Gateway.  Note that this does not work with all headers, for example the custom Amazon headers prefixed with <code>x-</code> for tracing and other diagnostics will remain and if you try to set them to empty strings they will be copied and the generated headers inserted.</p>

<h1 id="summary" class="anchor-link"><a href="#summary">Summary</a></h1>
<p>With the exception of handling binary media types and making sure to use an <code>ioutil.NopCloser</code>, the whole process was pretty straightforward.  While this approach is not appropriate for systems that need optimal performance or where latency constraints are tight, it may be ideal for some for some simpler projects.  If you have relatively low-traffic sites that may need to scale to higher traffic volumes, and for which some request latency (e.g. 100-300ms) is tolerable, then this combination of API Gateway and Lambda may be a perfect fit.</p>
 ]]></content:encoded></item><item><title>Writing the job description</title><link>https://adamdrake.com/writing-the-job-description.html</link><pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate><guid>https://adamdrake.com/writing-the-job-description.html</guid><description>&lt;h1 id="writing-the-job-description" class="anchor-link">&lt;a href="#writing-the-job-description">Writing the job description&lt;/a>&lt;/h1>
&lt;p>Ahh, the job description. It is the face of your company on job search sites. It sets the tone for all the rest of the hiring process that follows. It has the power to make or break your hiring success. It&amp;rsquo;s a shame they&amp;rsquo;re so often badly written.&lt;/p>
&lt;p>A good job description isn&amp;rsquo;t so different from a bad one. Mostly, it just has some of the letters in different places. Both types try to achieve the same goals: to describe the position and attract candidates to apply. There are a few key areas in which good job descriptions differ from bad ones:&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="writing-the-job-description" class="anchor-link"><a href="#writing-the-job-description">Writing the job description</a></h1>
<p>Ahh, the job description.  It is the face of your company on job search sites.  It sets the tone for all the rest of the hiring process that follows.  It has the power to make or break your hiring success.  It&rsquo;s a shame they&rsquo;re so often badly written.</p>
<p>A good job description isn&rsquo;t so different from a bad one.  Mostly, it just has some of the letters in different places.  Both types try to achieve the same goals: to describe the position and attract candidates to apply.  There are a few key areas in which good job descriptions differ from bad ones:</p>
<ol>
<li>They don&rsquo;t unnecessarily discriminate</li>
<li>They don&rsquo;t oversell</li>
<li>They accurately describe the work</li>
<li>They prepare the candidate for the hiring process</li>
</ol>
<p>In this article, we&rsquo;ll tackle each of these areas as we go through the process of writing our job description.</p>

<h1 id="the-job-description-what-is-it-good-for" class="anchor-link"><a href="#the-job-description-what-is-it-good-for">The job description: what is it good for?</a></h1>
<p>As we begin, it&rsquo;s important to keep in mind the intended purpose of writing our job description.  We want to give potential candidates an idea of the position on offer, and we want them to feel like it&rsquo;s an attractive enough offer to risk applying for it.</p>
<p>Applying for a position is always a risk.  Candidates will be investing their time and energy for our consideration, and in most cases, all except for one applicant will be rejected.  The hiring process, by necessity, is discriminatory.  After all, if anyone could do the job we&rsquo;re offering, we&rsquo;d never bother to check whether or not someone is capable of doing it.  Therefore, our job description <em>should</em> discriminate - but only in the areas where it&rsquo;s actually necessary.  Specifically, our goal is to discriminate based on competence - and only competence.</p>
<p>Many bad job descriptions, intentionally or not, exclude candidates for traits that have no bearing on competence.  For most roles, traits that have no bearing on competence include things like age, gender, sex, nationality, ethnicity, and so on.  As well, stereotypes or statistically more likely conditions that may be true for an entire country or group are sometimes unfairly applied to an individual.  These are common pitfalls that unfortunately end up excluding many talented and completely capable candidates from the hiring pool.  They have no place in a good job description.</p>
<p>Something that does have a place in a good job description is an accurate account of the critical skills needed for doing the work on offer.  This usually appears somewhere after the word &ldquo;required&rdquo; in the text.  Bad job descriptions tend to have all sorts of words in this section that describe a wish list of items that would be nice to have, but none of which are actually <em>required</em> for the position.  This wish list often includes various degrees of higher education and advanced skills, specific years of experience, and familiarity with specific technologies or specific versions of those technologies.</p>
<p>It&rsquo;s advantageous for us to be aware of the difference between required skills and helpful traits when we&rsquo;re writing our job descriptions.  While our specific position may very well require certain things like advanced study and specific technologies, this is typically the exception, rather than the rule.  There&rsquo;s a significant downside to misrepresenting helpful traits as requirements when this list discourages applications from capable candidates who may not fit the expected mold.</p>
<p>The goal when writing a good job description, then, should be to accurately relate this list of required skills.  This list should include both hard skills and soft skills.  If the work requires skill in collaboration, in time management, and in seeking responsibility and improvement opportunities, then these are all items we should list in addition to technical or hard skills.</p>
<p>After having written this list, go over each item and ask, &ldquo;Could someone without this trait still competently do the work?&rdquo; If the answer is yes, move that trait into the &ldquo;not required but would be nice&rdquo; section.</p>

<h1 id="dont-oversell-it" class="anchor-link"><a href="#dont-oversell-it">Don&rsquo;t oversell it</a></h1>
<p>Since the goal of a good job description is to accurately describe the position on offer (and by proxy, the company offering it), adding anything that seems to over-represent the realities of the position should be avoided.  Especially for technical hires, overzealous language used to refer to technical staff is an immediate red flag.  Words such as <em>rockstars</em>, <em>gurus</em>, <em>wizards</em>, or <em>ninjas</em> are indicative of a company that gives away titles more readily than appropriate salaries.  It&rsquo;s wording designed to appeal to the egos of developers who would make that trade.  You don&rsquo;t want to be that kind of company, and you don&rsquo;t want to attract that kind of talent.</p>
<p>In the same vein, it&rsquo;s pragmatic to avoid using common business buzzwords.  Buzzwords tend to use up a lot of letters and time and do so without actually conveying any useful information.  If a job description purports to be looking for a &ldquo;rockstar developer who can make a huge impact and help 10x the development team,&rdquo; any knowledgeable and effective technical candidate will recognize that sentence to be meaningless.  The downside to meaningless sentences is that they make it clear that your company doesn&rsquo;t have reasonable and achievable metrics for success.  No knowledgeable and self-respecting technical person would want to work for a company in which their contributions are arbitrarily measured.  What&rsquo;s worse, if contributions are arbitrarily measured, it is entirely likely that the technical team is the company&rsquo;s common scapegoat when business objectives are not achieved.</p>
<p>Instead of overselling the position and potentially turning off experienced candidates, a good job description will emphasize the openness of your organization.  This is a great opportunity to demonstrate the openness and honesty of your culture.  If your organization doesn&rsquo;t pay market salaries for your area, instead let potential candidates know what your company offers to offset any perceived lack of cash benefits.  If you offer childcare services or credits, remote working options, gym memberships or cell phone plans, or regular company lawn-bowling excursions, make a point of mentioning it in the job description.</p>

<h1 id="accurately-describe-the-work" class="anchor-link"><a href="#accurately-describe-the-work">Accurately describe the work</a></h1>
<p>It may be helpful to keep in mind that our job description isn&rsquo;t designed to appeal to everyone.  It&rsquo;s designed to appeal to people who would realistically enjoy doing the job.  It then follows that if we accurately describe what doing the job will be like, the attractiveness part of our job description goals will take care of itself.  With one or two sufficiently descriptive paragraphs, any potential candidate with the ability and willingness to suit the position should feel comfortable applying for it.</p>
<p>While it may be tempting to focus on new technologies and fancy projects, accurately describing the work also requires description of foundational technologies and practices, like writing tests and improving existing systems, should the job require those skills.  We want to ensure that we manage expectations appropriately for our potential candidates, instead of dangling the proverbial carrot.</p>
<p>Describing the work can also encompass facts about your company culture, the makeup of your team members, or common goals and practices.  Encapsulating the experience that a potential candidate may be signing up for is a great way to set expectations for all parties.</p>

<h1 id="prepare-the-candidate-for-the-hiring-process" class="anchor-link"><a href="#prepare-the-candidate-for-the-hiring-process">Prepare the candidate for the hiring process</a></h1>
<p>This section should be straightforward and informative.  If you&rsquo;ve followed this series of articles from the start, you&rsquo;re already familiar with the general stages of the hiring process, which we&rsquo;ll simply list in this section for the candidate.  If you&rsquo;re not already familiar with the hiring process, you may like to read <a href="/rethinking-hiring.html">Rethinking hiring</a>.</p>
<p>In your description of the process, include some general timeframes and an idea of when the candidate will receive responses from your organization.  This is a good opportunity to make some commitments to your potential candidates and increase their confidence in applying.</p>

<h1 id="an-example-job-description" class="anchor-link"><a href="#an-example-job-description">An example job description</a></h1>
<p>Below is an example job description written for a hypothetical growth-stage tech company that is looking for a software developer.  Each section exemplifies one of the points we discussed above.</p>
<blockquote>
<p>StartupCo is hiring developers!  We are a small and diverse group of people building the next generation of VR television for cats.  Since our customer base is growing, we need to add people to our team who can contribute to the continued joy of our clients (and their cats)!</p>

<h1 id="requirements" class="anchor-link"><a href="#requirements">Requirements</a></h1>
<p>We&rsquo;re looking for pragmatic developers who are comfortable writing new code, tests, and improving the quality of our existing codebase.  You understand the importance of automation, and you don&rsquo;t shy away from taking responsibility for what you build all the way from the prototyping stage through to monitoring and supporting the systems in production.  We want to work with people who share knowledge and learn from their teammates, and who collaborate well in team-based development environments.  If this sounds like you, we welcome you to apply!</p>

<h1 id="helpful-skills" class="anchor-link"><a href="#helpful-skills">Helpful skills</a></h1>
<p>The following traits would be welcome, but are not required:</p>
<ul>
<li>Familiarity with Framework X</li>
<li>Performance analysis and profiling for Database X</li>
<li>Distributed systems infrastructure, messaging systems, infrastructure monitoring</li>
<li>Experience contributing to or managing open source software projects</li>
</ul>

<h1 id="what-its-like-to-work-here" class="anchor-link"><a href="#what-its-like-to-work-here">What it&rsquo;s like to work here</a></h1>
<p>As a member of our software development team, you&rsquo;ll work alongside our Product team to implement new features for our customers.  You&rsquo;ll also help to take care of normal housekeeping practices of writing software like adding tests, improving automation, and improving performance to help keep our operational costs low and development speed high as we scale up our traffic.  We love clean code and smooth operations!</p>
<p>We have team members from all kinds of backgrounds!  Here are some facts about our team.</p>
<ul>
<li>
<p>All of us are effective developers in our domains, but only some have formal education in Computer Science.  We care about your ability to produce good code more than the formal education you might (or might not) have.</p>
</li>
<li>
<p>Some of our developers came to StartupCo with knowledge of relational database query optimization and performance, but most didn&rsquo;t.  We practice this together as part of our regular system improvements and so far it&rsquo;s really helped to increase the database knowledge of our team.</p>
</li>
<li>
<p>We think communication is important.  While our official company language is English, there are people on the team from a total of 14 different countries.  Since we also have some employees working remotely, we highly value written and verbal communication skills.</p>
</li>
<li>
<p>We give our team as much autonomy and trust as possible once they have demonstrated their capabilities.  We make sure to provide our team members with any help needed in improving time management and prioritization skills.</p>
</li>
<li>
<p>Most of our systems are in Language X and Framework Y, but some developers started here without much (or any) experience with either.  We found that after a relatively short time, people who have a solid programming background pick up the details.  Our team members are dedicated to learning and improving.</p>
</li>
</ul>

<h1 id="benefits-of-working-here" class="anchor-link"><a href="#benefits-of-working-here">Benefits of working here</a></h1>
<p>As a new company, StartupCo is working hard to adjust our salaries to market rates in the X area for our developers as we grow.  Our salaries are pretty competitive though, and in addition to cash benefits, we also offer additional perks:</p>
<ul>
<li>
<p>We cover all healthcare insurance costs for our employees and their immediate family, including medical, vision, dental, and a complementary fitness center membership.</p>
</li>
<li>
<p>We offer a robust 401(k) program that matches all your contributions up to 8% of your annual salary.</p>
</li>
<li>
<p>We cover full short-term disability, long-term disability, and life insurance.</p>
</li>
<li>
<p>We offer remote and flexible-time working arrangements.</p>
</li>
<li>
<p>We have full childcare services on-site and an equivalent reimbursement for our remote employees.</p>
</li>
<li>
<p>We have a monthly VR games tournament and picnic for our employees and their families, including any cats.</p>
</li>
<li>
<p>Technical staff get 2 all-expense-paid conference trips per year</p>
</li>
</ul>

<h1 id="apply" class="anchor-link"><a href="#apply">Apply!</a></h1>
<p>Our hiring process is very straightforward.  Once you apply to the job posting via API (we use <a href="https://applybyapi.com">ApplyByAPI</a>), we will contact you personally within 24 hours.  We&rsquo;ll schedule a short 20-minute phone call to chat and assess your verbal communication skills.  This is not a technical screening, fear not!</p>
<p>If you successfully move to the next stage, you&rsquo;ll be given a small 2-4 hour project in which you can demonstrate your development skills.  You will be able to use the language and tooling of your choice.</p>
<p>Lastly, we&rsquo;ll meet for one in-person interview (or video call) to discuss your project and answer any questions you have.</p>
<p>We are a team of great people building a really cool product for great customers.  We&rsquo;d love to have you join us!</p>
</blockquote>

<h1 id="serve-your-applicants" class="anchor-link"><a href="#serve-your-applicants">Serve your applicants</a></h1>
<p>As you can see, a good job description can be a helpful and encouraging way to get interested and suitable candidates to apply for your position.  By being clear about required skills and helpful skills, accurately describing the work without overselling it, and being transparent about your company and hiring process, your job description will provide a great starting point for finding your next ideal technical hire.</p>
<p>In addition to an attractive job description, using a top-of-the-funnel screening tool can help immediately qualify applicants, and also provide a fun way for talented candidates to apply.  You can read about the benefits of <a href="/filtering-for-better-tech-hiring.html">Filtering for better tech hiring</a> in my previous article.  You might also want to learn more about <a href="https://applybyapi.com">ApplyByAPI</a>, the automated way to screen candidates for technical competency and hire better developers.</p>
 ]]></content:encoded></item><item><title>The biggest smallest website</title><link>https://adamdrake.com/the-biggest-smallest-website.html</link><pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/the-biggest-smallest-website.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>I was surfing the web and, as is often the case, I stumbled upon a cool project: the &lt;a href="https://github.com/diracdeltas/FastestWebsiteEver">FastestWebsiteEver&lt;/a>. It&amp;rsquo;s &amp;ldquo;the greatest website to ever fit in a single TCP packet.&amp;rdquo;&lt;/p>
&lt;p>I had a think about that for a minute, and checked out the actual site, and noticed that it&amp;rsquo;s approximately 1130 bytes transferred. Now depending on how fresh you are on your &lt;a href="https://en.wikipedia.org/wiki/OSI_model">OSI Model&lt;/a>, you might remember that there are 7 layers. The data that fits into a single transmissable unit in one layer may be too big for one of the other layers to transmit as a single unit, resulting in fragmentation and reassembly. I thought 1130 bytes sounded rather large for something guaranteed to fit into a single packet (although 1500 bytes is standard MTU for Ethernet), so I decided it might be fun to dig up the old RFCs and have a look at what the TCP and IP specifications say.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>I was surfing the web and, as is often the case, I stumbled upon a cool project: the <a href="https://github.com/diracdeltas/FastestWebsiteEver">FastestWebsiteEver</a>.  It&rsquo;s &ldquo;the greatest website to ever fit in a single TCP packet.&rdquo;</p>
<p>I had a think about that for a minute, and checked out the actual site, and noticed that it&rsquo;s approximately 1130 bytes transferred.  Now depending on how fresh you are on your <a href="https://en.wikipedia.org/wiki/OSI_model">OSI Model</a>, you might remember that there are 7 layers.  The data that fits into a single transmissable unit in one layer may be too big for one of the other layers to transmit as a single unit, resulting in fragmentation and reassembly.  I thought 1130 bytes sounded rather large for something guaranteed to fit into a single packet (although 1500 bytes is standard MTU for Ethernet), so I decided it might be fun to dig up the old RFCs and have a look at what the TCP and IP specifications say.</p>

<h1 id="tcp-and-ip-rfcs" class="anchor-link"><a href="#tcp-and-ip-rfcs">TCP and IP RFCs</a></h1>
<p>One of the original TCP/IP specs, RFC 879, has been updated by <a href="https://tools.ietf.org/html/rfc6691">RFC 6691</a>.  In this RFC, we learn that:</p>
<blockquote>
<p>THE TCP MAXIMUM SEGMENT SIZE IS THE IP MAXIMUM DATAGRAM SIZE MINUS FORTY.</p>
</blockquote>
<p>Well, the maximum IP datagram size is 576 bytes, so we know that the maximum segment size (MSS) for TCP is 536 bytes.  This leaves 20 bytes for minimal TCP headers, and 20 bytes for minimal IP headers.  If we send an IP datagram of 536 bytes, we are guaranteed that the datagram (and the resulting TCP segment) will not be fragmented and will be delivered in a single unit.</p>
<p>Okay.  Let&rsquo;s build a website that fits into 536 bytes!</p>

<h1 id="http-rfc" class="anchor-link"><a href="#http-rfc">HTTP RFC</a></h1>
<p>First, we don&rsquo;t need a full-blown HTTP server for this.  We just need a TCP server that responds with a string of bytes containing the smallest valid HTTP response, and our website content, all of which has to be less than 536 bytes.  We have to respond with a valid HTTP response, but what is that, exactly?</p>
<p>Well, <a href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec6.html">RFC 2616</a> is pretty clear about the format of an HTTP response:</p>
<blockquote>
<p>Response      = Status-Line                      ; Section 6.1</p>
<pre><code>                  *(( general-header        ; Section 4.5

                   | response-header        ; Section 6.2

                   | entity-header ) CRLF)  ; Section 7.1

                  CRLF

                  [ message-body ]          ; Section 7.2
</code></pre>
</blockquote>
<p>That means that the only required element is the the <em>Status-Line</em>.</p>
<blockquote>
<p>Status-Line = HTTP-Version SP Status-Code SP Reason-Phrase CRLF</p>
</blockquote>
<p>Easy enough.  The smallest thing we could send as a response from our TCP server is <code>HTTP/1.1 200 OK\r\n</code>.  That response string is 17 bytes, which cuts our available bytes for the message body down to 519 bytes.  As a reminder of the accounting: we can send 576 bytes total in a single TCP segment, and we must reserve 20 for TCP header, 20 for IP header.  This leaves us 536 bytes for everything else.  We need another 17 bytes for the HTTP response, giving us 536-17=519 bytes.</p>

<h1 id="building-a-tcp-server" class="anchor-link"><a href="#building-a-tcp-server">Building a TCP server</a></h1>
<p>Writing a TCP server is pretty simple in many languages, but I chose to do it in Go.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">main</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;bufio&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;net&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">ip</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">net</span>.<span style="color:#a6e22e">IPv4</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">tcpaddr</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">net</span>.<span style="color:#a6e22e">TCPAddr</span>{<span style="color:#a6e22e">IP</span>: <span style="color:#a6e22e">ip</span>, <span style="color:#a6e22e">Port</span>: <span style="color:#ae81ff">8080</span>}
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">ln</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">net</span>.<span style="color:#a6e22e">ListenTCP</span>(<span style="color:#e6db74">&#34;tcp&#34;</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">tcpaddr</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">httpResponse</span> <span style="color:#f92672">:=</span> []byte(<span style="color:#e6db74">&#34;HTTP/1.1 200 OK\r\n&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">conn</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">ln</span>.<span style="color:#a6e22e">AcceptTCP</span>()
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">conn</span>.<span style="color:#a6e22e">SetNoDelay</span>(<span style="color:#66d9ef">true</span>) <span style="color:#75715e">// Silly windows are silly.  See Nagling.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">go</span> <span style="color:#66d9ef">func</span>(){
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">defer</span> <span style="color:#a6e22e">conn</span>.<span style="color:#a6e22e">Close</span>()
</span></span><span style="display:flex;"><span>            <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">_</span> = <span style="color:#a6e22e">bufio</span>.<span style="color:#a6e22e">NewReader</span>(<span style="color:#a6e22e">conn</span>).<span style="color:#a6e22e">ReadLine</span>()  <span style="color:#75715e">// This is used in the stdlib HTTP server
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#a6e22e">conn</span>.<span style="color:#a6e22e">Write</span>(<span style="color:#a6e22e">httpResponse</span>)
</span></span><span style="display:flex;"><span>        }()
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Most of that is straightforward, but there is one small item which may seem unexpected: <code>conn.SetNoDelay(true)</code>.  What&rsquo;s that about?</p>

<h2 id="nagling-an-aside" class="anchor-link"><a href="#nagling-an-aside">Nagling: an aside</a></h2>
<p>In the old days, before people knew how to write efficient networked applications (wait, is that not true anymore&hellip;?), it was sometimes the case that a TCP packet would need to be transmitted with a very small payload.  As a pathological example, consider a payload of 1 byte.  This would require at least 20 bytes for the IP header, and 20 bytes for the TCP header, just to send 1 byte of data.  Since having 40 to 1 overhead for data transmission is bad, John Nagle decided it would be a good idea to batch the sending of TCP packets.  Hence, we have <a href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle&rsquo;s Algorithm</a>.</p>
<p>The short version is that if you can fit more data into the TCP segment, wait and accumulate before sending anything.  This prioritizes throughput over latency.</p>
<p>For our purposes, since we want the lowest latency and we are carefully constructing our TCP segment, we can disable Nagling on our TCP connections.  This is accomplished in Go by setting <code>SetNoDelay(true)</code> on our connections as they come in.</p>

<h1 id="the-content" class="anchor-link"><a href="#the-content">The content</a></h1>
<p>Now that we have a working server that responds to TCP requests with a valid HTTP response, we can add some content using our remaining 519 bytes.  Since 1 ASCII character is 1 byte, that doesn&rsquo;t leave us much to work with.  It&rsquo;s not even 4 tweets worth of text (well, it&rsquo;s 1.85 tweets after the new limit rolls out).  However, we can compress the content before we send it, allowing us to fit much more into the same 519 bytes!</p>
<p>The downside to using compression is that we have to tell the HTTP client about it.  We&rsquo;ll need to add an encoding header to our HTTP response, which will take up some bytes.  In the old days, it was possible to send raw DEFLATE encoded data to a browser and have it do the decoding by default, but those days are gone now.</p>
<p>We&rsquo;ll have to put our header on a new line, which means we will need to take two bytes for a <code>\r\n</code> in addition to the header itself.  After our header, <code>Content-Encoding: deflate</code>, we also need an additional <code>\r\n</code> at the end of our HTTP response.  In total, the ability to compress the response costs us another 29 bytes.  Now we&rsquo;re down to 490 bytes for content, but it&rsquo;s for <em>compressed</em> content.  Using DEFLATE, we can probably reduce the size by 50% after compression, so if we start with about 1000 bytes, we should be able to compress down to 490.</p>
<p>In the meantime however, here&rsquo;s the updated server with compression:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">main</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;bufio&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;bytes&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;compress/flate&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;log&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;net&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">ip</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">net</span>.<span style="color:#a6e22e">IPv4</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">tcpaddr</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">net</span>.<span style="color:#a6e22e">TCPAddr</span>{<span style="color:#a6e22e">IP</span>: <span style="color:#a6e22e">ip</span>, <span style="color:#a6e22e">Port</span>: <span style="color:#ae81ff">8080</span>}
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">ln</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">net</span>.<span style="color:#a6e22e">ListenTCP</span>(<span style="color:#e6db74">&#34;tcp&#34;</span>, <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">tcpaddr</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">httpResponse</span> <span style="color:#f92672">:=</span> []byte(<span style="color:#e6db74">&#34;HTTP/1.1 200 OK\r\nContent-Encoding: deflate\r\n\r\n&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">resp</span> <span style="color:#f92672">:=</span> <span style="color:#e6db74">&#34;Hello, world!&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">var</span> <span style="color:#a6e22e">buf</span> <span style="color:#a6e22e">bytes</span>.<span style="color:#a6e22e">Buffer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">zw</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">flate</span>.<span style="color:#a6e22e">NewWriter</span>(<span style="color:#f92672">&amp;</span><span style="color:#a6e22e">buf</span>, <span style="color:#a6e22e">flate</span>.<span style="color:#a6e22e">BestCompression</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">err</span> = <span style="color:#a6e22e">zw</span>.<span style="color:#a6e22e">Write</span>([]byte(<span style="color:#a6e22e">resp</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">zw</span>.<span style="color:#a6e22e">Close</span>()  <span style="color:#75715e">// In case buffers need to be flushed
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#a6e22e">compressedBody</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">buf</span>.<span style="color:#a6e22e">Next</span>(<span style="color:#a6e22e">buf</span>.<span style="color:#a6e22e">Len</span>())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">conn</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">ln</span>.<span style="color:#a6e22e">AcceptTCP</span>()
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">conn</span>.<span style="color:#a6e22e">SetNoDelay</span>(<span style="color:#66d9ef">true</span>) <span style="color:#75715e">// Silly windows are silly.  See Nagling.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">go</span> <span style="color:#66d9ef">func</span>(){
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">defer</span> <span style="color:#a6e22e">conn</span>.<span style="color:#a6e22e">Close</span>()
</span></span><span style="display:flex;"><span>            <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">_</span> = <span style="color:#a6e22e">bufio</span>.<span style="color:#a6e22e">NewReader</span>(<span style="color:#a6e22e">conn</span>).<span style="color:#a6e22e">ReadLine</span>()  <span style="color:#75715e">// This is used in the stdlib HTTP server
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#a6e22e">conn</span>.<span style="color:#a6e22e">Write</span>(append(<span style="color:#a6e22e">httpResponse</span>, <span style="color:#a6e22e">compressedBody</span><span style="color:#f92672">...</span>))
</span></span><span style="display:flex;"><span>        }()
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="fin" class="anchor-link"><a href="#fin">Fin</a></h1>
<p>From that point, it&rsquo;s a matter of extending <code>resp</code> until you have the response body you want while still coming in under the 536 total bytes allowed for a single TCP segment.  If you wanted to be extra careful, you could add an if statement to check that the length of <code>compressedBody</code> is less than 536 (the IP datagram body size limit), and exit the program if it isn&rsquo;t.</p>
<p>If you find any issues with the code above or notice something I misinterpreted about the RFCs, do contact me so I can update things.</p>
<p>If you want to see the biggest smallest site, you can visit it at <a href="https://tinysite.adamdrake.com">tinysite.adamdrake.com</a>.</p>
<p>Lastly, I also did a quick TCP server in Rust as well to see if the performance was any better than the Go version, but there wasn&rsquo;t a big difference in this case.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">use</span> std::io::{Read, Write};
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">use</span> std::net::TcpListener;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">use</span> std::thread;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> listener <span style="color:#f92672">=</span> TcpListener::bind(<span style="color:#e6db74">&#34;127.0.0.1:9123&#34;</span>).unwrap();
</span></span><span style="display:flex;"><span>    println!(<span style="color:#e6db74">&#34;listening started, ready to accept&#34;</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> stream <span style="color:#66d9ef">in</span> listener.incoming() {
</span></span><span style="display:flex;"><span>        thread::spawn(<span style="color:#f92672">||</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> stream <span style="color:#f92672">=</span> stream.unwrap();
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">let</span> _ <span style="color:#f92672">=</span> stream.read(<span style="color:#f92672">&amp;</span><span style="color:#66d9ef">mut</span> [<span style="color:#ae81ff">0</span>; <span style="color:#ae81ff">128</span>]);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            stream.write(<span style="color:#e6db74">b</span><span style="color:#e6db74">&#34;Hello World</span><span style="color:#ae81ff">\r\n</span><span style="color:#e6db74">&#34;</span>).unwrap();
</span></span><span style="display:flex;"><span>        });
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div> ]]></content:encoded></item><item><title>From Enterprise Decentralization, to Tokenization, and Beyond!</title><link>https://adamdrake.com/from-enterprise-decentralization-to-tokenization-and-beyond.html</link><pubDate>Wed, 04 Oct 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/from-enterprise-decentralization-to-tokenization-and-beyond.html</guid><description>&lt;p>&lt;em>Note: This is post which I co-authord with Don Gossman and is cross-posted to the &lt;a href="https://blog.oceanprotocol.com/from-enterprise-decentralization-to-tokenization-and-beyond-abeaab786e14">Ocean Protocol site&lt;/a>.&lt;/em>&lt;/p>
&lt;p>We are putting together a blog series that tackles the lowly subject of enterprise transformation. Of particular importance will be data decentralization and how it will drastically change the way in which we interact and leverage data assets in the not-too-distant future (teaser: see Ocean Protocol). Simple topic, we know.&lt;/p>
&lt;p>In this first post, we will focus on the pitfalls of centralizing and consolidating IT capabilities, and what alternatives exist.&lt;/p></description><content:encoded><![CDATA[ <p><em>Note: This is post which I co-authord with Don Gossman and is cross-posted to the <a href="https://blog.oceanprotocol.com/from-enterprise-decentralization-to-tokenization-and-beyond-abeaab786e14">Ocean Protocol site</a>.</em></p>
<p>We are putting together a blog series that tackles the lowly subject of enterprise transformation. Of particular importance will be data decentralization and how it will drastically change the way in which we interact and leverage data assets in the not-too-distant future (teaser: see Ocean Protocol). Simple topic, we know.</p>
<p>In this first post, we will focus on the pitfalls of centralizing and consolidating IT capabilities, and what alternatives exist.</p>

<h1 id="first-off-quit-centralizing" class="anchor-link"><a href="#first-off-quit-centralizing">First Off, Quit Centralizing</a></h1>
<p>Tech centralization, in many organizational and technical contexts, is quickly becoming a footnote in the annals of IT history. There are times and places where it is the best approach, and of course the pendulum has swung from centralized to decentralized and back again numerous times over the years (recall the days of PC&rsquo;s on every desk which came after mainframes and dumb terminals). During the reign of monolithic vendors during the late 90&rsquo;s and naughts, the arguments in favor of centralization were clear: standardize and consolidate the technology stacks across the organization to increase economies of scale and encourage reuse. Once complete, then set to work on consolidating the resource pool in order to limit redundancy and under-utilization.</p>
<p>This tactic used to make a lot of sense. But in a digital world, the approach often gets lost in translation.</p>
<p>There are at least three main problems with centralization as it exists now:</p>
<ol>
<li>It creates bottlenecks for solution building blocks like tin, compute, storage, and personnel, because you need to go through centralized services that are servicing the demands of the entire enterprise (i.e. &ldquo;Did you raise a ticket? Good. Now get in line.&rdquo;);</li>
<li>It limits deployment capabilities through the standardization of toolsets and associated skillsets (i.e. &ldquo;We&rsquo;d love to build that, but our enterprise stack doesn&rsquo;t support the functionality, and the tech you&rsquo;ve requested isn&rsquo;t approved.&rdquo;); and,</li>
<li>It places an undue burden on IT as teams are under pressure to rein in costs (&ldquo;Hey IT, you&rsquo;re doing a great job! So great, in fact, that we&rsquo;re going to reduce your OpEx budget by 15% next year!&rdquo;).</li>
</ol>
<p>The first two problems can be remedied by changing the approach from one of standardization and consolidation to one of agility and &ldquo;best-of-breed&rdquo;. The third is a product of perception. IT is still viewed as a sink across most enterprises, and, as such, is constantly under pressure to reduce its costs. Generally, this cost-cutting manifests in one of two ways:</p>
<ol>
<li>Reducing IT headcount; or,</li>
<li>Shifting to fixed cost models that leverage contractors or Service Providers (SP&rsquo;s) whose primary function is staff augmentation.</li>
</ol>
<p>The result? IT hitting their annual targets, and a market that&rsquo;s a boon for contractors and SP&rsquo;s alike. Sweet! Done and dusted! Everyone can go home now.</p>
<p>Not so fast! This approach actually ends up creating a battle to the bottom between IT, procurement, and Service Providers as they all do whatever it takes to lower costs. The net effect is that project allocation favors those willing to pull their proverbial pants down the farthest, instead of those that can actually get the job done.</p>
<p>Centralization also tends to favor a distinct delineation between development and BAU (Business as Usual) teams. Traditionally, organizations kept their developer teams separate from their operational support teams. This siloed pattern is the antithesis of Agile and, more specifically, the DevOps approach. Solutions should be developed and supported by the same core teams, not thrown over the fence to an unsuspecting engineering or operations team with constrained bandwidth and possibly little-to-no skillsets for supporting a new solution.</p>
<p>Ultimately, centralization as an exercise in maximizing efficiency can lead to prioritizing &ldquo;keeping the lights on&rdquo; initiatives over everything else, especially in severely constrained environments. This goes for both operations, and new product initiatives. What&rsquo;s the best way to ensure the system doesn&rsquo;t go down? Never deploy new things! The result is little to no innovation because the capabilities and appetite simply do not exist. A strategy that served the enterprise well for decades has, unfortunately, passed its &ldquo;best before&rdquo; date. Companies must now be able to iterate their services and respond to demands as quickly as possible, or face diminishing returns and possible demise.</p>

<h1 id="instead-decentralize" class="anchor-link"><a href="#instead-decentralize">Instead, Decentralize</a></h1>
<p>&ldquo;What&rsquo;s the alternative?&rdquo; you say. We&rsquo;re glad you asked!</p>
<p>It&rsquo;s (drum roll please) Decentralization!</p>
<p>The good news is, the decentralize bug is catching on. We see this through enterprise adoption of the cloud, as well as through the adoption of FOSS (Free and Open Source Software). Even five years ago, the mere suggestion of leveraging the cloud and/or FOSS to build enterprise-grade solutions was enough to get you shunned! Now, the cloud and FOSS are everywhere, from the databases used to host data, to the compute engines used to process data, to the API&rsquo;s used to connect to data, as well as the portals used to consume it.</p>
<p>By decentralizing, we can remove the shackles of conformity and consolidation. We can scale compute through the power of MPP (Multi-Parallel Processing) on low-cost, commodity hardware. We can reduce storage .costs by storing data in the cloud, and we can tap into skillsets from resources outside the traditional pools or partnerships mandated in the past.</p>
<p>But these primatives are just the beginning, and only provide the figurative spring board in our journey towards full decentralization. In reality, current &ldquo;decentralization&rdquo; techniques are, in many ways, limited and simply shift the centralization and single point of failure from one place to another. Consider Big Data ecosystems confined to single data centers, or datasets deployed to single cloud providers (i.e. AWS vs. Azure vs. GCP. So many choices, yet so few answers!). We&rsquo;re heading in the right direction, but the fact is, we&rsquo;ve only just left the starting blocks.</p>
<p>In order to jump start the migration to full decentralization, there are two things we can do.</p>

<h1 id="productize" class="anchor-link"><a href="#productize">Productize</a></h1>
<p>Once decentralization begins, the next step is to productize. And no, we don&rsquo;t mean adopting a product-centric macro approach over a customer-centric one. What we mean is, technology solutions should be developed as unique &ldquo;products&rdquo;, in which a single product team made up of business AND IT owns the solution and all of its capabilities from end-to-end. In the years to come, IT infrastructure will become increasingly commoditized, but for now we must continue to consider both components.</p>
<p>Let us elaborate</p>
<p>You may have seen consulting collateral identifying different levels of data or analytic maturity within an organization. Adam has a great take on this sophistication model, leveraging the Kardashev Scale but spinning it for the data domain to create the aptly named &ldquo;Kardashev Scale for Data&rdquo;. Basically, there are three types or levels of data sophistication within any given organization:</p>
<ul>
<li>Type 1â€Š - Essential needs and legal requirements.</li>
<li>Type 2â€Š - Operational reporting, KPI&rsquo;s, DWH, Fragmentation.</li>
<li>Type 3â€Š - Data for the future, BI for decision-support, self-service and democratization, data org. focused on products and hard problems. No SQL monkeys.</li>
</ul>
<p>It&rsquo;s the last level on the journey to data maturity that&rsquo;s of interest to us, as this is when the focus shifts from being reactionary to being progressive. It&rsquo;s the point at which the focal point changes to one of products, and not just solutions cobbled together. This is significant because it means the institution is mature enough for the interests of both business and IT to align around the creation of unique value propositions. It also signifies that IT is no longer viewed as subservient to business, but as a partner. The entire value proposition is the result of a cohesive unit working together in concert, defining the solution and implementation plan, and overseeing delivery and operations, from soup to nuts.</p>
<p>In other words, productization requires Business and IT, development and operations, working together to deliver unique solutions. There&rsquo;s no sharing of resources across projects or programmes. It&rsquo;s a bootstrapped approach with a start-up like mentality where if you want more, you go out and get it and do it yourself.</p>
<p>How does this work? Please allow us to explain.</p>
<p>In this paradigm, business should always be the driver for new products and services, though IT can act as a catalyst. The reason? Because it&rsquo;s the business&rsquo; job, plain and simple. IT can act as a facilitator, but it&rsquo;s the LoB&rsquo;s responsibility to understand the market and come up with solutions. The paradigm ultimately relies on pitching the product concept from end-to-end, perhaps to an internal innovation group, and having the business, not IT, fight for budget. If a solution is deemed relevant, let business come up with the money to build it. Once the budget is secured, it then becomes IT&rsquo;s responsibility to actualize the solution. It must also be understood that this is a team effort in which business and IT are responsible for the overall success of the product. If the product fails, then only the product team is accountable with little to no finger pointing.</p>
<p>This type of approach generally allows for more innovative ideas to be tested and deployed than its centralization counterpart. There are a multitude of reasons for this. First, it predicates the inclusion of both the business and IT within the product team at inception in order to spec out the solution, determine resource requirements, etc. As a result, you don&rsquo;t just have business tossing IT a list of requirements saying, &ldquo;Here, go build this. Let us know when you&rsquo;re done.&rdquo;</p>
<p>Second, only the product team is responsible for staffing and cost allocation. That means the team can acquire who they want based on skillsets and qualifications, rather than who is available from the internal IT pool, or from the lowest cost service provider. This alone drastically improves a product&rsquo;s overall chances of success by bringing in the best available talent.</p>
<p>Third, the approach encourages product evolution. Let&rsquo;s be honestâ€Š - hubris and ego are fantastic motivators. If you&rsquo;re a product owner and a competing solution comes out, either internally or externally, there&rsquo;s a good chance that you will want to iterate a new version of your solution to one-up the competition. Actually, if you&rsquo;re a responsible product owner, this scenario never happens because you would constantly iterate your solution in order to maintain relevance.</p>
<p>Fourth, productization lends itself well to Agile methodology. We are firm believers that Agile is superior to Waterfall in almost all instances of delivery. We also abide by a <!-- raw HTML omitted --> approach, which means getting the smallest, relevant component of any given solution into production as quickly as possible, even if it&rsquo;s a hack job. This establishes a foothold in production (often a win in-and-of itself in large multinationals) that can become a beacon around which the team can rally its efforts.</p>
<p>Lastly, productization necessitates senior level sponsorship. Good luck receiving proper funding without executive stakeholders advocating the solution. Once budget is obtained, these stakeholders become benefactors overseeing the success of the project, helping the team navigate institutional bureaucracy and breaking down barriers when required.</p>

<h1 id="then-tokenize" class="anchor-link"><a href="#then-tokenize">Then Tokenize</a></h1>
<p>So you&rsquo;ve built a decentralized product from soup-to-nuts, and now your team effectively &ldquo;owns&rdquo; the solution platformâ€Š - the compute, the storage/persistence, the UX and UI, the API&rsquo;s, the dataâ€Š - along with the resources that built, as well as support, the solution. What do you do now? Well, you could sit back and reap the rewards of your killer app or service, or you can keep on evolving.</p>
<p>Ask yourself this: Is there any dormant capability in your solution? Do you have extra storage capacity, or latent compute? Did your team write some amazing code that could easily be refactored and applied to other use cases, or a framework that could be leveraged to improve processes and solutions elsewhere? Or maybe you created the holy grail of datasets that wraps aggregated transactional and channel feedback data in a warm CRM blanket for full featured customer insights and analytics? If the answer to any of these questions is yes, then boy do we have a proposition for you! (/sðŸ˜‰)</p>
<p>What if we told you there was a way to reduce the friction of commoditizing your assets? It&rsquo;s not just the app or service you created that offers value, but also the individual capabilities that make up the solution. Through tokenization, you can realize the value of the unique solution capabilities by trading access to those capabilities within a network of like-minded participants.</p>
<p>Let&rsquo;s explore this opportunity a bit more.</p>
<p>In an ideal world, your platform will hum along at fully optimized levels at all times. In reality, however, there could be times when resources are under-utilized (relative to established solution benchmarks). For instance, there could be periods of idle computation, when extra CPU/GPU/TPU bandwidth is available for use. What if these components were tokenized such that you could &ldquo;sell&rdquo; their usage to the highest bidder? This is the supply-side of your network.</p>
<p>Now let&rsquo;s say there&rsquo;s a team that needs massive compute capabilities, but only for a limited time, and only sporadically. A good example would be Finance departments in large, institutional banks that are required to do monthly, quarterly, and annual regulatory reporting to governing bodies. Creating a compute platform just for Finance might be overkill. Centralizing the compute is an option, but because it&rsquo;s communal, you&rsquo;re probably subject to &ldquo;first come, first served&rdquo; dynamics. However, if Finance has tokens, they could effectively pay to prioritize their position, or even reserve the compute, when they need it. This is the demand side of your network.</p>
<p>The last piece of the puzzle is the trustful transfer of tokens across the network from the demand side to the supply side. The good news is, there already exists a crypto-economic mechanism to handle this handshake without the need for expensive intermediary processing. That solution? Blockchain!</p>
<p>Bringing all these components together is the network protocol. The beauty is, these networks could exist in the wide-open yonder of the public domain, or controlled behind a firewall in an enterprise setting. The substrates remain the same for both, only the user base changes.</p>
<p>Please take a moment to digest this, we now have is a mechanism that promotes the tokenization of capabilities at their most granular level, the same mechanism that can inherently stores the usage metrics of these capabilities through immutable records, combined with a network that connects capability producers with consumers.</p>
<p>What we&rsquo;re talking about here is the potential future of computer networking. This is also, in a nutshell, what we want to do with Ocean. With Ocean, we are creating a platform that links data producers to data consumers, while providing, through blockchain, all of the requisite data security, privacy, and provenance capabilities already baked in. And because the network has blockchain at its core, Ocean has a foundation that underpins the network&rsquo;s tokens, providing the ability to monetize assets all the way down, and all the way up! Not only that, but because the system is decentralized by design, we can avoid many of the classic issues with centralizing, well, anything!</p>
<p>(Boom! Mind.Blown.)</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>The potential of decentralization in conjunction with blockchain is astonishing. We are talking about establishing the ability to distribute capabilities that maximize performance and minimize cost, while providing a mechanism that facilitates maximum resource utilization with the transparent quantification and monetization of usage. This paradigm shift has the potential to disrupt not just the way we distribute and leverage data, but the way we fundamentally interact.</p>
<p>Over the course of the next few blog posts, we will delve deeper into the world of enterprise tokenization, and what this means for the future of data platforms, as well as enterprises themselves.</p>

<h1 id="tldr" class="anchor-link"><a href="#tldr">TL;DR</a></h1>
<p>Centralization = Baaaaad (not really, but sort of.)</p>
<p>Decentralization = Goooood (#thumbsup)</p>
<p>Productization = Even Better (now we&rsquo;re talking!)</p>
<p>Tokenization = Data + Compute + Storage + Network + Tokens = $$$$$$ (what the what?!?)</p>
 ]]></content:encoded></item><item><title>Filtering for better tech hiring</title><link>https://adamdrake.com/filtering-for-better-tech-hiring.html</link><pubDate>Wed, 06 Sep 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/filtering-for-better-tech-hiring.html</guid><description>&lt;h1 id="filtering-for-better-tech" class="anchor-link">&lt;a href="#filtering-for-better-tech">Filtering for better tech&lt;/a>&lt;/h1>
&lt;p>In a previous article, we discussed a redesigned hiring process based on generating inbound demand coupled with effective automated filters. Ensuring that this process is streamlined requires further filters that determine the quality of your candidates with minimum friction at each step from application to employment. In this post, we&amp;rsquo;ll talk a bit more about the steps in that filtering process, how to design them, and what to consider along the way.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="filtering-for-better-tech" class="anchor-link"><a href="#filtering-for-better-tech">Filtering for better tech</a></h1>
<p>In a previous article, we discussed a redesigned hiring process based on generating inbound demand coupled with effective automated filters.  Ensuring that this process is streamlined requires further filters that determine the quality of your candidates with minimum friction at each step from application to employment.  In this post, we&rsquo;ll talk a bit more about the steps in that filtering process, how to design them, and what to consider along the way.</p>
<p>The goal of designing these filters is to provide candidates with ways to demonstrate their capabilities and potential.  It is also to allow both the candidate and the company to determine if there is compatibility between the working environment the candidate prefers and the working environment that the company provides.</p>
<p>The basic hiring process is as follows:</p>
<ol>
<li>Automated filtering</li>
<li>Phone screen</li>
<li>Short tech project</li>
<li>In-person or videoconference interview</li>
<li>Onboarding</li>
</ol>
<p>Before we discuss screening, we should first consider how the candidate is exposed to the job opening and factors that might influence their decision to apply.</p>

<h2 id="the-applicant-is-your-customer" class="anchor-link"><a href="#the-applicant-is-your-customer">The applicant is your customer</a></h2>
<p>With the wide availability and accessibility of job boards and job application resources available these days, it&rsquo;s highly likely that your ideal candidate has applied to more than one position, including yours. It serves your company well then to treat the applicant as if they are your customer.  Nothing will kill their consideration of your offered position faster than a tedious or disorganized interview experience.  It&rsquo;s important to remember that while tech and HR staff are being paid for their time, the candidate is donating their time in order to be considered for a position with your company.  This fact should be respected throughout the screening and interview process.</p>
<p>Not only does an efficient and time-considerate interview process make things easier on your HR staff, it also provides the candidate with a solid first impression of the inner workings of your company.  This impression greatly affects their engagement as an employee in the long run.</p>
<p>As a practical application of this, I often require that companies provide go/no-go feedback to a candidate within 24 hours of the completion of a step in the hiring process.  Don&rsquo;t keep candidates waiting on the back burner while you evaluate others.  With an effective hiring process and robust inbound recruiting, holding candidates in limbo is unnecessary.  Regardless, it only reflects negatively on you, your company, and your team.</p>

<h2 id="the-posting" class="anchor-link"><a href="#the-posting">The posting</a></h2>
<p>A few considerations will affect the success of our job posting.  The challenge is to create a posting that attracts the best possible talent to apply, without unintentionally discouraging any candidates based on genetic or social factors.  With mindful wording, we can ensure that possible candidates are not deciding to exclude themselves from applying.</p>
<p>Some general points to consider and things to avoid:</p>
<ul>
<li>
<p>Avoid using exclusionary language such as, &ldquo;If you are X, Y, or Z, then this role isn&rsquo;t for you.&rdquo;  Instead, use inclusive terms and describe the qualities of the candidates you seek.</p>
</li>
<li>
<p>Avoid describing your team with phrases such as &ldquo;dynamic&rdquo; or &ldquo;agile,&rdquo; or stating that you seek candidates with a &ldquo;founder&rsquo;s mentality.&rdquo;  Experienced people know those are all euphemisms for a chaotic and unproductive environment where people are overworked.  Unless you&rsquo;re offering double-digit common stock allocations, it&rsquo;s unreasonable to expect candidates to have the mentality of a founder.  They aren&rsquo;t one.</p>
</li>
<li>
<p>Be aware that anything you list as &ldquo;preferred&rdquo; is likely to be interpreted as &ldquo;required.&rdquo;  To the extent possible, avoid listing any preferences at all.  Instead, consider framing it as a list of topics that your ideal candidate will have the opportunity to learn, if they aren&rsquo;t already familiar with them.</p>
</li>
<li>
<p>Avoid overselling the position, or attempting to present it as more exciting or complicated than it is.  Describe the real work.  If you are unsure of the real work, talk to a few people who are currently performing well in the role and ask them to describe their normal day.  Use the overlap of their accounts to form a picture of the common tasks of the role.  Many HR professionals I&rsquo;ve encountered seem to believe that they need to juice up job descriptions to excite and entice candidates.  This only serves to cause qualified people to feel like they don&rsquo;t measure up.  It is of more importance to talk about the vision for the product and the technology.  Emphasize that you want to hire people who want to grow alongside the company as these product and technological advances transpire.</p>
</li>
</ul>
<p>Having created an inviting application environment and job posting, we&rsquo;re now prepared to discuss filtering and screening our candidate pool.</p>

<h2 id="step-1-filter-at-the-top-of-the-funnel" class="anchor-link"><a href="#step-1-filter-at-the-top-of-the-funnel">Step 1: Filter at the top of the funnel</a></h2>
<p>In poorly designed hiring processes, the onus is on the recruiter (or a company&rsquo;s founding members) to facilitate the initial candidate screening process.  This necessitates hours of human effort that is ultimately fruitless when spent on candidates who turn out to be lacking in fundamental development skills.  In our previous article, <a href="/rethinking-hiring.html">Rethink hiring: how automation helps tech startups get ahead</a>, we discussed how to redesign the hiring process to improve this initial screening.</p>
<p>The first step is a top-of-the-funnel filter that requires no human involvement.  This has the benefit of offering a more accurate and relevant pre-screening than human opinion may provide.  Since the automated screen accounts only for the ability to interact with APIs and no other factors that may, intentionally or subconsciously, cause exclusion, you can be certain that there is nothing preventing potentially well-suited candidates from reaching you.</p>
<p>With this redesigned process in place for initial applications, the focus of human effort is no longer on outbound recruiting, but on generating inbound leads.  Following the success of your team&rsquo;s outreach and community building, you&rsquo;ll still need a reliable screening process to help narrow down your hiring decisions.  Since the basic capability of interacting with APIs has already been accounted for, your further screening can focus not on evaluating basic skills, but on discovering the candidate&rsquo;s individual suitability for the position through relevant checks and projects.</p>

<h2 id="step-2-phone-screening" class="anchor-link"><a href="#step-2-phone-screening">Step 2: Phone screening</a></h2>
<p>This step is best executed as a phone call lasting no more than 20 minutes.  It can be completed by HR staff, or even an outsourced service.  The purpose of this screen is solely to evaluate the candidate&rsquo;s verbal communication skills.  It&rsquo;s okay to be upfront about the goal and just have a friendly conversation.</p>
<p>I often caution against underestimating the value of this step.  Contrary to popular belief, amazing products are not built by isolated geniuses writing code.  They are collaboratively created by knowledgeable developers who work well with their teammates and with colleagues in other departments.  Communication is critical to success in modern technical teams.</p>
<p>Ask the candidate to explain a recent work or side project, and to elaborate on thought processes and evaluate results.  The conversation should be sufficient to evaluate whether the person can communicate effectively as part of a team.  If interviewing for a senior position, ask them to describe a situation in which they had to communicate bad news or fire someone.  Make each question about the candidate, and use the opportunity to learn more about them as a person.  If they have questions about the role, you may choose to answer them, but keep in mind that this step in the process is intended to evaluate their ability to communicate things to others.</p>

<h2 id="step-3-complete-a-2-4-hour-tech-challenge" class="anchor-link"><a href="#step-3-complete-a-2-4-hour-tech-challenge">Step 3: Complete a 2-4 hour tech challenge</a></h2>
<p>At this stage of the interview process, the candidate has already been evaluated for basic technical competency and communication skills.  Your company should have a general idea of whether or not your staff might enjoy working with them from a personality perspective.  The goal of this challenge will be to evaluate the candidate&rsquo;s technical skills.</p>
<p>It&rsquo;s a waste of time to rely on contrived measures like whiteboard coding or algorithm tests in order to evaluate development skills.  Such tests are almost entirely irrelevant to the majority of development work, and likely do not represent the day-to-day challenges the candidate will face with your company.  Instead, it&rsquo;s up to your company to create a relevant and comprehensive tech challenge.  It should be demonstrative of the work that the candidate will be expected to do in the role they&rsquo;re applying for.  The time to build something to satisfy the challenge should take no more than 2-4 hours of the candidate&rsquo;s time.</p>
<p>In order to ensure that the task is representative and fits within the general time range, have some of your technical staff who are involved in hiring complete the challenge themselves.  If they cannot, then it&rsquo;s likely the challenge is either too difficult or too extensive.  Ask your staff to recall their level of ability when they were hired.  Have them use that knowledge to provide constructive feedback on the design of the challenge project.</p>
<p>You may choose to integrate technologies that your company uses, or give the candidate a chance to display their own creativity and style.  Whatever the challenge, it should be unique to your company&rsquo;s field.  The scope should be narrow enough that there is no concern on the part of the candidate that the company will simply take their code and use it in a company project without compensating them.   There should be zero concern that your company is attempting to crowdsource solutions to existing technical problems  The challenge should not implement something new that the company has never worked on before.</p>
<p>The goal is to gain an impression of the candidate&rsquo;s process when it comes to building software.  The evaluation of their work should include basic checks for things like copy-pasting from Stack Overflow, and if their code compiles and runs as intended.  Further, you can evaluate how they handle comments, automated testing, monitoring, deployment (e.g., docker/docker-compose), database interaction, performance, profiling, and anything else your company specifically values.</p>
<p>I&rsquo;ll provide a concrete example.  For some data science/engineering positions, you may ask candidates to build up a processing system that fits the following criteria:</p>
<ol>
<li>It takes a JSON or CSV file of arbitrary size and with arbitrary keys/fields.</li>
<li>It processes each record using all available CPU cores, and store the results in a SQLite database.</li>
</ol>
<p>This example is essentially an examination of whether the candidate understands that they cannot do things like read the whole file into memory (instead, they should use per-record/stream processing).  Since candidates must use all cores, this challenge should lead to consideration of topics such as parallelism, concurrency, queuing, and shared state/stateless processing.  Developers who are familiar with these topics would find this to be a very straightforward task, making it surprisingly useful for filtering out people who may not be effective in a data engineering/science role.  A project such as this serves our purposes of evaluating and screening applicants without being overly time-consuming nor overly advanced.</p>
<p>Ensure that senior devs understand how to do code reviews on the challenge, and which factors are to be considered a fail versus simply requiring further discussion with the candidate.  The project should be judged on the expected capabilities of a person who is entering the role, not compared to those of an experienced senior who might be nearing promotion.  Ensure that the evaluation is held to high standard.  Anyone who meets that standard should be invited for an in-person interview.</p>

<h2 id="step-4-the-in-person-interview-or-for-remote-hires-final-phone-interview" class="anchor-link"><a href="#step-4-the-in-person-interview-or-for-remote-hires-final-phone-interview">Step 4: The in-person interview (or for remote hires: final phone interview)</a></h2>
<p>At this stage of the process, all the necessary checks have been completed.  The candidate has demonstrated the communication skills and technical competencies required for the role.  Barring any last-minute red flags, your company should be comfortable hiring this person.  The objective of the interview is to have some in-depth conversation to determine if any dealbreakers arise, and if none do, to offer the candidate the position.</p>
<p>In keeping with the goal of making the process as fast as possible for the candidate, have a contract prepared beforehand.  Following the interview, have your decision makers give a quick thumbs-up or thumbs-down vote.  If it is decided that the candidate should be hired, offer them the contract right away.  It is important and in your company&rsquo;s best interest to emphasize that the terms are open to negotiation.  Some people, especially strong introverts and female candidates, are statistically less likely to negotiate offers confidently on the spot and in the moment.  To take advantage of that fact is unfair and will reflect poorly on you, the company, and the team.  To ensure the long-term job satisfaction and retention of your new hire, it is prudent to invite their input for a fair and equitable environment.  Once you&rsquo;ve emphasized that it is open for negotiation, and ask the candidate to consider the offer and give a reasonable deadline for them to return with their decision or counterproposal.</p>

<h2 id="step-5-onboarding" class="anchor-link"><a href="#step-5-onboarding">Step 5: Onboarding</a></h2>
<p>Now that you&rsquo;ve successfully chosen and secured your new hire, it&rsquo;s time to consider onboarding.  Onboarding is critically important in ensuring that the employees you&rsquo;re hiring are comfortable and productive in their new environment.  Ensure that you have the proper materials and documentation to assist candidates during the onboarding process.  It is common for startups to want to rapidly increase their headcount, but without established onboarding practices to support a strong company culture, rushing is almost universally harmful.  Poor onboarding results in a fragmented and unproductive company.  You&rsquo;ll have better output from your teams if you hire at a sustainable pace that allows team standards to be kept high.  If too many people are quickly onboarded to teams with weak company culture, standards are lost and chaos ensues.</p>
<p>Many companies consider onboarding to be a process that starts on the candidate&rsquo;s first day as a new employee.  While that&rsquo;s true to some extent, there&rsquo;s no reason to wait that long.  If you have documentation prepared, provide it to the candidate at the soonest possible time so that they can start familiarizing themselves with the state of things.  For technical hires, this documentation typically consists of system architecture diagrams and documentation, operation flows, and coding standards.  Providing onboarding materials at the earliest opportunity also gives your candidate the chance to review them when they are most excited about their new role.  This can further increase engagement, for the benefit of all.</p>
<p>Additionally, if you are hiring multiple candidates, consider having them start in cohorts.  Everyone comes from different backgrounds, so take full advantage of the opportunity to clearly communicate how things work.  Having a number of technical candidates simultaneously exposed to the same information and processes helps ensure consistent standards when they begin making contributions to the company.  This is the best opportunity to discuss and instill company standards in all areas.</p>

<h2 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h2>
<p>When executing each step of your hiring process, constantly consider the effectiveness of the steps you&rsquo;ve designed.  Like any other process, prevent stagnation by evaluating your successes and improving wherever possible.  Keep in mind that the steps suggested here are a general guide and starting point.  Your company&rsquo;s own unique culture should be on prominent display to candidates throughout the hiring process, allowing the best possible chance of a compatible partnership.  With an inviting, effective screening process that celebrates your company&rsquo;s culture, hiring can be more efficient, sustainable, and successful.</p>
 ]]></content:encoded></item><item><title>Rethinking hiring</title><link>https://adamdrake.com/rethinking-hiring.html</link><pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/rethinking-hiring.html</guid><description>&lt;h1 id="rethink-hiring-how-automation-helps-tech-startups-get-ahead" class="anchor-link">&lt;a href="#rethink-hiring-how-automation-helps-tech-startups-get-ahead">Rethink hiring: how automation helps tech startups get ahead&lt;/a>&lt;/h1>
&lt;p>Hiring is almost always difficult, especially when the hiring process isn&amp;rsquo;t designed in a way that supports the company&amp;rsquo;s objectives. In this article I&amp;rsquo;ll outline a few key points to imagining and redesigning the hiring process. We&amp;rsquo;ll discuss a focus on generating inbound applicant flow, minimizing steps in the hiring process by maximizing information gained at each step, and increasing use of automation throughout. By using these considerations to streamline technical filtering, companies can greatly reduce effort on the part of developers and HR staff. With an improved candidate pool and streamlined process, companies hire more effective and engaged tech staff and support their long-term growth goals.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="rethink-hiring-how-automation-helps-tech-startups-get-ahead" class="anchor-link"><a href="#rethink-hiring-how-automation-helps-tech-startups-get-ahead">Rethink hiring: how automation helps tech startups get ahead</a></h1>
<p>Hiring is almost always difficult, especially when the hiring process isn&rsquo;t designed in a way that supports the company&rsquo;s objectives.  In this article I&rsquo;ll outline a few key points to imagining and redesigning the hiring process.  We&rsquo;ll discuss a focus on generating inbound applicant flow, minimizing steps in the hiring process by maximizing information gained at each step, and increasing use of automation throughout.  By using these considerations to streamline technical filtering, companies can greatly reduce effort on the part of developers and HR staff.  With an improved candidate pool and streamlined process, companies hire more effective and engaged tech staff and support their long-term growth goals.</p>

<h2 id="designing-the-hiring-process" class="anchor-link"><a href="#designing-the-hiring-process">Designing the hiring process</a></h2>
<p>An effective hiring process is built on the least number of steps necessary to attract and screen candidates.  In this and upcoming articles, I&rsquo;ll detail the steps that I&rsquo;ve seen work very well at many growth-stage startups.  These are:</p>
<ol>
<li>Generating awareness and inbound demand</li>
<li>Automated filtering</li>
<li>Phone screen</li>
<li>Short tech project</li>
<li>In-person or video conference interview</li>
</ol>
<p>When designing the hiring process, ensure that the candidate feels engaged and valued.  A candidate&rsquo;s good experience while progressing through hiring translates to an engaged employee down the line.  Recall that the candidate is doing all of this work on their own time, unlike a company&rsquo;s HR staff or developers who are paid to spend time on hiring.  Make the entire hiring process transparent (e.g., post it on your company&rsquo;s website) and ensure that responses to candidates are fast.  I typically advise companies to have a limit of 24 hours for sending responses to candidates to let them know whether or not they will continue to the next step of the hiring process.</p>

<h2 id="generating-awareness" class="anchor-link"><a href="#generating-awareness">Generating awareness</a></h2>
<p>In a startup&rsquo;s early days, recruiting is primarily an outbound activity done by the initial tech hires, or cofounders.  While this may work well for a company of up to a few dozen employees, it&rsquo;s not a sustainable strategy as the company grows.  When personal networks are exhausted, outbound recruiting becomes increasingly impractical.</p>
<p>Relying on hired HR recruiters, internal or external, has its drawbacks when it comes to hunting potential candidates, as recruiters rarely have the technical background necessary to evaluate the capabilities of the people they&rsquo;re recruiting.  Their efforts are more effective when focused on building your company&rsquo;s brand and reach in the communities where your potential candidates are found.  In the same vein, the effectiveness of recruiters or HR staff is best measured by how their efforts in community building and other outreach activities generate inbound demand, rather than the number of candidates they&rsquo;ve contacted or resumes they&rsquo;ve solicited.  The number of unsolicited resumes received is a much better indicator of scalable HR success, as it serves as a measure of your inbound demand.</p>
<p>One way in which HR staff can help generate inbound demand is by organizing meetups and events.  Hosting meetups that entice fresh graduates from local universities is a great way to inform the next wave of job-seekers about your company&rsquo;s brand and culture.  Organizing talks by your company&rsquo;s staff at community meetups allows your company to display credibility and gain a following.  Any activities that increase your company&rsquo;s exposure and build a community surrounding your culture will be helpful in growing inbound demand.</p>

<h3 id="organizing-meetups" class="anchor-link"><a href="#organizing-meetups">Organizing meetups</a></h3>
<p>It is critical that meetups hosted or organized by your company seek to make a genuine contribution to the community on the whole, rather than being a blatant marketing effort.  It would spoil the environment to have HR staff collecting business cards, or asking attendees to sign up for mailing lists, or similar behavior.  If someone from the company is giving a talk at an event, ensure that it is focused on describing how your company solved an interesting tech problem, and that it offers advice to others who may be encountering similar issues.</p>
<p>That said, use this opportunity to showcase your company&rsquo;s culture, innovations, and staff.  Encouraging interaction, offering food, and setting up demonstrations of interesting technology are all ways to have fun with your event.</p>

<h3 id="publishing" class="anchor-link"><a href="#publishing">Publishing</a></h3>
<p>Additionally, starting an engineering blog highlighting the challenges that your company has faced and overcome is a great way to create relevancy, signal boost, and also give back to the community.  Don&rsquo;t be afraid to discuss specifics, detail obstacles, and elaborate on solutions you&rsquo;ve created.  Similarly, you can encourage members of your engineering teams to submit articles to journals or other publications.  The best question related to hiring that I&rsquo;ve ever heard in a board meeting came from one of the most savvy investors in Silicon Valley.  It was, &ldquo;How many of your software developers have, in the last year, published a technical article in a peer-reviewed technical journal?&rdquo;  At this particular company, the silence was deafening, but the board member was on to something.</p>
<p>In designing your outreach, the goal is not to promote the company but focus on the tech issues and how to solve them.  By creating a genuine culture of awareness and knowledge sharing, the growth of your brand&rsquo;s impact and outreach will naturally follow.</p>

<h2 id="automation-and-valuing-human-effort" class="anchor-link"><a href="#automation-and-valuing-human-effort">Automation and valuing human effort</a></h2>
<p>The consequence of having higher inbound demand is that a higher number of candidates will be in the application flow for a given opening, typically requiring more effort to vet them.  With appropriate automation, however, increased application flow can be handled without requiring more effort on the part of HR staff.</p>
<p>The great opportunity presented by automation is the ability to relieve humans of those tasks that they don&rsquo;t perform efficiently.  In the case of redesigning our hiring process, this means filtering tech candidates more effectively at the top of the funnel.  This enables us to have a large amount of inbound demand that is being effectively filtered from the very start.</p>
<p>Automation in this sense is not intended to replace human effort, but to complement it.  With ample inbound activity being generated by human interaction and community building, we want to handle the inbound traffic as effectively as possible without any increased demand on human time.  In reality, we can do one better.  Automation allows us to handle increased inbound flow while <em>decreasing</em> the human involvement required.</p>
<p>The first and biggest step in filtering is to start at the top of the funnel.  The goal is to design a filter that is extremely low-friction for the technical people you&rsquo;re recruiting, but also a relevant and telling basic evaluation of technical competency.  The best way I&rsquo;ve found to accomplish this is by only accepting applications from candidates who apply via API.  By design, this method cuts out a lot of noise typically present in a tech recruiting pipeline.</p>

<h2 id="open-secret-most-tech-people-can-barely-code" class="anchor-link"><a href="#open-secret-most-tech-people-can-barely-code">Open secret: most tech people can barely code</a></h2>
<p>A common problem I see when advising companies on hiring is that they are not aware of, or do not accept, the fact that many tech people can&rsquo;t really write code very well, with the common approximation being that <a href="https://www.joelonsoftware.com/2005/01/27/news-58/">199 out of 200</a> applicants for developer jobs can&rsquo;t really code.  While almost every developer relies on online resources for documentation to some extent, there are many candidates who cannot accomplish even basic programming tasks without copying and pasting existing code, which is why screening problems like FizzBuzz (credit to Reginald Braithwaite) are effective.  Therefore, we need simple but effective filters that demonstrate that a candidate can write code, without being burdensome enough to cause the candidate to decide to pass on our open role.  To accomplish this, we can require that all candidates apply by API.</p>
<p>No applications are accepted by email, company software, or other routes.  In modern development, interacting with REST APIs is essentially a required skill.  Candidates without this capability, or who cannot gain this capability with a few minutes of research, are unlikely to be successful in a developer role.  This same metric is effective whether the candidate is a student applying for an internship or a seasoned developer with 20 years of experience.  If they can&rsquo;t code against a REST API, or in this case send an application via one, then it&rsquo;s very unlikely that they will be an effective contributor in your tech team.</p>
<p>Since this application process acts as a filter requiring no human involvement or decision-making, your HR staff and developers are free to focus on building the company and generating inbound demand.  The nice thing about such a process is that it is very scalable.  Whether your focus is to hire five or five hundred new staff, an application by API filter just works.</p>
<p>In past companies, I set up a simple REST API for candidates to submit their details which are then sent by email directly to the relevant hiring parties.  It cuts down dramatically on the amount of noise coming into the hiring pipeline, and candidates have reported that they really enjoy and appreciate the fact that the filter is relevant, effective, and faster for them than filling out forms.</p>
<p>In future articles, I&rsquo;ll elaborate on other aspects of rethinking the hiring process, from creating relevant tech challenges to an effective interview process.  It&rsquo;s possible, even simple, to design a process optimized for the best results with the least time required, enabling you to hire faster, and hire better.</p>
 ]]></content:encoded></item><item><title>Teammate to Team Lead</title><link>https://adamdrake.com/teammate-to-team-lead.html</link><pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/teammate-to-team-lead.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>Growing organizations go through many changes on the journey of scaling up. A common one is the creation of new teams, and consequently, new team leaders. As startups move from teams of people, to teams of teams, former peers become leaders and must learn to excel in their new role. How do you tackle the challenges of being viewed differently and commanding a new level of respect, while at the same time remaining humble and approachable to your team?&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>Growing organizations go through many changes on the journey of scaling up.  A common one is the creation of new teams, and consequently, new team leaders.  As startups move from teams of people, to teams of teams, former peers become leaders and must learn to excel in their new role.  How do you tackle the challenges of being viewed differently and commanding a new level of respect, while at the same time remaining humble and approachable to your team?</p>
<p>Going from teammate to team lead presents many challenges that are not often openly discussed.  As you move into this new leadership position, it&rsquo;s important to ensure that you have the correct perspective to support the success of your team.  In this article I&rsquo;ll discuss a few main points I typically cover with people making this move, and share some strategies for successfully establishing yourself as a capable team leader.</p>

<h1 id="the-team-is-now-your-responsibility" class="anchor-link"><a href="#the-team-is-now-your-responsibility">The team is now your responsibility</a></h1>
<p>New leaders cannot afford to take this point lightly.  Everything the team now does (or fails to do) is on your shoulders.  This does not mean that you alone get all the glory.  On the contrary, any victories should be credited directly to the team&rsquo;s members.  However, if the team struggles or fails, you as their leader must take all the credit for those failures, as well as take responsibility for improving future performance.  A strong leader is someone the team can count on for representation and support.  Teams get the credit, leaders take the blame.  It&rsquo;s all on you.</p>
<p>As leader, you have become the face of the team within your organization.  You represent them when it comes to anyone with whom the team will interact.  Never complain about circumstances, other business units, or other teams.  Be aware of how your personal interactions with coworkers reflect on your team.</p>
<p>Leadership requires constant awareness of the effect that your actions have on others.  The key to mastering this attitude is remembering that your presence at work is now a representation of something greater than just you.</p>

<h1 id="accept-that-your-relationships-will-change" class="anchor-link"><a href="#accept-that-your-relationships-will-change">Accept that your relationships will change</a></h1>
<p>People treat and view leaders differently than they do peers.  Now that you&rsquo;ve officially moved into a leadership role, be aware that your former teammates will (and should) relate with you in a new way.  When in the past you may have regularly gone out together as a team, you now must give the team space to have those outings without you.  Don&rsquo;t be insulted if you aren&rsquo;t invited along.  Instead, be supportive of your team developing a new interpersonal culture.  Your team will have different discussions when you are present than when you are not.  Learn when to subtract yourself from a situation to allow them to discuss things on their own.</p>
<p>A certain level of separation is conducive to being respected, so cultivate a professional distance.  Maintain personal interest, but frame that interest with the sense of being a supportive coach.  If a team member comes to you with concerns, don&rsquo;t be drawn into commiserating as a co-worker may be.  Instead of complaining, present possible solutions, or simply ask how you can best support them at this time.  You should know everyone on your team and look out for their welfare, but without favoring any single team member.</p>

<h1 id="take-on-a-leaders-perspective" class="anchor-link"><a href="#take-on-a-leaders-perspective">Take on a leader&rsquo;s perspective</a></h1>
<p>Effective leaders are objective and aware of those responsibilities that are not specified in the job description.  Build an awareness of your team&rsquo;s position relative to the big picture of your organization.  One way to do this is by cultivating constant communication up the chain of command, and sideways with other team leads.  Maintain objectiveness in regards to your team&rsquo;s performance and ensure that you always consider the success of the whole organization.</p>
<p>If someone on your team isn&rsquo;t performing as expected, first ask yourself, &ldquo;What did I, as a leader, fail to do?&rdquo;  Have you been clear in explaining the intent of the project to your team?  Have you successfully conveyed the importance of certain aspects and provided adequate resources and training?  First looking at yourself is an important leadership practice, and one that will help you enable and empower your team members.</p>

<h1 id="build-up-your-team-members" class="anchor-link"><a href="#build-up-your-team-members">Build up your team members</a></h1>
<p>A leader&rsquo;s opinion carries more weight, and your casual words may unintentionally be taken for a directive.  Be hyper-aware of the impression that your words make on your team.  Instead of simply providing your opinion, create a culture of open discussion that encourages ideas and input from your team members.  You can do this by constantly asking questions that facilitate further discussion.  Become an expert practitioner of the Socratic method, using thoughtful questions to lead team members towards end goals.  Question assumptions, especially yours, and take care when phrasing disagreement.</p>
<p>Your goal should be to build up a culture of team members who come to you with plans for solving problems and achieving the objectives that you as their leader have set.  Itâ€™s important that the members of your team have a sense of ownership over how they will achieve these objectives.  You can support their sense of ownership by defaulting to their solution whenever possible.  Consider that even if you have a 95% solution and they have a 75% solution, the team and the organization overall may benefit from executing their approach.  A 75% solution passionately executed has a far greater chance of success than a 95% solution that someone is pushed to implement.  Your job is to help the team achieve their objectives, regardless of whose idea becomes the path for getting there.  Give everyone a chance to be the team&rsquo;s superstar.</p>

<h1 id="acknowledge-awkwardness-and-mistakes" class="anchor-link"><a href="#acknowledge-awkwardness-and-mistakes">Acknowledge awkwardness and mistakes</a></h1>
<p>No leader is perfect, and pretending that this isn&rsquo;t the case can cause moments of tension and awkwardness.  Don&rsquo;t be afraid to openly acknowledge your shortcomings to your team members.  Saying out loud that you&rsquo;re unsure or uncomfortable as a new leader in a particular situation will not negatively affect your credibility.  To the contrary, it humanizes you and instills confidence in your team that you&rsquo;re aware of your shortcomings or mistakes, and that you&rsquo;re interested in improving them.  Consider these situations to be opportunities to lead by example.  You&rsquo;ll encourage your team members to also practice humility and embrace opportunities to learn and grow.</p>
<p>With that in mind, a leader must still make decisions and take responsibility for the outcomes of those decisions.  Expressing that you are feeling unsure and then not doing anything to change that fact will only undermine your authority as a leader.  Instead, express that you&rsquo;re unsure, ask for input and information, and then come to a decision based on that input.  This will reinforce your position as a reasonable and measured leader.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>Establishing yourself in a new leadership role takes dedication and work, but primarily comes down to a shift in your own personal perspective.  In order for your team to perceive you in a different light, you must first relate differently with them.  To provide your team members with appropriate support, you must develop an awareness of their needs and of how your team&rsquo;s performance connects with your organization on the whole.  Become cognizant of the increased impact of your words as a leader, build up your team members, and lead by example when openly acknowledging mistakes.  By keeping these principles in mind, you can successfully cultivate your leadership presence and grow confidence - both confidence in yourself, and confidence that your team has in you.</p>
 ]]></content:encoded></item><item><title>Faster command line tools with Go</title><link>https://adamdrake.com/faster-command-line-tools-with-go.html</link><pubDate>Mon, 29 May 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/faster-command-line-tools-with-go.html</guid><description>&lt;h1 id="update" class="anchor-link">&lt;a href="#update">Update&lt;/a>&lt;/h1>
&lt;p>After some input from u/epiris on Reddit, I improved the code a bit further by changing the way bytestreams are scanned. Current fastest runtime is 0.308s for 10,512,769 rows, or about 34 Million rows per second. Since the file is 184 Megabytes, this is a processing speed of about 600 Megabytes per second, which is probably close to the read speed limit of my SSD.&lt;/p>
&lt;hr>
&lt;p>It all started with a blog post, &lt;a href="https://dlang.org/blog/2017/05/24/faster-command-line-tools-in-d/">Faster Command Line Tools in D&lt;/a>. It was at the top of &lt;a href="https://news.ycombinator.com">Hacker News&lt;/a> and got picked up by other sites as well. Then Euan Torano wrote &lt;a href="https://www.euantorano.co.uk/posts/faster-command-line-tools-in-nim/">Faster Command Line Tools in Nim&lt;/a>. After reading about both, I found some comments in the &lt;a href="https://www.reddit.com/r/golang/comments/6dhbwv/faster_command_line_tools_in_golang/">Reddit post&lt;/a> on the same topic, but in Go. Go is a great tool for many things, but I wasn&amp;rsquo;t sure what kind of performance I&amp;rsquo;d get out of this kind of tool.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="update" class="anchor-link"><a href="#update">Update</a></h1>
<p>After some input from u/epiris on Reddit, I improved the code a bit further by changing the way bytestreams are scanned.  Current fastest runtime is 0.308s for 10,512,769 rows, or about 34 Million rows per second.  Since the file is 184 Megabytes, this is a processing speed of about 600 Megabytes per second, which is probably close to the read speed limit of my SSD.</p>
<hr>
<p>It all started with a blog post, <a href="https://dlang.org/blog/2017/05/24/faster-command-line-tools-in-d/">Faster Command Line Tools in D</a>.  It was at the top of <a href="https://news.ycombinator.com">Hacker News</a> and got picked up by other sites as well.  Then Euan Torano wrote <a href="https://www.euantorano.co.uk/posts/faster-command-line-tools-in-nim/">Faster Command Line Tools in Nim</a>.  After reading about both, I found some comments in the <a href="https://www.reddit.com/r/golang/comments/6dhbwv/faster_command_line_tools_in_golang/">Reddit post</a> on the same topic, but in Go.  Go is a great tool for many things, but I wasn&rsquo;t sure what kind of performance I&rsquo;d get out of this kind of tool.</p>
<p><strong>TL;DR</strong>: I wrote a special-case version of the utility which processes the input in about 0.482 seconds, or about 22.8 million lines per second on my laptop, which is a processing rate of about 390 Megabytes per second.</p>
<p>The approximate performance of the other languages was as follows:</p>
<ul>
<li>
<p>Python: 15 seconds</p>
</li>
<li>
<p>D (DMD): 2.4 seconds</p>
</li>
<li>
<p>D (LDC): 1.4 seconds</p>
</li>
<li>
<p>Nim: 1.4 seconds</p>
</li>
<li>
<p>My current-fastest Go version: 0.338s</p>
</li>
</ul>

<h1 id="problem-statement" class="anchor-link"><a href="#problem-statement">Problem statement</a></h1>
<p>The original version of the problem, as outlined in the post on D, was the following:</p>
<blockquote>
<p>Itâ€™s a common programming task: Take a data file with fields separated by a delimiter (comma, tab, etc), and run a mathematical calculation involving several of the fields. Often these programs are one-time use scripts, other times they have longer shelf life. Speed is of course appreciated when the program is used more than a few times on large files.</p>
<p>The specific exercise weâ€™ll explore starts with files having keys in one field, integer values in another.
&hellip;
Fields are delimited by a TAB, and there may be any number of fields on a line. The file name and field numbers of the key and value are passed as command line arguments.</p>
</blockquote>
<p>Okay.  We&rsquo;ll have a delimited file (with tabs in this case), and we want to provide the filename, index for the key column, and index for the value column to our code.  With those, our code should compute the sum of all the values for each specific key, and then output the key having the largest value.  In SQL terms, this is a <code>GROUP BY</code> and a <code>MAX</code>.  (Note that I did not do a version of this problem in SQL, but from what I&rsquo;ve seen it is slower than the Go/Nim/D versions, though perhaps not the Python version.)</p>
<p>The data we will use is a <a href="https://storage.googleapis.com/books/ngrams/books/googlebooks-eng-all-1gram-20120701-0.gz">file of n-grams</a> from the Google Books dataset.  The file is 184 Megabytes, uncompressed, and has a total of 10,512,769 lines.</p>

<h1 id="first-attempt" class="anchor-link"><a href="#first-attempt">First attempt</a></h1>
<p>As a first try, we&rsquo;ll use all the built-in Go libraries for string and file processing.  We&rsquo;ll keep the code general and high-level, and see what kind of speed we get.</p>
<p>Since I like to start with data structures, we&rsquo;ll just use a simple <code>map[string]int</code> in this case, with the string keys being the keys from our file, and the integer values being the sum of all the values in the file for that particular key.  In other words, it&rsquo;s a <code>for</code> loop over the rows in the file, and an increment of a map value each time we go through the loop.  Then at the end we&rsquo;ll do a for loop over all the elements in the map and see which key has the largest value.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">main</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;bufio&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;flag&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;fmt&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;log&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;math&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;os&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;strconv&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;strings&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">processFile</span>(<span style="color:#a6e22e">filePath</span> <span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">keyIndex</span>, <span style="color:#a6e22e">valueIndex</span> <span style="color:#66d9ef">int</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">delim</span> <span style="color:#f92672">:=</span> <span style="color:#e6db74">&#34;\t&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fileHandle</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">Open</span>(<span style="color:#a6e22e">filePath</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">defer</span> <span style="color:#a6e22e">fileHandle</span>.<span style="color:#a6e22e">Close</span>()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">maxFieldIndex</span> <span style="color:#f92672">:=</span> int(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Max</span>(float64(<span style="color:#a6e22e">keyIndex</span>), float64(<span style="color:#a6e22e">valueIndex</span>)))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">sumByKey</span> <span style="color:#f92672">:=</span> make(<span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">int</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fileReader</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">bufio</span>.<span style="color:#a6e22e">NewScanner</span>(<span style="color:#a6e22e">fileHandle</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">fileReader</span>.<span style="color:#a6e22e">Scan</span>() {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">fields</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">strings</span>.<span style="color:#a6e22e">Split</span>(<span style="color:#a6e22e">strings</span>.<span style="color:#a6e22e">TrimSpace</span>(<span style="color:#a6e22e">fileReader</span>.<span style="color:#a6e22e">Text</span>()), <span style="color:#a6e22e">delim</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">maxFieldIndex</span> &lt; len(<span style="color:#a6e22e">fields</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">value</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">strconv</span>.<span style="color:#a6e22e">Atoi</span>(<span style="color:#a6e22e">fields</span>[<span style="color:#a6e22e">valueIndex</span>])
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">sumByKey</span>[<span style="color:#a6e22e">fields</span>[<span style="color:#a6e22e">keyIndex</span>]] <span style="color:#f92672">+=</span> <span style="color:#a6e22e">value</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">maxValue</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">maxKey</span> <span style="color:#f92672">:=</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">sumByKey</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">v</span> &gt; <span style="color:#a6e22e">maxValue</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">maxValue</span> = <span style="color:#a6e22e">v</span>
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">maxKey</span> = <span style="color:#a6e22e">k</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Println</span>(<span style="color:#e6db74">&#34;max_key:&#34;</span>, <span style="color:#a6e22e">maxKey</span>, <span style="color:#e6db74">&#34;sum:&#34;</span>, <span style="color:#a6e22e">sumByKey</span>[<span style="color:#a6e22e">maxKey</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">filePath</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">flag</span>.<span style="color:#a6e22e">String</span>(<span style="color:#e6db74">&#34;filePath&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>, <span style="color:#e6db74">&#34;Name of the file to parse&#34;</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">keyIndex</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">flag</span>.<span style="color:#a6e22e">Int</span>(<span style="color:#e6db74">&#34;keyIndex&#34;</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#34;Index of key (0 is first position)&#34;</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">valueIndex</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">flag</span>.<span style="color:#a6e22e">Int</span>(<span style="color:#e6db74">&#34;valueIndex&#34;</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#34;Index of value (0 is first position)&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">flag</span>.<span style="color:#a6e22e">Parse</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">processFile</span>(<span style="color:#f92672">*</span><span style="color:#a6e22e">filePath</span>, <span style="color:#f92672">*</span><span style="color:#a6e22e">keyIndex</span>, <span style="color:#f92672">*</span><span style="color:#a6e22e">valueIndex</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>processFile()</code> function does all the work, and that makes it easy for us to write a benchmark.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">main</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;testing&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Benchmark_processFile</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">processFile</span>(<span style="color:#e6db74">&#34;../ngrams.tsv&#34;</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h2 id="results" class="anchor-link"><a href="#results">Results</a></h2>
<p>The first version works, but it&rsquo;s not very fast.  We can see its performance by running <code>go test -cpuprofile cpu.prof -memprofile mem.prof -bench .</code> both to get a benchmark, and to see which parts are slow.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>max_key: <span style="color:#ae81ff">2006</span> sum: <span style="color:#ae81ff">22569013</span>
</span></span><span style="display:flex;"><span>Benchmark_processFile-4   	       1	<span style="color:#ae81ff">3486100959</span> ns/op
</span></span><span style="display:flex;"><span>PASS
</span></span><span style="display:flex;"><span>ok  	github.com/adamdrake/faster-command-line-tools-in-nim/Go/v1	3.491s
</span></span></code></pre></div><p>Our first version takes about 3.49 seconds to run, which isn&rsquo;t bad, but isn&rsquo;t great.  Why so slow?  Let&rsquo;s <code>go tool pprof cpu.prof</code> and find out.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Entering interactive mode <span style="color:#f92672">(</span>type <span style="color:#e6db74">&#34;help&#34;</span> <span style="color:#66d9ef">for</span> commands<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">(</span>pprof<span style="color:#f92672">)</span> text
</span></span><span style="display:flex;"><span>2250ms of 3490ms total <span style="color:#f92672">(</span>64.47%<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Dropped <span style="color:#ae81ff">33</span> nodes <span style="color:#f92672">(</span>cum &lt;<span style="color:#f92672">=</span> 17.45ms<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Showing top <span style="color:#ae81ff">10</span> nodes out of <span style="color:#ae81ff">65</span> <span style="color:#f92672">(</span>cum &gt;<span style="color:#f92672">=</span> 160ms<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      flat  flat%   sum%        cum   cum%
</span></span><span style="display:flex;"><span>     600ms 17.19% 17.19%     1530ms 43.84%  strings.genSplit
</span></span><span style="display:flex;"><span>     330ms  9.46% 26.65%      790ms 22.64%  runtime.mallocgc
</span></span><span style="display:flex;"><span>     260ms  7.45% 34.10%      260ms  7.45%  runtime.heapBitsSetType
</span></span><span style="display:flex;"><span>     200ms  5.73% 39.83%      200ms  5.73%  runtime.indexbytebody
</span></span><span style="display:flex;"><span>     200ms  5.73% 45.56%      310ms  8.88%  runtime.mapaccess1_faststr
</span></span><span style="display:flex;"><span>     170ms  4.87% 50.43%      410ms 11.75%  runtime.mapassign
</span></span><span style="display:flex;"><span>     160ms  4.58% 55.01%      160ms  4.58%  runtime.aeshashbody
</span></span><span style="display:flex;"><span>     120ms  3.44% 58.45%      400ms 11.46%  strings.Count
</span></span><span style="display:flex;"><span>     110ms  3.15% 61.60%     3440ms 98.57%  github.com/adamdrake/faster-command-line-tools-in-nim/Go/v1.processFile
</span></span><span style="display:flex;"><span>     100ms  2.87% 64.47%      160ms  4.58%  strconv.ParseInt
</span></span></code></pre></div><p>It seems like we spend a lot of time on <code>genSplit()</code>, which is the General Split command invoked by <code>strings.Split()</code> in our code.  To see this, we can type <code>list processFile</code> in <code>pprof</code> to get the line-by-line timing for that function.  Here&rsquo;s a selection of the output of <code>list processFile</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>         .      240ms     29:	<span style="color:#66d9ef">for</span> fileReader.Scan<span style="color:#f92672">()</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>         .      2.19s     30:		fields :<span style="color:#f92672">=</span> strings.Split<span style="color:#f92672">(</span>strings.TrimSpace<span style="color:#f92672">(</span>fileReader.Text<span style="color:#f92672">())</span>, delim<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>         .          .     31:
</span></span><span style="display:flex;"><span>         .          .     32:		<span style="color:#66d9ef">if</span> maxFieldIndex &lt; len<span style="color:#f92672">(</span>fields<span style="color:#f92672">)</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      10ms      190ms     33:			value, err :<span style="color:#f92672">=</span> strconv.Atoi<span style="color:#f92672">(</span>fields<span style="color:#f92672">[</span>valueIndex<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>         .          .     34:			<span style="color:#66d9ef">if</span> err !<span style="color:#f92672">=</span> nil <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>         .          .     35:				log.Fatal<span style="color:#f92672">(</span>err<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>         .          .     36:			<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>      80ms      800ms     37:			sumByKey<span style="color:#f92672">[</span>fields<span style="color:#f92672">[</span>keyIndex<span style="color:#f92672">]]</span> +<span style="color:#f92672">=</span> value
</span></span><span style="display:flex;"><span>         .          .     38:		<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>         .          .     39:	<span style="color:#f92672">}</span>
</span></span></code></pre></div><p>We see that out of the 3.49s we&rsquo;re spending processing our file, 2.19s of that is spent just splitting strings.  To confirm that <code>genSplit()</code> is in <code>strings.Split()</code> we can do the same thing with <code>list Split</code> and get all the details on where the time is going.</p>
<p>Let&rsquo;s assume that we aren&rsquo;t going to dive in and start making changes to the standard library.  What should we do to improve the speed?  The natural thing for most Go programmers is to turn to channels and goroutines.  Spoiler alert: that is slower.</p>

<h1 id="v2-channels-and-goroutines" class="anchor-link"><a href="#v2-channels-and-goroutines">V2: Channels and Goroutines</a></h1>
<p>Channels and goroutines are great, but often overused.  They have a startup cost, and many people are not aware of the fact that channels are a data structure that includes a mutex, and therefore subject to lock contention (i.e., they can be slow).  Regardless, let&rsquo;s see how the performance fares if we go that route.  We&rsquo;ll keep the map and other data in a <code>struct</code>, which we&rsquo;ll protect with a <code>sync.Mutex</code> so that we have thread-safe write access to the map (recall: in Go, a <code>map</code> is <strong>NOT</strong> thread-safe).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">main</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;flag&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;fmt&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;log&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;math&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;strconv&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;strings&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;sync&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fstream</span> <span style="color:#e6db74">&#34;github.com/adamdrake/gofstream&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">type</span> <span style="color:#a6e22e">kv</span> <span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">keyIndex</span>, <span style="color:#a6e22e">valueIndex</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">store</span>                <span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">sync</span>.<span style="color:#a6e22e">Mutex</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">worker</span>(<span style="color:#a6e22e">rows</span> <span style="color:#66d9ef">chan</span> <span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">data</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">kv</span>, <span style="color:#a6e22e">wg</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">sync</span>.<span style="color:#a6e22e">WaitGroup</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">defer</span> <span style="color:#a6e22e">wg</span>.<span style="color:#a6e22e">Done</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">keyIndex</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">data</span>.<span style="color:#a6e22e">keyIndex</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">valueIndex</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">data</span>.<span style="color:#a6e22e">valueIndex</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">maxFieldIndex</span> <span style="color:#f92672">:=</span> int(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Max</span>(float64(<span style="color:#a6e22e">keyIndex</span>), float64(<span style="color:#a6e22e">valueIndex</span>)))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">sumByKey</span> <span style="color:#f92672">:=</span> make(<span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">int</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">r</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">rows</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">fields</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">strings</span>.<span style="color:#a6e22e">Split</span>(<span style="color:#a6e22e">strings</span>.<span style="color:#a6e22e">TrimSpace</span>(<span style="color:#a6e22e">r</span>), <span style="color:#e6db74">&#34;\t&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">maxFieldIndex</span> &lt; len(<span style="color:#a6e22e">fields</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">value</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">strconv</span>.<span style="color:#a6e22e">Atoi</span>(<span style="color:#a6e22e">fields</span>[<span style="color:#a6e22e">data</span>.<span style="color:#a6e22e">valueIndex</span>])
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">sumByKey</span>[<span style="color:#a6e22e">fields</span>[<span style="color:#a6e22e">keyIndex</span>]] <span style="color:#f92672">+=</span> <span style="color:#a6e22e">value</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">data</span>.<span style="color:#a6e22e">Lock</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">sumByKey</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">data</span>.<span style="color:#a6e22e">store</span>[<span style="color:#a6e22e">k</span>] <span style="color:#f92672">+=</span> <span style="color:#a6e22e">v</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">data</span>.<span style="color:#a6e22e">Unlock</span>()
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">processFile</span>(<span style="color:#a6e22e">filePath</span> <span style="color:#66d9ef">string</span>, <span style="color:#a6e22e">keyIndex</span>, <span style="color:#a6e22e">valueIndex</span> <span style="color:#66d9ef">int</span>) {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">rows</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">fstream</span>.<span style="color:#a6e22e">New</span>(<span style="color:#a6e22e">filePath</span>, <span style="color:#ae81ff">100000</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">data</span> <span style="color:#f92672">:=</span> <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">kv</span>{<span style="color:#a6e22e">keyIndex</span>: <span style="color:#a6e22e">keyIndex</span>, <span style="color:#a6e22e">valueIndex</span>: <span style="color:#a6e22e">valueIndex</span>, <span style="color:#a6e22e">store</span>: make(<span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">int</span>)}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">wg</span> <span style="color:#f92672">:=</span> <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">sync</span>.<span style="color:#a6e22e">WaitGroup</span>{}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#ae81ff">4</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">wg</span>.<span style="color:#a6e22e">Add</span>(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">go</span> <span style="color:#a6e22e">worker</span>(<span style="color:#a6e22e">rows</span>, <span style="color:#a6e22e">data</span>, <span style="color:#a6e22e">wg</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">wg</span>.<span style="color:#a6e22e">Wait</span>()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">maxValue</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">maxKey</span> <span style="color:#f92672">:=</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">data</span>.<span style="color:#a6e22e">store</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">v</span> &gt; <span style="color:#a6e22e">maxValue</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">maxValue</span> = <span style="color:#a6e22e">v</span>
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">maxKey</span> = <span style="color:#a6e22e">k</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Println</span>(<span style="color:#e6db74">&#34;max_key:&#34;</span>, <span style="color:#a6e22e">maxKey</span>, <span style="color:#e6db74">&#34;sum:&#34;</span>, <span style="color:#a6e22e">data</span>.<span style="color:#a6e22e">store</span>[<span style="color:#a6e22e">maxKey</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">filePath</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">flag</span>.<span style="color:#a6e22e">String</span>(<span style="color:#e6db74">&#34;filePath&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>, <span style="color:#e6db74">&#34;Name of the file to parse&#34;</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">keyIndex</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">flag</span>.<span style="color:#a6e22e">Int</span>(<span style="color:#e6db74">&#34;keyIndex&#34;</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#34;Index of key (0 is first position)&#34;</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">valueIndex</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">flag</span>.<span style="color:#a6e22e">Int</span>(<span style="color:#e6db74">&#34;valueIndex&#34;</span>, <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#34;Index of value (0 is first position)&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">flag</span>.<span style="color:#a6e22e">Parse</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">processFile</span>(<span style="color:#f92672">*</span><span style="color:#a6e22e">filePath</span>, <span style="color:#f92672">*</span><span style="color:#a6e22e">keyIndex</span>, <span style="color:#f92672">*</span><span style="color:#a6e22e">valueIndex</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>This code has the same <code>processFile()</code> function as before, but this time it creates a streaming reader for the file, and streams each row of the file over a channel.  We then give the channel to a worker thread, and the workers do the same thing we did before.  We also have some additional complexity in the form of a <code>sync.WaitGroup</code> to make sure we actually wait and allow the workers to do their job before <code>main()</code> returns.  What&rsquo;s the performance?  Not great.  In fact, it&rsquo;s worse, at about 4.5s.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>max_key: <span style="color:#ae81ff">2006</span> sum: <span style="color:#ae81ff">22569013</span>
</span></span><span style="display:flex;"><span>Benchmark_processFile-4   	       1	<span style="color:#ae81ff">4476065569</span> ns/op
</span></span><span style="display:flex;"><span>PASS
</span></span><span style="display:flex;"><span>ok  	github.com/adamdrake/faster-command-line-tools-in-nim/Go/v4	4.482s
</span></span></code></pre></div><p>I won&rsquo;t go into the <code>pprof</code> output for this one, but you can see that the reason it&rsquo;s slower is because of <code>runtime.procyield</code>, due to all our goroutines.  I probably could have tried to do some things with <code>sync/atomic</code> instead of using a mutex on the struct, but spinning up goroutines for such a small file doesn&rsquo;t make much sense in this case anyway.  If the file was larger, perhaps we&rsquo;d get the benefit of using all cores, but for input of this size it just isn&rsquo;t worth it.</p>

<h1 id="v4-stop-using-strings" class="anchor-link"><a href="#v4-stop-using-strings">V4: Stop using strings</a></h1>
<p>Since it seems that a lot of the overhead is in parsing and splitting strings, why not just operate on the underlying bytes instead?  Credit to valyala for <a href="https://www.reddit.com/r/golang/comments/6dhbwv/faster_command_line_tools_in_golang/di3wo37/">their version</a>, which reads and splits on <code>bytes</code> instead of <code>string</code>.  Here&rsquo;s my version of their code, with an additional twist from a <a href="https://stackoverflow.com/a/27217267">Stack Overflow post</a> which allows us to use a faster string to integer parsing method, assuming that the input values we are summing are always positive integers.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">main</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;bufio&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;bytes&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;errors&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;fmt&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;os&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;unsafe&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">processFile</span>(<span style="color:#a6e22e">file</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">File</span>, <span style="color:#a6e22e">keyField</span>, <span style="color:#a6e22e">valueField</span> <span style="color:#66d9ef">int</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">sumByKey</span> = make(<span style="color:#66d9ef">map</span>[<span style="color:#66d9ef">string</span>]<span style="color:#66d9ef">int</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">maxField</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">keyField</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">valueField</span> &gt; <span style="color:#a6e22e">maxField</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">maxField</span> = <span style="color:#a6e22e">valueField</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">scanner</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">bufio</span>.<span style="color:#a6e22e">NewScanner</span>(<span style="color:#a6e22e">file</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">scanner</span>.<span style="color:#a6e22e">Scan</span>() {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">line</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">scanner</span>.<span style="color:#a6e22e">Bytes</span>()
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">key</span>, <span style="color:#a6e22e">val</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">getKeyVal</span>(<span style="color:#a6e22e">line</span>, <span style="color:#a6e22e">keyField</span>, <span style="color:#a6e22e">valueField</span>, <span style="color:#a6e22e">maxField</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">sumByKey</span>[<span style="color:#a6e22e">key</span>] <span style="color:#f92672">+=</span> <span style="color:#a6e22e">val</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">k</span> <span style="color:#66d9ef">string</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">key</span>, <span style="color:#a6e22e">val</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">sumByKey</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">val</span> &gt; <span style="color:#a6e22e">v</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">k</span> = <span style="color:#a6e22e">key</span>
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">v</span> = <span style="color:#a6e22e">val</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Printf</span>(<span style="color:#e6db74">&#34;max_key: %s sum: %d&#34;</span>, <span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">file</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">Open</span>(<span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">Args</span>[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">defer</span> <span style="color:#a6e22e">file</span>.<span style="color:#a6e22e">Close</span>()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">keyField</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">atoi</span>([]byte(<span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">Args</span>[<span style="color:#ae81ff">2</span>]))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">valueField</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">atoi</span>([]byte(<span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">Args</span>[<span style="color:#ae81ff">3</span>]))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">processFile</span>(<span style="color:#a6e22e">file</span>, <span style="color:#a6e22e">keyField</span>, <span style="color:#a6e22e">valueField</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">getKeyVal</span>(<span style="color:#a6e22e">line</span> []<span style="color:#66d9ef">byte</span>, <span style="color:#a6e22e">keyField</span>, <span style="color:#a6e22e">valueField</span>, <span style="color:#a6e22e">maxField</span> <span style="color:#66d9ef">int</span>) (<span style="color:#66d9ef">string</span>, <span style="color:#66d9ef">int</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">i</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">tabIndex</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">k</span> []<span style="color:#66d9ef">byte</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">v</span> []<span style="color:#66d9ef">byte</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">field</span> []<span style="color:#66d9ef">byte</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">&lt;=</span> <span style="color:#a6e22e">maxField</span> <span style="color:#f92672">&amp;&amp;</span> len(<span style="color:#a6e22e">line</span>) &gt; <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">tabIndex</span> = <span style="color:#a6e22e">bytes</span>.<span style="color:#a6e22e">IndexByte</span>(<span style="color:#a6e22e">line</span>, <span style="color:#e6db74">&#39;\t&#39;</span>) <span style="color:#75715e">// returns -1 if not found
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">tabIndex</span> &lt; <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">field</span> = <span style="color:#a6e22e">line</span>
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">line</span> = <span style="color:#66d9ef">nil</span>
</span></span><span style="display:flex;"><span>		} <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">field</span> = <span style="color:#a6e22e">line</span>[:<span style="color:#a6e22e">tabIndex</span>]
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">line</span> = <span style="color:#a6e22e">line</span>[<span style="color:#a6e22e">tabIndex</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>:]
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">switch</span> <span style="color:#a6e22e">i</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">keyField</span>:
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">k</span> = <span style="color:#a6e22e">field</span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">case</span> <span style="color:#a6e22e">valueField</span>:
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">v</span> = <span style="color:#a6e22e">field</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">i</span><span style="color:#f92672">++</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">val</span>, <span style="color:#a6e22e">_</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">atoi</span>(<span style="color:#a6e22e">v</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> string(<span style="color:#a6e22e">k</span>), <span style="color:#a6e22e">val</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">var</span> <span style="color:#a6e22e">errAtoi</span> = <span style="color:#a6e22e">errors</span>.<span style="color:#a6e22e">New</span>(<span style="color:#e6db74">&#34;invalid number&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">atoi</span>(<span style="color:#a6e22e">input</span> []<span style="color:#66d9ef">byte</span>) (<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">error</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">val</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; len(<span style="color:#a6e22e">input</span>); <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">char</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">input</span>[<span style="color:#a6e22e">i</span>]
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">char</span> &lt; <span style="color:#e6db74">&#39;0&#39;</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">char</span> &gt; <span style="color:#e6db74">&#39;9&#39;</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>, <span style="color:#a6e22e">errAtoi</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">val</span> = <span style="color:#a6e22e">val</span><span style="color:#f92672">*</span><span style="color:#ae81ff">10</span> <span style="color:#f92672">+</span> int(<span style="color:#a6e22e">char</span>) <span style="color:#f92672">-</span> <span style="color:#e6db74">&#39;0&#39;</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">val</span>, <span style="color:#66d9ef">nil</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Now, instead of reading in the line as a string and then splitting the string on the delimiter with <code>strings.Split()</code>, we&rsquo;re reading in the line as a bytestring, and using the <code>bytes.IndexByte()</code> function to find the index of the delimiter in the bytestring.  We loop through the bytestring by finding the current delimiter (which corresponds to the command line arguments we received for key index and value index), and sum the values as always.  How much do we save by operating on the bytes instead of the strings?  A lot.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>max_key: <span style="color:#ae81ff">2006</span> sum: <span style="color:#ae81ff">22569013</span>
</span></span><span style="display:flex;"><span>Benchmark_processFile-4   	       1	<span style="color:#ae81ff">1517321373</span> ns/op
</span></span><span style="display:flex;"><span>PASS
</span></span></code></pre></div><p>Great!  This approach cut our runtime by about 60%, and it&rsquo;s still pretty usable as production code.  It&rsquo;s not too customized, it still fits the requirements of the original problem definition of key column and value column being command line arguments, and it&rsquo;s pretty readable.  Where is the time mostly spent?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">(</span>pprof<span style="color:#f92672">)</span> text
</span></span><span style="display:flex;"><span>1200ms of 1500ms total <span style="color:#f92672">(</span>80.00%<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>Showing top <span style="color:#ae81ff">10</span> nodes out of <span style="color:#ae81ff">41</span> <span style="color:#f92672">(</span>cum &gt;<span style="color:#f92672">=</span> 50ms<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      flat  flat%   sum%        cum   cum%
</span></span><span style="display:flex;"><span>     260ms 17.33% 17.33%      670ms 44.67%  github.com/adamdrake/faster-command-line-tools-in-nim/Go/v5.getKeyVal
</span></span><span style="display:flex;"><span>     200ms 13.33% 30.67%      330ms 22.00%  runtime.mapaccess1_faststr
</span></span><span style="display:flex;"><span>     170ms 11.33% 42.00%      170ms 11.33%  runtime.indexbytebody
</span></span><span style="display:flex;"><span>     120ms  8.00% 50.00%      260ms 17.33%  runtime.mapassign
</span></span><span style="display:flex;"><span>     100ms  6.67% 56.67%      100ms  6.67%  runtime.aeshashbody
</span></span><span style="display:flex;"><span>      90ms  6.00% 62.67%      120ms  8.00%  runtime.mallocgc
</span></span><span style="display:flex;"><span>      70ms  4.67% 67.33%     1500ms   100%  github.com/adamdrake/faster-command-line-tools-in-nim/Go/v5.processFile
</span></span><span style="display:flex;"><span>      70ms  4.67% 72.00%       70ms  4.67%  runtime.memeqbody
</span></span><span style="display:flex;"><span>      70ms  4.67% 76.67%       80ms  5.33%  syscall.Syscall
</span></span><span style="display:flex;"><span>      50ms  3.33% 80.00%       50ms  3.33%  github.com/adamdrake/faster-command-line-tools-in-nim/Go/v5.atoi
</span></span></code></pre></div><p>Most of the time is spent splitting the bytes and getting the key/value pairs, as expected.  Let&rsquo;s <code>list getKeyVal</code> to take a closer look.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>260ms      670ms <span style="color:#f92672">(</span>flat, cum<span style="color:#f92672">)</span> 44.67% of Total
</span></span><span style="display:flex;"><span>         .          .     51:	var tabIndex int
</span></span><span style="display:flex;"><span>         .          .     52:	var k <span style="color:#f92672">[]</span>byte
</span></span><span style="display:flex;"><span>         .          .     53:	var v <span style="color:#f92672">[]</span>byte
</span></span><span style="display:flex;"><span>         .          .     54:	var field <span style="color:#f92672">[]</span>byte
</span></span><span style="display:flex;"><span>         .          .     55:
</span></span><span style="display:flex;"><span>      20ms       20ms     56:	<span style="color:#66d9ef">for</span> i &lt;<span style="color:#f92672">=</span> maxField <span style="color:#f92672">&amp;&amp;</span> len<span style="color:#f92672">(</span>line<span style="color:#f92672">)</span> &gt; <span style="color:#ae81ff">0</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      20ms      160ms     57:		tabIndex <span style="color:#f92672">=</span> bytes.IndexByte<span style="color:#f92672">(</span>line, <span style="color:#e6db74">&#39;\t&#39;</span><span style="color:#f92672">)</span> // returns -1 <span style="color:#66d9ef">if</span> not found
</span></span><span style="display:flex;"><span>      20ms       20ms     58:		<span style="color:#66d9ef">if</span> tabIndex &lt; <span style="color:#ae81ff">0</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>         .          .     59:			field <span style="color:#f92672">=</span> line
</span></span><span style="display:flex;"><span>         .          .     60:			line <span style="color:#f92672">=</span> nil
</span></span><span style="display:flex;"><span>         .          .     61:		<span style="color:#f92672">}</span> <span style="color:#66d9ef">else</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      10ms       10ms     62:			field <span style="color:#f92672">=</span> line<span style="color:#f92672">[</span>:tabIndex<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>      60ms       60ms     63:			line <span style="color:#f92672">=</span> line<span style="color:#f92672">[</span>tabIndex+1:<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>         .          .     64:		<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>         .          .     65:		switch i <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      10ms       10ms     66:		<span style="color:#66d9ef">case</span> keyField:
</span></span><span style="display:flex;"><span>         .          .     67:			k <span style="color:#f92672">=</span> field
</span></span><span style="display:flex;"><span>      10ms       10ms     68:		<span style="color:#66d9ef">case</span> valueField:
</span></span><span style="display:flex;"><span>         .          .     69:			v <span style="color:#f92672">=</span> field
</span></span><span style="display:flex;"><span>         .          .     70:		<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>      10ms       10ms     71:		i++
</span></span><span style="display:flex;"><span>         .          .     72:	<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>      40ms       90ms     73:	val, _ :<span style="color:#f92672">=</span> atoi<span style="color:#f92672">(</span>v<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>      60ms      280ms     74:	<span style="color:#66d9ef">return</span> string<span style="color:#f92672">(</span>k<span style="color:#f92672">)</span>, val
</span></span><span style="display:flex;"><span>         .          .     75:<span style="color:#f92672">}</span>
</span></span></code></pre></div><p>We can see that the most time is spent getting the index of the bytes, and some on string casting for the key (so that we can use it as the map key).  In a practical scenario, we&rsquo;d probably stop here since, as mentioned above, this is probably about as fast as the code will get while still being sufficiently general, readable, etc.  We can do better though, if we break the requirements of the original comparison.</p>

<h1 id="v5-lets-go-nuts" class="anchor-link"><a href="#v5-lets-go-nuts">V5: Let&rsquo;s go nuts</a></h1>
<p>Let&rsquo;s put some of the practical concerns aside for the moment and focus on what we know about the problem.  First, we are trusting our input data, which we&rsquo;d normally be more careful about in a real-world situation.  With that in mind, we can change the definitions of our <code>atoi()</code> function so that it doesn&rsquo;t do any error checking, and so that it only operates on <code>[]byte</code> and returns <code>int</code>.  Here&rsquo;s what the simplified <code>atoi</code> looks like.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">atoi</span>(<span style="color:#a6e22e">s</span> []<span style="color:#66d9ef">byte</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">x</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> ; <span style="color:#a6e22e">i</span> &lt; len(<span style="color:#a6e22e">s</span>); <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">c</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">s</span>[<span style="color:#a6e22e">i</span>]
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">x</span> = <span style="color:#a6e22e">x</span><span style="color:#f92672">*</span><span style="color:#ae81ff">10</span> <span style="color:#f92672">+</span> int(<span style="color:#a6e22e">c</span>) <span style="color:#f92672">-</span> <span style="color:#e6db74">&#39;0&#39;</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">x</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We also know that the keys and values are always integers, so we could use an <code>int</code> type instead of <code>string</code> in the map keys, and we could also remove the <code>string(k)</code> cast in the <code>getKeyVal()</code> implementation above.  However, we know in this case that we want the value between the first and second separator, and between the second and third separator, every time.  So in this contrived instance, we don&rsquo;t actually need to iterate and check delimiters.  We can just treat the entire line like the bytestring it is, and only find the indexes for the first, second, and third instances of the delimiter.</p>
<p>Another important fact is that, for this dataset, we know the largest key.  Therefore, instead of a map that we previously saw was costing us about 800ms to increment, we can use an array.  In this case, our integer key will be the index, and the value at that index will be the sum for that key.  With that in mind, we have a highly customised, but <strong>SUPER FAST</strong> version below.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">file</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">Open</span>(<span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">Args</span>[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">defer</span> <span style="color:#a6e22e">file</span>.<span style="color:#a6e22e">Close</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">processFile</span>(<span style="color:#a6e22e">file</span>)
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">processFile</span>(<span style="color:#a6e22e">file</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">File</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">sumByKey</span> [<span style="color:#ae81ff">2009</span>]<span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">scanner</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">bufio</span>.<span style="color:#a6e22e">NewScanner</span>(<span style="color:#a6e22e">file</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">key</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">val</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">scanner</span>.<span style="color:#a6e22e">Scan</span>() {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">line</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">scanner</span>.<span style="color:#a6e22e">Bytes</span>()
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">firstTab</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">bytes</span>.<span style="color:#a6e22e">IndexByte</span>(<span style="color:#a6e22e">line</span>, <span style="color:#e6db74">&#39;\t&#39;</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">secondTab</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">bytes</span>.<span style="color:#a6e22e">IndexByte</span>(<span style="color:#a6e22e">line</span>[<span style="color:#a6e22e">firstTab</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>:], <span style="color:#e6db74">&#39;\t&#39;</span>) <span style="color:#f92672">+</span> <span style="color:#a6e22e">firstTab</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">thirdTab</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">bytes</span>.<span style="color:#a6e22e">IndexByte</span>(<span style="color:#a6e22e">line</span>[<span style="color:#a6e22e">secondTab</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>:], <span style="color:#e6db74">&#39;\t&#39;</span>) <span style="color:#f92672">+</span> <span style="color:#a6e22e">secondTab</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">key</span> = <span style="color:#a6e22e">atoi</span>(<span style="color:#a6e22e">line</span>[<span style="color:#a6e22e">firstTab</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span> : <span style="color:#a6e22e">secondTab</span>])
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">val</span> = <span style="color:#a6e22e">atoi</span>(<span style="color:#a6e22e">line</span>[<span style="color:#a6e22e">secondTab</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span> : <span style="color:#a6e22e">thirdTab</span>])
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">sumByKey</span>[<span style="color:#a6e22e">key</span>] <span style="color:#f92672">+=</span> <span style="color:#a6e22e">val</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">k</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">v</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">val</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">sumByKey</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">val</span> &gt; <span style="color:#a6e22e">v</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">k</span> = <span style="color:#a6e22e">i</span>
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">v</span> = <span style="color:#a6e22e">val</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Printf</span>(<span style="color:#e6db74">&#34;max_key: %d sum: %d\n&#34;</span>, <span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>What&rsquo;s the <code>pprof</code> result?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Benchmark_processFile-4   	max_key: <span style="color:#ae81ff">2006</span> sum: <span style="color:#ae81ff">22569013</span>
</span></span><span style="display:flex;"><span>max_key: <span style="color:#ae81ff">2006</span> sum: <span style="color:#ae81ff">22569013</span>
</span></span><span style="display:flex;"><span>max_key: <span style="color:#ae81ff">2006</span> sum: <span style="color:#ae81ff">22569013</span>
</span></span><span style="display:flex;"><span>max_key: <span style="color:#ae81ff">2006</span> sum: <span style="color:#ae81ff">22569013</span>
</span></span><span style="display:flex;"><span>max_key: <span style="color:#ae81ff">2006</span> sum: <span style="color:#ae81ff">22569013</span>
</span></span><span style="display:flex;"><span>       3	 <span style="color:#ae81ff">482369483</span> ns/op
</span></span></code></pre></div><p>It&rsquo;s crazy fast!  This version finishes in 0.482s (482ms) on my machine.  Where is the most time spent now?  (Note that because the benchmark ran multiple times in order to get a stable timing for the run, the <code>pprof</code> results are the sum of all the runs.)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>      20ms      1.26s     38:	<span style="color:#66d9ef">for</span> scanner.Scan<span style="color:#f92672">()</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      70ms       70ms     39:		line :<span style="color:#f92672">=</span> scanner.Bytes<span style="color:#f92672">()</span>
</span></span><span style="display:flex;"><span>      40ms      200ms     40:		firstTab :<span style="color:#f92672">=</span> bytes.IndexByte<span style="color:#f92672">(</span>line, <span style="color:#e6db74">&#39;\t&#39;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>     190ms      330ms     41:		secondTab :<span style="color:#f92672">=</span> bytes.IndexByte<span style="color:#f92672">(</span>line<span style="color:#f92672">[</span>firstTab+1:<span style="color:#f92672">]</span>, <span style="color:#e6db74">&#39;\t&#39;</span><span style="color:#f92672">)</span> + firstTab + <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>     260ms      610ms     42:		thirdTab :<span style="color:#f92672">=</span> bytes.IndexByte<span style="color:#f92672">(</span>line<span style="color:#f92672">[</span>secondTab+1:<span style="color:#f92672">]</span>, <span style="color:#e6db74">&#39;\t&#39;</span><span style="color:#f92672">)</span> + secondTab + <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>      80ms      160ms     43:		key <span style="color:#f92672">=</span> atoi<span style="color:#f92672">(</span>line<span style="color:#f92672">[</span>firstTab+1 : secondTab<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>      40ms      180ms     44:		val <span style="color:#f92672">=</span> atoi<span style="color:#f92672">(</span>line<span style="color:#f92672">[</span>secondTab+1 : thirdTab<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>      70ms       70ms     45:		sumByKey<span style="color:#f92672">[</span>key<span style="color:#f92672">]</span> +<span style="color:#f92672">=</span> val
</span></span><span style="display:flex;"><span>         .          .     46:	<span style="color:#f92672">}</span>
</span></span></code></pre></div><p>Most of the time is spent indexing into the bytestring, which is what we expected.  There may be some clever ways to reduce this, in addition to some data structures which would allow us to do the incrementing faster, but at this point we&rsquo;re pretty far down the path of optimizing past production usage, and hand-tuned Fortran/assembly isn&rsquo;t really the goal.  In the end though, we processed a 184MB file, with 10,512,769 rows, in 0.482s.</p>
<p>Happy optimizing!</p>

<h1 id="updated-code" class="anchor-link"><a href="#updated-code">Updated code:</a></h1>
<p>Since the article was posted on Reddit and Hackernews, there was a user (Epiris) on Reddit who suggested some improvements.  After their suggestions, below is the code and benchmarks for the updated version.  It&rsquo;s important to note that a personal requirement I have for the code is that it cannot read all data into memory, since we must assume that the data stream could be arbitrarily large.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">processLine</span>(<span style="color:#a6e22e">b</span> []<span style="color:#66d9ef">byte</span>) (<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">key</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">val</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">b</span>[<span style="color:#a6e22e">i</span>] <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#39;\t&#39;</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">i</span><span style="color:#f92672">++</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span>; <span style="color:#a6e22e">b</span>[<span style="color:#a6e22e">i</span>] <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#39;\t&#39;</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">key</span> = <span style="color:#a6e22e">key</span><span style="color:#f92672">*</span><span style="color:#ae81ff">10</span> <span style="color:#f92672">+</span> int(<span style="color:#a6e22e">b</span>[<span style="color:#a6e22e">i</span>]) <span style="color:#f92672">-</span> <span style="color:#e6db74">&#39;0&#39;</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span>; <span style="color:#a6e22e">b</span>[<span style="color:#a6e22e">i</span>] <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#39;\t&#39;</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">val</span> = <span style="color:#a6e22e">val</span><span style="color:#f92672">*</span><span style="color:#ae81ff">10</span> <span style="color:#f92672">+</span> int(<span style="color:#a6e22e">b</span>[<span style="color:#a6e22e">i</span>]) <span style="color:#f92672">-</span> <span style="color:#e6db74">&#39;0&#39;</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">key</span>, <span style="color:#a6e22e">val</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">processFile</span>(<span style="color:#a6e22e">file</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">File</span>) (<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">sumByKey</span> [<span style="color:#ae81ff">2009</span>]<span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">scanner</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">bufio</span>.<span style="color:#a6e22e">NewScanner</span>(<span style="color:#a6e22e">file</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">scanner</span>.<span style="color:#a6e22e">Scan</span>() {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">line</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">scanner</span>.<span style="color:#a6e22e">Bytes</span>()
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">k1</span>, <span style="color:#a6e22e">v1</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">processLine</span>(<span style="color:#a6e22e">line</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">sumByKey</span>[<span style="color:#a6e22e">k1</span>] <span style="color:#f92672">+=</span> <span style="color:#a6e22e">v1</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">k</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">var</span> <span style="color:#a6e22e">v</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">val</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">sumByKey</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">val</span> &gt; <span style="color:#a6e22e">v</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">k</span> = <span style="color:#a6e22e">i</span>
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">v</span> = <span style="color:#a6e22e">val</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>And here is the associated benchmark.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Benchmark_processFile</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">file</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">Open</span>(<span style="color:#e6db74">&#34;../ngrams.tsv&#34;</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">defer</span> <span style="color:#a6e22e">file</span>.<span style="color:#a6e22e">Close</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">data</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">ioutil</span>.<span style="color:#a6e22e">ReadAll</span>(<span style="color:#a6e22e">file</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">ResetTimer</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">processFile</span>(<span style="color:#a6e22e">data</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">k</span> <span style="color:#f92672">!=</span> <span style="color:#ae81ff">2006</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">v</span> <span style="color:#f92672">!=</span> <span style="color:#ae81ff">22569013</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">Fatalf</span>(<span style="color:#e6db74">`bad result %v | %v`</span>, <span style="color:#a6e22e">k</span>, <span style="color:#a6e22e">v</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The output of the benchmarking:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Benchmark_processFile-4   	       5	 <span style="color:#ae81ff">309631168</span> ns/op	    <span style="color:#ae81ff">4152</span> B/op	       <span style="color:#ae81ff">4</span> allocs/op
</span></span></code></pre></div> ]]></content:encoded></item><item><title>Enough with the microservices</title><link>https://adamdrake.com/enough-with-the-microservices.html</link><pubDate>Sat, 20 May 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/enough-with-the-microservices.html</guid><description>&lt;h1 id="tldr" class="anchor-link">&lt;a href="#tldr">Tl;dr:&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>Donâ€™t even consider microservices unless you have a system thatâ€™s too complex to manage as a monolith. The majority of software systems should be built as a single monolithic application. Do pay attention to good modularity within that monolith, but donâ€™t try to separate it into separate services.&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>&amp;ndash; Martin Fowler&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>If you canâ€™t build a well-structured monolith, what makes you think microservices is the answer?&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>&amp;ndash; &lt;a href="https://twitter.com/simonbrown">Simon Brown&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h1 id="intro" class="anchor-link">&lt;a href="#intro">Intro&lt;/a>&lt;/h1>
&lt;p>Much has been written on the pros and cons of microservices, but unfortunately I&amp;rsquo;m still seeing them as something being pursued in a &lt;a href="https://en.wikipedia.org/wiki/Cargo_cult">cargo cult&lt;/a> fashion in the growth-stage startup world. At the risk of rewriting Martin Fowler&amp;rsquo;s &lt;a href="https://martinfowler.com/bliki/MicroservicePremium.html">Microservice Premium&lt;/a> article, I thought it would be good to write up some thoughts so that I can send them to clients when the topic arises, and hopefully help people avoid some of the mistakes I&amp;rsquo;ve seen. The mistake of choosing a path towards a given architecture or technology on the basis of so-called &lt;em>best practices&lt;/em> articles found online is a costly one, and if I can help a single company avoid it then writing this will have been worth it.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="tldr" class="anchor-link"><a href="#tldr">Tl;dr:</a></h1>
<blockquote>
<p>Donâ€™t even consider microservices unless you have a system thatâ€™s too complex to manage as a monolith. The majority of software systems should be built as a single monolithic application. Do pay attention to good modularity within that monolith, but donâ€™t try to separate it into separate services.</p>
</blockquote>
<blockquote>
<p>&ndash; Martin Fowler</p>
</blockquote>
<blockquote>
<p>If you canâ€™t build a well-structured monolith, what makes you think microservices is the answer?</p>
</blockquote>
<blockquote>
<p>&ndash; <a href="https://twitter.com/simonbrown">Simon Brown</a></p>
</blockquote>

<h1 id="intro" class="anchor-link"><a href="#intro">Intro</a></h1>
<p>Much has been written on the pros and cons of microservices, but unfortunately I&rsquo;m still seeing them as something being pursued in a <a href="https://en.wikipedia.org/wiki/Cargo_cult">cargo cult</a> fashion in the growth-stage startup world.  At the risk of rewriting Martin Fowler&rsquo;s <a href="https://martinfowler.com/bliki/MicroservicePremium.html">Microservice Premium</a> article, I thought it would be good to write up some thoughts so that I can send them to clients when the topic arises, and hopefully help people avoid some of the mistakes I&rsquo;ve seen.  The mistake of choosing a path towards a given architecture or technology on the basis of so-called <em>best practices</em> articles found online is a costly one, and if I can help a single company avoid it then writing this will have been worth it.</p>

<h1 id="context" class="anchor-link"><a href="#context">Context</a></h1>
<p>Microservices are still (unfortunately) currently a big thing and a tech buzzword <em>du jour</em>.  The approach has been around forever (<a href="https://en.wikipedia.org/wiki/Service-oriented_architecture">Service-Oriented architecture</a> anyone?) but for most of the companies I encounter, microservices aren&rsquo;t simply a waste of time or a distraction.  They actually make things <strong>worse</strong>.</p>
<p>This might seem strange, because most of the articles on microservices are extolling their countless virtues like decoupling tech systems, better horizontal scalability, removing dependencies between development teams, and so on.  If you&rsquo;re the size of Uber, Airbnb, Facebook, or Twitter, then that is all probably true.  I&rsquo;ve helped larger organizations with their microservices transitions, including helping them set up messaging systems and other technologies which allow for amazing scalability properties.  However, for growth-stage startups, all of that technology, and those microservices, are rarely needed.</p>
<blockquote>
<p>You are not Netflix, stop trying to be them!</p>
<p>&ndash;Russ Miles</p>
</blockquote>
<p>Russ Miles makes this his first point in his post <em>8 ways to lose at microservices adoption</em>, and it&rsquo;s something I see all the time.  Growth-stage startups often want to emulate the <em>best practices</em> they see at those companies, often to their own detriment.  Best practices are context dependent.  What is a best practice for a company like Facebook, may or may not be a best practice for a startup with a total engineering team size of 100 or less.</p>
<p>Even if you are smaller than the tech giants, you still might, on the balance, get some benefit from moving towards a microservices architecture.  However, a growth-stage startup doing a wholesale migration to microservices should be a firing-level offense for the tech people involved.</p>

<h1 id="why-microservices" class="anchor-link"><a href="#why-microservices">Why microservices?</a></h1>
<p>Usually, in growth-stage startups, the main motivation for moving to microservices is that hope that doing so will remove dependencies between development teams and/or improve the ability of the system to handle larger traffic loads (i.e., scalability).  Common complaints and symptoms are things like merge conflicts, bugs in deployment due to parts of the application not being ready to use partially implemented features, and horizontal scalability.  Let&rsquo;s break these down individually.</p>

<h2 id="dependencies" class="anchor-link"><a href="#dependencies">Dependencies</a></h2>
<p>In an early-stage startup, the dev team is small and the tech is small.  People can work well together without stepping on toes and it seems like everything is relatively fast to implement.  Life is good.</p>
<p>As the startup grows, the dev team grows, and the codebase grows, and soon there are multiple teams working on the same codebase.  These teams are often largely composed of the people who were around at the earlier stage of the startup.  Since many early-stage startups are a first job for many junior developers, they don&rsquo;t realize that the communication effectiveness has to increase as the team size and codebase size increases.  As is often the case for tech people who have limited experience, they reach for a technical solution to a people problem, and decide they need microservices in order to reduce dependencies or coupling between dev teams.</p>
<p>In reality, they need to address the people-related problems via more effective communication.  When a startup has multiple dev teams, it is a requirement that they stay coordinated and informed about everyone&rsquo;s work.  They need to collaborate.  Software development, in any organization of this size, is a social endeavor.  If there is little communication or information sharing between teams, they will have the same dependency problems, with or without the microservices.  However, with the microservices, they will also have all of the negative technical problems that come attached.</p>
<p>It is true that keeping the code modular, as a tech solution to the problem, can mitigate some of the inter-team dependencies inherent in software development, but the communication component still must be grown and improved as the team size grows.</p>
<p>Don&rsquo;t confuse <strong>decoupling</strong> with <strong>distribution</strong>.  You can achieve decoupling by having a monolith, composed of well-defined modules, with well-defined interfaces, and you <strong>should</strong>.  You don&rsquo;t need to <strong>distribute</strong> your application as separate services in order to benefit from the <strong>decoupling</strong> you get by having modules with clear interfaces.</p>

<h2 id="partial-feature-implementation" class="anchor-link"><a href="#partial-feature-implementation">Partial-feature implementation</a></h2>
<p>This point is often addressed by <a href="https://en.wikipedia.org/wiki/Feature_toggle">feature flags</a>, which are something you might need to be familiar with to successfully implement microservices anyway.  Especially as you get into <strong>rapid deployment</strong> (discussed more below), you may need to deploy parts of features which are not yet ready on certain platforms, or where the frontend implementation is complete but that backend is not, and so on.  As companies grow, and deployment and ops systems become more automated and complex, feature flags are something important to use and to use wisely.</p>

<h2 id="horizontal-scalability" class="anchor-link"><a href="#horizontal-scalability">Horizontal scalability</a></h2>
<p>This point has some merit in that multiple copies of the same microservice can be deployed in order to achieve a form of scalability.  However, most companies that adopt microservices too early will use the same storage subsystem (most often a database) to back all of their microservices.  What that means is that you don&rsquo;t really have horizontal scalability for your application, only for your service.  If this is the scalability method you plan to use, why not just deploy more copies of your monolith behind a load balancer?  You&rsquo;ll accomplish the same goal with less complexity.  Not only that, but the complexity that accompanies horizontal scalability should only be borne as a last resort.  Your first effort should be in taking reasonable steps to improve your application performance.  Often, even basic things can result in performance hundreds of times faster than the original system, and that also includes wisely using services which support your application.  I mentioned in my post on <a href="/redis-performance-triage-handbook.html">Redis performance triage</a>, for example.</p>

<h1 id="are-we-ready-for-microservices" class="anchor-link"><a href="#are-we-ready-for-microservices">Are we ready for microservices?</a></h1>
<p>This question is often never even considered when deliberating what an architecture should resemble, but it should be.  Many times, the senior technologists in a company simply identify complaints or pain points of developers or of the business, and then find something on the Internet claiming microservices architectures address those issues.  This claim has many caveats.  Microservices, like many things, come with positive and negative effects.  If your organization is mature enough, and has the tech in place, then the challenges associated with having microservices can be minimized, making the positive effects all the more apparent.  So what does it mean to be ready for microservices?  Martin Fowler wrote down his <a href="https://martinfowler.com/bliki/MicroservicePrerequisites.html">Microservice Prerequisites</a> years ago, and in my experience most growth-stage startups have totally ignored him.  Martin&rsquo;s prerequisites are a good place to start, so let&rsquo;s consider them.</p>
<ol>
<li>Rapid provisioning</li>
<li>Basic monitoring</li>
<li>Rapid deployment</li>
</ol>
<p>I can tell you from experience with dozens of growth-stage startups that almost none of them have even one of these prerequisites in place, never mind all of them.  If your tech team doesn&rsquo;t have the ability to quickly provision, deploy, and monitor all of your current systems, you <strong>must</strong> gain that capability before you consider migrating to microservices.  Let&rsquo;s consider each of these prerequisites in a bit more detail.</p>

<h2 id="rapid-provisioning" class="anchor-link"><a href="#rapid-provisioning">Rapid provisioning</a></h2>
<p>If your organization has only one or a few people in your entire dev team who can set up new services, virtual or otherwise, you are not ready for microservices.  You will need multiple members in each team with the ability to provision infrastructure and deploy services to that infrastructure without requiring outside assistance.  Remember, if you have a <em>DevOps Team</em>, then you are absolutely not doing DevOps.  Developers should be involved in managing everything about their applications, including infrastructure.</p>
<p>Likewise, if your current architecture is not backed by flexible infrastructure that is easy to scale up and down and can be managed by various people in the teams, you must address this before moving towards microservices.  You can of course have microservices running on your own bare metal machines, and you may have superior performance for lower cost, but you must still be able to have flexibility on ops and deployment of your services.</p>

<h2 id="basic-monitoring" class="anchor-link"><a href="#basic-monitoring">Basic monitoring</a></h2>
<p>If you don&rsquo;t monitor the system and application performance of your monolith, then you will have a miserable time with microservices.  You need familiarity with system level metrics (such as CPU and RAM), application level metrics (such as request latency per endpoint, or errors per endpoint), and business level metrics (such as transactions per second, or revenue per second) to understand the performance of your systems.  For all the complexities of the monolith, an ensemble of microservices is far more complex to understand, let alone troubleshoot, when it comes to performance.  Set up something like <a href="https://prometheus.io">Prometheus</a> and add all the necessary instrumentation to your monolith before carving parts of it out into microservices.</p>

<h2 id="rapid-deployment" class="anchor-link"><a href="#rapid-deployment">Rapid deployment</a></h2>
<p>If you don&rsquo;t have a good continuous integration and deployment process and system in place for your monolith, then trying to manage integration and deployment for your microservices will be nearly impossible.  Imagine having 10 teams and 100 services, all of which require manual integration testing and deployment.  Now imagine the same manual work, but with only one monolith.  How many ways can things go wrong with 100 services?  How many ways with 1 monolith?  This prerequisite is an excellent example of the complexity that comes along with a microservices approach.</p>
<p>Fowler&rsquo;s list has also been extended with a couple of additional prerequisites by <a href="https://www.infoq.com/news/2017/05/economics-microservices">Phil Calcado</a>, but I would say those are more along the lines of important extensions than true prerequisites.</p>

<h1 id="what-if-we-have-the-prerequisites" class="anchor-link"><a href="#what-if-we-have-the-prerequisites">What if we have the prerequisites?</a></h1>
<p>Even with the prerequisites in place, it is important to consider the negatives of microservices in order to make sure the approach really makes sense for your business.  The simple fact is that a lot of tech people pretend that the <a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">fallacies of distributed computing</a> are somehow not a concern in the microservices world, but all of those things must be taken into account in order to be successful.  For most growth-stage startups, there are just too many reasons to avoid microservices.</p>

<h2 id="increased-operational-overhead" class="anchor-link"><a href="#increased-operational-overhead">Increased operational overhead</a></h2>
<p>This is partially covered by the <strong>Rapid Deployment</strong> prerequisite, but consider that with microservices often come lofty aims of containerizing everything (probably with Docker) and using something like Kubernetes to orchestrate all of it.  While both systems are wonderful pieces of technology in many ways, for most growth-stage startups they can be a distraction.  I&rsquo;ve seen startups scale up to fantastic levels using <code>rsync</code> for their deployment and orchestration.  I&rsquo;ve also seen many  more startups get stuck in the quagmire of hugely complex ops tooling, which ends up stealing away valuable time they could be using to build features for customers.</p>

<h2 id="your-app-can-get-slower" class="anchor-link"><a href="#your-app-can-get-slower">Your app can get slower</a></h2>
<p>If you have multiple modules in your monolith, with well-defined APIs, then you have nearly zero overhead when interacting with those APIs.  This is definitely not the case with microservices, since they are often running on other machines and require a network hop between your services.  This can slow down your whole system considerably.  This situation becomes even worse if you have some services which need to contact multiple other services, synchronously, in order to complete a request.  I have worked with companies that had nearly 10 services, which had to be called, in order, for a request to be serviced.  At each step they have network overhead and other delays to service the request, and they could have easily put all of those services into one artifact, perhaps as different modules, and probably done some additional redesign to make things asynchronous.  It could have saved them an order of magnitude on their infrastructure costs.</p>

<h2 id="local-development-is-more-difficult" class="anchor-link"><a href="#local-development-is-more-difficult">Local development is more difficult</a></h2>
<p>If you have one monolith, probably backed by a database, then getting your application to run locally during your development process is pretty easy.  If you have 100 services, possibly with multiple datastores that may have dependencies, now local development can be an absolute nightmare.  Even Docker containers won&rsquo;t save you from this level of complexity.  They can make things easier of course, but you&rsquo;ll still have to deal with the dependency issue somehow.  Microservices, in theory, remove this requirement because each service is supposed to be independent from the start.  However, for growth-stage startups, that is almost never the case.  People usually need to have all (or nearly all) the services running on their machine in order to properly develop and test new features.  This complexity is extremely wasteful.</p>

<h2 id="it-can-be-harder-to-scale" class="anchor-link"><a href="#it-can-be-harder-to-scale">It can be harder to scale</a></h2>
<p>The easiest way to scale a monolith is to simply deploy additional copies of your monolith behind a load balancer.  This is a dead-simple way to scale up if your system receives more traffic, and it involves minimal additional complexity from an operations perspective.  The longer your system can survive on something like <a href="https://aws.amazon.com/elasticbeanstalk/">Elastic Beanstalk</a>, the better.  That will keep you and the team free to work on actually building things for customers instead of battling with your deployment pipeline.  Some of this pain can be mitigated by having the proper CI/CD systems as in the <strong>Rapid Deployment</strong> prerequisite, but things get a lot more complex when you&rsquo;re in the microservices world, and often that complexity is more trouble than it&rsquo;s worth.</p>

<h1 id="now-what" class="anchor-link"><a href="#now-what">Now what?</a></h1>
<p>If you&rsquo;re in a growth-stage startup with the need to make some changes to your architecture and microservices aren&rsquo;t the answer they seem to be, what is it that you <strong>should</strong> be doing?</p>
<p>It&rsquo;s important to note that Fowler&rsquo;s prerequisites are something of a <a href="https://en.wikipedia.org/wiki/Capability_Maturity_Model">Capability Maturity Model</a> for tech, and of course Fowler does have his own article on the topic of a <a href="https://martinfowler.com/bliki/MaturityModel.html">Maturity Model</a>.  <strong>IF</strong> it makes sense for the company, we can use his prerequisites and take other intermediate steps to prepare for a move to microservices.  To quote Fowler:</p>
<blockquote>
<p>The vital point here is that the true outcome of a maturity model assessment isn&rsquo;t what level you are but the list of things you need to work on to improve. Your current level is merely a piece of intermediate work in order to determine that list of skills to acquire next.</p>
</blockquote>
<p>So how do we look for things to improve, and what path should we take to get there?  There are a few simple, general steps. The first two <strong>alone</strong> will typically solve many of the problems that cause teams to move towards microservices, and without all the associated complexity.</p>
<ol>
<li>Clean up the application.  Make sure it has good automated tests and is using the current versions of all libraries, frameworks, and languages.</li>
<li>Refactor the application into clear modules with clear APIs.  Don&rsquo;t allow bits of the code to reach into the modules directly.  All interaction should be via the APIs presented by the module.</li>
<li>Choose one module in the application and split it into its own application on the same host.  This starts to give you some of the usefulness of totally separate microservices, but with fewer of the operations headaches.  You will, however, still have to cope with communication between two different components, albeit on the same host.  That fact allows you to disregard some of the complexity inherent in network partitions and availability on fully distributed systems like a microservices architecture.</li>
<li>Take the separated module and put it on a different host system.  Now you&rsquo;ll have to deal with the issues surrounding communication over a network, but you will have bought yourself a little less coupling between the two systems.</li>
<li>If possible, refactor the data storage system so that the module on the other host now has total responsibility for storage of data within its context.</li>
</ol>
<p>Even at larger scales, almost every company I&rsquo;ve seen only really needs the first two steps in order to be happy.  If they can do well with those, the remaining steps aren&rsquo;t always as important as they originally thought.  Better still, if you decide to stop at any point along the way, the system is still maintainable and probably in better shape than it was when you started.</p>

<h1 id="outro" class="anchor-link"><a href="#outro">Outro</a></h1>
<p>I can&rsquo;t claim that any of these ideas are unique, or that I came up with them.  This is simply a summary of observations and thoughts I&rsquo;ve collected from others who seem to have encountered the same thing.  Many others who have been around a lot longer than I have written about these topics, and some with a lot more clarity, like <a href="https://www.oreilly.com/ideas/modules-vs-microservices">Sander Mak&rsquo;s article on Modules and Microservices</a>.  Either way, these lessons are important and hopefully useful for companies considering what to do with their architectural future.  Consider all options carefully, and make sure that microservices are an appropriate path for your organization.</p>
<p>At least start with the first two steps in the section above, and <strong>after</strong> those are complete, then consider again whether microservices are the right direction for your organization.  Chances are, a lot of the issues you had previously will simply disappear.</p>
 ]]></content:encoded></item><item><title>Enough with the microservices (Chinese translation)</title><link>https://adamdrake.com/enough-with-the-microservices-chinese-translation.html</link><pubDate>Sat, 20 May 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/enough-with-the-microservices-chinese-translation.html</guid><description>&lt;p>èµ„æ·±æž¶æž„å¸ˆAdam Drakeåœ¨ä»–çš„åšå®¢ä¸Šåˆ†äº«äº†ä»–å¯¹å¾®æœåŠ¡çš„çœ‹æ³•ï¼Œä»–ä»Žè‡ªå·±çš„ç»éªŒå‡ºå‘ï¼Œç»“åˆMartin Fowlerå¯¹å¾®æœåŠ¡çš„è§è§£ï¼Œå¸®åŠ©æƒ³è¦é‡‡ç”¨å¾®æœåŠ¡çš„å…¬å¸é‡æ–°å®¡è§†å¾®æœåŠ¡ã€‚ä»¥ä¸‹å†…å®¹å·²èŽ·å¾—ä½œè€…ç¿»è¯‘æŽˆæƒï¼ŒæŸ¥çœ‹è‹±æ–‡åŽŸæ–‡ &lt;a href="https://adamdrake.com/enough-with-the-microservices.html">Enough with the microservicesã€‚&lt;/a>&lt;/p>
&lt;p>ç®€ä»‹&lt;/p>
&lt;p>å…³äºŽå¾®æœåŠ¡çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿å·²ç»æœ‰è¿‡å¤ªå¤šçš„è®¨è®ºï¼Œä¸è¿‡æˆ‘ä»ç„¶çœ‹åˆ°å¾ˆå¤šæˆé•¿åž‹åˆåˆ›å…¬å¸å¯¹å®ƒè¿›è¡Œç€ç›²ç›®å´‡æ‹œã€‚å†’ç€â€œé‡å¤å‘æ˜Žè½®å­â€çš„é£Žé™©ï¼ˆMartin Fowlerå·²ç»å†™è¿‡â€œMicroservice Premiumâ€çš„æ–‡ç« ï¼‰ï¼Œæˆ‘æƒ³æŠŠæˆ‘çš„ä¸€äº›æƒ³æ³•å†™ä¸‹æ¥ï¼Œåœ¨å¿…è¦çš„æ—¶å€™å¯ä»¥å‘ç»™å®¢æˆ·ï¼Œä¹Ÿå¸Œæœ›èƒ½å¤Ÿå¸®åŠ©äººä»¬é¿å…çŠ¯ä¸‹æˆ‘ä¹‹å‰è§è¿‡çš„é‚£äº›é”™è¯¯ã€‚åœ¨è¿›è¡Œæž¶æž„æˆ–æŠ€æœ¯é€‰åž‹æ—¶ï¼Œå°†ç½‘ç»œä¸Šæ‰¾åˆ°çš„ä¸€äº›æ‰€è°“çš„æœ€ä½³å®žè·µæ–‡ç« ä½œä¸ºæŒ‡å—ï¼Œä¸€æ—¦åšå‡ºäº†é”™è¯¯çš„å†³å®šï¼Œå°±è¦ä»˜å‡ºæƒ¨é‡çš„ä»£ä»·ã€‚å¦‚æžœèƒ½å¤Ÿå¸®åŠ©å“ªæ€•ä¸€ä¸ªå…¬å¸é¿å…çŠ¯ä¸‹è¿™ç§é”™è¯¯ï¼Œé‚£ä¹ˆå†™è¿™ç¯‡æ–‡ç« éƒ½æ˜¯å€¼å¾—çš„ã€‚&lt;/p></description><content:encoded><![CDATA[ <p>èµ„æ·±æž¶æž„å¸ˆAdam Drakeåœ¨ä»–çš„åšå®¢ä¸Šåˆ†äº«äº†ä»–å¯¹å¾®æœåŠ¡çš„çœ‹æ³•ï¼Œä»–ä»Žè‡ªå·±çš„ç»éªŒå‡ºå‘ï¼Œç»“åˆMartin Fowlerå¯¹å¾®æœåŠ¡çš„è§è§£ï¼Œå¸®åŠ©æƒ³è¦é‡‡ç”¨å¾®æœåŠ¡çš„å…¬å¸é‡æ–°å®¡è§†å¾®æœåŠ¡ã€‚ä»¥ä¸‹å†…å®¹å·²èŽ·å¾—ä½œè€…ç¿»è¯‘æŽˆæƒï¼ŒæŸ¥çœ‹è‹±æ–‡åŽŸæ–‡ <a href="/enough-with-the-microservices.html">Enough with the microservicesã€‚</a></p>
<p>ç®€ä»‹</p>
<p>å…³äºŽå¾®æœåŠ¡çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿å·²ç»æœ‰è¿‡å¤ªå¤šçš„è®¨è®ºï¼Œä¸è¿‡æˆ‘ä»ç„¶çœ‹åˆ°å¾ˆå¤šæˆé•¿åž‹åˆåˆ›å…¬å¸å¯¹å®ƒè¿›è¡Œç€ç›²ç›®å´‡æ‹œã€‚å†’ç€â€œé‡å¤å‘æ˜Žè½®å­â€çš„é£Žé™©ï¼ˆMartin Fowlerå·²ç»å†™è¿‡â€œMicroservice Premiumâ€çš„æ–‡ç« ï¼‰ï¼Œæˆ‘æƒ³æŠŠæˆ‘çš„ä¸€äº›æƒ³æ³•å†™ä¸‹æ¥ï¼Œåœ¨å¿…è¦çš„æ—¶å€™å¯ä»¥å‘ç»™å®¢æˆ·ï¼Œä¹Ÿå¸Œæœ›èƒ½å¤Ÿå¸®åŠ©äººä»¬é¿å…çŠ¯ä¸‹æˆ‘ä¹‹å‰è§è¿‡çš„é‚£äº›é”™è¯¯ã€‚åœ¨è¿›è¡Œæž¶æž„æˆ–æŠ€æœ¯é€‰åž‹æ—¶ï¼Œå°†ç½‘ç»œä¸Šæ‰¾åˆ°çš„ä¸€äº›æ‰€è°“çš„æœ€ä½³å®žè·µæ–‡ç« ä½œä¸ºæŒ‡å—ï¼Œä¸€æ—¦åšå‡ºäº†é”™è¯¯çš„å†³å®šï¼Œå°±è¦ä»˜å‡ºæƒ¨é‡çš„ä»£ä»·ã€‚å¦‚æžœèƒ½å¤Ÿå¸®åŠ©å“ªæ€•ä¸€ä¸ªå…¬å¸é¿å…çŠ¯ä¸‹è¿™ç§é”™è¯¯ï¼Œé‚£ä¹ˆå†™è¿™ç¯‡æ–‡ç« éƒ½æ˜¯å€¼å¾—çš„ã€‚</p>
<p>å¦‚ä»Šå¾®æœåŠ¡æ˜¯ä¸ªçƒ­é—¨æŠ€æœ¯ï¼Œå¾®æœåŠ¡æž¶æž„ä¸€ç›´ä»¥æ¥éƒ½å­˜åœ¨ï¼ˆé¢å‘æœåŠ¡æž¶æž„ä¹Ÿç®—æ˜¯å§ï¼Ÿï¼‰ï¼Œä½†å¯¹äºŽæˆ‘æ‰€è§è¿‡çš„å¤§éƒ¨åˆ†å…¬å¸æ¥è¯´ï¼Œå¾®æœåŠ¡ä¸ä»…æµªè´¹äº†ä»–ä»¬çš„æ—¶é—´ï¼Œåˆ†æ•£äº†ä»–ä»¬çš„æ³¨æ„åŠ›ï¼Œè€Œä¸”è®©äº‹æƒ…å˜å¾—æ›´ç³Ÿç³•ã€‚</p>
<p>è¿™å¬èµ·æ¥ä¼¼ä¹Žå¾ˆå¥‡æ€ªï¼Œå› ä¸ºå¤§éƒ¨åˆ†å…³äºŽå¾®æœåŠ¡çš„æ–‡ç« éƒ½ä¼šè‚¯å®šå¾®æœåŠ¡çš„å„ç§å¥½å¤„ï¼Œæ¯”å¦‚è§£è€¦ç³»ç»Ÿã€æ›´å¥½çš„ä¼¸ç¼©æ€§ã€æ¶ˆé™¤å¼€å‘å›¢é˜Ÿä¹‹é—´çš„ä¾èµ–ï¼Œç­‰ç­‰ã€‚å¦‚æžœä½ çš„å…¬å¸æœ‰Uberã€Airbnbã€Facebookæˆ–Twitteré‚£æ ·çš„è§„æ¨¡ï¼Œé‚£ä¹ˆå°±æ²¡æœ‰ä»€ä¹ˆé—®é¢˜ã€‚æˆ‘æ›¾ç»å¸®åŠ©ä¸€äº›å¤§åž‹ç»„ç»‡è½¬åž‹åˆ°å¾®æœåŠ¡æž¶æž„ï¼ŒåŒ…æ‹¬æ­å»ºæ¶ˆæ¯ç³»ç»Ÿå’Œé‡‡ç”¨ä¸€äº›èƒ½å¤Ÿæå‡ä¼¸ç¼©æ€§çš„æŠ€æœ¯ã€‚ä¸è¿‡ï¼Œå¯¹äºŽæˆé•¿åž‹åˆåˆ›å…¬å¸æ¥è¯´ï¼Œå¾ˆå°‘éœ€è¦è¿™äº›æŠ€æœ¯å’ŒæœåŠ¡ã€‚</p>
<p>Russ Milesåœ¨ä»–çš„ã€Šè®©å¾®æœåŠ¡å¤±æ•ˆçš„å…«ç§æ–¹å¼ã€‹è¿™ç¯‡æ–‡ç« ä¸­è¡¨è¾¾äº†ä»–çš„é¦–è¦è§‚ç‚¹ï¼Œè€Œåœ¨æˆ‘çœ‹æ¥ï¼Œè¿™äº›åœºæ™¯å´åˆ°å¤„å¯è§ã€‚æˆé•¿åž‹åˆåˆ›å…¬å¸æ€»æ˜¯æƒ³æ¨¡ä»¿é‚£äº›å¤§å…¬å¸çš„æœ€ä½³å®žè·µï¼Œç”¨å®ƒä»¬æ¥å¼¥è¡¥è‡ªèº«çš„ä¸è¶³ã€‚ä½†æ˜¯ï¼Œæœ€ä½³å®žè·µæ˜¯è¦è§†æƒ…å†µè€Œå®šçš„ã€‚æœ‰äº›ä¸œè¥¿å¯¹äºŽFacebookæ¥è¯´æ˜¯æœ€ä½³å®žè·µï¼Œä½†å¯¹äºŽåªæœ‰ä¸åˆ°ç™¾äººçš„åˆåˆ›å…¬å¸æ¥è¯´ï¼Œå®ƒä»¬å°±ä¸ä¸€å®šä¹Ÿæ˜¯æœ€ä½³å®žè·µã€‚</p>
<p>å¦‚æžœä½ çš„å…¬å¸æ¯”é‚£äº›å¤§å…¬å¸å°ä¸€äº›ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šä½ ä»ç„¶èƒ½å¤Ÿä»Žå¾®æœåŠ¡æž¶æž„ä¸­èŽ·ç›Šã€‚ä½†æ˜¯ï¼Œå¯¹äºŽæˆé•¿åž‹åˆåˆ›å…¬å¸æ¥è¯´ï¼Œå¤§è§„æ¨¡åœ°è¿ç§»åˆ°å¾®æœåŠ¡æ˜¯ä¸€ç§è¿‡é”™ï¼Œè€Œä¸”å¯¹æŠ€æœ¯äººæ¥è¯´æ˜¯ä¸å…¬å¹³çš„ã€‚</p>
<p>ä¸ºä»€ä¹ˆé€‰æ‹©å¾®æœåŠ¡ï¼Ÿ</p>
<p>ä¸€èˆ¬æ¥è¯´ï¼Œæˆé•¿åž‹åˆåˆ›å…¬å¸é‡‡ç”¨å¾®æœåŠ¡æž¶æž„æœ€ä¸»è¦çš„ç›®çš„ä¸ºäº†å‡å°‘æˆ–æ¶ˆé™¤å¼€å‘å›¢é˜Ÿä¹‹é—´çš„ä¾èµ–ï¼Œæˆ–è€…æå‡ç³»ç»Ÿå¤„ç†å¤§æµé‡è´Ÿè½½çš„èƒ½åŠ›ï¼ˆæ¯”å¦‚ä¼¸ç¼©æ€§ï¼‰ã€‚å¼€å‘äººå‘˜ç»å¸¸æŠ±æ€¨çš„é—®é¢˜å’Œå¸¸è§çš„ç—‡çŠ¶åŒ…æ‹¬åˆå¹¶å†²çªã€ç”±æœªå®Œæ•´å®žçŽ°çš„åŠŸèƒ½å¼•èµ·çš„éƒ¨ç½²é”™è¯¯ä»¥åŠä¼¸ç¼©æ€§é—®é¢˜ã€‚æŽ¥ä¸‹æ¥è®©æˆ‘ä»¬é€ä¸ªè¯´æ˜Žè¿™äº›é—®é¢˜ã€‚</p>
<p>ä¾èµ–</p>
<p>åœ¨åˆåˆ›å…¬å¸çš„æ—©æœŸé˜¶æ®µï¼Œå¼€å‘å›¢é˜Ÿè§„æ¨¡ä¸å¤§ï¼Œä½¿ç”¨çš„æŠ€æœ¯ä¹Ÿå¾ˆç®€å•ã€‚äººä»¬åœ¨ä¸€èµ·å·¥ä½œï¼Œä¸ä¼šå‡ºçŽ°æ··ä¹±ï¼Œè¦å®žçŽ°ä¸€äº›åŠŸèƒ½ä¹Ÿæ¯”è¾ƒå¿«ã€‚ä¸€åˆ‡çœ‹èµ·æ¥éƒ½å¾ˆç¾Žå¥½ã€‚</p>
<p>éšç€å…¬å¸çš„ä¸æ–­å‘å±•ï¼Œå¼€å‘å›¢é˜Ÿä¹Ÿåœ¨å£®å¤§ï¼Œä»£ç åº“ä¹Ÿåœ¨å¢žé•¿ï¼Œç„¶åŽå°±å‡ºçŽ°äº†å¤šä¸ªå›¢é˜Ÿåœ¨åŒä¸€ä¸ªä»£ç åº“ä¸Šå·¥ä½œçš„æƒ…å†µã€‚è¿™äº›å›¢é˜Ÿçš„å¤§éƒ¨åˆ†æˆå‘˜éƒ½æ˜¯å…¬å¸æ—©æœŸçš„å‘˜å·¥ã€‚å› ä¸ºåˆåˆ›å…¬å¸çš„æ—©æœŸå‘˜å·¥ä¸€èˆ¬éƒ½æ˜¯åˆçº§å¼€å‘äººå‘˜ï¼Œä»–ä»¬å¹¶æ²¡æœ‰æ„è¯†åˆ°ä¸€ä¸ªé—®é¢˜ï¼Œé‚£å°±æ˜¯åœ¨å›¢é˜Ÿè§„æ¨¡å¢žé•¿å’Œä»£ç åº“å¢žé•¿çš„åŒæ—¶ï¼Œæ²Ÿé€šæ•ˆçŽ‡ä¹Ÿéœ€è¦éšä¹‹æå‡ã€‚å¯¹äºŽç¼ºä¹ç»éªŒçš„æŠ€æœ¯äººå‘˜æ¥è¯´ï¼Œä»–ä»¬å€¾å‘äºŽé€šè¿‡æŠ€æœ¯é—®é¢˜æ¥è§£å†³äººçš„é—®é¢˜ï¼Œå¹¶å¸Œæœ›é€šè¿‡å¾®æœåŠ¡æ¥å‡å°‘å¼€å‘å›¢é˜Ÿä¹‹é—´çš„ä¾èµ–å’Œè€¦åˆã€‚</p>
<p>å®žé™…ä¸Šï¼Œä»–ä»¬çœŸæ­£éœ€è¦åšçš„æ˜¯é€šè¿‡æœ‰æ•ˆçš„æ²Ÿé€šæ¥è§£å†³äººçš„é—®é¢˜ã€‚å½“ä¸€ä¸ªåˆåˆ›å…¬å¸æœ‰å¤šä¸ªå¼€å‘å›¢é˜Ÿæ—¶ï¼Œå›¢é˜Ÿä¹‹é—´éœ€è¦åè°ƒï¼Œå›¢é˜Ÿæˆå‘˜éœ€è¦çŸ¥é“æ¯ä¸ªäººéƒ½åœ¨åšä»€ä¹ˆï¼Œä»–ä»¬éœ€è¦åä½œã€‚åœ¨è¿™æ ·è§„æ¨¡çš„ä¼ä¸šé‡Œï¼Œè½¯ä»¶å¼€å‘å…¶å®žå…·å¤‡äº†ç¤¾äº¤çš„æ€§è´¨ã€‚å¦‚æžœå›¢é˜Ÿä¹‹é—´ç¼ºä¹æ²Ÿé€šæˆ–è€…ç¼ºä¹ä¿¡æ¯åˆ†äº«ï¼Œä¸ç®¡ç”¨ä¸ç”¨å¾®æœåŠ¡ï¼Œä¸€æ ·å­˜åœ¨ä¾èµ–é—®é¢˜ï¼Œè€Œå°±ç®—ä½¿ç”¨äº†å¾®æœåŠ¡ï¼Œä¹Ÿä»ç„¶å­˜åœ¨è´Ÿé¢çš„æŠ€æœ¯é—®é¢˜ã€‚</p>
<p>å°†ä»£ç æ¨¡å—åŒ–ä½œä¸ºè§£å†³è¿™ä¸ªé—®é¢˜çš„æŠ€æœ¯æ–¹æ¡ˆï¼Œç¡®å®žèƒ½å¤Ÿç¼“è§£è½¯ä»¶å¼€å‘å›ºæœ‰çš„å›¢é˜Ÿä¾èµ–é—®é¢˜ï¼Œä½†å›¢é˜Ÿé—´çš„æ²Ÿé€šä»ç„¶è¦éšç€å›¢é˜Ÿè§„æ¨¡çš„å¢žé•¿è€Œä¸æ–­æ”¹è¿›ã€‚</p>
<p>ä¸è¦æ··æ·†äº†è§£è€¦å’Œåˆ†å¸ƒå¼äºŒè€…çš„å«ä¹‰ã€‚ç”±æ¨¡å—å’ŒæŽ¥å£ç»„æˆçš„å•ä½“å¯ä»¥å¸®åŠ©ä½ è¾¾åˆ°è§£è€¦çš„ç›®çš„ï¼Œè€Œä¸”ä½ ä¹Ÿåº”è¯¥è¿™ä¹ˆåšã€‚ä½ æ²¡æœ‰å¿…è¦æŠŠåº”ç”¨ç¨‹åºæ‹†åˆ†æˆåˆ†å¸ƒå¼çš„å¤šä¸ªç‹¬ç«‹æœåŠ¡ï¼Œåœ¨æ¨¡å—é—´å®šä¹‰æ¸…æ™°çš„æŽ¥å£åŒæ ·èƒ½è¾¾åˆ°è§£è€¦çš„ç›®çš„ã€‚</p>
<p>éƒ¨åˆ†åŠŸèƒ½å®žçŽ°</p>
<p>å¾®æœåŠ¡é‡Œéœ€è¦ç”¨åˆ°åŠŸèƒ½æ ‡å¿—ï¼ˆfeature flagï¼‰ï¼Œå¾®æœåŠ¡å¼€å‘äººå‘˜éœ€è¦ç†Ÿæ‚‰è¿™ç§æŠ€æœ¯ã€‚ç‰¹åˆ«æ˜¯åœ¨è¿›è¡Œå¿«é€Ÿå¼€å‘ï¼ˆä¸‹é¢ä¼šæ·±å…¥è®¨è®ºï¼‰çš„æ—¶å€™ï¼Œä½ å¯èƒ½éœ€è¦éƒ¨ç½²ä¸€äº›åŠŸèƒ½ï¼Œè¿™äº›åŠŸèƒ½åœ¨æŸäº›å¹³å°ä¸Šè¿˜æ²¡æœ‰å®žçŽ°ï¼Œæˆ–è€…å‰ç«¯å·²ç»å®Œå…¨å®žçŽ°ï¼Œä½†åŽç«¯è¿˜æ²¡æœ‰ã€‚éšç€å…¬å¸çš„å‘å±•ï¼Œéƒ¨ç½²å’Œè¿ç»´ç³»ç»Ÿå˜å¾—è¶Šæ¥è¶Šè‡ªåŠ¨åŒ–å’Œå¤æ‚ï¼ŒåŠŸèƒ½æ ‡å¿—ä¹Ÿå˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚</p>
<p>æ°´å¹³ä¼¸ç¼©</p>
<p>é€šè¿‡éƒ¨ç½²åŒä¸€ä¸ªå¾®æœåŠ¡çš„å¤šä¸ªå®žä¾‹æ¥èŽ·å¾—ä¼¸ç¼©æ€§ï¼Œè¿™æ˜¯å¾®æœåŠ¡çš„ä¼˜ç‚¹ä¹‹ä¸€ã€‚ä¸è¿‡ï¼Œå¤§å¤šæ•°è¿‡æ—©é‡‡ç”¨å¾®æœåŠ¡çš„å…¬å¸åœ¨è¿™äº›å¾®æœåŠ¡èƒŒåŽä½¿ç”¨äº†åŒä¸€ä¸ªå­˜å‚¨ç³»ç»Ÿã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™äº›æœåŠ¡å…·å¤‡äº†ä¼¸ç¼©æ€§ï¼Œä½†æ•´ä¸ªåº”ç”¨å¹¶ä¸å…·å¤‡ä¼¸ç¼©æ€§ã€‚å¦‚æžœä½ æ­£æ‰“ç®—ä½¿ç”¨è¿™æ ·çš„ä¼¸ç¼©æ–¹å¼ï¼Œé‚£ä¸ºä»€ä¹ˆä¸ç›´æŽ¥åœ¨è´Ÿè½½å‡è¡¡å™¨åŽé¢éƒ¨ç½²å¤šä¸ªå•ä½“å®žä¾‹å‘¢ï¼Ÿä½ å¯ä»¥ç”¨æ›´ç®€å•çš„æ–¹å¼è¾¾åˆ°ç›¸åŒçš„ç›®çš„ã€‚å†è€…ï¼Œæ°´å¹³ä¼¸ç¼©åº”è¯¥è¢«ä½œä¸ºæ€æ‰‹é”æ¥ä½¿ç”¨ã€‚ä½ é¦–å…ˆè¦å…³æ³¨çš„åº”è¯¥æ˜¯å¦‚ä½•æå‡åº”ç”¨ç¨‹åºçš„æ€§èƒ½ã€‚ä¸€äº›ç®€å•çš„ä¼˜åŒ–å¸¸å¸¸èƒ½å¸¦æ¥æ•°ç™¾å€çš„æ€§èƒ½æå‡ï¼Œè¿™é‡Œä¹ŸåŒ…æ‹¬å¦‚ä½•æ­£ç¡®åœ°ä½¿ç”¨å…¶ä»–æœåŠ¡ã€‚ä¾‹å¦‚ï¼Œæˆ‘åœ¨ä¸€ç¯‡åšæ–‡é‡Œæåˆ°çš„Redisæ€§èƒ½è¯Šæ–­ã€‚</p>
<p>æˆ‘ä»¬ä¸ºå¾®æœåŠ¡åšå¥½å‡†å¤‡äº†å—ï¼Ÿ</p>
<p>åœ¨è®¨è®ºæž¶æž„é€‰åž‹æ—¶ï¼Œäººä»¬ç»å¸¸ä¼šå¿½ç•¥è¿™ä¸ªé—®é¢˜ï¼Œä½†å…¶å®žå´æ˜¯æœ€é‡è¦çš„ã€‚é«˜çº§æŠ€æœ¯äººå‘˜åœ¨äº†è§£äº†å¼€å‘äººå‘˜æˆ–ä¸šåŠ¡äººå‘˜çš„æŠ±æ€¨æˆ–ç—›ç‚¹ä¹‹åŽï¼Œåœ¨ç½‘ä¸Šæ‰¾å¯»æ‰¾è§£å†³æ–¹æ¡ˆï¼Œä»–ä»¬æ€»æ˜¯å®£ç§°èƒ½è§£å†³è¿™äº›é—®é¢˜ã€‚ä½†åœ¨è¿™äº›ä¿¡èª“æ—¦æ—¦çš„è§‚ç‚¹èƒŒåŽï¼Œæœ‰å¾ˆå¤šéœ€è¦æ³¨æ„çš„åœ°æ–¹ã€‚å¾®æœåŠ¡æœ‰åˆ©ä¹Ÿæœ‰å¼Šã€‚å¦‚æžœä½ çš„ä¼ä¸šè¶³å¤Ÿæˆç†Ÿï¼Œå¹¶ä¸”å…·æœ‰ä¸€å®šçš„æŠ€æœ¯ç§¯ç´¯ï¼Œé‚£ä¹ˆé‡‡ç”¨å¾®æœåŠ¡æ‰€é¢ä¸´çš„æŒ‘æˆ˜ä¼šå°å¾ˆå¤šï¼Œå¹¶ä¸”èƒ½å¤Ÿå¸¦æ¥æ›´å¤šæ­£é¢å¥½å¤„ã€‚é‚£ä¹ˆæ€Žæ ·æ‰ç®—å·²ç»ä¸ºå¾®æœåŠ¡åšå¥½å‡†å¤‡äº†å‘¢ï¼ŸMartin Fowleråœ¨å¤šå¹´å‰è¡¨è¾¾äº†ä»–å¯¹å¾®æœåŠ¡å…ˆå†³æ¡ä»¶çš„çœ‹æ³•ï¼Œä½†æ˜¯ä»Žæˆ‘çš„ç»éªŒæ¥çœ‹ï¼Œå¤§å¤šæ•°æˆé•¿åž‹åˆåˆ›å…¬å¸å®Œå…¨å¿½ç•¥äº†ä»–çš„è§‚ç‚¹ã€‚Martinçš„è§‚ç‚¹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åˆ‡å…¥ç‚¹ï¼Œè®©æˆ‘ä»¬æ¥é€ä¸ªè¯´æ˜Žã€‚</p>
<p>æˆ‘æ•¢è¯´ï¼Œå¤§éƒ¨åˆ†æˆé•¿åž‹åˆåˆ›å…¬å¸å‡ ä¹Žè¿žä¸€ä¸ªå…ˆå†³æ¡ä»¶éƒ½æ— æ³•æ»¡è¶³ï¼Œæ›´ä¸ç”¨è¯´æ»¡è¶³æ‰€æœ‰çš„æ¡ä»¶äº†ã€‚å¦‚æžœä½ çš„æŠ€æœ¯å›¢é˜Ÿä¸å…·å¤‡å¿«é€Ÿé…ç½®ã€éƒ¨ç½²å’Œç›‘æŽ§èƒ½åŠ›ï¼Œé‚£ä¹ˆåœ¨è¿ç§»åˆ°å¾®æœåŠ¡å‰å¿…é¡»å…ˆèŽ·å¾—è¿™äº›èƒ½åŠ›ã€‚æŽ¥ä¸‹æ¥è®©æˆ‘ä»¬æ›´è¯¦ç»†åœ°è®¨è®ºè¿™äº›å…ˆå†³æ¡ä»¶ã€‚</p>
<p>å¿«é€Ÿé…ç½®</p>
<p>å¦‚æžœä½ çš„å¼€å‘å›¢é˜Ÿé‡Œåªæœ‰å°‘æ•°å‡ ä¸ªäººå¯ä»¥é…ç½®æ–°æœåŠ¡ã€è™šæ‹ŸçŽ¯å¢ƒæˆ–å…¶ä»–é…å¥—è®¾æ–½ï¼Œé‚£è¯´æ˜Žä½ ä»¬è¿˜æ²¡æœ‰ä¸ºå¾®æœåŠ¡åšå¥½å‡†å¤‡ã€‚ä½ çš„æ¯ä¸ªå›¢é˜Ÿé‡Œéƒ½åº”è¯¥è¦æœ‰å‡ ä¸ªè¿™æ ·çš„äººï¼Œä»–ä»¬å…·å¤‡äº†é…ç½®åŸºç¡€è®¾æ–½å’Œéƒ¨ç½²æœåŠ¡çš„èƒ½åŠ›ï¼Œè€Œä¸”ä¸éœ€è¦æ±‚åŠ©äºŽå¤–éƒ¨ã€‚è¦æ³¨æ„ï¼Œå…‰æ˜¯æœ‰ä¸€ä¸ªDevOpså›¢é˜Ÿå¹¶ä¸æ„å‘³ç€ä½ åœ¨å®žæ–½DevOpsã€‚å¼€å‘äººå‘˜åº”è¯¥å‚ä¸Žç®¡ç†ä¸Žåº”ç”¨ç¨‹åºç›¸å…³çš„ç»„ä»¶ï¼ŒåŒ…æ‹¬åŸºç¡€è®¾æ–½ã€‚</p>
<p>ç±»ä¼¼çš„ï¼Œå¦‚æžœä½ æ²¡æœ‰çµæ´»çš„åŸºç¡€è®¾æ–½ï¼ˆæ˜“äºŽä¼¸ç¼©å¹¶ä¸”å¯ä»¥ç”±å›¢é˜Ÿé‡Œçš„ä¸åŒäººå‘˜æ¥ç®¡ç†ï¼‰æ¥æ”¯æ’‘å½“å‰çš„æž¶æž„ï¼Œé‚£ä¹ˆåœ¨è¿ç§»åˆ°å¾®æœåŠ¡å‰å¿…é¡»å…ˆè§£å†³è¿™ä¸ªé—®é¢˜ã€‚ä½ å½“ç„¶å¯ä»¥åœ¨è£¸æœºä¸Šè¿è¡Œå¾®æœåŠ¡ï¼Œä»¥æ›´ä½Žçš„æˆæœ¬èŽ·å¾—å‡ºä¼—çš„æ€§èƒ½ï¼Œä½†åœ¨æœåŠ¡çš„è¿ç»´å’Œéƒ¨ç½²æ–¹é¢ä¹Ÿå¿…é¡»å…·å¤‡çµæ´»æ€§ã€‚</p>
<p>åŸºæœ¬çš„ç›‘æŽ§</p>
<p>å¦‚æžœä½ ä¸æ›¾å¯¹ä½ çš„å•ä½“åº”ç”¨è¿›è¡Œè¿‡æ€§èƒ½ç›‘æŽ§ï¼Œé‚£ä¹ˆåœ¨è¿ç§»åˆ°å¾®æœåŠ¡æ—¶ï¼Œä½ çš„æ—¥å­ä¼šå¾ˆéš¾è¿‡ã€‚ä½ éœ€è¦ç†Ÿæ‚‰ç³»ç»Ÿçº§åˆ«çš„åº¦é‡æŒ‡æ ‡ï¼ˆæ¯”å¦‚CPUå’Œå†…å­˜ï¼‰ã€åº”ç”¨çº§åˆ«çš„åº¦é‡æŒ‡æ ‡ï¼ˆæ¯”å¦‚ç«¯ç‚¹çš„è¯·æ±‚å»¶è¿Ÿæˆ–ç«¯ç‚¹çš„é”™è¯¯ï¼‰å’Œä¸šåŠ¡çº§åˆ«çš„åº¦é‡æŒ‡æ ‡ï¼ˆæ¯”å¦‚æ¯ç§’äº‹åŠ¡æ•°æˆ–æ¯ç§’æ”¶ç›Šï¼‰ï¼Œè¿™æ ·æ‰å¯ä»¥æ›´å¥½åœ°ç†è§£ç³»ç»Ÿçš„æ€§èƒ½ã€‚åœ¨æ€§èƒ½æ–¹é¢ï¼Œå¾®æœåŠ¡ç”Ÿæ€ç³»ç»Ÿæ¯”å•ä½“ç³»ç»Ÿè¦å¤æ‚å¾—å¤šï¼Œå°±æ›´ä¸ç”¨æè¯Šæ–­é—®é¢˜çš„å¤æ‚æ€§äº†ã€‚ä½ å¯ä»¥æ­å»ºä¸€ä¸ªç›‘æŽ§ç³»ç»Ÿï¼ˆå¦‚Prometheusï¼‰ï¼Œåœ¨å°†å•ä½“åº”ç”¨æ‹†åˆ†æˆå¾®æœåŠ¡ä¹‹å‰å¯¹åº”ç”¨åšä¸€äº›å¢žå¼ºï¼Œä»¥ä¾¿è¿›è¡Œç›‘æŽ§ã€‚</p>
<p>å¿«é€Ÿéƒ¨ç½²</p>
<p>å¦‚æžœä½ çš„å•ä½“ç³»ç»Ÿæ²¡æœ‰ä¸€ä¸ªå¾ˆå¥½çš„æŒç»­é›†æˆæµç¨‹å’Œéƒ¨ç½²ç³»ç»Ÿï¼Œé‚£ä¹ˆè¦é›†æˆå’Œéƒ¨ç½²å¥½ä½ çš„å¾®æœåŠ¡å‡ ä¹Žæ˜¯ä»¶ä¸å¯èƒ½çš„äº‹ã€‚æƒ³è±¡ä¸€ä¸‹è¿™æ ·çš„åœºæ™¯ï¼š10ä¸ªå›¢é˜Ÿå’Œ100ä¸ªæœåŠ¡ï¼Œå®ƒä»¬éƒ½éœ€è¦è¿›è¡Œæ‰‹åŠ¨æµ‹è¯•å’Œéƒ¨ç½²ï¼Œç„¶åŽå†å°†è¿™äº›å·¥ä½œä¸Žæµ‹è¯•å’Œéƒ¨ç½²ä¸€ä¸ªå•ä½“æ‰€éœ€è¦çš„å·¥ä½œè¿›è¡Œå¯¹æ¯”ã€‚100ä¸ªæœåŠ¡ä¼šå‡ºçŽ°å¤šå°‘ç§é—®é¢˜ï¼Ÿè€Œå•ä½“ç³»ç»Ÿå‘¢ï¼Ÿè¿™äº›å…ˆå†³æ¡ä»¶å¾ˆå¥½åœ°è¯´æ˜Žäº†å¾®æœåŠ¡çš„å¤æ‚æ€§ã€‚</p>
<p>Phil Calcadoåœ¨Fowlerçš„å…ˆå†³æ¡ä»¶æ¸…å•é‡Œæ·»åŠ äº†ä¸€äº›ä¸œè¥¿ï¼Œä¸è¿‡æˆ‘è®¤ä¸ºå®ƒä»¬æ›´åƒæ˜¯é‡è¦çš„æ‰©å±•ï¼Œè€Œä¸æ˜¯çœŸæ­£çš„å…ˆå†³æ¡ä»¶ã€‚</p>
<p>å¦‚æžœæˆ‘ä»¬å…·å¤‡äº†è¿™äº›å…ˆå†³æ¡ä»¶å‘¢ï¼Ÿ</p>
<p>å°±ç®—å…·å¤‡äº†è¿™äº›æ¡ä»¶ï¼Œä»ç„¶éœ€è¦æ³¨æ„å¾®æœåŠ¡çš„è´Ÿé¢å› ç´ ï¼Œç¡®ä¿å¾®æœåŠ¡èƒ½å¤Ÿä¸ºä½ çš„ä¸šåŠ¡å¸¦æ¥çœŸæ­£çš„ä»·å€¼ã€‚äº‹å®žä¸Šï¼Œå¾ˆå¤šæŠ€æœ¯äººå‘˜å¯¹å¾®æœåŠ¡ä¸­å­˜åœ¨çš„åˆ†å¸ƒå¼è®¡ç®—è°¬è®ºè§†è€Œä¸è§ï¼Œä½†ä¸ºäº†ç¡®ä¿èƒ½å¤ŸæˆåŠŸï¼Œè¿™äº›é—®é¢˜æ˜¯å¿…é¡»è¦è€ƒè™‘åˆ°çš„ã€‚å¯¹äºŽå¤§éƒ¨åˆ†æˆé•¿åž‹åˆåˆ›å…¬å¸æ¥è¯´ï¼ŒåŸºäºŽå„ç§åŽŸå› ï¼Œä»–ä»¬åº”è¯¥é¿å…ä½¿ç”¨å¾®æœåŠ¡ã€‚</p>
<p>è¿è¥æˆæœ¬çš„å¢žåŠ </p>
<p>å¿«é€Ÿéƒ¨ç½²è¿™ä¸€å…ˆå†³æ¡ä»¶å·²ç»æ¶µç›–äº†ä¸€éƒ¨åˆ†æˆæœ¬ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œå¯¹å¾®æœåŠ¡è¿›è¡Œå®¹å™¨åŒ–ï¼ˆå¯èƒ½ä½¿ç”¨Dockerï¼‰å’Œä½¿ç”¨å®¹å™¨ç¼–æŽ’ç³»ç»Ÿï¼ˆæ¯”å¦‚Kubernetesï¼‰ä¹Ÿéœ€è¦è€—è´¹å¾ˆå¤šæˆæœ¬ã€‚Dockerå’ŒKuberneteséƒ½æ˜¯å¾ˆä¼˜ç§€çš„æŠ€æœ¯ï¼Œä½†æ˜¯å¯¹äºŽå¤§éƒ¨åˆ†æˆé•¿åž‹åˆåˆ›å…¬å¸æ¥è¯´ï¼Œå®ƒä»¬éƒ½æ˜¯ä¸€ç§è´Ÿæ‹…ã€‚æˆ‘è§è¿‡åˆåˆ›å…¬å¸ä½¿ç”¨rsyncä½œä¸ºéƒ¨ç½²å’Œç¼–æŽ’å·¥å…·ï¼Œæˆ‘ä¹Ÿè§è¿‡å¾ˆå¤šçš„åˆåˆ›å…¬å¸é™·å…¥è¿ç»´å·¥å…·çš„å¤æ‚æ€§æ³¥æ½­é‡Œï¼Œä»–ä»¬å› æ­¤æµªè´¹äº†å¾ˆå¤šæ—¶é—´ï¼Œè€Œè¿™äº›æ—¶é—´æœ¬æ¥å¯ä»¥ç”¨äºŽä¸ºç”¨æˆ·å¼€å‘æ›´å¤šçš„åŠŸèƒ½ã€‚</p>
<p>ä½ çš„åº”ç”¨ä¼šè¢«æ‹–æ…¢</p>
<p>å¦‚æžœä½ çš„å•ä½“ç³»ç»Ÿé‡ŒåŒ…å«äº†å¤šä¸ªæ¨¡å—ï¼Œå¹¶ä¸”åœ¨æ¨¡å—é—´å®šä¹‰äº†è‰¯å¥½çš„APIï¼Œé‚£ä¹ˆAPIä¹‹é—´çš„äº¤äº’å°±å‡ ä¹Žæ²¡æœ‰ä»€ä¹ˆé¢å¤–å¼€é”€ã€‚ä½†å¯¹äºŽå¾®æœåŠ¡æ¥è¯´å°±ä¸æ˜¯è¿™ä¹ˆä¸€å›žäº‹äº†ï¼Œå› ä¸ºå®ƒä»¬ä¸€èˆ¬è¿è¡Œåœ¨ä¸åŒçš„æœºå™¨ä¸Šï¼Œå®ƒä»¬ä¹‹é—´éœ€è¦é€šè¿‡ç½‘ç»œè¿›è¡Œäº¤äº’ã€‚è¿™æ ·ä¼šåœ¨ä¸€å®šç¨‹åº¦ä¸Šæ‹–æ…¢æ•´ä¸ªç³»ç»Ÿã€‚å¦‚æžœä¸€ä¸ªè¯·æ±‚éœ€è¦å¤šä¸ªæœåŠ¡è¿›è¡ŒåŒæ­¥äº¤äº’ï¼Œé‚£ä¹ˆæƒ…å†µä¼šå˜å¾—æ›´åŠ ç³Ÿç³•ã€‚æˆ‘æ›¾ç»å·¥ä½œè¿‡çš„ä¸€ä¸ªå…¬å¸ï¼Œä»–ä»¬éœ€è¦è°ƒç”¨å°†è¿‘10ä¸ªæœåŠ¡æ‰èƒ½å¤„ç†å®ŒæŸäº›è¯·æ±‚ã€‚å¤„ç†è¯·æ±‚çš„æ¯ä¸€ä¸ªæ­¥éª¤éƒ½éœ€è¦é¢å¤–çš„ç½‘ç»œå¼€é”€å’Œå»¶è¿Ÿï¼Œä½†å®žé™…ä¸Šï¼Œä»–ä»¬å¯ä»¥æŠŠè¿™äº›æœåŠ¡æ”¾åœ¨å•ä¸ªè½¯ä»¶åŒ…é‡Œï¼ŒæŒ‰ç…§ä¸åŒçš„æ¨¡å—æ¥åŒºåˆ†ï¼Œæˆ–è€…æŠŠå®ƒä»¬è®¾è®¡æˆå¼‚æ­¥çš„ã€‚è¿™æ ·å¯ä»¥ä¸ºä»–ä»¬èŠ‚çœå¤§é‡çš„åŸºç¡€è®¾æ–½æˆæœ¬ã€‚</p>
<p>æœ¬åœ°å¼€å‘å˜å¾—æ›´åŠ å›°éš¾</p>
<p>å¦‚æžœä½ æœ‰ä¸€ä¸ªå•ä½“åº”ç”¨ï¼ŒåŽç«¯åªæœ‰ä¸€ä¸ªæ•°æ®åº“ï¼Œé‚£ä¹ˆåœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œåœ¨æœ¬åœ°è¿è¡Œè¿™ä¸ªåº”ç”¨æ˜¯å¾ˆå®¹æ˜“çš„ã€‚å¦‚æžœä½ æœ‰100ä¸ªæœåŠ¡ï¼Œå¹¶ä½¿ç”¨äº†å¤šä¸ªæ•°æ®å­˜å‚¨ç³»ç»Ÿï¼Œè€Œä¸”å®ƒä»¬ä¹‹é—´äº’ç›¸ä¾èµ–ï¼Œé‚£ä¹ˆæœ¬åœ°å¼€å‘å°±ä¼šå˜æˆä¸€ä¸ªå™©æ¢¦ã€‚å³ä½¿æ˜¯Dockerä¹Ÿæ— æ³•æŠŠä½ ä»Žè¿™ç§å¤æ‚æ€§æ³¥æ½­ä¸­æ‹¯æ•‘å‡ºæ¥ã€‚è™½ç„¶äº‹æƒ…åŽŸæœ¬å¯ä»¥ç®€å•ä¸€äº›ï¼Œä¸è¿‡ä»ç„¶éœ€è¦å¤„ç†ä¾èµ–é—®é¢˜ã€‚ç†è®ºä¸Šè¯´ï¼Œå¾®æœåŠ¡ä¸å­˜åœ¨è¿™äº›é—®é¢˜ï¼Œå› ä¸ºå¾®æœåŠ¡è¢«è®¤ä¸ºæ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚ä¸è¿‡ï¼Œå¯¹äºŽæˆé•¿åž‹åˆåˆ›å…¬å¸æ¥è¯´ï¼Œå°±ä¸æ˜¯è¿™ä¹ˆä¸€å›žäº‹äº†ã€‚æŠ€æœ¯äººå‘˜ä¸€èˆ¬éœ€è¦åœ¨æœ¬åœ°è¿è¡Œæ‰€æœ‰ï¼ˆæˆ–è€…å‡ ä¹Žæ‰€æœ‰ï¼‰çš„æœåŠ¡æ‰èƒ½è¿›è¡Œæ–°åŠŸèƒ½çš„å¼€å‘å’Œæµ‹è¯•ã€‚è¿™ç§å¤æ‚æ€§æ˜¯å¯¹èµ„æºçš„å·¨å¤§æµªè´¹ã€‚</p>
<p>éš¾ä»¥ä¼¸ç¼©</p>
<p>å¯¹å•ä½“ç³»ç»Ÿè¿›è¡Œä¼¸ç¼©çš„æœ€ç®€å•æ–¹å¼æ˜¯åœ¨è´Ÿè½½å‡è¡¡å™¨åŽé¢éƒ¨ç½²å•ä½“ç³»ç»Ÿçš„å¤šä¸ªå®žä¾‹ã€‚åœ¨æµé‡å¢žé•¿çš„æƒ…å†µä¸‹ï¼Œè¿™æ˜¯ä¸€ç§éžå¸¸ç®€å•çš„ä¼¸ç¼©æ–¹å¼ï¼Œè€Œä¸”ä»Žè¿ç»´è§’åº¦æ¥è®²ï¼Œå®ƒçš„å¤æ‚æ€§æ˜¯æœ€ä½Žçš„ã€‚ä½ çš„ç³»ç»Ÿåœ¨ç¼–æŽ’å¹³å°ï¼ˆå¦‚Elastic Beanstalkï¼‰ä¸Šè¿è¡Œçš„æ—¶é—´è¶Šé•¿è¶Šå¥½ï¼Œä½ å’Œä½ çš„å›¢é˜Ÿå°±å¯ä»¥é›†ä¸­ç²¾åŠ›å¼€å‘å®¢æˆ·éœ€è¦çš„ä¸œè¥¿ï¼Œè€Œä¸æ˜¯å¿™äºŽè§£å†³éƒ¨ç½²ç®¡é“é—®é¢˜ã€‚ä½¿ç”¨åˆé€‚çš„CI/CDç³»ç»Ÿå¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä½†åœ¨å¾®æœåŠ¡ç”Ÿæ€ç³»ç»Ÿé‡Œï¼Œäº‹æƒ…è¦å¤æ‚å¾—å¤šï¼Œè€Œä¸”è¿™äº›å¤æ‚æ€§æ‰€é€ æˆçš„éº»çƒ¦å·²ç»è¶…è¿‡äº†å®ƒä»¬æ‰€èƒ½å¸¦æ¥çš„å¥½å¤„ã€‚</p>
<p>ç„¶åŽå‘¢ï¼Ÿ</p>
<p>å¦‚æžœä½ åˆšå¥½èº«å¤„ä¸€ä¸ªæˆé•¿åž‹åˆåˆ›å…¬å¸é‡Œï¼Œéœ€è¦å¯¹æž¶æž„åšä¸€äº›è°ƒæ•´ï¼Œè€Œå¾®æœåŠ¡ä¼¼ä¹Žä¸èƒ½è§£å†³ä½ çš„é—®é¢˜ï¼Œè¿™ä¸ªæ—¶å€™åº”è¯¥æ€Žä¹ˆåŠžï¼Ÿ</p>
<p>Fowleræå‡ºçš„å…ˆå†³æ¡ä»¶å¯ä»¥è¯´æ˜¯æŠ€æœ¯é¢†åŸŸçš„èƒ½åŠ›æˆç†Ÿåº¦æ¨¡åž‹ï¼ŒFowleråœ¨ä»–çš„æ–‡ç« é‡Œå¯¹æˆç†Ÿåº¦æ¨¡åž‹è¿›è¡Œè¿‡ä»‹ç»ã€‚å¦‚æžœè¿™ç§æˆç†Ÿåº¦æ¨¡åž‹å¯¹äºŽå…¬å¸æ¥è¯´æ˜¯è¯´å¾—é€šçš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥æŒ‰ç…§Fowleræå‡ºçš„å…ˆå†³æ¡ä»¶ï¼Œå¹¶ä½¿ç”¨å…¶ä»–çš„ä¸€äº›ä¸­é—´æ­¥éª¤ä¸ºå‘å¾®æœåŠ¡è¿ç§»åšå¥½å‡†å¤‡ã€‚ä¸‹é¢çš„å†…å®¹å¼•ç”¨è‡ªFowlerçš„æ–‡ç« ã€‚</p>
<p>å…³é”®æ˜¯ä½ è¦è®¤è¯†åˆ°ï¼Œæˆç†Ÿåº¦æ¨¡åž‹çš„è¯„ä¼°ç»“æžœå¹¶ä¸ä»£è¡¨ä½ çš„å½“å‰æ°´å¹³ï¼Œå®ƒä»¬åªæ˜¯åœ¨å‘Šè¯‰ä½ éœ€è¦åšå“ªäº›å·¥ä½œæ‰èƒ½æœç€æ”¹è¿›çš„ç›®æ ‡å‰è¿›ã€‚ä½ å½“å‰çš„æ°´å¹³åªæ˜¯ä¸€ç§ä¸­é—´å·¥ä½œï¼Œç”¨äºŽç¡®å®šä¸‹ä¸€æ­¥è¯¥èŽ·å¾—ä»€ä¹ˆæ ·çš„æŠ€èƒ½ã€‚
é‚£ä¹ˆï¼Œæˆ‘ä»¬è¯¥åšå‡ºæ€Žæ ·çš„æ”¹è¿›ï¼Œä»¥åŠå¦‚ä½•è¾¾æˆè¿™äº›ç›®æ ‡ï¼Ÿæˆ‘ä»¬éœ€è¦ç»è¿‡ä¸€äº›ç®€å•çš„æ­¥éª¤ï¼Œå…¶ä¸­å‰é¢ä¸¤æ­¥å°±å¯ä»¥è§£å†³å¾ˆå¤šåœ¨å‘å¾®æœåŠ¡è¿ç§»è¿‡ç¨‹ä¸­ä¼šå‡ºçŽ°çš„é—®é¢˜ï¼Œè€Œä¸”ä¸ä¼šå¸¦æ¥ç›¸å…³çš„å¤æ‚æ€§ã€‚</p>
<p>æ¸…ç†åº”ç”¨ç¨‹åºã€‚ç¡®ä¿åº”ç”¨ç¨‹åºå…·æœ‰è‰¯å¥½çš„è‡ªåŠ¨åŒ–æµ‹è¯•å¥—ä»¶ï¼Œå¹¶ä½¿ç”¨äº†æœ€æ–°ç‰ˆæœ¬çš„è½¯ä»¶åŒ…ã€æ¡†æž¶å’Œç¼–ç¨‹è¯­è¨€ã€‚
é‡æž„åº”ç”¨ç¨‹åºï¼ŒæŠŠå®ƒæ‹†åˆ†æˆå¤šä¸ªæ¨¡å—ï¼Œä¸ºæ¨¡å—å®šä¹‰æ¸…æ™°çš„APIã€‚ä¸è¦è®©å¤–éƒ¨ä»£ç ç›´æŽ¥è§¦åŠæ¨¡å—å†…éƒ¨ï¼Œæ‰€æœ‰çš„äº¤äº’éƒ½åº”è¯¥é€šè¿‡æ¨¡å—æä¾›çš„APIæ¥è¿›è¡Œã€‚
ä»Žåº”ç”¨ç¨‹åºä¸­é€‰æ‹©ä¸€ä¸ªæ¨¡å—ï¼Œå¹¶æŠŠå®ƒæ‹†åˆ†æˆç‹¬ç«‹çš„åº”ç”¨ç¨‹åºï¼Œéƒ¨ç½²åœ¨ç›¸åŒçš„ä¸»æœºä¸Šã€‚ä½ å¯ä»¥ä»Žä¸­èŽ·å¾—ä¸€äº›å¥½å¤„ï¼Œè€Œä¸ä¼šå¸¦æ¥å¤ªå¤šçš„è¿ç»´éº»çƒ¦ã€‚ä¸è¿‡ï¼Œä½ ä»ç„¶éœ€è¦è§£å†³è¿™ä¸¤ä¸ªåº”ç”¨ä¹‹é—´çš„äº¤äº’é—®é¢˜ï¼Œè™½ç„¶å®ƒä»¬éƒ½éƒ¨ç½²åœ¨åŒä¸€ä¸ªä¸»æœºä¸Šã€‚ä¸è¿‡ä½ å¯ä»¥æ— è§†å¾®æœåŠ¡æž¶æž„é‡Œå›ºæœ‰çš„ç½‘ç»œåˆ†åŒºé—®é¢˜å’Œåˆ†å¸ƒå¼ç³»ç»Ÿçš„å¯ç”¨æ€§é—®é¢˜ã€‚
æŠŠç‹¬ç«‹å‡ºæ¥çš„æ¨¡å—ç§»åŠ¨åˆ°ä¸åŒçš„ä¸»æœºä¸Šã€‚çŽ°åœ¨ï¼Œä½ éœ€è¦å¤„ç†è·¨ç½‘ç»œäº¤äº’é—®é¢˜ï¼Œä¸è¿‡è¿™æ ·å¯ä»¥è®©è¿™ä¸¤ä¸ªç³»ç»Ÿä¹‹é—´çš„è€¦åˆé™å¾—æ›´ä½Žã€‚
å¦‚æžœæœ‰å¯èƒ½ï¼Œå¯ä»¥é‡æž„æ•°æ®å­˜å‚¨ç³»ç»Ÿï¼Œè®©å¦ä¸€ä¸ªä¸»æœºä¸Šçš„æ¨¡å—è´Ÿè´£è‡ªå·±çš„æ•°æ®å­˜å‚¨ã€‚
åœ¨æˆ‘æ‰€è§è¿‡çš„å…¬å¸é‡Œï¼Œå¦‚æžœä»–ä»¬èƒ½å¤Ÿå®Œæˆå‰é¢ä¸¤ä¸ªæ­¥éª¤å°±ç®—ä¸‡äº‹å¤§å‰äº†ã€‚å¦‚æžœä»–ä»¬èƒ½å¤Ÿå®Œæˆå‰é¢ä¸¤ä¸ªæ­¥éª¤ï¼Œé‚£ä¹ˆå‰©ä¸‹çš„æ­¥éª¤ä¸€èˆ¬ä¸ä¼šåƒä»–ä»¬æœ€åˆæƒ³è±¡çš„é‚£ä¹ˆé‡è¦äº†ã€‚å¦‚æžœä½ å†³å®šåœ¨è¿™ä¸ªè¿‡ç¨‹çš„æŸä¸ªç‚¹ä¸Šåœä¸‹æ¥ï¼Œè€Œç³»ç»Ÿä»ç„¶å…·æœ‰å¯ç»´æŠ¤æ€§å’Œæ¯”åˆšå¼€å§‹æ—¶æ›´å¥½çš„çŠ¶æ€ï¼Œé‚£ä¹ˆå°±å†å¥½ä¸è¿‡äº†ã€‚</p>
<p>ç»“å°¾</p>
<p>æˆ‘ä¸èƒ½è¯´è¿™äº›æƒ³æ³•éƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„ï¼Œä¹Ÿä¸èƒ½è¯´æ˜¯æˆ‘æ‰€ç‹¬æœ‰çš„ã€‚æˆ‘åªæ˜¯ä»Žå…¶ä»–é­é‡äº†ç›¸åŒé—®é¢˜çš„äººé‚£é‡Œæ”¶é›†æƒ³æ³•ï¼Œå¹¶è¿žåŒè§‚å¯Ÿåˆ°çš„çŽ°è±¡åœ¨è¿™é‡Œä½œäº†ä¸€æ¬¡æ€»ç»“ã€‚è¿˜æœ‰å…¶ä»–å¾ˆå¤šæ¯”æˆ‘æ›´æœ‰ç»éªŒçš„äººä¹Ÿå†™è¿‡è¿™æ–¹é¢çš„æ–‡ç« ï¼Œä»–ä»¬å‰–æžåœ°æ›´åŠ æ·±å…¥ï¼Œæ¯”å¦‚Sander Makå†™çš„æœ‰å…³æ¨¡å—å’Œå¾®æœåŠ¡çš„æ–‡ç« ã€‚ä¸ç®¡æ€Žæ ·ï¼Œå¯¹äºŽæ­£åœ¨è€ƒè™‘å¯¹ä»–ä»¬çš„æœªæ¥æž¶æž„åšå‡ºè°ƒæ•´çš„å…¬å¸æ¥è¯´ï¼Œè¿™äº›ç»éªŒéƒ½æ˜¯éžå¸¸é‡è¦çš„ã€‚è®¤çœŸåœ°æ€è€ƒæ¯ä¸€ä¸ªé—®é¢˜ï¼Œç¡®ä¿å¾®æœåŠ¡å¯¹ä½ ä»¬çš„ç»„ç»‡æ¥è¯´æ˜¯ä¸€ä¸ªæ­£ç¡®çš„é€‰æ‹©ã€‚</p>
<p>æœ€èµ·ç åœ¨å®Œæˆäº†ä¸Šè¿°çš„å‰é¢ä¸¤ä¸ªæ­¥éª¤ä¹‹åŽï¼Œå†æ…Žé‡è€ƒè™‘ä¸€ä¸‹å¾®æœåŠ¡å¯¹äºŽä½ çš„ç»„ç»‡æ¥è¯´æ˜¯å¦æ˜¯æ­£ç¡®çš„æ–¹å‘ã€‚ä½ ä¹‹å‰çš„å¾ˆå¤šé—®é¢˜å¯èƒ½ä¼šè¿Žåˆƒè€Œè§£ã€‚</p> ]]></content:encoded></item><item><title>Redis Performance Triage Handbook</title><link>https://adamdrake.com/redis-performance-triage-handbook.html</link><pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/redis-performance-triage-handbook.html</guid><description>&lt;h1 id="intro" class="anchor-link">&lt;a href="#intro">Intro&lt;/a>&lt;/h1>
&lt;p>I do a lot of work with growth-stage startups, and many of them use &lt;a href="https://redis.io">Redis&lt;/a> for all sorts of things. Sometimes as a key/value store for caching, sometimes as a message queue, sometimes as a pub/sub message broker, etc. Redis is a great tool, with great performance, when used properly. However, I&amp;rsquo;ve often seen cases where it is not used with good performance in mind, often to the detriment of system uptime and customer satisfaction. High-performance, customer-facing products literally go down for hours per day due to relatively subtle or seemingly innocent misuses of Redis.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="intro" class="anchor-link"><a href="#intro">Intro</a></h1>
<p>I do a lot of work with growth-stage startups, and many of them use <a href="https://redis.io">Redis</a> for all sorts of things.  Sometimes as a key/value store for caching, sometimes as a message queue, sometimes as a pub/sub message broker, etc.  Redis is a great tool, with great performance, when used properly.  However, I&rsquo;ve often seen cases where it is not used with good performance in mind, often to the detriment of system uptime and customer satisfaction.  High-performance, customer-facing products literally go down for hours per day due to relatively subtle or seemingly innocent misuses of Redis.</p>

<h1 id="redis-overview" class="anchor-link"><a href="#redis-overview">Redis Overview</a></h1>
<p>I won&rsquo;t go into too much detail about the particulars of Redis commands and capabilities here, since the assumption is that you already know those things and are wanting to make sure you either use them properly, or you have some kind of performance problem which requires correction.</p>
<p>From a performance perspective, it&rsquo;s important to note some things about Redis.  The foremost of these is that it is single-threaded.</p>
<p>Redis is single-threaded, by design (with small exception for background IO).  If you run it on a machine with more than one hyperthread, all of the additional CPUs/cores/hyperthreads will be wasted.  One Redis instance will run commands on one hyperthread (AKA AWS vCPU), no matter how many are present in the machine.  If you need more performance, you will have to run multiple Redis instances, one per hyperthread, on different ports.  If you run multiple Redis commands and some are faster than others, then all the commands will be blocked while each slow command is being run.</p>
<p>If you are using Redis on Amazon Web Services ElastiCache, this single-threaded nature means that using any AWS ElastiCache instances which have multiple vCPUs makes no sense from a CPU perspective.  Your Redis will not use them (though Memcached will).  Those larger ElastiCache instances are only useful for Redis if you need the additional memory space.</p>

<h1 id="performance-triage" class="anchor-link"><a href="#performance-triage">Performance triage</a></h1>

<h2 id="look-at-slowlog" class="anchor-link"><a href="#look-at-slowlog">Look at <code>SLOWLOG</code>.</a></h2>
<p>This will tell you which commands are taking a lot of time to run, and therefore blocking all the other commands.  Remember, Redis only does <strong>one</strong> thing at a time.  If you find some slow-running commands here, track them down in your code and see if there are ways to speed them up.  Also note any appearance of <code>evalsha</code>, which denotes a LUA script.  While using LUA inside Redis is fine in theory, and gives some nice functionality akin to stored procedures, it can be a performance problem.  Consider the code below from the <a href="https://github.com/Automattic/kue/blob/master/lib/kue.js#L263">kue.js Javascript library</a>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-javascript" data-lang="javascript"><span style="display:flex;"><span><span style="color:#66d9ef">var</span> <span style="color:#a6e22e">script</span> <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;local msg = redis.call( &#34;keys&#34;, &#34;&#39;</span> <span style="color:#f92672">+</span> <span style="color:#a6e22e">prefix</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;:jobs:*:inactive&#34; )\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        local need_fix = 0\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        for i,v in ipairs(msg) do\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          local queue = redis.call( &#34;zcard&#34;, v )\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          local jt = string.match(v, &#34;&#39;</span> <span style="color:#f92672">+</span> <span style="color:#a6e22e">prefix</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;:jobs:(.*):inactive&#34;)\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          local pending = redis.call( &#34;LLEN&#34;, &#34;&#39;</span> <span style="color:#f92672">+</span> <span style="color:#a6e22e">prefix</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;:&#34; .. jt .. &#34;:jobs&#34; )\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          if queue &gt; pending then\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            need_fix = need_fix + 1\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            for j=1,(queue-pending) do\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">              redis.call( &#34;lpush&#34;, &#34;&#39;</span> <span style="color:#f92672">+</span> <span style="color:#a6e22e">prefix</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;:&#34;..jt..&#34;:jobs&#34;, 1 )\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            end\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">          end\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        end\n\
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        return need_fix&#39;</span>;
</span></span></code></pre></div><p>This code can potentially be very slow, since it uses the <code>KEYS</code> command (among other things).  Which leads us to&hellip;</p>

<h2 id="no-keys-command-ever" class="anchor-link"><a href="#no-keys-command-ever">No <code>KEYS</code> command. Ever.</a></h2>
<p>Even the Redis site says this is for <a href="https://redis.io/topics/benchmarks">debugging only</a>.  This command stops the server while the keyspace is scanned for matches, which can take a really long time.</p>
<blockquote>
<p>Warning: consider <code>KEYS</code> as a command that should only be used in production environments with extreme care. It may ruin performance when it is executed against large databases. This command is intended for debugging and special operations, such as changing your keyspace layout. Don&rsquo;t use KEYS in your regular application code. If you&rsquo;re looking for a way to find keys in a subset of your keyspace, consider using <code>SCAN</code> or sets.</p>
</blockquote>
<p>Instead of <code>KEYS</code>, use <code>SCAN</code>, which like all the Redis commands has <a href="https://redis.io/topics/benchmarks">good documentation</a>.</p>

<h2 id="dont-open-a-new-connection-for-every-command" class="anchor-link"><a href="#dont-open-a-new-connection-for-every-command">Don&rsquo;t open a new connection for every command.</a></h2>
<p>In Redis, establishing a new connection and tearing it down again is expensive.  If you are opening a new connection for every command then you might be wasting 95% of your performance doing so.  Keeping the connection alive and issuing commands over a persistent connection, in my local tests, is about <strong>25 times faster</strong> than opening a new connection for each request.  If you want to check for this on your current Redis instance, check the <code>total_connections_received</code> value in your <code>INFO</code> output.  If it is high, then your application(s) might be opening a new connection for every request, and thus wasting a ton of capacity.</p>
<p>In the tests below, the <code>-k 0</code> flag means do not keep the connection alive (i.e., start a new connection for each command).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ redis-benchmark -k <span style="color:#ae81ff">0</span> -t get,set -q
</span></span><span style="display:flex;"><span>WARNING: keepalive disabled, you probably need <span style="color:#e6db74">&#39;echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse&#39;</span> <span style="color:#66d9ef">for</span> Linux and <span style="color:#e6db74">&#39;sudo sysctl -w net.inet.tcp.msl=1000&#39;</span> <span style="color:#66d9ef">for</span> Mac OS X in order to use a lot of clients/requests
</span></span><span style="display:flex;"><span>SET: 8142.00 requests per second
</span></span><span style="display:flex;"><span>GET: 7230.14 requests per second
</span></span></code></pre></div><p>We can see the huge performance increase if we change the benchmark and reuse the connections.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ redis-benchmark -k <span style="color:#ae81ff">1</span> -t get,set -q
</span></span><span style="display:flex;"><span>SET: 198807.16 requests per second
</span></span><span style="display:flex;"><span>GET: 193423.59 requests per second
</span></span></code></pre></div><p>P.S. - If you haven&rsquo;t used <code>redis-benchmark</code> before, now is a good time to <a href="https://redis.io/topics/benchmarks">check it out</a>.</p>

<h2 id="use-variadic-versions-of-commands-instead-of-using-set-in-a-loop-for-example" class="anchor-link"><a href="#use-variadic-versions-of-commands-instead-of-using-set-in-a-loop-for-example">Use variadic versions of commands instead of using <code>SET</code> in a loop, for example.</a></h2>
<p>If you have a list of key/value pairs you need to set, or some other operation you need to do repeatedly, use the variadic version of the command if it exists.  Looping over a list and issuing 100 <code>SET</code> commands is a lot slower than using a single <code>MSET</code> with 100 key/value pairs.  This slowness can compound if you are opening and closing a new connection for every command, which should not be the case if you are reusing connections as in the previous step.  Check out the example with <code>SET</code> versus <code>MSET</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ redis-benchmark -q -t set,mset
</span></span><span style="display:flex;"><span>SET: 158730.16 requests per second
</span></span><span style="display:flex;"><span>MSET <span style="color:#f92672">(</span><span style="color:#ae81ff">10</span> keys<span style="color:#f92672">)</span>: 178253.12 requests per second
</span></span></code></pre></div><p>This gets even more impressive if we use pipelining&hellip;</p>

<h2 id="pipeline-your-commands" class="anchor-link"><a href="#pipeline-your-commands">Pipeline your commands.</a></h2>
<p>In cases where you want to further improve performance, or cannot use variadic commands, Redis supports pipelining, which lets you send a big batch of commands all at once.  Doing this can dramatically speed up the number of commands your Redis instance can execute every second.  Check out the below examples comparing zero pipelining to pipelining 75 commands.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ redis-benchmark -k <span style="color:#ae81ff">1</span> -t get,set -q -P <span style="color:#ae81ff">75</span>
</span></span><span style="display:flex;"><span>SET: 1587301.50 requests per second
</span></span><span style="display:flex;"><span>GET: 2127659.75 requests per secondh
</span></span></code></pre></div><p>This is a speedup of almost <strong>300 times</strong> over the first benchmark with no connection keepalive.  Pipelining can make a massive difference in throughput on your Redis if it is appropriate for your application.</p>
<p>Now check out the performance when we use connection keepalive, and use a variadic command for setting key/value pairs, and use pipelining.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ redis-benchmark -q -P <span style="color:#ae81ff">75</span> -t set,mset
</span></span><span style="display:flex;"><span>SET: 1754386.00 requests per second
</span></span><span style="display:flex;"><span>MSET <span style="color:#f92672">(</span><span style="color:#ae81ff">10</span> keys<span style="color:#f92672">)</span>: 387596.91 requests per second
</span></span></code></pre></div><p>Since <code>MSET</code> is sending 10 keys per request, and doing about 400,000 requests per second, we&rsquo;re setting about 4 million keys, compared to about 2 million for the non-variadic version.  Now we are <strong>500 times</strong> faster than the initial version.</p>

<h2 id="provide-expiration-for-a-key-along-with-the-set-command-not-as-a-separate-expire-command" class="anchor-link"><a href="#provide-expiration-for-a-key-along-with-the-set-command-not-as-a-separate-expire-command">Provide expiration for a key along with the <code>SET</code> command, not as a separate <code>EXPIRE</code> command.</a></h2>
<p>Because Redis is single-threaded, every unneccessary command is a waste and is blocking other commands.  You can provide an expiration time/TTL in your <code>SET</code> command, so issuing a <code>SET</code>, followed immediately by an <code>EXPIRE</code> is a waste.  Avoid using separate <code>EXPIRE</code> commands if at all possible.</p>

<h2 id="use-blocking-pushpop-commands-where-appropriate" class="anchor-link"><a href="#use-blocking-pushpop-commands-where-appropriate">Use blocking push/pop commands, where appropriate.</a></h2>
<p>Redis can work well as a basic queing system, but you don&rsquo;t want to tax the system for no reason by repeatedly checking the queue to see if there are items present.  Instead, on the client, use the blocking version of push and pop like <code>BLPUSH</code> and <code>BLPOP</code>, respectively.  This way the client will wait to do the operation instead of just issuing the standard command over and over again.  This is a common mistake when building a worker to push queue items, and results in high CPU usage on the client system in addition to a lot of commands issued on the Redis instance for no reason.  You should probably provide a timeout for the operation as well, unless you want to block forever.</p>

<h2 id="dont-use-multiple-databases" class="anchor-link"><a href="#dont-use-multiple-databases">Don&rsquo;t use multiple databases.</a></h2>
<p>Remember that due to the single-threaded nature of Redis, if one command is running, the next one is blocked.  If you use multiple databases inside the same Redis instance, then you are requiring the use of the <code>SELECT</code> command to choose which database you want.  There are other issues surrounding using multiple databases in Redis, and even Salvatore himself has said it isn&rsquo;t a good idea and is a feature <a href="https://groups.google.com/forum/#!topic/redis-db/vS5wX8X4Cjg">he wishes he could remove</a>.  If you&rsquo;re using multiple databases, you&rsquo;re probably just better off having a prefix in your keyspace to represent the different sets of data.</p>

<h2 id="dont-send-an-auth-command-with-an-empty-string" class="anchor-link"><a href="#dont-send-an-auth-command-with-an-empty-string">Don&rsquo;t send an <code>AUTH</code> command with an empty string.</a></h2>
<p>As with the <code>SELECT</code>, taking up CPU cycles with an <code>AUTH</code> command is not a good idea.  If you don&rsquo;t have any password on your Redis instance, make sure your code and/or the Redis library you are using is not sending an <code>AUTH &quot;&quot;</code> to the Redis server.</p>

<h2 id="if-memory-usage-is-getting-consistently-high-scan-your-keyspace" class="anchor-link"><a href="#if-memory-usage-is-getting-consistently-high-scan-your-keyspace">If memory usage is getting consistently high, <code>SCAN</code> your keyspace.</a></h2>
<p>Redis generally handles key expiration very well, but sometimes it can be necessary to do a manual <code>SCAN</code> through the keyspace in order to expire keys.  I wouldn&rsquo;t do this as a matter of course since eviction seems to work well in current versions of Redis, but I do know of some customers using ElastiCache Redis instances on AWS that have to do this in order to keep their memory usage under control.  The expiration of keys in Redis is quite good in general.</p>
<blockquote>
<p><strong>How Redis expires keys:</strong></p>
</blockquote>
<blockquote>
<p>Redis keys are expired in two ways: a passive way, and an active way.  A key is passively expired simply when some client tries to access it, and the key is found to be timed out.  Of course, this is not a complete solution as there are expired keys that will never be accessed again.  To address this, Redis periodically tests a few keys at random among keys with an expire set. All the keys that are expired are deleted from the keyspace.  Specifically, this is what Redis does 10 times per second:</p>
<ol>
<li>Test 20 random keys from the set of keys with an associated expire.</li>
<li>Delete all the keys found expired.</li>
<li>If more than 25% of keys were expired, start again from step 1.</li>
</ol>
<p>This is a trivial probabilistic algorithm.  Basically, the assumption is that our sample is representative of the whole key space.  We continue to expire keys until the percentage of keys that are likely to be expired is under 25%.  This means that at any given moment the maximum amount of keys already expired that are using memory is at most equal to the maximum amount of write operations per second divided by 4.</p>
</blockquote>

<h1 id="fin" class="anchor-link"><a href="#fin">Fin</a></h1>
<p>Above are some areas to examine if your Redis instance isn&rsquo;t performing well.  In general, you should be getting many thousands - if not millions - of commands from your Redis instance.  Chances are that your application/site isn&rsquo;t that busy, so you should be able to use Redis as your data structure server throughout your growth cycle.  If you do happen to need additional Redis instances with some kind of load balancing or sharding, consider setting up <a href="https://github.com/twitter/twemproxy">twemproxy</a>.</p>
 ]]></content:encoded></item><item><title>An Unreasonably Deep Dive into Project Euler Problem 3</title><link>https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-3.html</link><pubDate>Sun, 14 May 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-3.html</guid><description>&lt;h1 id="intro" class="anchor-link">&lt;a href="#intro">Intro&lt;/a>&lt;/h1>
&lt;p>I&amp;rsquo;ve been busy as usual for the last couple of months, and haven&amp;rsquo;t really had time to extend the Project Euler series after &lt;a href="https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-1.html">Problem 1&lt;/a> and &lt;a href="https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-2.html">Problem 2&lt;/a> articles.&lt;/p>
&lt;p>However, I finally did set aside some time to play around with Problem 3: finding the largest &lt;a href="https://en.wikipedia.org/wiki/Prime_factor">prime factor&lt;/a> of a number.&lt;/p>
&lt;h1 id="problem-statement" class="anchor-link">&lt;a href="#problem-statement">Problem Statement&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>The prime factors of 13195 are 5, 7, 13 and 29.&lt;/p>
&lt;p>What is the largest prime factor of the number 600851475143?&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="intro" class="anchor-link"><a href="#intro">Intro</a></h1>
<p>I&rsquo;ve been busy as usual for the last couple of months, and haven&rsquo;t really had time to extend the Project Euler series after <a href="/an-unreasonably-deep-dive-into-project-euler-problem-1.html">Problem 1</a> and <a href="/an-unreasonably-deep-dive-into-project-euler-problem-2.html">Problem 2</a> articles.</p>
<p>However, I finally did set aside some time to play around with Problem 3: finding the largest <a href="https://en.wikipedia.org/wiki/Prime_factor">prime factor</a> of a number.</p>

<h1 id="problem-statement" class="anchor-link"><a href="#problem-statement">Problem Statement</a></h1>
<blockquote>
<p>The prime factors of 13195 are 5, 7, 13 and 29.</p>
<p>What is the largest prime factor of the number 600851475143?</p>
</blockquote>

<h1 id="definitions-and-theorems" class="anchor-link"><a href="#definitions-and-theorems">Definitions and Theorems</a></h1>
<p><strong>Definition</strong>: For two integers a and b, we can say that a <em>divides</em> b, a is a <em>divisor</em> of b, b is a <em>multiple</em> of a, or a is a <em>factor</em> of b if, for some integer y, y*a=b.</p>
<p><strong>Definition</strong>: an integer n is <em>prime</em> if the only divisors of n are itself and 1.  Note that 1 and -1 are divisors of every integer.</p>
<p><strong>Definition</strong>: a whole number n is <em>composite</em> if it is not prime.  That is, it has some integer divisors beyond itself and 1.</p>
<p><strong>Theorem</strong> (Fundamental Theorem of Arithmetic): Every integer greater than 1 is either <strong>prime</strong>, or the <strong>product of primes</strong> (i.e., composite).  Also, for composite number, the prime factorization is unique up to the order of the factors.  There is 1, and only 1, prime factorization for a composite number.</p>
<p><strong>Proof</strong>: see <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic#Proof">Wikipedia</a></p>
<p>To start considering the problem, we know that the given number is either prime or composite (product of unique set of primes).  We can assume the number is composite, otherwise the problem statement doesn&rsquo;t make much sense and/or is trivial.</p>
<p>We must therefore find the unique prime factors of the number, and then find which of those primes is largest.</p>

<h1 id="v1-brute-force" class="anchor-link"><a href="#v1-brute-force">V1: Brute force</a></h1>
<p>These sorts of approaches are often underestimated and can be very effective in practical applications.  They&rsquo;re a good place to start.</p>
<p>A naive algorithm could be to loop through all the numbers from 2 to n-1, and check if each one divides n.  If some number d does divide n, then put it in the list of divisors.  After finding all the divisors, check each one to determine if it is prime.  To check primality, loop through all the numbers between 3 and d-1 to check if one of the numbers is a divisor of d.  If you find any such numbers, d is not prime and therefore not a prime factor of n.  If you find no such number, then d divides n but d does not have any other divisors. Thus, d is prime. Thus, d is a prime factor of n.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">v1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// V1:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Take a number n, calculate all its factors,
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// for each factor f, test if f is itself
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// prime by getting all its factors.  If only 1 and f
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// are divisors of f, then f is prime, and a factor
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// of n, and therefore a prime factor.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;math&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// If the only divisors of n are 1 and n, then n is prime
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isPrime</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">n</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">n</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">facs</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">factors</span>(<span style="color:#a6e22e">n</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> len(<span style="color:#a6e22e">facs</span>) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Generate all factors
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">factors</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) []<span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">facs</span> <span style="color:#f92672">:=</span> make([]<span style="color:#66d9ef">int</span>, <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">2</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">n</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">n</span>), float64(<span style="color:#a6e22e">i</span>)) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0.0</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">facs</span> = append(<span style="color:#a6e22e">facs</span>, <span style="color:#a6e22e">i</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">facs</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Given some n, return the largest prime factor of n
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">LargestPrimeFactor</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">biggest</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">2</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">n</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">n</span>), float64(<span style="color:#a6e22e">i</span>)) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0.0</span> { <span style="color:#75715e">// i divides n evenly
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">isPrime</span>(<span style="color:#a6e22e">i</span>) { <span style="color:#75715e">// i is prime
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>				<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">i</span> &gt; <span style="color:#a6e22e">biggest</span> { <span style="color:#75715e">// i is new biggest prime
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>					<span style="color:#a6e22e">biggest</span> = <span style="color:#a6e22e">i</span>
</span></span><span style="display:flex;"><span>				}
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">biggest</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We have three functions: one which calculates all the factors of a given number, one which tests if a number is prime, and one which ties it all together (<code>LargestPrimeFactor</code>).  While this solution is very inefficient, it does work for small numbers, so the logic is correct.  We can see this by writing the necessary tests, using benchmark functions to look at performance of the functions and system.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">v1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;testing&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;reflect&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">NUMBER</span> <span style="color:#66d9ef">int</span> = <span style="color:#ae81ff">600851475143</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">benchmarkNumber</span> <span style="color:#66d9ef">int</span> = <span style="color:#ae81ff">13195</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">benchmarkPrime</span> <span style="color:#66d9ef">int</span> = <span style="color:#ae81ff">29</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Test_factors</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">type</span> <span style="color:#a6e22e">args</span> <span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">tests</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">name</span> <span style="color:#66d9ef">string</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">args</span> <span style="color:#a6e22e">args</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">want</span> []<span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}{
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;factors of zero&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">0</span>}, <span style="color:#a6e22e">want</span>: []<span style="color:#66d9ef">int</span>{}},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;factors of 6&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">6</span>}, <span style="color:#a6e22e">want</span>: []<span style="color:#66d9ef">int</span>{<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>}},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;factors of a prime, 7&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">7</span>}, <span style="color:#a6e22e">want</span>: []<span style="color:#66d9ef">int</span>{}},
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">tt</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">tests</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Run</span>(<span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">name</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">got</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">factors</span>(<span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">args</span>.<span style="color:#a6e22e">n</span>); !<span style="color:#a6e22e">reflect</span>.<span style="color:#a6e22e">DeepEqual</span>(<span style="color:#a6e22e">got</span>, <span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">want</span>) {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Errorf</span>(<span style="color:#e6db74">&#34;factors() = %v, want %v&#34;</span>, <span style="color:#a6e22e">got</span>, <span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">want</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		})
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Test_isPrime</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">type</span> <span style="color:#a6e22e">args</span> <span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">tests</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">name</span> <span style="color:#66d9ef">string</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">args</span> <span style="color:#a6e22e">args</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">want</span> <span style="color:#66d9ef">bool</span>
</span></span><span style="display:flex;"><span>	}{
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;even, not prime&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">8</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">false</span>},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;odd, not prime&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">15</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">false</span>},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;zero, not prime&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">0</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">false</span>},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;one, not prime&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">1</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">false</span>},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;a prime number, 7&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">7</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">true</span>},
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">tt</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">tests</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Run</span>(<span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">name</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">got</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">isPrime</span>(<span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">args</span>.<span style="color:#a6e22e">n</span>); <span style="color:#a6e22e">got</span> <span style="color:#f92672">!=</span> <span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">want</span> {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Errorf</span>(<span style="color:#e6db74">&#34;isPrime() = %v, want %v&#34;</span>, <span style="color:#a6e22e">got</span>, <span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">want</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		})
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Test_LargestPrimeFactor</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">type</span> <span style="color:#a6e22e">args</span> <span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">tests</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">name</span> <span style="color:#66d9ef">string</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">args</span> <span style="color:#a6e22e">args</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">want</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}{
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;benchmarkNumber&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#a6e22e">benchmarkNumber</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#a6e22e">benchmarkPrime</span>},
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">tt</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">tests</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Run</span>(<span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">name</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">got</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">LargestPrimeFactor</span>(<span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">args</span>.<span style="color:#a6e22e">n</span>); !<span style="color:#a6e22e">reflect</span>.<span style="color:#a6e22e">DeepEqual</span>(<span style="color:#a6e22e">got</span>, <span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">want</span>) {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Errorf</span>(<span style="color:#e6db74">&#34;LargestPrimeFactor() = %v, want %v&#34;</span>, <span style="color:#a6e22e">got</span>, <span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">want</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		})
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Benchmark_factors</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">benchmarks</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">name</span>  <span style="color:#66d9ef">string</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">input</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}{
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;benchmarkNumber&#34;</span>, <span style="color:#a6e22e">input</span>: <span style="color:#a6e22e">benchmarkNumber</span>},
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">bm</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">benchmarks</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">Run</span>(<span style="color:#a6e22e">bm</span>.<span style="color:#a6e22e">name</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">factors</span>(<span style="color:#a6e22e">bm</span>.<span style="color:#a6e22e">input</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		})
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Benchmark_LargestPrimeFactor</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">benchmarks</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">name</span>  <span style="color:#66d9ef">string</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">input</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}{
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;benchmarkNumber&#34;</span>, <span style="color:#a6e22e">input</span>: <span style="color:#a6e22e">benchmarkNumber</span>},
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">bm</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">benchmarks</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">Run</span>(<span style="color:#a6e22e">bm</span>.<span style="color:#a6e22e">name</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">LargestPrimeFactor</span>(<span style="color:#a6e22e">bm</span>.<span style="color:#a6e22e">input</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		})
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Benchmark_isPrime</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">benchmarks</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">name</span>  <span style="color:#66d9ef">string</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">input</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}{
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;benchmarkNumber&#34;</span>, <span style="color:#a6e22e">input</span>: <span style="color:#a6e22e">benchmarkNumber</span>},
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">bm</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">benchmarks</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">Run</span>(<span style="color:#a6e22e">bm</span>.<span style="color:#a6e22e">name</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">isPrime</span>(<span style="color:#a6e22e">bm</span>.<span style="color:#a6e22e">input</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		})
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Note that in the <code>Benchmark_</code> functions, we are using the sub-test/sub-benchmark format, where we define multiple pieces of test data/test cases which can be run.  In the benchmark case we are only using one, but we could easily increase that later if desired, so the flexibility is nice.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ go test -bench<span style="color:#f92672">=</span>. -benchmem
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4         	            3000	    <span style="color:#ae81ff">416669</span> ns/op	     <span style="color:#ae81ff">248</span> B/op	       <span style="color:#ae81ff">5</span> allocs/op
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4         	    2000	    <span style="color:#ae81ff">625321</span> ns/op	     <span style="color:#ae81ff">624</span> B/op	      <span style="color:#ae81ff">28</span> allocs/op
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                    	    3000	    <span style="color:#ae81ff">414224</span> ns/op	     <span style="color:#ae81ff">248</span> B/op	       <span style="color:#ae81ff">5</span> allocs/op
</span></span></code></pre></div><p>So far, not great for performance nor for memory allocations.  Let&rsquo;s improve.</p>

<h1 id="v2-skip-the-even-numbers" class="anchor-link"><a href="#v2-skip-the-even-numbers">V2: Skip the even numbers</a></h1>
<p>By definition of <strong>prime</strong>, we know that 2 is the only even prime number.  Since all other even numbers are divisible by 2, they have a divisor other than themselves and 1 - thus, they are not prime.  Therefore, we can modify our solution to exclude checking whether or not these numbers are prime, and see if that speeds up the system.  The code is almost the same as the previous version, with the difference being the addition of an <code>isEven()</code> function to check the parity of the number.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">v2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;math&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// V2:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// We know that 2 is the only even prime, so we can
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// exclude that from being checked.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">n</span>), <span style="color:#ae81ff">2.0</span>) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0.0</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Ignore even factors since they can never be prime
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">factors</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) []<span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">facs</span> <span style="color:#f92672">:=</span> make([]<span style="color:#66d9ef">int</span>, <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">2</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">n</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">i</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">n</span>), float64(<span style="color:#a6e22e">i</span>)) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0.0</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">facs</span> = append(<span style="color:#a6e22e">facs</span>, <span style="color:#a6e22e">i</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">facs</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Even numbers can&#39;t be prime, so we don&#39;t need to check them
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isPrime</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">n</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">n</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">n</span>) {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">facs</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">factors</span>(<span style="color:#a6e22e">n</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> len(<span style="color:#a6e22e">facs</span>) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">LargestPrimeFactor</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">biggest</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">2</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">n</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">i</span>) { <span style="color:#75715e">// skip even numbers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>			<span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">n</span>), float64(<span style="color:#a6e22e">i</span>)) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0.0</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">isPrime</span>(<span style="color:#a6e22e">i</span>) {
</span></span><span style="display:flex;"><span>				<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">i</span> &gt; <span style="color:#a6e22e">biggest</span> {
</span></span><span style="display:flex;"><span>					<span style="color:#a6e22e">biggest</span> = <span style="color:#a6e22e">i</span>
</span></span><span style="display:flex;"><span>				}
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">biggest</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We use the same testing and benchmarking code as in V1, but with the addition of a test and benchmark for <code>isEven()</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Test_isEven</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">type</span> <span style="color:#a6e22e">args</span> <span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">tests</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">name</span> <span style="color:#66d9ef">string</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">args</span> <span style="color:#a6e22e">args</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">want</span> <span style="color:#66d9ef">bool</span>
</span></span><span style="display:flex;"><span>	}{
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;Even number, 4&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">4</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">true</span>},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;Even number, 0&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">0</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">true</span>},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;Even number, -2&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">true</span>},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;Odd number, 3&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">3</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">false</span>},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;Odd number, 1&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#ae81ff">1</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">false</span>},
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;Odd number, -5&#34;</span>, <span style="color:#a6e22e">args</span>: <span style="color:#a6e22e">args</span>{<span style="color:#a6e22e">n</span>: <span style="color:#f92672">-</span><span style="color:#ae81ff">5</span>}, <span style="color:#a6e22e">want</span>: <span style="color:#66d9ef">false</span>},
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">tt</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">tests</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Run</span>(<span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">name</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">got</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">args</span>.<span style="color:#a6e22e">n</span>); !<span style="color:#a6e22e">reflect</span>.<span style="color:#a6e22e">DeepEqual</span>(<span style="color:#a6e22e">got</span>, <span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">want</span>) {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Errorf</span>(<span style="color:#e6db74">&#34;isEven() = %v, want %v&#34;</span>, <span style="color:#a6e22e">got</span>, <span style="color:#a6e22e">tt</span>.<span style="color:#a6e22e">want</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		})
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">Benchmark_isEven</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">benchmarks</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">name</span>  <span style="color:#66d9ef">string</span>
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">input</span> <span style="color:#66d9ef">int</span>
</span></span><span style="display:flex;"><span>	}{
</span></span><span style="display:flex;"><span>		{<span style="color:#a6e22e">name</span>: <span style="color:#e6db74">&#34;Odd number, 3&#34;</span>, <span style="color:#a6e22e">input</span>: <span style="color:#ae81ff">3</span>},
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">bm</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">benchmarks</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">Run</span>(<span style="color:#a6e22e">bm</span>.<span style="color:#a6e22e">name</span>, <span style="color:#66d9ef">func</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>				<span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">bm</span>.<span style="color:#a6e22e">input</span>)
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		})
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Since we are expecting fewer numbers to be checked, we would expect better performance, right?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ go test -bench<span style="color:#f92672">=</span>. -benchmem
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4         	            1000	   <span style="color:#ae81ff">1903807</span> ns/op	     <span style="color:#ae81ff">248</span> B/op	       <span style="color:#ae81ff">5</span> allocs/op
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4         	     500	   <span style="color:#ae81ff">2716207</span> ns/op	     <span style="color:#ae81ff">624</span> B/op	      <span style="color:#ae81ff">28</span> allocs/op
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                    	    1000	   <span style="color:#ae81ff">1905843</span> ns/op	     <span style="color:#ae81ff">248</span> B/op	       <span style="color:#ae81ff">5</span> allocs/op
</span></span><span style="display:flex;"><span>Benchmark_isEven/Odd_number,_3-4                       	50000000	      24.7 ns/op	       <span style="color:#ae81ff">0</span> B/op	       <span style="color:#ae81ff">0</span> allocs/op
</span></span></code></pre></div><p><strong>WRONG!</strong>  Though it doesn&rsquo;t look like our memory allocations have changed, performance is definitely worse than before - but by how much exactly?  For this, we can use the helpful <a href="https://godoc.org/golang.org/x/tools/cmd/benchcmp"><code>benchcmp</code></a> command.  It&rsquo;s easy to install with just a <code>go get golang.org/x/tools/cmd/benchcmp</code>.  The we can redirect the output of the V1 benchmark and the V2 benchmark to a file, and use benchcmp to compare the files.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ go test -bench<span style="color:#f92672">=</span>. -benchmem &gt; v1.bm
</span></span></code></pre></div><p>And in the V2 package directory</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ go test -bench<span style="color:#f92672">=</span>. -benchmem &gt; v2.bm
</span></span></code></pre></div><p>Then, with both files in the same directory, we can easily see what&rsquo;s going on.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ benchcmp v1.bm v2.bm
</span></span><span style="display:flex;"><span>benchmark                                          old ns/op     new ns/op     delta
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4                <span style="color:#ae81ff">414686</span>        <span style="color:#ae81ff">1901842</span>       +358.62%
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">623854</span>        <span style="color:#ae81ff">2723608</span>       +336.58%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">414616</span>        <span style="color:#ae81ff">1907886</span>       +360.16%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old allocs     new allocs     delta
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4                <span style="color:#ae81ff">5</span>              <span style="color:#ae81ff">5</span>              +0.00%
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">28</span>             <span style="color:#ae81ff">28</span>             +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">5</span>              <span style="color:#ae81ff">5</span>              +0.00%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old bytes     new bytes     delta
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4                <span style="color:#ae81ff">248</span>           <span style="color:#ae81ff">248</span>           +0.00%
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">624</span>           <span style="color:#ae81ff">624</span>           +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">248</span>           <span style="color:#ae81ff">248</span>           +0.00%
</span></span></code></pre></div>
<h1 id="v3" class="anchor-link"><a href="#v3">V3</a></h1>
<p>It seems that in the new version, checking the parity of the numbers in order to avoid testing even numbers for primality is actually slower.  We know from the <a href="/an-unreasonably-deep-dive-into-project-euler-problem-2.html">deep-dive into Project Euler Problem 2</a> that testing parity of numbers with a bitwise AND is <strong>much</strong> faster, so let&rsquo;s replace our naive implementation with that one and call it V3.  There will be no other changes, so we will just swap out the implementation of <code>isEven()</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">x</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">x</span><span style="color:#f92672">&amp;</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Now we can use the same tests and benchmarks, and see if we obtained better performance over V2, and therefore hopefully over V1.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ go test -bench<span style="color:#f92672">=</span>. -benchmem
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4         	           10000	    <span style="color:#ae81ff">222491</span> ns/op	     <span style="color:#ae81ff">248</span> B/op	       <span style="color:#ae81ff">5</span> allocs/op
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4         	    5000	    <span style="color:#ae81ff">345445</span> ns/op	     <span style="color:#ae81ff">624</span> B/op	      <span style="color:#ae81ff">28</span> allocs/op
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                    	   10000	    <span style="color:#ae81ff">223073</span> ns/op	     <span style="color:#ae81ff">248</span> B/op	       <span style="color:#ae81ff">5</span> allocs/op
</span></span><span style="display:flex;"><span>Benchmark_isEven/Odd_number,_3-4                      2000000000	      0.29 ns/op	       <span style="color:#ae81ff">0</span> B/op	       <span style="color:#ae81ff">0</span> allocs/op
</span></span></code></pre></div><p>As before, the bitwise version is much faster for testing parity.  Was there any performance improvement over V2, and hopefully over V1?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ benchcmp v2.bm v3.bm
</span></span><span style="display:flex;"><span>benchmark                                          old ns/op     new ns/op     delta
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4                <span style="color:#ae81ff">2016066</span>       <span style="color:#ae81ff">222356</span>        -88.97%
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">2915830</span>       <span style="color:#ae81ff">358904</span>        -87.69%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">2013975</span>       <span style="color:#ae81ff">222206</span>        -88.97%
</span></span><span style="display:flex;"><span>Benchmark_isEven/Odd_number,_3-4                   26.9          0.29          -98.92%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old allocs     new allocs     delta
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4                <span style="color:#ae81ff">5</span>              <span style="color:#ae81ff">5</span>              +0.00%
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">28</span>             <span style="color:#ae81ff">28</span>             +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">5</span>              <span style="color:#ae81ff">5</span>              +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isEven/Odd_number,_3-4                   <span style="color:#ae81ff">0</span>              <span style="color:#ae81ff">0</span>              +0.00%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old bytes     new bytes     delta
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4                <span style="color:#ae81ff">248</span>           <span style="color:#ae81ff">248</span>           +0.00%
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">624</span>           <span style="color:#ae81ff">624</span>           +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">248</span>           <span style="color:#ae81ff">248</span>           +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isEven/Odd_number,_3-4                   <span style="color:#ae81ff">0</span>             <span style="color:#ae81ff">0</span>             +0.00%
</span></span></code></pre></div><p>Memory usage is the same, but the parity checking time was reduced by about 99%, so it&rsquo;s almost free now.  Let&rsquo;s see if that bought us some significant improvement over the first version.  Intuitively, we are skipping primality checks on half the numbers (the even ones greater than 2) so that should reduce the runtime by about half.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ benchcmp v1.bm v3.bm
</span></span><span style="display:flex;"><span>benchmark                                          old ns/op     new ns/op     delta
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4                <span style="color:#ae81ff">414686</span>        <span style="color:#ae81ff">222356</span>        -46.38%
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">623854</span>        <span style="color:#ae81ff">358904</span>        -42.47%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">414616</span>        <span style="color:#ae81ff">222206</span>        -46.41%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old allocs     new allocs     delta
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4                <span style="color:#ae81ff">5</span>              <span style="color:#ae81ff">5</span>              +0.00%
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">28</span>             <span style="color:#ae81ff">28</span>             +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">5</span>              <span style="color:#ae81ff">5</span>              +0.00%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old bytes     new bytes     delta
</span></span><span style="display:flex;"><span>Benchmark_factors/benchmarkNumber-4                <span style="color:#ae81ff">248</span>           <span style="color:#ae81ff">248</span>           +0.00%
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">624</span>           <span style="color:#ae81ff">624</span>           +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">248</span>           <span style="color:#ae81ff">248</span>           +0.00%
</span></span></code></pre></div><p>That intuition seems to be correct.  We reduced the runtime by about 50%.  However, if we think about the properties of prime factors, we can take a different and <strong>MUCH</strong> faster approach to solving the problem.</p>

<h1 id="v4" class="anchor-link"><a href="#v4">V4</a></h1>
<p>When we started out, we were given some number n and our naive solution was to check all the numbers from 3 to n-1 to see if they are divisors of n.  If so, we then went on to check if the number is prime, and therefore a prime divisor.  To check if a number is prime, we generated all its factors, and if there were no factors between 3 and n-1, inclusive, then the number is prime.</p>
<p>The problem is that we did a lot of extra work to check if a number is prime.  The reasoning is this: if a number <strong>IS NOT</strong> prime, then it will have at least one divisor which is less than or equal to its square root.  If a number has some divisors between 3 and the number, call them a and b, then the largest they can both be is a = b = sqrt(n) since a * b = n.  Therefore, if one of the numbers is larger, then the other must be smaller.  The two numbers pivot around the square root of n, and can be at most sqrt(n).</p>
<p>To see why this is true, consider the number 100, which has square root 10.  In this case, a = b = 10.  If a goes up to 20, b goes down to 5.  If we want to know if a number is prime, we can simply check to see if it has any divisors less than its square root.</p>
<p>Additionally, instead of generating all factors and then checking if each is prime, we can simply start at 3 - the smallest possible factor - and work our way up to sqrt(n).</p>
<p>With that in mind, we can change our <code>isPrime()</code> function and check a much smaller set of numbers.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isPrime</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">n</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">n</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">n</span>) {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">3</span>; <span style="color:#a6e22e">i</span> <span style="color:#f92672">&lt;=</span> int(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Sqrt</span>(float64(<span style="color:#a6e22e">n</span>))); <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">i</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">continue</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">n</span>), float64(<span style="color:#a6e22e">i</span>)) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0.0</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Now we can run the same set of tests (which pass) and benchmarks again to see how much performance we gained (if any).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ benchcmp v3.bm v4.bm
</span></span><span style="display:flex;"><span>ignoring Benchmark_factors/benchmarkNumber-4: before has <span style="color:#ae81ff">1</span> instances, after has <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>benchmark                                          old ns/op     new ns/op     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">358904</span>        <span style="color:#ae81ff">223015</span>        -37.86%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">222206</span>        <span style="color:#ae81ff">239</span>           -99.89%
</span></span><span style="display:flex;"><span>Benchmark_isEven/Odd_number,_3-4                   0.29          0.29          +0.00%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old allocs     new allocs     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">28</span>             <span style="color:#ae81ff">0</span>              -100.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">5</span>              <span style="color:#ae81ff">0</span>              -100.00%
</span></span><span style="display:flex;"><span>Benchmark_isEven/Odd_number,_3-4                   <span style="color:#ae81ff">0</span>              <span style="color:#ae81ff">0</span>              +0.00%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old bytes     new bytes     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">624</span>           <span style="color:#ae81ff">0</span>             -100.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">248</span>           <span style="color:#ae81ff">0</span>             -100.00%
</span></span><span style="display:flex;"><span>Benchmark_isEven/Odd_number,_3-4                   <span style="color:#ae81ff">0</span>             <span style="color:#ae81ff">0</span>             +0.00%
</span></span></code></pre></div><p>Great!  We now have 0 memory allocations, which will make things faster, and we check fewer numbers, which will also make things faster.  This is demonstrated by the 99% reduction in runtime for <code>isPrime()</code> and a 38% reduction for finding the largest prime factor compared to V3.</p>
<p>If we compare to V1, we see that we are down about 64%.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ benchcmp v1.bm v4.bm
</span></span><span style="display:flex;"><span>ignoring Benchmark_factors/benchmarkNumber-4: before has <span style="color:#ae81ff">1</span> instances, after has <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>benchmark                                          old ns/op     new ns/op     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">623854</span>        <span style="color:#ae81ff">223015</span>        -64.25%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">414616</span>        <span style="color:#ae81ff">239</span>           -99.94%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old allocs     new allocs     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">28</span>             <span style="color:#ae81ff">0</span>              -100.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">5</span>              <span style="color:#ae81ff">0</span>              -100.00%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old bytes     new bytes     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">624</span>           <span style="color:#ae81ff">0</span>             -100.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">248</span>           <span style="color:#ae81ff">0</span>             -100.00%
</span></span></code></pre></div>
<h1 id="bonus-round-v5" class="anchor-link"><a href="#bonus-round-v5">Bonus round: V5</a></h1>
<p>If we wanted to squeeze out a bit more performance (without going on to more advanced methods like the <a href="https://en.wikipedia.org/wiki/General_number_field_sieve">General Number Field Sieve</a>, the current top performer for prime factorization) we can take advantage again of the fact that all primes larger than 2 are odd.  With this fact in mind, we only need to check odd divisors, and when checking for primality, we need only check odd numbers.  This removes the call to <code>isEven()</code> entirely, since we don&rsquo;t need to check for that now, but it does make our <code>isPrime()</code> implementation more brittle since we are assuming the caller is always providing odd numbers.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">v5</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;math&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isPrime</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">3</span>; <span style="color:#a6e22e">i</span> <span style="color:#f92672">&lt;=</span> int(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Sqrt</span>(float64(<span style="color:#a6e22e">n</span>))); <span style="color:#a6e22e">i</span> = <span style="color:#a6e22e">i</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">n</span>), float64(<span style="color:#a6e22e">i</span>)) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0.0</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">LargestPrimeFactor</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">biggest</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// First, find factors
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">3</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">n</span>; <span style="color:#a6e22e">i</span> = <span style="color:#a6e22e">i</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">n</span>), float64(<span style="color:#a6e22e">i</span>)) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0.0</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#75715e">// i is a factor, so check if it&#39;s prime
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>			<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">isPrime</span>(<span style="color:#a6e22e">i</span>) {
</span></span><span style="display:flex;"><span>				<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">i</span> &gt; <span style="color:#a6e22e">biggest</span> {
</span></span><span style="display:flex;"><span>					<span style="color:#a6e22e">biggest</span> = <span style="color:#a6e22e">i</span>
</span></span><span style="display:flex;"><span>				}
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">biggest</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Now we start at 3 and increment by 2 in each loop, which will only test odd numbers.  The performance is a bit better, but we&rsquo;re starting to get only marginal benefits at this point.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ benchcmp v4.bm v5.bm
</span></span><span style="display:flex;"><span>ignoring Benchmark_isEven/Odd_number,_3-4: before has <span style="color:#ae81ff">1</span> instances, after has <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>benchmark                                          old ns/op     new ns/op     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">223015</span>        <span style="color:#ae81ff">201270</span>        -9.75%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">239</span>           <span style="color:#ae81ff">231</span>           -3.35%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old allocs     new allocs     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">0</span>              <span style="color:#ae81ff">0</span>              +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">0</span>              <span style="color:#ae81ff">0</span>              +0.00%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old bytes     new bytes     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">0</span>             <span style="color:#ae81ff">0</span>             +0.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">0</span>             <span style="color:#ae81ff">0</span>             +0.00%
</span></span></code></pre></div><p>We get another 10% or so increase overall compared to V4.  What about compared to our original implementation?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ benchcmp v1.bm v5.bm
</span></span><span style="display:flex;"><span>ignoring Benchmark_factors/benchmarkNumber-4: before has <span style="color:#ae81ff">1</span> instances, after has <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>benchmark                                          old ns/op     new ns/op     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">623854</span>        <span style="color:#ae81ff">201270</span>        -67.74%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">414616</span>        <span style="color:#ae81ff">231</span>           -99.94%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old allocs     new allocs     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">28</span>             <span style="color:#ae81ff">0</span>              -100.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">5</span>              <span style="color:#ae81ff">0</span>              -100.00%
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>benchmark                                          old bytes     new bytes     delta
</span></span><span style="display:flex;"><span>Benchmark_LargestPrimeFactor/benchmarkNumber-4     <span style="color:#ae81ff">624</span>           <span style="color:#ae81ff">0</span>             -100.00%
</span></span><span style="display:flex;"><span>Benchmark_isPrime/benchmarkNumber-4                <span style="color:#ae81ff">248</span>           <span style="color:#ae81ff">0</span>             -100.00%
</span></span></code></pre></div><p>Overall, we are down about 68% for the small benchmark number provided in the challenge.  Let&rsquo;s try a bigger number and see if the percentages change as the numbers increase (they should).  The random number I first typed originally was so slow to compute with V1 that I cancelled the benchmark.  I&rsquo;ve replaced it with a random 10 digit number <code>8275832758</code>.  Here are the results (I removed all the benchmark data that was the same as before).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ benchcmp v1.1.bm v5.1.bm
</span></span><span style="display:flex;"><span>Benchmark_isPrime/8275832758-4                     <span style="color:#ae81ff">275850428911</span>     <span style="color:#ae81ff">9771163</span>       -100.00%
</span></span></code></pre></div><p>I tried to also do the benchmark for <code>LargestPrimeFactor()</code> as well, but <code>go test</code> died mysteriously due to a SIGQUIT somewhere.  Perhaps a bug report is in order.</p>

<h1 id="outro" class="anchor-link"><a href="#outro">Outro</a></h1>
<p>At this point, we aren&rsquo;t getting much more in the way of performance improvements, so there&rsquo;s no need to carry out more changes to this algorithm.  If we want to have better performance, especially for numbers with a greater number of digits, we will have to change the algorithm and use something more intelligent and parallelizable (there are other sieves for which this is possible).</p>
 ]]></content:encoded></item><item><title>The Ten-Minute Reorg</title><link>https://adamdrake.com/the-ten-minute-reorg.html</link><pubDate>Sun, 26 Mar 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/the-ten-minute-reorg.html</guid><description>&lt;p>I spend a lot of time working with growth-stage startups. I often see similar problems across companies when it comes to scaling up their tech teams. At a certain point, the intuitive way to grow a team breaks down, and a reorganization (&amp;ldquo;reorg&amp;rdquo;) is necessary in order to adopt a scalable structure. Where some companies may take months to design and execute a reorg, I prefer to handle the majority of it in about ten minutes. In this post I&amp;rsquo;ll discuss the rationale, and introduce the major stages of the ten-minute reorg.&lt;/p></description><content:encoded><![CDATA[ <p>I spend a lot of time working with growth-stage startups.  I often see similar problems across companies when it comes to scaling up their tech teams.  At a certain point, the intuitive way to grow a team breaks down, and a reorganization (&ldquo;reorg&rdquo;) is necessary in order to adopt a scalable structure.  Where some companies may take months to design and execute a reorg, I prefer to handle the majority of it in about ten minutes.  In this post I&rsquo;ll discuss the rationale, and introduce the major stages of the ten-minute reorg.</p>

<h1 id="evolution-of-a-tech-team" class="anchor-link"><a href="#evolution-of-a-tech-team">Evolution of a Tech Team</a></h1>
<p>When a startup has a small team, usually less than five people at inception, each person will probably have a clear specialization.  As the company and workload grows, the intuitive coping method is to hire additional people.  The new staff fill a new specialized need in order to maintain the output of the team.  If the frontend development team is bogged down with work, another developer is hired to work on frontend tasks.  This is similar to vertically scaling a database server, only with people instead of hardware.</p>
<p>Eventually, this single team gets large enough that it&rsquo;s no longer manageable as a single entity.  The intuitive solution is to split it into two teams, and since technology leaders are typically responsible for the team structure, they proceed as they would with a technical problem.  There&rsquo;s a clear interface between the frontend and the backend of their software, so frontend and backend teams are created.  The company assumes that each of these teams will continue to scale up both people and output as needed.</p>
<p>However, whereas with technology you have an API facilitating a link between the otherwise decoupled frontend and backend services, this partition doesn&rsquo;t work as well with teams.  There is an inherently strict dependency between both teams in order to deliver a product to the customer: the backend can&rsquo;t be delivered without the frontend, and the frontend can&rsquo;t be useful without the backend.  This organizational structure provides many opportunities for conflict and roadblocks when it comes to expediently releasing products to customers.</p>
<p>The result of continuing to scale these vertical teams is an increase in headcount, staff costs, communication complexities, software complexities - and a decrease in output.</p>
<p>If vertical teams aren&rsquo;t the answer, then what should we do?</p>

<h2 id="enter-feature-teams" class="anchor-link"><a href="#enter-feature-teams">Enter Feature Teams</a></h2>
<p>Instead of hiring more people in an attempt to solve a bottlenecked area and ultimately adding to the problem, there&rsquo;s a much simpler fix available.  Take your current organizational chart, rotate it 90 degrees (or Pi/2 radians if you prefer) and use that as your new organizational chart.  The columns of the chart represent your new cross-functional teams, each with their own team lead who reports to the next level of leadership in the organization. In growth-stage startups, this is usually the CTO.</p>
<p>The benefits of having teams with this composition are immense.  Instead of a particular feature having to go through multiple steps and teams in order to arrive at the customer, a single team can now handle the implementation, testing, and deployment.  By reducing the number of dependencies from multiple tiers in multiple teams to a single streamlined team, a company can quickly and much more efficiently progress from idea to deployed feature.</p>
<p>Feature teams work from a single, prioritized backlog.  They can pull stories from the backlog as quickly as they have capacity available.  The priority of the backlog is decided by the Product organization, so feature teams never have any confusion about what they&rsquo;ll work on next.</p>
<p>Teams develop features in parallel, and each feature goes through the deployment pipeline as part of a continuous delivery process.  The flow resembles a standard fan-out/fan-in pattern similar to a high-performance processing system, except with people and teams instead of worker threads and queues.</p>
<p>
<img class="enclosure" src="/static/images/feature_teams_fan_out_fan_in.png" alt="Fan-out/fan-in pattern diagram"  />
</p>

<h1 id="implementing-the-ten-minute-reorg" class="anchor-link"><a href="#implementing-the-ten-minute-reorg">Implementing the Ten-Minute Reorg</a></h1>
<p>When moving to this type of scalable organization, the most significant change is from having all teams report to a single leader (probably a CTO) to having each team report to their own team lead, who in turn reports to the CTO.  Anecdotally, I&rsquo;ve found that when technology organizations grow to around twenty or twenty-five people, they simply cease to function effectively without this intermediate leadership layer.</p>

<h2 id="step-1-selecting-the-team-leads" class="anchor-link"><a href="#step-1-selecting-the-team-leads">Step 1: Selecting the Team Leads</a></h2>
<p>The first thing to consider is that the team lead is a not necessarily a tech lead.  The team lead may or may not be the most technically competent person on the team.  Leading a team requires many skills in addition to technical capability, including communication, planning, managing expectations, and the ability to ask tough questions and provide tough feedback.  The first and foremost job of the team leader is to ensure that the team has everything it needs in order to be able to have a high output of features to customers.  Sometimes the best technically-minded developers aren&rsquo;t strong enough in these important areas to be a suitable choice for team lead without further management skills training.</p>
<p>You&rsquo;ll need as many team leads as you will have teams.  I suggest a team size of four to five members, plus the team lead.  This allows for two backend developers, a frontend developer, and someone specializing in testing.  In larger organizations, the size of the team may increase to also include someone who specializes in databases, someone with a focused development operations background, or similar.  Regardless of the number of people, the team should, to the extent possible, have all the skills needed in order to take ideas through the entire development process and deploy features to customers.</p>

<h2 id="step-2-get-the-team-leads-on-board" class="anchor-link"><a href="#step-2-get-the-team-leads-on-board">Step 2: Get the Team Leads on Board</a></h2>
<p>Have a meeting with the prospective team leads.  Provide them with the background of why the current structure is no longer suitable, and how they can expect the organizational flow to evolve.  Help them understand that having cross-functional teams allows your organization to parallelize development and become much more effective.  While dependencies between teams or different software components may still exist, they will be reduced in comparison to a totally separated frontend team and backend team.</p>
<p>Describe the role of the team lead.  Communicate that this meeting is taking place because you believe those in attendance have the potential to be great team leads.  Impress upon them that the team lead role is perhaps the most important in the entire tech organization.  Team leads serve as the glue between ground-level operations and code, and the big-picture goals at the  strategic level.  They are the communication interface between ideas and output.</p>
<p>Make sure you get their support, since you&rsquo;ll need it in the weeks ahead.</p>

<h2 id="step-3-get-the-whole-tech-team-on-board" class="anchor-link"><a href="#step-3-get-the-whole-tech-team-on-board">Step 3: Get the Whole Tech Team on Board</a></h2>
<p>Have a meeting with the whole tech team.  Help them understand the same goals you impressed upon the team leads, but most importantly, as always, communicate the <em>why</em> of these goals.</p>
<p>Often, people are worried about blowback from employees.  In general, I&rsquo;ve found the opposite to be true.  Once people understand that this evolved company structure will allow them to be more productive and to have more ownership of their work, they tend to be extremely excited about the changes.</p>
<p>There will, however, be some people who are apprehensive about these changes.  I&rsquo;ve found this generally to be due one of two reasons.</p>
<p>In some cases, the person is just naturally averse to change and might have some legitimate concerns.  Hear them out and try to address their worries.</p>
<p>In other cases, certain people may be unhappy for a more problematic reason.  Quite simply, they&rsquo;re unhappy because in this new model there will be nowhere for slackers to hide.  In a large team of developers, someone who wants to coast and not actively produce can slip by unnoticed for some time.  However, as part of a tight team geared for high output with only one or two people assigned to a certain skill area, it becomes quickly apparent when one person isn&rsquo;t performing as well as the others.  Those who fall into this category of concern tend to be the most vocal in their opposition, reflecting the fact that they have the most to lose from being noticed.  Deflect their questions and speak with them privately after the general meeting.  If further investigation reveals that they can&rsquo;t perform because they lack the necessary mentoring or development, then it&rsquo;s partially your responsibility as a leader to address their needs.  If they simply don&rsquo;t want to be responsible for performing, then it&rsquo;s your responsibility as a leader to fire them.  Small, high-output feature teams cannot abide members who don&rsquo;t have the drive to perform.</p>
<p>After the briefing, the entire tech team should be aware of the current state, be on board for the goals to be accomplished, and understand the reasons for wanting to accomplish these goals.  The team lead role should be sufficiently explained, and those who have accepted your nomination to become team leads should be introduced as such to the rest of the team.  Now, it&rsquo;s time for the actual reorg.</p>

<h2 id="step-4-the-ten-minute-reorg" class="anchor-link"><a href="#step-4-the-ten-minute-reorg">Step 4: The Ten-Minute Reorg</a></h2>
<p>Many companies will take weeks to accomplish this next step.  Growth-stage startups can&rsquo;t afford that long.  Luckily, it only needs to take about ten minutes.</p>
<p>Have the team leads stand in maximally separated areas of the room.  Explain that the goal is to create a first draft of the new company structure.  Teams should be as balanced as possible given the skills present in the current employees, and you as a leader will have the final say on team makeup in order to provide better balance, plan for future staffing, and make other strategic decisions.  The goal is to get as close as possible to a reasonable approximation of the final teams.  Have everyone assign themselves to teams by standing with the appropriate team leader.  Give them ten minutes to accomplish this objective.</p>
<p>Be on hand to answer questions that will almost certainly arise during this time.  After the ten minutes are up, make note of the people on each potential team, and thank everyone for their time.  Let them know that the reorg will undergo further discussion with the team leads before everything is final.</p>

<h2 id="step-5-what-next" class="anchor-link"><a href="#step-5-what-next">Step 5: What Next?</a></h2>
<p>Talk with the team leads about the prospective teams.  Address any concerns about balance of skills or personalities of the people within each team, and as much as possible with your current staff, balance the team.  If there are gaps, these will be filled by cross-training, hiring, or some combination of the two.  However, don&rsquo;t treat every skill shortage as a hiring problem - that strategy harkens back to your previous organizational structure and presents scaling problems.  Now, the goal is to make each team productive, which will often mean broadening the skills of the people in the teams.</p>
<p>Throughout this process, many questions will likely arise.  How do the feature teams interact with the product owners or product team? How do two teams handle a situation where they&rsquo;re working on two different features for the same software component? (Hint: one team takes both features.)  You may even encounter questions for which you have no answers yet - this is an expected and necessary part of the process.  It&rsquo;s important to remember that your reorg is about heading in a defined direction, and that the process of getting there is a process of evolution.  What works tomorrow may not work for your organization a year from now.  It&rsquo;s important to keep your goals in mind while remaining fluid on the process of achieving them.</p>
<p>What does the flow look like?  Will each team have their own development environment? While this question is a future post in itself, generally, each development team member should have a complete development environment on their machine, including databases and/or mocks as needed.  Enabling each person to do their own development and testing locally will result in them being able to work faster and thus be more productive.  After local testing, each person should send a pull request and review their work with their team lead.  Once everything is reviewed and approved, their changes should be merged with master and pushed to the development pipeline shared by all teams.  This pipeline includes the development, testing, staging, and production environments.  This is the fan-in portion of the process, which I&rsquo;ll elaborate on in future posts.</p>

<h2 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h2>
<p>In a growth-stage startup with under one hundred developers, there&rsquo;s no real need for a long drawn-out reorg process.  It can be started and completed in a matter of days, with the major component of creating initial teams finished in ten minutes.  I&rsquo;ve used this process multiple times with teams of varying sizes, from less than twenty up to nearly a hundred, and it has worked well across that spectrum.  If you are a growth-stage startup or similarly-sized company with reduced development output due to bottlenecks, it might be time for your ten-minute reorg.</p>
<p>Good luck!</p>
<p>P.S. - In case you want the DOT code for the team flow above:</p>
<pre tabindex="0"><code class="language-DOT" data-lang="DOT">digraph G {
	rankdir=LR
	
	&#34;Feature Backlog&#34; -&gt; &#34;Feature Team 1&#34;;
	&#34;Feature Backlog&#34; -&gt; &#34;Feature Team 2&#34;;
	&#34;Feature Backlog&#34; -&gt; &#34;Feature Team 3&#34;;

	&#34;Feature Team 1&#34; -&gt; &#34;Deployment Pipeline&#34;;
	&#34;Feature Team 2&#34; -&gt; &#34;Deployment Pipeline&#34;;
	&#34;Feature Team 3&#34; -&gt; &#34;Deployment Pipeline&#34;;

	&#34;Feature Backlog&#34; [shape=box];
	&#34;Deployment Pipeline&#34; [shape=Msquare];
	&#34;Customer&#34; [shape=doublecircle];
    
	&#34;Deployment Pipeline&#34; -&gt; &#34;Customer&#34;
}
</code></pre> ]]></content:encoded></item><item><title>Command and Control</title><link>https://adamdrake.com/command-and-control.html</link><pubDate>Sat, 28 Jan 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/command-and-control.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>When I advise organizations, they often ask if I have written down or somehow codified my perspectives on leadership and operations. Until now, the answer has been a polite &lt;em>not yet&lt;/em>. I simply didn&amp;rsquo;t believe I have accumulated sufficient experience to warrant writing something from a position of authority on the topic of leadership and operations in organizations. After much consideration and gentle prodding from advisory clients, I have come to understand that my perspective may be flawed. I have long known that leaders benefit from sharing knowledge and experiences, and although I may never view myself as an authority on leadership, I can understand the value in having a summary of my philosophy available for distribution. If taking the time to share my experiences is something which can be helpful for others, then I am happy to do so.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>When I advise organizations, they often ask if I have written down or somehow codified my perspectives on leadership and operations.  Until now, the answer has been a polite <em>not yet</em>.  I simply didn&rsquo;t believe I have accumulated sufficient experience to warrant writing something from a position of authority on the topic of leadership and operations in organizations.  After much consideration and gentle prodding from advisory clients, I have come to understand that my perspective may be flawed.  I have long known that leaders benefit from sharing knowledge and experiences, and although I may never view myself as an authority on leadership, I can understand the value in having a summary of my philosophy available for distribution.  If taking the time to share my experiences is something which can be helpful for others, then I am happy to do so.</p>
<p>This text essentially introduces both my leadership philosophy and also provides personal experience (where possible) to help with clarification.  I do not claim to have invented any of these concepts or approaches, and surely people who have far more experience than I do will have additional valuable perspectives, sometimes differing from my own.</p>

<h1 id="front-matter" class="anchor-link"><a href="#front-matter">Front Matter</a></h1>
<p>Organizations have varying levels of complexity.  This can be due to the structure of the organization, the size or number of employees, the geographic dispersion, or any number of factors.  If we want to understand the nature of leading organizations, we are well served to consider which organizations have been dealing with these problems the longest, and therefore have many lessons learned from which we can draw.  The organizations which have done so are, arguably, the militaries of the world.</p>
<p>Humans have been forming groups for the purpose of fighting likely since the first clans of us banded together.  Conflict and the prosecution of violence has been present in our society from the beginning, and military leadership theory has evolved to meet and fulfill the requirements of forming people together as a unit to accomplish an objective under the most difficult circumstances and with the direst consequences for failure.</p>
<p>When many people think about command and control, they think about micromanagement, but nothing could be further form the truth.  The modern version of military command and control in the post-Prussian-Auftragstaktik world, is all about establishing and encouraging autonomy while simultaneously maintaining alignment.  When reworded in this language, it is familiar and desirable to the same companies who would be quick to dismiss anything from the militaries of the world as bureaucratic and micromanaging.</p>
<p>So instead of dismissing thousands of years of continuously-refined leadership knowledge, let&rsquo;s dive into it a bit and summarize what is useful in a business context and how we can apply the same leadership principles in such an environment.</p>

<h1 id="auftragstaktik" class="anchor-link"><a href="#auftragstaktik">Auftragstaktik</a></h1>
<p>Literally &ldquo;mission tactics&rdquo;, auftragstaktik is a system for providing direction and vision for achieving objectives.  It was originally developed and applied with great success in the Prussian military, an organization renowned for its efficiency, innovativeness, and adaptability.  It is such an effective approach that it is still in use today, although in the US and UK it&rsquo;s now called <em>mission command</em> instead.</p>
<p>Modern startups which reach a scale beyond which a couple of co-founders can manage are always striving for autonomy, innovation, and progress among their teams, and auftragstaktik is a great way to go about that.  In this article I&rsquo;ll just provide an overview of the six principles of Misson Command as described by the US Army.</p>
<p>The US Army defines Command as &ldquo;the creative and skillful exercise of authority through timely decisionmaking and leadership&rdquo; and the concept of mission command is discussed at length in <a href="/static/ADP-6-0-Mission-Command.pdf">Army Doctrinal Publication 6-0</a> (ADP 6-0).  They also define <em>leadership</em> as &ldquo;the process of influencing people by providing purpose, direction, and motivation to accomplish the mission and improve the organization&rdquo; (ADP 6-0, Paragraph 23).</p>

<h1 id="business-perspective" class="anchor-link"><a href="#business-perspective">Business perspective</a></h1>
<p>Mission Command is relatively straightforward, with the main requirement being that teams understand the desired end-state of their work, why the desired end-state is important, and any constraints imposted on the achievement of the desired end-state.</p>
<p>First, the teams need to know where they are supposed to go.  Without an understanding of the direction, they cannot make progress.  Additionally, when teams are doing work to make progress towards an objective, there are thousands of tiny decisions they need to make along the way.  In a micromanaging environment, they will have to ask the manager to make a decision each time.  In a mission command environment, they will use the desired end-state as a guide to make those decisions themselves, which allows the team to maximise its autonomy and make continued progress towards the objective at maximum speed.</p>
<p>Secondly, when people understand why something is important they are able not only to identify with the objective and increase the chances of success, but they also have a broader perspective, which allows them come up with additional ideas, suggestions, or courses of action which could work better than the original plan.  These efficiencies and increased speed are something startups are constantly trying to cultivate.</p>
<p>At this point, the group understands where things are going, and why we are going there.  They should also be fully informed of any constraints on achieving the objective.  Is there a deadline?  Are there technological requirements?  Are there security concerns which require the solution to meet some criteria?  Are there regulatory requirements which must be managed?  All of these things should be made clear to the team.  However, it&rsquo;s important to note that the goal is to communicate the absolute constraints.  If something is a preference and not a requirement, then it should not be mentioned.  The essence of the process is that the team must figure out how to achieve the objective.</p>
<p>Once the team has been fully informed, now they can get to work on figuring out how to solve the problem.  They may come up with multiple solutions and in those cases should present the benefits and risks of each solution to the leader.  Together the leader and the team can decide on the course of action.</p>
<p>This process maximally involves the team as the owner of the solution, and in an ideal world the entire solution is their idea.  This ownership results in more personal commitment to the goal than if the team were simply given a painfully-detailed process to execute.</p>
<p>At this point, the job of the leader is to handle communication and to remove impediments for the team in order to make sure that they are achieving their objective as efficiently and effectively as possible.</p>
<p>Again, it&rsquo;s important to note that Mission Command is supposed to be the opposite of micromanagement.</p>
<p>A fantastic perspective on this is contained in <a href="/static/MCDP-6-Command-and-Control.pdf">Marine Corps Doctrinal Publication 6 - Command and Control</a> (MCDP 6) on page 137:</p>
<blockquote>
<p>The reality of technological development is that equipment which improves the ability to monitor what is happening may also increase the temptation and the means to try to direct what is happening. Consequently, increased capability on the part of equipment brings with it the need for increased understanding and discipline on the part of users. Just because our technology allows us to micromanage does not mean that we should.</p>
</blockquote>

<h1 id="six-principles-of-mission-command" class="anchor-link"><a href="#six-principles-of-mission-command">Six principles of Mission Command</a></h1>
<p>The US Army sets out six principles of Mission Command in their doctrine:</p>
<ol>
<li>
<p>Build cohesive teams through mutual trust.</p>
</li>
<li>
<p>Create shared understanding.</p>
</li>
<li>
<p>Provide clear commander&rsquo;s intent.</p>
</li>
<li>
<p>Exercise disciplined initiative.</p>
</li>
<li>
<p>Use mission orders.</p>
</li>
<li>
<p>Accept prudent risk.</p>
</li>
</ol>
<p>These principles, if internalized in an organization and implemented well, almost guarantee the organization will have consistent and efficient progress towards their objectives, so let&rsquo;s examine them each in detail.</p>

<h1 id="build-cohesive-teams-through-mutual-trust" class="anchor-link"><a href="#build-cohesive-teams-through-mutual-trust">Build cohesive teams through mutual trust</a></h1>
<p>It is obvious that if there is no trust within a team or teams, then there will be a lack of cohesiveness and therefore a lack of mutual support.  Building trust among teams is often the product of shared experiences and history of working together, especially if those experiences involve shared struggle.  Working towards a difficult objective together is arguably the best way to build unit cohesion.</p>
<p>There is also the trust that the team has for their leader, and this is developed in a slightly different way.  It is reinforced through consistent and fair treatment, clear communication, and making sure that the people on the team know the leader cares about their individual welfare.  If someone on the team doesn&rsquo;t think the leader cares about them, then they will not trust that leader.</p>
<p>Additionally, leaders must seek ways to build trust outside of their direct teams.  This is often called peer leadership or stakeholder management in the business context, but the result is the same.  Elements outside of the leader&rsquo;s direct control, referred to as <em>Unified Action Partners</em> in ADP 6-0, are the entities with which the team works.  A primary example might be the IT Operations team and Software Engineering team, in companies where those are still separated.  The VP Engineering (or person leading all of the development efforts) will need to make sure that there is mutual trust between their group of developers and the IT Ops group (a primary UAP).  If this mutual trust does not exist, then there will be consistent and problematic resistance for software deployments, hardware upgrades, and all the other things which are required for a successful tech company to operate.  Mutual trust with IT Ops as a UAP is critical.  The goal of all these activities is to forge unity of effort, which is the coordination and cooperation needed to achieve objectives, even if the two groups are not on the same reporting line.</p>

<h1 id="create-shared-understanding" class="anchor-link"><a href="#create-shared-understanding">Create shared understanding</a></h1>
<p>One thing leaders almost always struggle with is how to create alignment of effort within the organization.  This alignment of effort is nothing more than shared understanding on the direction and why it&rsquo;s important.</p>
<p>This shared understanding is created and maintained through consistent and productive dialog in all directions.  Leaders must talk to higher leadership, peers, and subordinates consistently, and build a culture of collaboration.  This is a difficult task, and requires constant tuning and attention, but it is critical to the functioning of an organization.  This collaborative culture, and the consistent messaging from leadership, is required in order to ensure that the entire organization has the same understanding.</p>

<h1 id="provide-clear-commanders-intent" class="anchor-link"><a href="#provide-clear-commanders-intent">Provide clear commander&rsquo;s intent</a></h1>
<p>Commander&rsquo;s intent is simply a clear, concise, explanation of what the leader wants accomplished and why.  It is absolutely critical to get this right because if you want people to work autonomously, they need to understand the overall goal they are trying to achieve.  This overall goal is the commander&rsquo;s intent.</p>
<p>One problem I see in organizations <strong>all the time</strong> is that people don&rsquo;t actually know what they are supposed to do without being told what to do.  They may have a basic understanding of the direction of the company, but they don&rsquo;t know how <em>they as individuals</em> are supposed to contribute to achieving that objective.  This almost always results from the executive leadership forming some kind of strategy, and then the middle management thinking that all they have to do is repeat the strategy down to their subordinate teams.  NO!  Every leader, at every level, should start with the intent of their leader, then create their own intent for their team which describes how the specific team will make progress towards the higher intent, confirm this scoped intent with their leader, and then communicate the scoped intent down to the teams in a way the teams will understand.  This translation of commander&rsquo;s intent is absolutely critical and should take place at every level of leadership.  If the teams don&rsquo;t understand how the commander&rsquo;s intent applies to them, there will be no unity of effort.</p>
<p>The secondary goal of the commander&rsquo;s intent is to provide understanding to the teams so they can continue to function with increasing autonomy.  It is impossible for a leader to know every possible outcome as a project is being undertaken, so the commander&rsquo;s intent should provide broad guidance along with any constraints, so that teams can independently seize the initiative and make progress towards the objective.  Since successful mission command requires subordinates to exercise initiative in the absence of direct supervision from higher leadership, a very clear understanding of the commander&rsquo;s intent is required.</p>

<h1 id="exercise-disciplined-initiative" class="anchor-link"><a href="#exercise-disciplined-initiative">Exercise disciplined initiative</a></h1>
<p>The Army defines disciplined initiative as action in the absence of orders, when existing orders no longer fit the situation, or when unforeseen opportunities or threats arise (ADP 6-0, Paragraph 16).  This is precisely the autonomy and initiative which startups and other organizations always crave.  So why do they struggle with achieving it?</p>
<p>The critical factor in enabling the exercise of disciplined initiative is whether or not the commander&rsquo;s intent is clear.  Providing a clear commander&rsquo;s intent to your teams allows them to exercise such initiative because they understand the desired end-state, and the constraints.  Within those constraints they should be encouraged to take initiative wherever possible in order to make faster progress towards the objective and/or continue to make progress towards the objective (if impediments arise).</p>
<p>With all that in mind, it is still the responsibility of the people on the team to discuss with leadership whenever they have deviated from any agreed-upon plan, and it is the job of the leadership to make sure their commander&rsquo;s intent is sufficiently broad to allow such deviations to take place.  If not, then they&rsquo;re just micromanaging.</p>

<h1 id="use-mission-orders" class="anchor-link"><a href="#use-mission-orders">Use mission orders</a></h1>
<p>This one is critical.  <strong>Mission orders are directives about <em>what</em> to achieve and not <em>how</em> to achieve it</strong>.  The goal here is to provide as much direction as needed to achieve the objective, while simultaneously providing the maximum amount of freedom to maneuver.  In this way, the team can use their more detailed knowledge of the situation in order to make the best progress towards achieving the desired end-state.</p>
<p>In the mission orders framework, there is maximum autonomy and leadership only gets involved if they need to somehow provide a modification to the constraints or if the desired end-state has somehow changed.  Other than those situations, the role of leadership is to support the team and to coordinate up to higher leadership and out to other teams.</p>

<h1 id="accept-prudent-risk" class="anchor-link"><a href="#accept-prudent-risk">Accept prudent risk</a></h1>
<p>Prudent risk is considered here to be the deliberate exposure to potential loss when the leader judges that the risk of loss is worth the reward of progress towards the objective.  The classic example of this in a technology company is incurring technical debt in the codebase in order to achieve earlier product launch, to meet a required deadline, or for other reasons.  This technical debt should be a calculated and prudent risk accepted by the engineering leadership.  It is something which could cause potential loss or problems in the future, but still makes sense to do when balanced with the benefits of having something shipped now.</p>
<p>Judging and accepting prudent risk is a primary function of a leader.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>This is a basic overview of mission-type tactics, and it&rsquo;s a clear translation from these basic foundations as used in some militaries (in this case the US Army) to the way larger teams and organizations can make use of these same principles.  Although I used the US Army as an example in the post, the US Marine Corps are, as a general philosophy for a large military unit, the masters of the small-unit actions, on short notice, with maximum autonomy.  I&rsquo;ll be discussing their collected knowledge more in future posts.</p>
<p>Militaries have been learning the best ways to deal with groups of humans under adverse conditions for longer than any other type of organization.  Although the stakes are certainly higher in battle, human psychology does not differ significantly between a military unit in the field and a technology team writing code at a startup.  Don&rsquo;t miss this opportunity to learn from thousands of years of organizational research.</p>
 ]]></content:encoded></item><item><title>I am Here to Win</title><link>https://adamdrake.com/i-am-here-to-win.html</link><pubDate>Thu, 26 Jan 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/i-am-here-to-win.html</guid><description>&lt;p>I&amp;rsquo;m not here to be right, I&amp;rsquo;m here to win. That&amp;rsquo;s a phrase I often keep in mind, especially when I feel my own ego getting the best of me or when I see someone else&amp;rsquo;s ego affecting their judgment. In this context, &lt;em>win&lt;/em> means making progress towards a larger strategic goal, likely by achieving some intermediate objective. So if you are playing to &lt;em>win&lt;/em> and not just to be &lt;em>right&lt;/em> then you are putting aside your own ego and emotional involvement in order to make progress towards a larger goal.&lt;/p></description><content:encoded><![CDATA[ <p>I&rsquo;m not here to be right, I&rsquo;m here to win.  That&rsquo;s a phrase I often keep in mind, especially when I feel my own ego getting the best of me or when I see someone else&rsquo;s ego affecting their judgment.  In this context, <em>win</em> means making progress towards a larger strategic goal, likely by achieving some intermediate objective.  So if you are playing to <em>win</em> and not just to be <em>right</em> then you are putting aside your own ego and emotional involvement in order to make progress towards a larger goal.</p>
<p>The ability to subordinate your own ego is critical in achieving success individually and, more importantly, for your team.</p>
<p>However, when advising companies, especially companies who are relatively young and have successful founders, I often observe interactions where people have lost sight of their actual mission and are instead focusing on having their idea or approach be the one chosen.  In other words, they&rsquo;re defending their ideas because of their ego instead of because of the progress the idea will achieve in relation to the overall objective.</p>
<p>Classic examples of this are debates on tabs versus spaces, emacs versus vim, MySQL versus PostgreSQL, and all the usual programming language debates.  In general, you can build almost any tech product on the planet with any tools.  You can go a long way with Java and MSSQL, or Python and PostgreSQL.  There&rsquo;s a point at which having debates about such topics is more about being right than about advancing towards the larger objective.</p>
<p>This kind of situation comes up in more forms than expected, and can be as trivial as debating what to name some variable or class even though both fit the coding standard.</p>
<p>This phenomenon seems to be especially common in successful startups, with young and intelligent founders.  They&rsquo;re used to being right, and they&rsquo;re used to pushing their points and being assertive.  Sometimes, their egos have grown along with their company and they have lost sight of the fact that humility is the most important trait for any leader.  Although their assertiveness and focused approach might have afforded some fast progress in the early days of the company, it starts to be a detriment as the company grows.</p>
<p>If the founders are doing a good job of hiring and growing, they&rsquo;re bringing in experienced talent who can make very valuable contributions to the business.  These experienced professionals also come with their own opinions which, although probably not too different from the founders on a strategic level, will probably be different operationally.  This then leads to another question I&rsquo;m frequently asked: How do you handle situations where someone else&rsquo;s solution isn&rsquo;t as good as yours?  The answer is simple.  If the other person&rsquo;s solution is still good enough and meets the requirements, you encourage them to use it.</p>
<p>Much of leadership is not about reaching an objective with the perfect path, but rather making continuous progress towards the objective.  This continuous progress, over long time horizons, is more effective than trying to do everything perfectly along the way.  In more technical terms, leadership is about <em>global</em> optimizations and not <em>local</em> optimizations.  As a leader, it&rsquo;s your duty to make sure you have enough strategic perspective, and enough control over your own ego, to determine when someone else&rsquo;s solution is a better move for <em>global</em> optimization.</p>
<blockquote>
<p>A good solution applied with vigor now is better than a perfect solution applied ten minutes later.
-General George S. Patton Junior</p>
</blockquote>
<p>Live by this quote.  Just because your solution may seem like the 100% solution doesn&rsquo;t mean the 85% solution won&rsquo;t actually be better for the team and the business.  Consider how much more committed someone will be if they are actually working on, and responsible for, implementing their own solution.  It&rsquo;s a lot more likely someone will fight to get their solution implemented on time and on target since they have a sense of ownership.  If you tell them to implement your solution, then at best they&rsquo;re just doing what they&rsquo;re told, and that&rsquo;s not a way to consistently lead people.  You&rsquo;ll just end up being another founder/micro-manager who can&rsquo;t scale a growth-stage company and is eventually fired by the Board of Directors.</p>
<p>If someone else&rsquo;s 85% solution will achieve progress now, if that solution will help you to win, then what&rsquo;s the point in arguing for the implementation of your solution over a colleague&rsquo;s?  At that point, you&rsquo;re only feeding your own ego and you should ask yourself the important question.</p>
<p>Am I here to be right, or am I here to win?</p>
 ]]></content:encoded></item><item><title>On Confidence</title><link>https://adamdrake.com/on-confidence.html</link><pubDate>Thu, 26 Jan 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/on-confidence.html</guid><description>&lt;p>Bearing, presence, gravitas, and authority are all some words used to describe those who project confidence. When I am advising executives and leaders to help them with their teams, one of the topics of concern for them is confidence and how to gain it. Or at the very least, how to project confidence even when it&amp;rsquo;s not there. The latter seems to be especially concerning to those who are relatively new in their leadership positions.&lt;/p></description><content:encoded><![CDATA[ <p>Bearing, presence, gravitas, and authority are all some words used to describe those who project confidence.  When I am advising executives and leaders to help them with their teams, one of the topics of concern for them is confidence and how to gain it.  Or at the very least, how to project confidence even when it&rsquo;s not there.  The latter seems to be especially concerning to those who are relatively new in their leadership positions.</p>
<p>The truth is that confidence, like many things, is the product of experience.  Specifically, the experience of trying, failing, trying again, and eventually learning from your experiences (even if not successful). Confidence is knowing that even if you don&rsquo;t have an exact solution to a problem at the moment, you can help the team come up with a solution to any problem.  A person can become confident in a specific domain, but the overall confidence that is apparent in experienced leaders is earned from challenging experiences which often resulted in unpleasant outcomes.</p>
<p>That is all well and good as an explanation for the origins of professional bearing and presence in experienced leaders, but for newer leaders the main concern is how to <strong>gain</strong> confidence in the first place.  In other words, how can they be confident when they haven&rsquo;t yet had the experience?</p>
<p>The short answer is: fake it until you make it.</p>
<p>
<img class="enclosure" src="/static/images/fake_it_til_you_make_it.jpg" alt="Cat in lion costume &lsquo;Fake it til you make it&rsquo; meme"  />
</p>
<p>Since confidence is only really expressed or noticeable upon interaction with others, we can consider what a typical interaction process looks like for leaders.  By having confidence <em>in this process</em>, leaders will tend to be viewed as confident overall.  Remember, confidence is <strong>not</strong> about having all the answers, and the process below applies to leaders generally, not just those with less experience.  Confidence is about being sure that you can help the group solve a problem.</p>

<h1 id="example" class="anchor-link"><a href="#example">Example</a></h1>
<p>Let&rsquo;s assume, as an example, that you are a relatively fresh technical lead.  You are directly responsible for one or more teams, and there is currently a component which must be completed in order to help a project be successful.  This component has strict performance requirements in terms of processing speed and other things, so it&rsquo;s not a matter of straightforward design and implementation.  You are not sure how to solve the problem as you have never experienced something like this.  What do you do?</p>

<h2 id="step-1-collect-information" class="anchor-link"><a href="#step-1-collect-information">Step 1: Collect information</a></h2>
<p>One of the most important tasks leaders must complete is collecting the amount of information necessary to make an informed decision and direct the actions of subordinates.</p>
<p>This is not just a matter of referring to a requirements sheet and checking off a box.  Leaders should make sure they have collected information up, down, and across the organization.  This serves multiple purposes including personally getting a better understanding of the strategic landscape, making sure people&rsquo;s opinions are taken into account, and also becoming informed about additional situations or motivations you may not have heard about yet.  Pay particular attention to things which may explain people&rsquo;s motivations.  Often this is about power in the form of the size of their team, or money in the form of bonuses, raises, or similar.  Also have an understanding of P&amp;L responsibility and whether or not the person you&rsquo;re talking with has some kind of targets relating to P&amp;L numbers.</p>

<h3 id="talk-to-the-bosses" class="anchor-link"><a href="#talk-to-the-bosses">Talk to the bosses</a></h3>
<p>First, it&rsquo;s important to confirm that the overall vision and understanding is correct.  If a problem is to be solved, and the intent of your boss is not clear, then obviously the solution may not achieve the desired outcome.  If you disagree with the boss about their strategy or decisions, now is the time to ask them to help explain it to you again.  This should always be done respectfully, and in the context of enabling you to better execute their vision.</p>

<h3 id="talk-to-the-peers" class="anchor-link"><a href="#talk-to-the-peers">Talk to the peers</a></h3>
<p>Once the direction from the boss is clear, it&rsquo;s time to talk with your peers to make sure they have the same understanding and also to make sure they aren&rsquo;t trying to solve the same problem.  It&rsquo;s shocking how often multiple teams within companies try to solve exactly the same problem because they simply weren&rsquo;t aware that anyone else was working on it.  This de-conflicting step can save huge amounts of time, so it&rsquo;s a worthwhile investment.</p>
<p>If another team is working on the same problem, some new leaders have concern about helping the current team complete the project versus continuing to work on the project themselves in parallel.  There is often anxiety about who will get credit and whether or not the team(s) will look bad.</p>
<p>The top priority for your boss is that things are accomplished.  In general, as long as objectives are met on time and within any specified constraints, they won&rsquo;t care whether or not you personally or your team generally solved the problem.  They just want the problem solved.  You&rsquo;ll be a lot better off working with another team to get the problem solved more quickly than trying to outrun them on a parallel track.  Work together and support each other instead of trying to get credit.</p>

<h3 id="talk-to-the-teams" class="anchor-link"><a href="#talk-to-the-teams">Talk to the teams</a></h3>
<p>After you&rsquo;ve had the required conversations upwards and outwards, it&rsquo;s time to talk with the teams.  By this point, you should have a very broad and complete understanding of the what and the why, and it&rsquo;s up to you to make sure the teams understand the same things, in context, so that they can come up with the how.  In this step, you are offering perspective and guidance if needed, but in order to build successful autonomous teams it is absolutely necessary for the teams to own the solution.  Ideally they should come up with the solution on their own and be totally responsible for the implementation.  Confidence with the teams is almost automatic at this point since you have a very good understanding of the problem domain, the intended strategy from higher up, and the general activities of other teams which could be in conflict from a time and money perspective.  Remember, it&rsquo;s not your job to solve the problem.  It&rsquo;s your job to help the team solve the problem.</p>

<h2 id="set-a-direction" class="anchor-link"><a href="#set-a-direction">Set a direction</a></h2>
<p>After these planning steps have taken place, you have the context and direction from higher, the knowledge about other projects from your peers, and some possible options for solutions from the teams.  It is time to set a direction for solving the problem.  This could be as simple as accepting the advice of the team(s) on how to solve the problem, and in the cases where you haven&rsquo;t solved the same or similar problem before that is a likely outcome.</p>
<p>Sometimes though, you will have had experience solving these kinds of problems, and your past experiences can provide useful changes to the plans made by the teams.  In these cases, make sure that you are providing guidance by sharing your experiences and not overly influencing the teams by simply telling them what to do.  They should own the solution.  Be advised that what might appear like a small suggestion to you can come across like an absolutely critical requirement to the team.</p>
<p>The desired outcome of this step is that given all information currently available, a direction has been set and actions can be taken by the team.</p>

<h2 id="steering" class="anchor-link"><a href="#steering">Steering</a></h2>
<p>Now that plans are in motion, the primary job of the leader is to make sure that progress is consistent and that all the necessary parties are kept informed of the situation.  This means regular discussions and checks with the team to make sure they don&rsquo;t need anything, in addition to communication up and out.</p>
<p>On the topic of consistent progress, it is also sometimes necessary to adjust scope along the way.  People may try to pile on additional requirements after everything is in motion.  Sometimes there are additional requirements which can be added with little or no additional work by the team.  There are even rare cases where additional requirements result in less work for the teams.  In these situations, it&rsquo;s almost always best to add the additional features or requirements.  It builds goodwill with the stakeholders and ensures they take you seriously in the future when you tell them that their improvement cannot be added.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>Throughout this process, it was not incumbent upon the leader to actually solve any specific problem.  Rather, the job of the leader is to coordinate and guide the activities of the team, share their personal experiences with the team where appropriate, and help the team avoid known pitfalls.  There is also a large translation component, since the vision and direction set by the leader&rsquo;s boss may not be directly applicable to the individuals on the leader&rsquo;s team doing the implementation.  Some modifications to the message at those interfaces is nearly always required, and translating those messages to people with different perspectives is itself a huge leadership skill.</p>
<p>If you follow the process above, with humility, then it is only a matter of time before your team and your bosses will view you as a person with confidence and the ability to achieve objectives on time and on target.</p>
 ]]></content:encoded></item><item><title>On Forecasts</title><link>https://adamdrake.com/on-forecasts.html</link><pubDate>Thu, 26 Jan 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/on-forecasts.html</guid><description>&lt;h1 id="overview" class="anchor-link">&lt;a href="#overview">Overview&lt;/a>&lt;/h1>
&lt;p>I was meeting with a client recently, and since it was the end of the year and they were in their budgeting process we were discussing forecasting methodologies. They were asking about their marketing function specifically, but the conversation applied more or less to all areas of the business which set targets and/or develop a budget. So basically, the whole business.&lt;/p>
&lt;p>It&amp;rsquo;s important to note that in many companies budgeting and forecasting are the same thing, so this is as much a budgeting topic as a forecasting one. The reason that a lot of departments are asked to do forecasts in the first place is simply so that the forecast can be added as a line item in a budget.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="overview" class="anchor-link"><a href="#overview">Overview</a></h1>
<p>I was meeting with a client recently, and since it was the end of the year and they were in their budgeting process we were discussing forecasting methodologies.  They were asking about their marketing function specifically, but the conversation applied more or less to all areas of the business which set targets and/or develop a budget.  So basically, the whole business.</p>
<p>It&rsquo;s important to note that in many companies budgeting and forecasting are the same thing, so this is as much a budgeting topic as a forecasting one.  The reason that a lot of departments are asked to do forecasts in the first place is simply so that the forecast can be added as a line item in a budget.</p>
<p>These forecasts and/or budget line items are also often directly placed into compensation or bonus schemes either directly for a given employee or indirectly by so-called <em>performance-based</em> compensation packages for executives.  In other words, forecasts end up touching almost every part of the business and every person in the business, though some stand to benefit more than others.</p>
<p>The problem is that in many businesses, budgeting and forecasting are totally broken.  There is often a months-long budgeting process wherein thousands of hours are used in order to produce forecasts for inclusion into a budget.  Often the honest estimates of employees are negotiated up (or down) in a series of meetings, the end result being a budget which may not be realistically achievable at all.  The budget might address the dreams of an executive team or investors, but it may be impossible to achieve in reality.</p>
<p>In a perfect world, there would be no yearly budgets and no five-year plans, and we would all operate with rolling forecasts.  This is explained in detail in a great book called <a href="https://www.amazon.com/gp/product/1578518660/">Beyond Budgeting</a> which is one of the two books I recommend to all of my clients (the other being <a href="https://www.amazon.com/gp/product/1857885597/">The Art of Action</a>.</p>
<p>I&rsquo;ve had numerous discussions with companies about this topic over the years, but that experience has not been documented.  The goal of this post is to begin to give an overview of those discussions, answer some frequently asked questions, resolve some common misunderstandings, and provide reasonable expectations.</p>

<h1 id="some-preliminaries" class="anchor-link"><a href="#some-preliminaries">Some preliminaries</a></h1>
<p>First things first, is your organization mature enough in age and measurement capabilities to actually have historical data you can use for forecasting?  For many startups, the answer is a clear <strong>NO</strong>.  If your business has yearly seasonality, and you have only been operating for a year or two, then chances are that your growth rate will dominate seasonal effects.  Equivalently, if you want to forecast sales for a brand new office or new subsidiary in another country then you simply will not be able to do that.  You might be able to make an educated guess, possibly informed by deep domain knowledge, but you will not be able to make a forecast in the proper sense.</p>
<p>In these cases, the best bet is for you to make a guess and be explicit about the fact that it is a guess.  Calling it a forecast only serves as an attempt to add legitimacy where there is none.  It&rsquo;s always better to acknowledge and manage uncertainty than it is to pretend it doesn&rsquo;t exist.</p>
<p>In the case where you do have sufficient historical data (called a <em>time series</em>) on which to base your forecasts, there are many options on how to use it.  So when we talk about forecasting sales for next quarter, or per-capita sick days per department, we&rsquo;re well into the domain of time series forecasting.</p>

<h1 id="time-series-basics" class="anchor-link"><a href="#time-series-basics">Time Series Basics</a></h1>
<p>A <em>time series</em> is simply a sequence of values which are ordered in time.  The interval between each value is typically the same.  Examples would be yearly sales for a company, the monthly average cost of fuel for a car, the number of calories you eat every day, and so on.  This is typically the thing which you want to forecast.</p>
<p>The <em>frequency</em> of the time series is the interval at which the time series values are measured.  This could be daily, weekly, or 1000 times per second.</p>
<p>Observed time series data, like monthly revenue, can be decomposed into three main components: <em>trend</em>, <em>seasonality</em>, and <em>residuals</em>.  Time series decomposition can be done in other ways, and with methods requiring varying degrees of mathematical sophistication, but that discussion is beyond the scope of this post.</p>
<p>The <em>trend</em> is the general direction of the time series data.  Is it going up or down over the interval?  In many forecast problems for startups, the trend will almost completely explain the data and dominate any future forecasts on certain timescales, so your forecast will effectively be just the trend.</p>
<p>The <em>seasonality</em> is the variability which repeatedly occurs in the data.  A common example would be a consumer products company which will see higher sales during the Christmas holidays every year, or restaurants which often see lower revenue on certain days of the week or months of the year.  This is a consistent pattern related to the business operations.</p>
<p>The <em>residuals</em> is what is leftover after the trend and seasonal components of the time series have been extracted.  This is also sometimes called the <em>noise</em>.</p>
<p>You can see what this decomposition looks like in this <a href="https://stackoverflow.com/questions/20672236/time-series-decomposition-function-in-python#28284962">Stack Overflow post</a>.</p>
<p>
<img class="enclosure" src="/static/images/timeseries_decomposition.jpg" alt="Time series decomposition"  />
</p>
<p>A <em>hierarchical time series</em> is one in which the time series data is aggregated into levels.  In the figure below, from <a href="https://www.otexts.org/fpp/9/4">Forecasting: Principles and Practice</a> you can see a 2-level hierarchy.</p>
<p>
<img class="enclosure" src="/static/images/timeseries_hierarchical.png" alt="Hierarchical time series"  />
</p>
<p>This is typically the situation in a company when they want to, for example, forecast their revenue for the next accounting period.  They will typically settle for a <em>top-down</em> forecast or a <em>bottom-up</em> forecast, or some combination thereof.</p>
<p>In a <em>top-down</em> forecast, what typically happens is the leadership will set a target at the top and then ask the lower levels how they plan to get there.  Note that this isn&rsquo;t necessarily what a top-down forecast <em>should be</em>, but it&rsquo;s often what occurs in practice.</p>
<p>In a <em>bottom-up</em> forecast the leadership will ask the lowest levels to produce forecasts, which then get rolled into higher level forecasts, which continues all the way up until there is a single forecast which has aggregated information from the entire organization.</p>

<h2 id="a-note-on-budgets" class="anchor-link"><a href="#a-note-on-budgets">A note on budgets.</a></h2>
<p>For the purposes of budgeting, forecasts are often hierarchical.  This adds a bit of complexity because you must answer the question of whether you will use top-down, bottom-up, a mixture of the two, and how you will combine the forecasts.</p>
<p>Of additional importance is the fact that the variance in the forecasts may combine in unexpected ways.  It may be the case that your bottom-up forecast, by the time it gets to the top, has such a wide variance that it is almost useless.  THIS IS NOT A BAD THING!  Knowing the truth about the predictability in your organization is something to manage and minimize, but not something to ignore.  If your forecast variance is so wide as to be useless, then it is better to spend your efforts on ways to manage uncertainty in your organization.</p>

<h1 id="organizational-maturity" class="anchor-link"><a href="#organizational-maturity">Organizational maturity</a></h1>
<p>We can consider the maturity of an organization in a few different ways for our purposes.</p>
<ol>
<li>
<p>Quality of data.  Is it reliable and usable?</p>
</li>
<li>
<p>Historical data available.  Is there enough data?  Are forecasts even possible?</p>
</li>
<li>
<p>Quality of data infrastructure.  Can we do the desired computations in the desired time?</p>
</li>
<li>
<p>What is the confidence about whether or not the target can actually be achieved?  Are there additional factors which are not accounted for in the data but which materially impact the accuracy of the forecasts?  Did one of your manufacturing facilities get destroyed for example, and you now have 20% lower production capacity compared to last year?</p>
</li>
</ol>
<p>To the second point, some textbooks will mention that for ARIMA models you need <em>at least</em> 50 to 60 data points to start doing accurate forecasts.  In reality, any time series can be modeled, it&rsquo;s just a matter of signal to noise ratio and whether or not the forecast variance is acceptable.  If I tell you that your revenue for next year should be either down 80% or up 400%, that might not be useful, but it is still a valid model.</p>
<blockquote>
<p>All models are wrong but some are useful.</p>
<p>&ndash; George Box</p>
</blockquote>
<p>It&rsquo;s also important to note that a forecast is a guideline for the operation of the business.  Until our AI overlords take over, humans still have the most complete context and should serve as the sanity check for any forecasts.  Just because a computer says you might have a 200% revenue increase next year, doesn&rsquo;t mean it is correct.</p>

<h1 id="top-down-versus-bottom-up" class="anchor-link"><a href="#top-down-versus-bottom-up">Top-down versus bottom-up</a></h1>
<p>This is one of the main questions which comes up, and the answer is that it depends.  For hierarchical time series forecasting, a combination of the two methods is often most useful and straightforward.</p>
<p>However, even simpler still is just doing a bottom-up forecast.  Trust the people on the ground.  Trust the data.  They know more than you do and just because you don&rsquo;t like what they&rsquo;re telling you doesn&rsquo;t make it false.  If they came up with incorrect forecasts due to now having complete context and information from leadership, then leadership should consider how they can improve communication of pertinent information, which will also confer enormous benefits to many other areas of the business.</p>
<p>I constantly work with companies who are either concerned about hitting their targets because they didn&rsquo;t accept the estimates and forecasts of the people actually responsible for delivering.  Just because you want a forecast to be higher doesn&rsquo;t mean you should turn a forecast into a <em>stretch goal / big hairy audacious goal / SMART goal / whatever</em>.  A <strong>forecast</strong> is not an <strong>objective</strong>.</p>

<h1 id="variance-in-forecasts" class="anchor-link"><a href="#variance-in-forecasts">Variance in forecasts</a></h1>
<p>One thing I almost always see is companies not putting variance or some measure of uncertainty around their forecasts.  This usually happens because the senior management doesn&rsquo;t want to see it, doesn&rsquo;t want to acknowledge it, or would say the forecast was invalid or useless with that particular level of variance.  None of that actually serves to decrease the variance however, and they will still require employees to produce forecasts, so everyone chooses to ignore the variance.  The question then becomes, what to do if the variance is so high that the forecast is not deemed useful?  That&rsquo;s a separate business question, but the short answer is that it pays to focus more on business changes which can allow the organization to cope with the uncertainty and adapt to the rapid pace of change.  Simply wishing for forecast variance to be smaller does not make it so.  Channeling the spirit of Neil deGrasse Tyson for a moment, the nice thing about facts is that they are true whether or not you believe them.</p>

<h1 id="forecast-intervals" class="anchor-link"><a href="#forecast-intervals">Forecast intervals</a></h1>
<p>Many of these forecasts are prepared for the next 12 months, because they are going to form the basis for the budget for the next operating year.  In some contexts this can make sense, especially when operational costs are relatively fixed.  If you have a multi-year lease for warehouse space at a fixed cost then you can be pretty certain about those costs over the next 12 months.</p>
<p>However, it&rsquo;s almost always a horrible decision to incorporate forecasts with wide variance into a budget since that basically converts them from forecasts with forecast error to targets in a budget.</p>
<p>Let&rsquo;s say you do create a 12 month forecast.  Intuitively, your uncertainty about month 11 is far greater than about month 1.  So why not just update the forecast as you gain more information?  Then you can use these new forecasts to project out 12 months, with the understanding that the further you project out, the more uncertain you will be.  This is the whole point of rolling forecasts.  You can update the forecasts as you have new information, and you are not stuck with massive under or overestimation on a 12 month forecast because you aren&rsquo;t held to those numbers.  If you can&rsquo;t accurately estimate a number for the next month, and there is plenty of historical data and context, then that is another problem entirely, but in a startup which has many product changes launching in parallel and many additional business development activities, 12 months is simply too long of a time horizon to make any sort of reasonable forecast for some things.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>There&rsquo;s no question that forecasting and budgeting are here to stay, at least for now.  There&rsquo;s a craving for certainty in business as in life, and a concrete desire for investors to truly understand the risks which might befall the companies in their portfolios.  While this might make sense in larger companies which are very stable, the companies with the greatest promise for growth are also precisely those which are not amenable to accurate forecasting, and for precisely that reason.  The growth potential is high, but the variability in possible outcomes is equally high.  Especially in these cases, when the difference between forecast accuracy at 3 months and 12 months is so massive, it only makes sense to focus on rolling forecasts at short intervals instead of making budget commitments at longer ones.</p>
<p>This is not to say that plans should not be made.  In fact, quite the opposite.  Plans should be drawn up and contingency plans made as well.  General Eisenhower said it best.</p>
<blockquote>
<p>Plans are nothing; planning is everything.</p>
<p>&ndash; General Dwight D. Eisenhower</p>
</blockquote>
<p>So yes, make plans, but <strong>do not expect everything to go as planned</strong>.  Additionally, if you require your people to make a forecast or budget, and they will be penalized for not meeting the forecast, then they will always try to play things safe and intentionally provide low numbers and behave conservatively.  They will focus on avoiding risks instead of pursuing rewards.  In some businesses conservative behavior might be desired, though hopefully not encouraged via arcane budgeting exercises, while in others there is an insatiable craving for innovation.  If you want innovation, you can&rsquo;t require someone to build a business case with 5 years of forecasts for something that doesn&rsquo;t even exist yet.  If those numbers are ever achieved then it will be purely by chance.</p>
<p>The better strategy is to create an organization which can adapt to the changes it encounters and which is robust to changes in market conditions, revenue, and other factors.  There are simply some things which cannot be predicted to a satisfactory level of certainty.  If you are including the variance along with your forecasts, as you should be, then it may be the case that the variance is too high for the forecasts to be useful.  At that point you must either confront the truth that the future is less certain than you want it to be, and plan accordingly, or you can live in denial and instead treat forecasts like concrete predictions of the future.</p>
 ]]></content:encoded></item><item><title>Leadership and Communication</title><link>https://adamdrake.com/leadership-and-communication.html</link><pubDate>Thu, 19 Jan 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/leadership-and-communication.html</guid><description>&lt;p>Good leadership is hard to quantify, especially when considering intrinsic qualities like humility (which I argue is the most important quality of all). However, there are external skills which can separate effective and ineffective leaders, and communication is arguably the most fundamental of those externally-visible skills.&lt;/p>
&lt;p>When a company is small, and everyone fits in a single room, then a shared vision can almost be maintained by osmosis. Additionally, at this stage a company is usually extremely focused on a narrow goal or set of goals, so there is clarity not only due to small company sizes having more efficient communication, but also because the set of objectives is small as well.&lt;/p></description><content:encoded><![CDATA[ <p>Good leadership is hard to quantify, especially when considering intrinsic qualities like humility (which I argue is the most important quality of all).  However, there are external skills which can separate effective and ineffective leaders, and communication is arguably the most fundamental of those externally-visible skills.</p>
<p>When a company is small, and everyone fits in a single room, then a shared vision can almost be maintained by osmosis.  Additionally, at this stage a company is usually extremely focused on a narrow goal or set of goals, so there is clarity not only due to small company sizes having more efficient communication, but also because the set of objectives is small as well.</p>
<p>When working with growth-stage companies, perhaps the biggest difficulty which invariably arises is the need to maintain clarity of vision and to maintain a common understanding of the mission of the organization as the team grows.  If this understanding is not shared across the business, the business will fail.</p>
<p>The failure mode of inadequate communication from higher leadership often manifests as general confusion about purpose, frustration with seemingly constant &ldquo;changes from management&rdquo; and a lack of progress towards what the executive level sees as the company objectives.  There may be a lot of great work being done, and a lot of great progress being made, but that work and progress may be in many different directions instead of a single mutually-supported one.</p>
<p>When that happens, the fact is that the executives are not communicating effectively as leaders, and they are not ensuring that their subordinate leadership is doing the same.</p>
<p>As an organization grows, more attention must be paid to the structure and content of communication in order to ensure it is simple and easy to remember.  Any complicated messaging will soon be forgotten by others, or worse will be labeled as useless management-speak and will cause frustration, resentment, and further feelings that management is detached from the employees.</p>
<p>The usual way that executives pose this problem to me is to ask how to maintain common understanding as the organization grows.  They are already experiencing some of the failure modes listed above, and the executive level often feels frustrated and may even claim that &ldquo;people just aren&rsquo;t doing what they&rsquo;re told.&rdquo;  The answer to their question is that the bigger an organization becomes, the simpler and more clear the communication must be.</p>

<h1 id="as-simple-as-possible-as-detailed-as-necessary" class="anchor-link"><a href="#as-simple-as-possible-as-detailed-as-necessary">As simple as possible, as detailed as necessary</a></h1>
<p>General George S. Patton Jr. was one of the most well-known commanders of World War II, and as Commanding General of the Third Army, he was responsible for hundreds of thousands of people in his organization.  He was well-versed in the need for clear and easily understandable communication to his subordinate leadership.  Here are some examples from his <strong>Letter of Instruction 1</strong> dated 6 March 1944 and sent to what would in businesses terms be called his middle management.</p>
<p>When discussing visits by officers to other levels of the organization:</p>
<blockquote>
<p>The function of these staff officers is to observe, not to meddle. In addition to their own specialty, they must observe and report anything of military importance. Remember, too, that your primary mission as a leader is to see with your own eyes and to be seen by the troops while engaged in personal reconnaissance.</p>
</blockquote>
<p>When discussing rest and rotations:</p>
<blockquote>
<p>Staff personnel, commissioned and enlisted, who do not rest, do not last. All sections must run a duty roster and enforce compliance. The intensity of staff operations during battle is periodic. At the Army and Corps levels the busiest times are the periods from one to three hours after daylight, and from three to five hours after dark. In the lower echelons and in the administrative and supply staffs, the time of the periods is different but just as definite. When the need arises, everyone must work all the time, but these emergencies are not frequent; &ldquo;unfatigued men last longer and work better at high pressure.&rdquo;</p>
</blockquote>
<p>That is a very clear communication of Patton&rsquo;s expectations for his subordinate leadership.  If you were part of his organization, there would be no question as to whether or not you should make sure your people have proper rest and to what extent they should be worked.</p>
<p>You could do a bit of rewording and the same guidance would equally apply to many tech companies.  How many expect entire tech teams or engineering departments to be on-call at all times?  How many have no on-call rotation or roster to speak of?</p>
<p>On planning:</p>
<blockquote>
<p>Plans must be simple and flexible. Actually they only form a datum plane from which you build as necessity directs or opportunity offers. They should be made by the people who are going to execute them.</p>
</blockquote>
<p>This is clear and easy to understand.  Every subordinate leader who received the letter would know that they should not be making detailed plans.  The people who execute the plan should make the plan, and it is the job of the leader to provide the context and constraints for the plan.  Which leads to the topic of orders.</p>
<blockquote>
<p>Formal orders will be preceded by letters of instruction and by personal conferences. In this way the whole purpose of the operation will be made clear, together with the mission to be accomplished by each major unit. In this way, if communication breaks down during combat, each commander can and must so act as to attain the general objective. The order itself will be short, accompanied by a sketch &ndash; it tells WHAT to do, not HOW. It is really a memorandum and an assumption of responsibility by the issuing commander.</p>
</blockquote>
<p>In other words, people should have a good understanding of the overall situation and context before any direction is given, and even then, the order should be short and should only describe <strong>WHAT</strong> needs to be done, but not <strong>HOW</strong> it should be done.  Leaders provide the what, and the team doing the work provides options for the how.</p>
<p>Perhaps the most succinct guidance is contained in section 7, the final one of the letter.</p>
<blockquote>
<ol start="7">
<li>COURAGE</li>
</ol>
<p>DO NOT TAKE COUNSEL OF YOUR FEARS.</p>
</blockquote>

<h1 id="where-to-start" class="anchor-link"><a href="#where-to-start">Where to start</a></h1>
<p>So we have some examples of a leader, who is responsible for a massive organization of around 250,000 people, and how they communicated their vision to their subordinate leadership.  How can you translate this into your organization and what are some ways you can determine whether or not the communication is clear enough?</p>
<p>Whenever I&rsquo;m talking with anyone at an organization, regardless of their position, I usually ask three questions very early in the conversation in order to help me understand the effectiveness of communication from senior leadership or, in the case of executives, how well they have internalized and can communicate their vision.</p>
<ul>
<li>What is the mission of the company?</li>
<li>Why is that important?</li>
<li>How did the work you are doing today achieve progress towards the mission?</li>
</ul>
<p>It is extremely rare to find people, let alone whole teams, who can answer those three questions.  In the cases where I do encounter people who can answer these questions, I know their leadership is on the right track.</p>
<p>As a good starting point, every person in your team should be able to immediately answer these questions, from memory, because you as a leader were able to provide a clear and simple vision which can be easily memorized.</p>
<p>Making sure everyone understands those questions also forces a leader to consider them and to make sure their direction is focused and clear.  Focus and clarity is like adding fuel to the fire for a growth-stage startup.</p>
 ]]></content:encoded></item><item><title>An Unreasonably Deep Dive into Project Euler Problem 2</title><link>https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-2.html</link><pubDate>Tue, 17 Jan 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-2.html</guid><description>&lt;p>First, the problem definition:&lt;/p>
&lt;blockquote>
&lt;p>Each new term in the Fibonacci sequence is generated by adding the previous two terms. By starting with 1 and 2, the first 10 terms will be:&lt;/p>
&lt;p>1, 2, 3, 5, 8, 13, 21, 34, 55, 89, &amp;hellip;&lt;/p>
&lt;p>By considering the terms in the Fibonacci sequence whose values do not exceed four million, find the sum of the even-valued terms.&lt;/p>
&lt;/blockquote>
&lt;p>Classic Fibonacci problem, with a slight twist due to the summation on top. Spoiler alert: a simple loop is fastest. Keep reading to see why.&lt;/p></description><content:encoded><![CDATA[ <p>First, the problem definition:</p>
<blockquote>
<p>Each new term in the Fibonacci sequence is generated by adding the previous two terms. By starting with 1 and 2, the first 10 terms will be:</p>
<p>1, 2, 3, 5, 8, 13, 21, 34, 55, 89, &hellip;</p>
<p>By considering the terms in the Fibonacci sequence whose values do not exceed four million, find the sum of the even-valued terms.</p>
</blockquote>
<p>Classic Fibonacci problem, with a slight twist due to the summation on top.  Spoiler alert: a simple loop is fastest.  Keep reading to see why.</p>

<h1 id="first-attempt-recursion" class="anchor-link"><a href="#first-attempt-recursion">First Attempt: Recursion</a></h1>
<p>The Fibonacci sequence is defined as f(n) = f(n-1) + f(n-2) where the first two elements are defined in this problem as f(1) = 1 and f(2) = 2.</p>
<p>This means</p>
<p>f(3) = f(2) + f(1) = 2 + 1 = 3,</p>
<p>f(4) = f(3) + f(2) = 3 + 2 = 5,</p>
<p>and so on.</p>
<p>This recursive definition translates easily into most programming languages although, as we&rsquo;ll see, the performance isn&rsquo;t the best.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">fibsRecursion</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">limit</span> <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">2</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">limit</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">fibsRecursion</span>(<span style="color:#a6e22e">limit</span><span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">+</span> <span style="color:#a6e22e">fibsRecursion</span>(<span style="color:#a6e22e">limit</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>This function takes an input <code>limit</code> and will generate the nth Fibonacci number.  The function alone doesn&rsquo;t solve our problem, because we still need to calculate the whole sequence of numbers, check if each is even, and add the even ones to the sum.  We can wrap that functionality in a small <code>for</code> loop.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">sumEvenFibsRecursion</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">sum</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">next</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">1</span>; <span style="color:#a6e22e">next</span> &lt; <span style="color:#a6e22e">limit</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">next</span> = <span style="color:#a6e22e">fibsRecursion</span>(<span style="color:#a6e22e">i</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">next</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">sum</span> <span style="color:#f92672">+=</span> <span style="color:#a6e22e">next</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">sum</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Where <code>isEven</code> is a small helper function to cut down on typing.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">x</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">x</span>), <span style="color:#ae81ff">2</span>) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Ok, now we can calculate Fibonacci numbers, iterate up to a limit, check if they are even, and sum them.  There are also tests and a benchmark, for completeness.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">main</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> <span style="color:#e6db74">&#34;testing&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">LIMIT</span> <span style="color:#66d9ef">int</span> = <span style="color:#ae81ff">3999999</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">SUM_LIMIT</span> <span style="color:#66d9ef">int</span> = <span style="color:#ae81ff">4613732</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestIsEven</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> (<span style="color:#a6e22e">isEven</span>(<span style="color:#ae81ff">4</span>) <span style="color:#f92672">!=</span> <span style="color:#66d9ef">true</span>) <span style="color:#f92672">||</span> (<span style="color:#a6e22e">isEven</span>(<span style="color:#ae81ff">3</span>) <span style="color:#f92672">!=</span> <span style="color:#66d9ef">false</span>) {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;isEven returned incorrect value&#34;</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestFibsRecursion</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">firstTen</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">int</span>{<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">13</span>, <span style="color:#ae81ff">21</span>, <span style="color:#ae81ff">34</span>, <span style="color:#ae81ff">55</span>, <span style="color:#ae81ff">89</span>}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">firstTen</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">fib</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">fibsRecursion</span>(<span style="color:#a6e22e">i</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">fib</span> <span style="color:#f92672">!=</span> <span style="color:#a6e22e">v</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;recursion gave&#34;</span>, <span style="color:#a6e22e">fib</span>, <span style="color:#e6db74">&#34;want&#34;</span>, <span style="color:#a6e22e">v</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestSumEvenFibsRecursion</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">result</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">sumEvenFibsRecursion</span>(<span style="color:#a6e22e">LIMIT</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">result</span> <span style="color:#f92672">!=</span> <span style="color:#a6e22e">SUM_LIMIT</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;wanted&#34;</span>, <span style="color:#a6e22e">SUM_LIMIT</span>, <span style="color:#e6db74">&#34;got&#34;</span>, <span style="color:#a6e22e">result</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">BenchmarkSumEvenFibsRecursion</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">sumEvenFibsRecursion</span>(<span style="color:#a6e22e">LIMIT</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We can run the tests and see that everything passes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#f92672">===</span> RUN   TestIsEven
</span></span><span style="display:flex;"><span>--- PASS: TestIsEven <span style="color:#f92672">(</span>0.00s<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">===</span> RUN   TestFibsRecursion
</span></span><span style="display:flex;"><span>--- PASS: TestFibsRecursion <span style="color:#f92672">(</span>0.00s<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">===</span> RUN   TestSumEvenFibsRecursion
</span></span><span style="display:flex;"><span>--- PASS: TestSumEvenFibsRecursion <span style="color:#f92672">(</span>0.05s<span style="color:#f92672">)</span>
</span></span></code></pre></div><p>Now on to the benchmark so we can look at the performance characteristics of this approach.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>BenchmarkSumEvenFibsRecursion-4               <span style="color:#ae81ff">30</span>          <span style="color:#ae81ff">46091679</span> ns/op
</span></span></code></pre></div><p>That is extremely slow, as expected.  The recursive approach is doing a ton of unnecessary work.  Additionally, <a href="https://en.wikipedia.org/wiki/Tail_call">tail-call optimization</a> is not always supported in Go, at least there was no <a href="https://groups.google.com/forum/#!msg/golang-nuts/0oIZPHhrDzY/2nCpUZDKZAAJ">plan to implement TCO more broadly</a>, which also can result in memory usage or performance characteristics that are difficult to analyze or plan for.</p>
<p>From a time and space complexity perspective, we can think of the space complexity first.  There will be a function call, recursively, for each Fibonacci number calculated.  So if we want the first 5 numbers, we&rsquo;ll have 5 function calls on the stack.  The depth of the stack is <code>O(n)</code> and memory requirement will be <code>N * frameSize</code>, where frameSize is the size of the frame inserted into the stack with each function call.</p>
<p>On the time complexity side, the short version is the bound on time complexity is <code>O(2^n)</code>.</p>
<p>The slightly longer version is that the tight bound is <code>O(Phi^n)</code> where <code>Phi</code> is the so-called <em>golden ratio</em> 1.618&hellip; and <code>n</code> is the nth Fibonacci number.  In other words, it&rsquo;s still exponential but with a slightly smaller base.  To see why, consider that the recurrence relation use to generate the sequence is proportional to the time complexity required to calculated it.  At that point you can use the closed-form approximation for the Fibonacci sequence numbers themselves.  Since the numbers in the sequence grow as <code>O(Phi)</code> then the time complexity grows that way too.</p>

<h1 id="second-attempt-iteration" class="anchor-link"><a href="#second-attempt-iteration">Second Attempt: Iteration</a></h1>
<p>In the recursive case, we were recalculating the Fibonacci numbers all the time, which leads to a lot of wasted computation.  Consider that for computing <code>F(4)</code> (the fourth Fibonacci number) we would compute <code>F(3) + F(2) + F(1)</code>, but we already have <code>F(2) and F(1)</code> when we computed <code>F(3)</code>, so why computer them again?  Instead of starting from a limit and calling functions all the way down as our recursive function did, we can simply build up the list of Fibonacci numbers from the bottom.  This allows us to use numbers already calculated to calculate the next number in the sequence.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">sumEvenFibsSlice</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fibs</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">int</span>{<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">newElement</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">2</span>; <span style="color:#a6e22e">newElement</span> &lt; <span style="color:#a6e22e">limit</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">newElement</span> = <span style="color:#a6e22e">fibs</span>[<span style="color:#a6e22e">i</span><span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> <span style="color:#a6e22e">fibs</span>[<span style="color:#a6e22e">i</span><span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>]
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">fibs</span> = append(<span style="color:#a6e22e">fibs</span>, <span style="color:#a6e22e">newElement</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">sumEvens</span>(<span style="color:#a6e22e">fibs</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>In this example, we start with a slice that has the first two numbers as given in the problem, and then appends the remaining numbers onto the slice until the new element in the sequence is greater than or equal to the limit, at which point we return the sum of the even numbers in the slice.</p>
<p>We can write the test and benchmark code as before.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestSumEvenFibsSlice</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">sumEvenFibsSlice</span>(<span style="color:#a6e22e">LIMIT</span>) <span style="color:#f92672">!=</span> <span style="color:#a6e22e">SUM_LIMIT</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;&#34;</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">BenchmarkSumEvenFibsSlice</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">sumEvenFibsSlice</span>(<span style="color:#a6e22e">LIMIT</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Which gives us passing tests and a new benchmark number.</p>
<pre tabindex="0"><code>BenchmarkSumEvenFibsSlice-4               200000              6210 ns/op
</code></pre><p>This is a faster approach compared to the recursive solution, by a lot.  In fact the recursive solution takes about 7400 times longer, so we&rsquo;re on the right track.</p>
<p>Now that we have an iterative solution, many newcomers to Go will think that it makes sense to spin off a thread/goroutine to do the calculations and pass the results back over a channel for our function to use.</p>

<h1 id="winner-a-simple-loop" class="anchor-link"><a href="#winner-a-simple-loop">Winner: a simple loop</a></h1>
<p>Slices perform acceptably, but they&rsquo;re still relatively slow.  We can do better by using a simple loop and accumulating our sum along the way.  The code starts index <code>i</code> and <code>j</code> at 1, and adds and swaps them until the limit is reached.  The benefit of this approach is that we are only using a few integer values, and we are only iterating until we reach the limit, so this approach is linear for our values.</p>
<p><strong>NOTE</strong> that there is a caveat here as we are dealing with values which fit into a normal <code>int</code> type in Go.  If the integers become too big and we need to use arbitrarily-large integers, we will have different performance characteristics.  For our purposes though, the simple looping approach has <code>O(n)</code> time complexity.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">sumEvenFibsLoop</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">sum</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">j</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>; <span style="color:#a6e22e">j</span> &lt; <span style="color:#a6e22e">limit</span>; <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">j</span> = <span style="color:#a6e22e">i</span><span style="color:#f92672">+</span><span style="color:#a6e22e">j</span>, <span style="color:#a6e22e">i</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">i</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">sum</span> <span style="color:#f92672">+=</span> <span style="color:#a6e22e">i</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">sum</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Test and benchmark:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestSumEvenFibsLoop</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">sumEvenFibsLoop</span>(<span style="color:#a6e22e">LIMIT</span>) <span style="color:#f92672">!=</span> <span style="color:#a6e22e">SUM_LIMIT</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;sumevenfibloop&#34;</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">BenchmarkSumEvenFibsLoop</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">sumEvenFibsLoop</span>(<span style="color:#a6e22e">LIMIT</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><pre tabindex="0"><code>BenchmarkSumEvenFibsLoop-4                300000              5535 ns/op
</code></pre><p>The performance of this approach is the best so far, but just barely.  It outperforms the slice approach, but not by much.</p>

<h1 id="digression-channels" class="anchor-link"><a href="#digression-channels">Digression: Channels</a></h1>
<p>A common thing newcomers do when they pick up Go is they reach for channels and goroutines.  Although these are awesome tools and it&rsquo;s great they are so easy to use in the language, they aren&rsquo;t always good for performance.  The short reason is that channels are essentially a mutable data structure, and therefore require locks.  Locks are an enemy of performance, so in many tasks you will slow down your computations if you use channels and goroutines.</p>
<p>For example, we can use the standard approach of creating a function which returns a channel of values.  We&rsquo;ll drop our iterative solution from before into a function which is spun off as its own goroutine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">fibsChannel</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">chan</span> <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">output</span> <span style="color:#f92672">:=</span> make(<span style="color:#66d9ef">chan</span> <span style="color:#66d9ef">int</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">go</span> <span style="color:#66d9ef">func</span>() {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">defer</span> close(<span style="color:#a6e22e">output</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">j</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>; <span style="color:#a6e22e">j</span> &lt; <span style="color:#a6e22e">limit</span>; <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">j</span> = <span style="color:#a6e22e">i</span><span style="color:#f92672">+</span><span style="color:#a6e22e">j</span>, <span style="color:#a6e22e">i</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">output</span> <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">i</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}()
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">output</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We can use this for our specific problem in the following way.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">sumEvenFibsChannel</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">sum</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fibs</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">fibsChannel</span>(<span style="color:#a6e22e">limit</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">f</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">fibs</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">f</span>) {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">sum</span> <span style="color:#f92672">+=</span> <span style="color:#a6e22e">f</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">sum</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>along with the accompanying tests and benchmarks.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestFibsChannel</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">firstTen</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">int</span>{<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">13</span>, <span style="color:#ae81ff">21</span>, <span style="color:#ae81ff">34</span>, <span style="color:#ae81ff">55</span>, <span style="color:#ae81ff">89</span>}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fibs</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">fibsChannel</span>(<span style="color:#ae81ff">90</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">_</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">firstTen</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">chanVal</span> <span style="color:#f92672">:=</span> <span style="color:#f92672">&lt;-</span><span style="color:#a6e22e">fibs</span>
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">v</span> <span style="color:#f92672">!=</span> <span style="color:#a6e22e">chanVal</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;fibChannel incorrect.  Expected&#34;</span>, <span style="color:#a6e22e">v</span>, <span style="color:#e6db74">&#34;but received&#34;</span>, <span style="color:#a6e22e">chanVal</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestSumEvenFibsChannel</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">sumEvenFibsChannel</span>(<span style="color:#a6e22e">LIMIT</span>) <span style="color:#f92672">!=</span> <span style="color:#a6e22e">SUM_LIMIT</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;&#34;</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">BenchmarkSumEvenFibsChannel</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">sumEvenFibsChannel</span>(<span style="color:#a6e22e">LIMIT</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>All the tests pass, and we can get a look at the performance of the channels approach.</p>
<pre tabindex="0"><code>BenchmarkSumEvenFibsChannel-4             100000             18677 ns/op
</code></pre><p>At 18,677 ns/op the channels approach takes around 3 times as long as the slices approach, and about 3.4 times as long as the simple loop, so although channels and goroutines are a wonderful part of the language, they are not a good fit for all problems.</p>

<h1 id="digression-solution-by-approximation" class="anchor-link"><a href="#digression-solution-by-approximation">Digression: Solution by approximation</a></h1>
<p>It was briefly mentioned earlier that the runtime complexity of the recursive solution is <code>O(Phi^n)</code> where <code>Phi</code> is the <a href="https://en.wikipedia.org/wiki/Golden_ratio#Relationship_to_Fibonacci_sequence">Golden Ratio</a>.  With some further analysis you can show that the Nth Fibonacci number can be approximated by <code>1/sqrt(5) * Phi^(n+1)</code>.  We can use this method to generate our Fibonacci numbers as well.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">fibApprox</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fib</span> <span style="color:#f92672">:=</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">/</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Sqrt</span>(<span style="color:#ae81ff">5</span>)) <span style="color:#f92672">*</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Pow</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Phi</span>, float64(<span style="color:#a6e22e">n</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> int(<span style="color:#a6e22e">fib</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.5</span>) <span style="color:#75715e">//  BUG: This only works for postive numbers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestFibApprox</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">firstTen</span> <span style="color:#f92672">:=</span> []<span style="color:#66d9ef">int</span>{<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">13</span>, <span style="color:#ae81ff">21</span>, <span style="color:#ae81ff">34</span>, <span style="color:#ae81ff">55</span>, <span style="color:#ae81ff">89</span>}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">v</span> <span style="color:#f92672">:=</span> <span style="color:#66d9ef">range</span> <span style="color:#a6e22e">firstTen</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">fib</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">fibApprox</span>(<span style="color:#a6e22e">i</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">fib</span> <span style="color:#f92672">!=</span> <span style="color:#a6e22e">v</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;got&#34;</span>, <span style="color:#a6e22e">fib</span>, <span style="color:#e6db74">&#34;want&#34;</span>, <span style="color:#a6e22e">v</span>)
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestSumEvenFibsApprox</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">sumEvenFibsApprox</span>(<span style="color:#a6e22e">LIMIT</span>) <span style="color:#f92672">!=</span> <span style="color:#a6e22e">SUM_LIMIT</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;&#34;</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">BenchmarkSumEvenFibsApprox</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">sumEvenFibsApprox</span>(<span style="color:#a6e22e">LIMIT</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>However, although we have a closed-form solution it is not yet faster than our simple loop implementation.</p>
<pre tabindex="0"><code>BenchmarkSumEvenFibsApprox-4              200000              7769 ns/op
</code></pre><p>Part of the reason for this is because for the numbers we&rsquo;re dealing with, which fit into 64 bit integers, the simple loop has an apparently linear time complexity.  However, once we get into arbitrarily large numbers and need something from <code>math/big</code> then we won&rsquo;t have the same performance characteristics and the closed-form solution may be faster, even though it does contain exponentiation.  Recall that <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring">exponentiation by squaring</a> has a computational complexity of about <code>O(log n)</code>.</p>

<h1 id="bonus-round-bitwise-and-for-evenodd-checking" class="anchor-link"><a href="#bonus-round-bitwise-and-for-evenodd-checking">Bonus Round: Bitwise and for even/odd checking</a></h1>
<p>Although the fastest approach we tested was the simple loop, we were still using the <code>isEven()</code> function, which used modular arithmetic to tell us if the integer was even or not.  I also wanted to check to see if there would be a significant speedup from switching to <a href="https://en.wikipedia.org/wiki/Bitwise_operation#AND">bitwise operations</a> to check the <a href="https://en.wikipedia.org/wiki/Parity_(mathematics)">parity</a> of the numbers.</p>
<p>The short version is that replacing the <code>math.Mod()</code> call with a bitwise <code>and</code>, we can determine the parity of the number in a much more computationally-efficient way.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">isEven</span>(<span style="color:#a6e22e">x</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">bool</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">x</span><span style="color:#f92672">&amp;</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>I had benchmarks for <code>isEven()</code> before and after.</p>
<p>Before:</p>
<pre tabindex="0"><code>BenchmarkIsEvenEven-4                   30000000                43.5 ns/op
BenchmarkIsEvenOdd-4                    30000000                44.8 ns/op
</code></pre><p>After:</p>
<pre tabindex="0"><code>BenchmarkIsEvenEven-4                   2000000000               0.34 ns/op
BenchmarkIsEvenOdd-4                    2000000000               0.34 ns/op
</code></pre><p>This is a performance improvement of <strong>130 times</strong>.</p>
<p>When we use this bitwise version for the parity checking in the other algorithms, we see the expected speedups.</p>
<pre tabindex="0"><code>BenchmarkSumEvenFibsSlice-4              3000000               455 ns/op
BenchmarkSumEvenFibsRecursion-4               30          46208502 ns/op
BenchmarkSumEvenFibsLoop-4              30000000                49.7 ns/op
BenchmarkSumEvenFibsChannel-4             100000             11670 ns/op
BenchmarkSumEvenFibsApprox-4             1000000              1766 ns/op
</code></pre><p>If we wanted to further speed up the simple loop, we could remove the overhead of the function call to <code>isEven()</code> and inline the bitwise and.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">sumEvenFibsLoop</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">sum</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">j</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>; <span style="color:#a6e22e">j</span> &lt; <span style="color:#a6e22e">limit</span>; <span style="color:#a6e22e">i</span>, <span style="color:#a6e22e">j</span> = <span style="color:#a6e22e">i</span><span style="color:#f92672">+</span><span style="color:#a6e22e">j</span>, <span style="color:#a6e22e">i</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">i</span><span style="color:#f92672">&amp;</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">sum</span> <span style="color:#f92672">+=</span> <span style="color:#a6e22e">i</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">sum</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Which cuts off a bit more time, about 11%.</p>
<pre tabindex="0"><code>BenchmarkSumEvenFibsLoop-4      30000000                44.0 ns/op
</code></pre>
<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>Project Euler problems, in addition to fun programming exercises, can be great ways to refresh mathematics and computer science skills you may have forgotten or may not have used in a while.  For this problem alone we got into time and memory complexity, recurence relations, recursion, channels and goroutines, bitwise operations, and testing and benchmarking in Go.</p>
<p>We could have gone further down the rabbit hole, especially on the mathematics side of things, but then it would be <a href="https://en.wikipedia.org/wiki/Turtles_all_the_way_down">turtles all the way down</a> and we wouldn&rsquo;t be able to move on to other problems.</p>
 ]]></content:encoded></item><item><title>An Unreasonably Deep Dive into Project Euler Problem 1</title><link>https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-1.html</link><pubDate>Wed, 04 Jan 2017 00:00:00 +0000</pubDate><guid>https://adamdrake.com/an-unreasonably-deep-dive-into-project-euler-problem-1.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>As part of my work in keeping my technical skills sharp, I periodically go back to basics or solve old problems again in order to ensure my foundations are strong. So it was with great fun that I decided to start back at the beginning with &lt;a href="https://projecteuler.net">Project Euler&lt;/a>.&lt;/p>
&lt;p>One of the techniques I also use for this sort of thing is not just to solve the problem, but to really explore it. Write additional code, tests, benchmarks, and explore the underlying mathematics where practical.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>As part of my work in keeping my technical skills sharp, I periodically go back to basics or solve old problems again in order to ensure my foundations are strong.  So it was with great fun that I decided to start back at the beginning with <a href="https://projecteuler.net">Project Euler</a>.</p>
<p>One of the techniques I also use for this sort of thing is not just to solve the problem, but to really explore it.  Write additional code, tests, benchmarks, and explore the underlying mathematics where practical.</p>
<p>With that in mind, here is a deep dive into <a href="https://projecteuler.net/problem=1">Project Euler - Problem 1</a>.</p>

<h1 id="overview" class="anchor-link"><a href="#overview">Overview</a></h1>
<p>The problem is short and easy to understand:</p>
<blockquote>
<p>If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9. The sum of these multiples is 23.  Find the sum of all the multiples of 3 or 5 below 1000.</p>
</blockquote>
<p>A simple brute-force approach to this is simply to iterate through all of the numbers from 1 to 999 (since we are only to check numbers below 1000), check if the number is divisible by 3 or 5, and sum the ones which are.</p>
<p>If you want the Python one-liner:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span>sum([x <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1000</span>) <span style="color:#66d9ef">if</span> ((x <span style="color:#f92672">%</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>) <span style="color:#f92672">or</span> (x <span style="color:#f92672">%</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>))])
</span></span></code></pre></div><p>Of if you are using Go, as I was:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Go" data-lang="Go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">bruteForce</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">total</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> <span style="color:#f92672">&lt;=</span> <span style="color:#a6e22e">limit</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">i</span>), <span style="color:#ae81ff">5</span>) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">||</span> <span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Mod</span>(float64(<span style="color:#a6e22e">i</span>), <span style="color:#ae81ff">3</span>) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> {
</span></span><span style="display:flex;"><span>			<span style="color:#a6e22e">total</span> <span style="color:#f92672">+=</span> <span style="color:#a6e22e">i</span>
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#a6e22e">total</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>
<h1 id="does-it-work" class="anchor-link"><a href="#does-it-work">Does it work?</a></h1>
<p>This works fine and both produce the required answer of 233168, which we can verify with some tests in Go:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Go" data-lang="Go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestBruteForce</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">bruteForce</span>(<span style="color:#ae81ff">9</span>) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">23</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;The sum of values from 1 to 10 which are divisible by 5 and 3 should be 23&#34;</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">bruteForce</span>(<span style="color:#ae81ff">999</span>) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">233168</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;The sum of values from 1 to 1000 which are divisible by 5 and 3 should be 233168&#34;</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>And we can run the tests to ensure that everything passes and is working normally.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>go test -v
</span></span><span style="display:flex;"><span><span style="color:#f92672">===</span> RUN   TestBruteForce
</span></span><span style="display:flex;"><span>--- PASS: TestBruteForce <span style="color:#f92672">(</span>0.00s<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>PASS
</span></span><span style="display:flex;"><span>ok      _path/...     0.008s
</span></span></code></pre></div>
<h1 id="how-fast-is-it" class="anchor-link"><a href="#how-fast-is-it">How fast is it?</a></h1>
<p>This is enough for a working solution, and it isn&rsquo;t too slow, but it&rsquo;s not great as we can see by the built-in benchmark capabilities in Go.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Go" data-lang="Go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">BenchmarkBruteForce</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">bruteForce</span>(<span style="color:#ae81ff">999</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>A benchmark function takes a <code>*testing.B</code> and iterates up to <code>b.N</code>, which is a number defined by the package and dependent on the stability of the timing of your function call, and produces output telling you how many times the function was run in order to perform the benchmark provide the required execution time per call.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>go test -bench .
</span></span><span style="display:flex;"><span>BenchmarkBruteForce-4              <span style="color:#ae81ff">10000</span>            <span style="color:#ae81ff">227761</span> ns/op
</span></span></code></pre></div><p>So our brute force approach took 10000 iterations to settle on a timing of 227,761 nanoseconds per operation.</p>
<p>Now we have not only solved the problem, but added tests and benchmarks.  Perhaps a bit more effort than some people put into Project Euler, but not bad.  However, this solution is still linear in the number of elements we have to check.  In other words, if we wanted to check the numbers up to 1,000,000 instead of only up to 1,000 then the solution would take much longer to run.  This solution is O(n) which isn&rsquo;t bad, but isn&rsquo;t great either.  We check the increase in runtime by simply modifying the argument in our benchmark function.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Go" data-lang="Go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">BenchmarkBruteForce</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">bruteForce</span>(<span style="color:#ae81ff">1000000</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Now we will have different timing and benchmark information.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>go test -bench .
</span></span><span style="display:flex;"><span>BenchmarkBruteForce-4                  <span style="color:#ae81ff">3</span>         <span style="color:#ae81ff">441286594</span> ns/op
</span></span></code></pre></div><p>So by increasing the numbers we have to check by a factor of 1000, we now have a runtime of 441,286,594 ns/op instead of 227,761 ns/op, which is an increase of about 1900x.  Not good.  For more on asymptotic analysis of runtime, check out the Wikipedia article on <a href="https://en.wikipedia.org/wiki/Big_O_notation">Big O Notation</a>.</p>

<h1 id="performance-upgrades" class="anchor-link"><a href="#performance-upgrades">Performance upgrades</a></h1>
<p>There are some options to improve the performance, like splitting the range of numbers into parts and spawning multiple worker threads to check each part, thereby parallelizing the work.  This is a lot of complexity though, especially when you want to make sure that ranges checked don&rsquo;t overlap, managing potential shared state, and so on.  If we think a bit more about the problem, there is a better way.</p>
<p>We want to sum all the multiples of 3 or 5 less than 1000.  We can think about the sequence of multiples of 3 as (3, 6, 9, 12, 15, &hellip;, 999), which is the same as 3 * (1, 2, 3, 4, 5, &hellip;, 333).  We can do the same for the case of multiples of 5.  The benefit of considering the problem in this way is that the list of numbers has a closed-form solution (i.e., a formula) for calculating the sum.</p>
<p>Such a sequence, where the difference between each number is constant, is called a <a href="https://en.wikipedia.org/wiki/Arithmetic_progression">finite arithmetic progression</a> or finite arithmetic sequence and the sum of a finite arithmetic progression is called a finite arithmetic series.  The formula for the sum is <code>1/2 * n * (a_1 + a_n)</code>. where <code>n</code> is the number of terms being added, <code>a_1</code> is the first element in the sequence, and <code>a_n</code> is the last element in the sequence.</p>
<p>From our example for multiples of 3, we know that <code>a_1 = 1</code> and we know that <code>a_n = floor(999/3) = 333</code> and we also know that the total number of elements in the sequence will be <code>n = floor(999/3) = 333 = a_n</code>.  So for our purposes, the sum of our sequences is equal to <code>n * (n + 1) * 0.5</code>.  We can make a small helper function to calculate this for us.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">arithSum</span>(<span style="color:#a6e22e">n</span> <span style="color:#66d9ef">float64</span>) <span style="color:#66d9ef">float64</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> (<span style="color:#a6e22e">n</span> <span style="color:#f92672">*</span> (<span style="color:#a6e22e">n</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)) <span style="color:#f92672">/</span> <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Now we can simply compute the sum of the arithmetic sequence for all the multiples of 3 and 5 without iterating through anything at all.  Since we already know the answers to the questions from the brute force case, we can also write the appropriate tests.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">TestArithSeq</span>(<span style="color:#a6e22e">t</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">T</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">arithSeq</span>(<span style="color:#ae81ff">9</span>) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">23</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;The sum of values from 1 to 10 which are divisible by 5 and 3 should be 23&#34;</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">arithSeq</span>(<span style="color:#ae81ff">999</span>) <span style="color:#f92672">!=</span> <span style="color:#ae81ff">233168</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">t</span>.<span style="color:#a6e22e">Fatal</span>(<span style="color:#e6db74">&#34;The sum of values from 1 to 1000 which are divisible by 5 and 3 should be 233168&#34;</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>For the corresponding function:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Go" data-lang="Go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">arithSeq</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">float64</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">threes</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">*</span> <span style="color:#a6e22e">arithSum</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Floor</span>((<span style="color:#a6e22e">limit</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">3</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fives</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> <span style="color:#a6e22e">arithSum</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Floor</span>((<span style="color:#a6e22e">limit</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> int(<span style="color:#a6e22e">threes</span> <span style="color:#f92672">+</span> <span style="color:#a6e22e">fives</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>But there is a problem because not all of our tests pass.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>go test -v
</span></span><span style="display:flex;"><span><span style="color:#f92672">===</span> RUN   TestArithSeq
</span></span><span style="display:flex;"><span>--- FAIL: TestArithSeq <span style="color:#f92672">(</span>0.00s<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>		0001_test.go:10: The sum of values from <span style="color:#ae81ff">1</span> to <span style="color:#ae81ff">1000</span> which are divisible by <span style="color:#ae81ff">5</span> and <span style="color:#ae81ff">3</span> should be 233168
</span></span><span style="display:flex;"><span><span style="color:#f92672">===</span> RUN   TestBruteForce
</span></span><span style="display:flex;"><span>--- PASS: TestBruteForce <span style="color:#f92672">(</span>0.00s<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>FAIL
</span></span><span style="display:flex;"><span>exit status <span style="color:#ae81ff">1</span>
</span></span></code></pre></div><p>What is the problem?  Why did the test for <code>n = 9</code> pass but the test for <code>n = 999</code> fail?  The answer starts at 15, which is divisible by both 5 <strong>and</strong> 3.  Because we summed all the multiple of 5, and all the multiples of 3, we also summed all the multiples of 15.  In other words, all the multiples of 15 are double counted because we need them to be summed as a multiple of 5, or as a multiple of 3, but not both.  This a common problem in combinatorics, the study of finite or countable discrete structures, and the answer is easily described by the <a href="https://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle">inclusion-exclusion principle</a>.</p>
<p>For some set <code>A</code>, like the set of all multiples of 3, and some set <code>B</code>, like the set of all multiples of 5, then when we add them we have to subtract their interaction because it is counted twice.  In our case, this intersection is the set of all multiples of 15.  So we can get the correct solution by simply removing the sum of all multiples of 15 from our total.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">arithSeq</span>(<span style="color:#a6e22e">limit</span> <span style="color:#66d9ef">float64</span>) <span style="color:#66d9ef">int</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">threes</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">*</span> <span style="color:#a6e22e">arithSum</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Floor</span>(<span style="color:#a6e22e">limit</span><span style="color:#f92672">-/</span><span style="color:#ae81ff">3</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fives</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> <span style="color:#a6e22e">arithSum</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Floor</span>(<span style="color:#a6e22e">limit</span><span style="color:#f92672">/</span><span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">fifteens</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">15</span> <span style="color:#f92672">*</span> <span style="color:#a6e22e">arithSum</span>(<span style="color:#a6e22e">math</span>.<span style="color:#a6e22e">Floor</span>(<span style="color:#a6e22e">limit</span><span style="color:#f92672">/</span><span style="color:#ae81ff">15</span>))
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> int(<span style="color:#a6e22e">threes</span> <span style="color:#f92672">+</span> <span style="color:#a6e22e">fives</span> <span style="color:#f92672">-</span> <span style="color:#a6e22e">fifteens</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Now all of our tests will pass.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>go test -v
</span></span><span style="display:flex;"><span><span style="color:#f92672">===</span> RUN   TestArithSeq
</span></span><span style="display:flex;"><span>--- PASS: TestArithSeq <span style="color:#f92672">(</span>0.00s<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">===</span> RUN   TestBruteForce
</span></span><span style="display:flex;"><span>--- PASS: TestBruteForce <span style="color:#f92672">(</span>0.00s<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>PASS
</span></span></code></pre></div><p>Ok, great.  Now we have another way of solving the problem, but what was the actual speed benefit?  It&rsquo;s pretty dramatic.  First, we need to add a benchmark function to our <code>_test.go</code> file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">BenchmarkArithSeq</span>(<span style="color:#a6e22e">b</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">testing</span>.<span style="color:#a6e22e">B</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> <span style="color:#a6e22e">i</span> <span style="color:#f92672">:=</span> <span style="color:#ae81ff">0</span>; <span style="color:#a6e22e">i</span> &lt; <span style="color:#a6e22e">b</span>.<span style="color:#a6e22e">N</span>; <span style="color:#a6e22e">i</span><span style="color:#f92672">++</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">arithSeq</span>(<span style="color:#ae81ff">999</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Now we can see the difference.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>go test -bench .
</span></span><span style="display:flex;"><span>BenchmarkBruteForce-4              <span style="color:#ae81ff">10000</span>            <span style="color:#ae81ff">227689</span> ns/op
</span></span><span style="display:flex;"><span>BenchmarkArithSeq-4             <span style="color:#ae81ff">100000000</span>               21.8 ns/op
</span></span><span style="display:flex;"><span>PASS
</span></span></code></pre></div><p>Both of those are for the specified Project Euler problem of summing only the multiples below 1000.  In this case, the solution using the arithmetic series approach is about 10,000 times faster than the brute-force approach.</p>
<p>Better still, because the arithmetic series approach requires the same number of operations regardless of the input size, it doesn&rsquo;t matter if we want to do the summation for multiples up to 1000 or 1,000,000 it will always take the same amount of processing time.  So the arithmetic series approach is constant time (also denoted O(1)).  Much better.</p>
<p>There are probably other interesting ways to solve this problem, like finding the prime factors of all the numbers less than <code>n</code> to see if 3 or 5 is one of the factors, but I think this is enough for now.</p>
 ]]></content:encoded></item><item><title>Remembering The Fallen</title><link>https://adamdrake.com/remembering-the-fallen.html</link><pubDate>Thu, 22 Sep 2016 00:00:00 +0000</pubDate><guid>https://adamdrake.com/remembering-the-fallen.html</guid><description>&lt;p>Those that know me are aware that I have always had great respect for people who have served or are serving in the military. I thought it would be a nice project to create a Twitter bot that would tweet, on a given day, all the US Servicemembers killed in action on that day in prior years. You can view it &lt;a href="https://twitter.com/thedailyfallen">on Twitter&lt;/a> or follow @thedailyfallen directly.&lt;/p>
&lt;p>I&amp;rsquo;ve had questions before about simple Data Science, Machine Learning, and software development projects before, so here is a good example of just such a project.&lt;/p></description><content:encoded><![CDATA[ <p>Those that know me are aware that I have always had great respect for people who have served or are serving in the military.  I thought it would be a nice project to create a Twitter bot that would tweet, on a given day, all the US Servicemembers killed in action on that day in prior years.  You can view it <a href="https://twitter.com/thedailyfallen">on Twitter</a> or follow @thedailyfallen directly.</p>
<p>I&rsquo;ve had questions before about simple Data Science, Machine Learning, and software development projects before, so here is a good example of just such a project.</p>
<p>Some people might say there isn&rsquo;t much Data Science going on here.  <strong>FALSE!</strong>  Any experienced Data Science person will tell you that the majority of the work is acquiring, cleaning, and transforming the data.  Often there is little or no actual machine learning happening in a successful Data Science project.  Data Science projects are successful because they make the business more successful.  Sometimes that requires zero machine learning.  In this project, probably 80% to 90% of the time was spent finding, cleaning, and transforming the data, which is par for the course in <strong>ANY</strong> Data Science project in my experience.</p>
<p>Excuse the digression.</p>

<h1 id="acquire-data" class="anchor-link"><a href="#acquire-data">Acquire data</a></h1>
<p>This wasn&rsquo;t as quick as I thought it would be, but it never is.</p>
<p>The Department of Defense website wasn&rsquo;t very helpful, but after some searching I found some suitable data from the <a href="https://catalog.archives.gov/id/4734832">National Archives</a>.</p>
<p>The data is in <em>Defense Casualty Analysis System</em> (DCAS) format, and includes all the service members who have died from 1950 through 2005, with another file containing deaths for 2006.  The files are pipe-delimited and the fields are pretty well documented in the <a href="https://catalog.archives.gov/OpaAPI/media/4734832/content/arcmedia/electronic-records/rg-330/DCAS/DCAS_DOC_PDF.pdf">associated PDF</a>.</p>
<p>They are also very clear on the contents of the file(s):</p>
<blockquote>
<p>This file contains the records of U.S. military personnel casualties for deaths between the years 1950 and 2005, and two records of deaths related to Vietnam that occurred in 2006. The casualties occurred worldwide and resulted from both hostile and non-hostile action. The war or conflict for each casualty is identified as occurring during the Korean War, Vietnam War, Gulf War, War on Terrorism, or Peacetime. Because of the broad nature of the category of Peacetime, several fields further describe those casualties in terms of location, circumstances, category, and reason. Each record includes such information as: the service member&rsquo;s name, service number, service branch, rank, pay grade, occupation, birth date, gender, home of record (city, county, state or province, country), marital status, religion, race, ethnicity, casualty circumstances, casualty location (city, state or province, country or over water), unit, duty, process date, death date, war or conflict, operation incident type, aircraft type, hostile or non-hostile death indicator, casualty type, and casualty category. Since this is the public use version of the file, the service number field is masked.</p>
</blockquote>

<h1 id="clean-and-transform-data" class="anchor-link"><a href="#clean-and-transform-data">Clean and transform data</a></h1>
<p>There were some records with errors in the file, as is nearly always the case, so after taking only the records listed as <code>KILLED IN ACTION</code> I further filtered out the ones where the date of death wasn&rsquo;t 8 characters long since the file represents death date as an 8 character string in <code>yyyymmdd</code> format.</p>
<p>After that it was a matter of constructing the tweet string I wanted, which was a concatenation of rank, name, KILLED IN ACTION, location of death, and year of death.  The month and day are always the same as the current one, only the year is different, so I didn&rsquo;t include it in the tweet text.  Additionally, I split out the day and month of death, so that I could match on it later to get all the records for a particular month and day.</p>
<p>After these steps I simply output the tweet text, day of death, and month of death columns in a new pipe-delimited file.</p>
<p>The preprocessing code is pretty standard fare.  I&rsquo;m sure it can be made cleaner and/or more efficient, but it&rsquo;s not needed for this data set or project.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datetime
</span></span><span style="display:flex;"><span>pd<span style="color:#f92672">.</span>options<span style="color:#f92672">.</span>mode<span style="color:#f92672">.</span>chained_assignment <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;allpuf.dat&#39;</span>, sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;|&#39;</span>, low_memory<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, header<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>kia <span style="color:#f92672">=</span> data[(data[<span style="color:#ae81ff">44</span>] <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;KILLED IN ACTION&#39;</span>)]
</span></span><span style="display:flex;"><span>kia<span style="color:#f92672">.</span>rename(columns<span style="color:#f92672">=</span>{<span style="color:#ae81ff">7</span> : <span style="color:#e6db74">&#39;rank&#39;</span>, <span style="color:#ae81ff">34</span> : <span style="color:#e6db74">&#39;dod&#39;</span>, <span style="color:#ae81ff">35</span> : <span style="color:#e6db74">&#39;yod&#39;</span>, <span style="color:#ae81ff">30</span> : <span style="color:#e6db74">&#39;countryOfDeath&#39;</span>}, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kia[<span style="color:#e6db74">&#39;dod&#39;</span>] <span style="color:#f92672">=</span> kia[<span style="color:#e6db74">&#39;dod&#39;</span>]<span style="color:#f92672">.</span>astype(str)
</span></span><span style="display:flex;"><span>kia[<span style="color:#e6db74">&#39;dodlen&#39;</span>] <span style="color:#f92672">=</span> kia[<span style="color:#e6db74">&#39;dod&#39;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: len(str(x)))
</span></span><span style="display:flex;"><span>kia <span style="color:#f92672">=</span> kia[kia[<span style="color:#e6db74">&#39;dodlen&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">8</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kia[<span style="color:#e6db74">&#39;name&#39;</span>] <span style="color:#f92672">=</span> kia[<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39; &#39;</span>)[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;, &#39;</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(x<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39; &#39;</span>)[<span style="color:#ae81ff">1</span>:]))
</span></span><span style="display:flex;"><span>kia[<span style="color:#e6db74">&#39;yod&#39;</span>] <span style="color:#f92672">=</span> kia[<span style="color:#e6db74">&#39;yod&#39;</span>]<span style="color:#f92672">.</span>astype(str)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kia[<span style="color:#e6db74">&#39;dayDeath&#39;</span>] <span style="color:#f92672">=</span> kia[<span style="color:#e6db74">&#39;dod&#39;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: int(str(x)[<span style="color:#ae81ff">6</span>:]))
</span></span><span style="display:flex;"><span>kia[<span style="color:#e6db74">&#39;monthDeath&#39;</span>] <span style="color:#f92672">=</span> kia[<span style="color:#e6db74">&#39;dod&#39;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: int(str(x)[<span style="color:#ae81ff">4</span>:<span style="color:#ae81ff">6</span>]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kia[<span style="color:#e6db74">&#39;tweet&#39;</span>] <span style="color:#f92672">=</span> kia[<span style="color:#e6db74">&#39;rank&#39;</span>] <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34; &#34;</span> <span style="color:#f92672">+</span> kia[<span style="color:#e6db74">&#39;name&#39;</span>] <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;KILLED IN ACTION, &#34;</span> <span style="color:#f92672">+</span> kia[<span style="color:#e6db74">&#39;countryOfDeath&#39;</span>] <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;. &#34;</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;(&#34;</span> <span style="color:#f92672">+</span> kia[<span style="color:#e6db74">&#39;yod&#39;</span>] <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;)&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>toTweet <span style="color:#f92672">=</span> kia[[<span style="color:#e6db74">&#39;tweet&#39;</span>, <span style="color:#e6db74">&#39;dayDeath&#39;</span>, <span style="color:#e6db74">&#39;monthDeath&#39;</span>]]
</span></span><span style="display:flex;"><span>toTweet<span style="color:#f92672">.</span>to_csv(<span style="color:#e6db74">&#39;kia.tweets.dat&#39;</span>, sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;|&#39;</span>, index<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, headers<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>)
</span></span></code></pre></div>
<h1 id="prototype-the-bot" class="anchor-link"><a href="#prototype-the-bot">Prototype the bot</a></h1>
<p>Before going through all the Twitter account setup and API access things, it&rsquo;s easier to just prototype things by printing the tweets STDOUT.  The main idea is to load in the file, get the current day and month, take all the deaths on the current day and month and then calculate the delay between them so that all can be tweeted before the end of the day.  I also put in a buffer of two minutes, so that the script would finish no later than 2358.  I do not account for things like rate limiting, restarting the service should it fail, exception handling, and so on.  Out of scope for this project.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#f92672">import</span> sys
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> datetime <span style="color:#f92672">import</span> datetime
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>():
</span></span><span style="display:flex;"><span>	kia <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(sys<span style="color:#f92672">.</span>argv[<span style="color:#ae81ff">1</span>], sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;|&#39;</span>)
</span></span><span style="display:flex;"><span>	now <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()
</span></span><span style="display:flex;"><span>	year <span style="color:#f92672">=</span> now<span style="color:#f92672">.</span>year
</span></span><span style="display:flex;"><span>	day <span style="color:#f92672">=</span> now<span style="color:#f92672">.</span>day
</span></span><span style="display:flex;"><span>	month <span style="color:#f92672">=</span> now<span style="color:#f92672">.</span>month
</span></span><span style="display:flex;"><span>	buffer_seconds <span style="color:#f92672">=</span> <span style="color:#ae81ff">120</span>
</span></span><span style="display:flex;"><span>	remaining_secs <span style="color:#f92672">=</span> (datetime(year, month, day<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">-</span> datetime<span style="color:#f92672">.</span>now())<span style="color:#f92672">.</span>total_seconds() <span style="color:#f92672">-</span> buffer_seconds
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	tweets <span style="color:#f92672">=</span> kia[(kia[<span style="color:#e6db74">&#39;dayDeath&#39;</span>] <span style="color:#f92672">==</span> day) <span style="color:#f92672">&amp;</span> (kia[<span style="color:#e6db74">&#39;monthDeath&#39;</span>] <span style="color:#f92672">==</span> month)][<span style="color:#e6db74">&#39;tweet&#39;</span>]<span style="color:#f92672">.</span>values
</span></span><span style="display:flex;"><span>	delay <span style="color:#f92672">=</span> math<span style="color:#f92672">.</span>floor(remaining_secs <span style="color:#f92672">/</span> len(tweets))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> tweet <span style="color:#f92672">in</span> tweets:
</span></span><span style="display:flex;"><span>		print(tweet)
</span></span><span style="display:flex;"><span>		time<span style="color:#f92672">.</span>sleep(delay)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>	main()
</span></span></code></pre></div>
<h1 id="get-twitter-api-credentials" class="anchor-link"><a href="#get-twitter-api-credentials">Get Twitter API credentials</a></h1>
<p>Now it&rsquo;s time to set up a new Twitter account and get API access.  The hardest part is finding an available handle on Twitter.  Really.  It will probably take you longer to settle on an available name than it will to get your API keys.</p>
<p>Note that you <strong>must</strong> provide a phone number in order for Twitter to generate all the tokens you need.</p>
<ol>
<li>
<p>Set up a new Twitter account, make sure to include a phone number</p>
</li>
<li>
<p>Go to <a href="https://dev.twitter.com">https://dev.twitter.com</a> and set up a new application</p>
</li>
<li>
<p>After the application is set up, copy the Consumer Key and Consumer Secret strings</p>
</li>
<li>
<p>Click the button to generate an <a href="https://dev.twitter.com/oauth/overview/application-owner-access-tokens">access token</a></p>
</li>
<li>
<p>Copy the Token and Token Secret strings</p>
</li>
</ol>

<h1 id="get-the-bot-tweeting" class="anchor-link"><a href="#get-the-bot-tweeting">Get the bot tweeting</a></h1>
<p>The first step is to <code>pip install twython</code>, a Python library for Twitter which allows tweeting (amongst other things) from any Python script.  It&rsquo;s straightforward to use and flexible as well, as you can see from the <a href="https://twython.readthedocs.io/en/latest/usage/basic_usage.html">Basic Usage</a> page.</p>
<p>Then, simply add in the necessary credentials, set up the Twitter connection object, and post an actual tweet instead of the print we had before.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Python" data-lang="Python"><span style="display:flex;"><span><span style="color:#f92672">import</span> sys
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> twython <span style="color:#f92672">import</span> Twython
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> datetime <span style="color:#f92672">import</span> datetime
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>consumer_key <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;YOUR CONSUMER KEY HERE&#39;</span>
</span></span><span style="display:flex;"><span>consumer_secret <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;YOUR CONSUMER SECRET HERE&#39;</span>
</span></span><span style="display:flex;"><span>token <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;YOUR TOKEN HERE&#39;</span>
</span></span><span style="display:flex;"><span>token_secret <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;YOUR TOKEN SECRET HERE&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>twitter <span style="color:#f92672">=</span> Twython(consumer_key, consumer_secret, token, token_secret)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>():
</span></span><span style="display:flex;"><span>	kia <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(sys<span style="color:#f92672">.</span>argv[<span style="color:#ae81ff">1</span>], sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;|&#39;</span>)
</span></span><span style="display:flex;"><span>	now <span style="color:#f92672">=</span> datetime<span style="color:#f92672">.</span>now()
</span></span><span style="display:flex;"><span>	year <span style="color:#f92672">=</span> now<span style="color:#f92672">.</span>year
</span></span><span style="display:flex;"><span>	day <span style="color:#f92672">=</span> now<span style="color:#f92672">.</span>day
</span></span><span style="display:flex;"><span>	month <span style="color:#f92672">=</span> now<span style="color:#f92672">.</span>month
</span></span><span style="display:flex;"><span>	buffer_seconds <span style="color:#f92672">=</span> <span style="color:#ae81ff">120</span>
</span></span><span style="display:flex;"><span>	remaining_secs <span style="color:#f92672">=</span> (datetime(year, month, day<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">-</span> datetime<span style="color:#f92672">.</span>now())<span style="color:#f92672">.</span>total_seconds() <span style="color:#f92672">-</span> buffer_seconds
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	tweets <span style="color:#f92672">=</span> kia[(kia[<span style="color:#e6db74">&#39;dayDeath&#39;</span>] <span style="color:#f92672">==</span> day) <span style="color:#f92672">&amp;</span> (kia[<span style="color:#e6db74">&#39;monthDeath&#39;</span>] <span style="color:#f92672">==</span> month)][<span style="color:#e6db74">&#39;tweet&#39;</span>]<span style="color:#f92672">.</span>values		
</span></span><span style="display:flex;"><span>	delay <span style="color:#f92672">=</span> math<span style="color:#f92672">.</span>floor(remaining_secs <span style="color:#f92672">/</span> len(tweets))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> tweet <span style="color:#f92672">in</span> tweets:
</span></span><span style="display:flex;"><span>		twitter<span style="color:#f92672">.</span>update_status(status<span style="color:#f92672">=</span>tweet)
</span></span><span style="display:flex;"><span>		time<span style="color:#f92672">.</span>sleep(delay)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>	main()
</span></span></code></pre></div><p>This will have our bot tweeting all the required death records, and it should finish no later than 1158 on any given day.</p>

<h1 id="deploy-to-a-virtual-machine-somewhere" class="anchor-link"><a href="#deploy-to-a-virtual-machine-somewhere">Deploy to a virtual machine somewhere</a></h1>
<p>Since I do my work on a laptop which isn&rsquo;t always running, I keep the bot going on a virtual machine with Amazon Web Services.  I won&rsquo;t go into details here of getting an EC2 instance up and running on AWS, but once you have that you can just SFTP or SCP the bot and the data file up to the machine.</p>
<p>Additionally, since the bot uses Pandas, rather than bothering with pip and dependencies and so on, I did what I always do for Python and just installed <a href="https://www.anaconda.com/products/individual">Anaconda</a> from Continuum Analytics.  If you aren&rsquo;t using Anaconda for your Python work, life is probably harder for you than it needs to be.</p>
<p>Also, if you are still using Python 2 instead of Python 3&hellip;</p>
<p>
<img class="enclosure" src="/static/images/yourebad.jpg" alt="Futurama meme &lsquo;You&rsquo;re bad and you should feel bad&rsquo;"  />
</p>

<h1 id="add-scheduling" class="anchor-link"><a href="#add-scheduling">Add scheduling</a></h1>
<p>For something like this, the easiest way to schedule it is to just add a cron job to run the bot every day at midnight, and it will then finish before 2358 on the same day.</p>
<p>So <code>crontab -e</code> and we just add an entry like <code>00 00 * * * /path/to/your/python /path/to/your/script /path/to/your/input/file</code></p>
<p>Now the bot will start every day at midnight, and finish by 2358, only to be restarted for a new day a few minutes later.</p>

<h1 id="fin" class="anchor-link"><a href="#fin">Fin</a></h1>
<p>If you want to do some quick Data Science projects, I&rsquo;d say this is a pretty representative and straightforward example.  Additionally, though I haven&rsquo;t gotten around to it yet, putting the code on GitHub is usually a good idea.  If you decide to do that, <strong>DO NOT FORGET</strong> to remove your API credentials before you commit and push the code.</p>
<p>So that&rsquo;s it.  Gathering data and building Twitter bots isn&rsquo;t any kind of magic, although bots which interact with others are a different matter.</p>
<p>Now when I pull up my Twitter feed I get a nice reminder of those who gave their lives in service of the interests of the United States.</p>
<p>Remember.</p>
 ]]></content:encoded></item><item><title>Competitors are Not the Problem</title><link>https://adamdrake.com/competitors-are-not-the-problem.html</link><pubDate>Sat, 30 Jul 2016 00:00:00 +0000</pubDate><guid>https://adamdrake.com/competitors-are-not-the-problem.html</guid><description>&lt;p>I advise many successful companies, and some of them have grown very quickly to their current size and state. They developed a product or service, matched it with a market, and are experiencing a great deal of success. During the earlier parts of this journey they were acutely aware of the possibility of competitors being able to overtake them or the reality that other competitors really were jockeying for position in the market. However, their growth rate meant that any competitors simply couldn&amp;rsquo;t keep up.&lt;/p></description><content:encoded><![CDATA[ <p>I advise many successful companies, and some of them have grown very quickly to their current size and state.  They developed a product or service, matched it with a market, and are experiencing a great deal of success.  During the earlier parts of this journey they were acutely aware of the possibility of competitors being able to overtake them or the reality that other competitors really were jockeying for position in the market.  However, their growth rate meant that any competitors simply couldn&rsquo;t keep up.</p>
<p>The leaders of these organizations have the feeling of close competitors fresh in their minds, and therefore many companies experiencing quick growth are unreasonably fixated on defending against or staying ahead of competitors when they really should be starting to repair and improve the internal structural areas necessary to continue their growth.</p>
<p>While maintaining awareness of the market and competitor activities is important, once an organization has reached a position which is clearly dominant in the market, I have observed that the bigger risk to the organization starts to come from within.  Companies with that kind of growth trajectory typically forsake upgrading leadership skills and business processes necessary to continue the growth, often to their detriment.</p>
<p>These aren&rsquo;t particularly new ideas, and <a href="https://en.wikipedia.org/wiki/Arnold_J._Toynbee">Arthur Toynbee</a> has written extensively on the growth and collapse of many societies in his works.  The main idea is that an organization (society in Toynbee&rsquo;s case) is grown by a creative minority whose ideas and progress attract a large group of followers. At some point this creative minority can become a dominant minority, the group starts erecting some types of walls or protective measures, and by that time the group is in breakdown mode.</p>

<h1 id="king-of-the-mountain" class="anchor-link"><a href="#king-of-the-mountain">King of the mountain</a></h1>
<p>A fortified position is far easier to defend than to capture.  If your organization has already reached a dominant position in a given area, and you are still making progress on improving your products and services for your customers, any competitor will have to work extremely hard to unseat you.  Your organization is probably still led by a creative minority, and it is their direction and enthusiasm which leads to progress.</p>
<p>There is a tendency in these cases for some people, especially executives, to begin focusing on external threats.  However, if you do a bit of introspection about the organization there are likely numerous internal ways in which growth can slow or perhaps be eliminated entirely.  These areas are the bigger risk.</p>
<p>Newer organizations which have experienced rapid growth are typically headed by visionary but perhaps inexperienced founders.  Their leadership and operations capabilities have almost certainly improved along the way, but it&rsquo;s likely the company growth has outpaced their ability to upgrade their own skills.  This often results in a young and vibrant company, with a great growth story, that begins to focus too much on defending against competitors when they should be focusing on creating systems to maintain growth.</p>
<p>If you don&rsquo;t want to be public about your software development practices in order to defend against competitors, rather than blogging and doing tech talks and so on in order to continue attracting top talent, this means you.  There&rsquo;s are many reasons why Uber and other fast-growing companies do a huge amount of sharing about their technology work and practices, and one of those is because they know the big challenge is continuing to recruit many good developers.  They aren&rsquo;t getting overly sidetracked or paranoid about things Lyft might discover.</p>

<h1 id="look-in-the-mirror" class="anchor-link"><a href="#look-in-the-mirror">Look in the mirror</a></h1>
<p>Humans often have a tendency to focus externally when identifying risks or weakness.  This feeling is natural and has its place in a world where you might be eaten by a lion, but there are cases when the biggest risk to your livelihood doesn&rsquo;t come from external threats but rather from internal deficiencies.</p>
<p>With this in mind, you can shift the focus to the internal areas of the business which are presenting the largest impediments to growth.  When this doesn&rsquo;t happen, the result might be the creation of what Toynbee calls an <em>internal proletariat</em>.</p>
<p>In my experience some of the main issues tend to be things like:</p>
<ul>
<li>
<p>insufficient leadership capabilities</p>
</li>
<li>
<p>lack of business and technical processes</p>
</li>
<li>
<p>insufficient documentation for existing processes</p>
</li>
<li>
<p>ineffective or missing onboarding processes</p>
</li>
<li>
<p>ineffective methods for increasing inbound candidates/recruiting</p>
</li>
</ul>
<p>If the creative minority (leadership) doesn&rsquo;t handle these sorts of things and instead becomes just the dominant minority (management) then an internal proletariat develops further and the organization begins to implode.  One of the signs of implosion is excessive defensive emphasis, which often manifests as fear and paranoia about competitors.</p>
<p>It&rsquo;s not uncommon for a growing company to talk about leaving competitors behind (less emphasis on defense) and after two years that same company might be having executive team off-site meetings about how to best address the competitive threat.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>From Toynbee&rsquo;s perspective, when a society is growing rapidly it is difficult to define the borders because the society and culture is radiating out at a rapid pace.  If you&rsquo;re at the point in your business where you could buy your competitor(s), and you are continuing to deliver improvements to your product or service, then your competition is probably not your biggest risk.</p>
<p>You have to look internally at the things your business requires in order to grow.  You have to avoid the creation of an <em>internal proletariat</em>. You have to ensure your culture and vision continues to radiate outwards at a rapid pace.  The requirements for these objectives will almost certainly <strong>not</strong> be technological things, but rather leadership capabilities and processes for operating the business.</p>
 ]]></content:encoded></item><item><title>How Do You Punish People?</title><link>https://adamdrake.com/how-do-you-punish-people.html</link><pubDate>Mon, 11 Jul 2016 00:00:00 +0000</pubDate><guid>https://adamdrake.com/how-do-you-punish-people.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>The title of this post is literally the first question I received from someone when I was doing leadership advising at a very successful company. The company was dominant in their market and were continuing to grow internationally. The person who asked me the question was intelligent and had previously worked for a large technology organization before taking on their current role leading a department. The person knew I was there to help the executive team become more effective leaders and thereby help the company continue their along their growth trajectory, but for this person leadership was seemingly a matter of delegation and punishment.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>The title of this post is literally the first question I received from someone when I was doing leadership advising at a very successful company.  The company was dominant in their market and were continuing to grow internationally.  The person who asked me the question was intelligent and had previously worked for a large technology organization before taking on their current role leading a department.  The person knew I was there to help the executive team become more effective leaders and thereby help the company continue their along their growth trajectory, but for this person leadership was seemingly a matter of delegation and punishment.</p>
<p>The first question they asked me, at the very beginning of our conversation was &ldquo;How do you punish people?&rdquo;  Another form of this question, which has also been posed to me, is &ldquo;How do you hold people accountable?&rdquo;  For the remainder of this post I&rsquo;ll refer to punishment but the points hold for accountability as well.</p>
<p>The answer is, I don&rsquo;t punish people.  When leadership is effective, punishment isn&rsquo;t typically necessary.  Furthermore I would consider instituting external punishment or negative reinforcement or whatever you want to call it to be a possible sign of <strong>bad</strong> leadership.</p>
<p>The standard follow-up question is &ldquo;If you don&rsquo;t punish and hold people accountable, how do you get them to do anything?&rdquo;  The answer is, you lead them.</p>

<h1 id="leadership-versus-management" class="anchor-link"><a href="#leadership-versus-management">Leadership versus Management</a></h1>
<p>One definition of leadership is that leadership is the ability to get people to want to do what you want them to do.  Put another way, a good leader has the ability to develop intrinsic motivation in other people.  When this takes place, those other people have many powerful motivations to do a good job, and will generally put all their effort into this work since they understand and feel the value.  So if something doesn&rsquo;t go well, why would you fault them?  What punishment would be appropriate?  It&rsquo;s probably your fault as a leader for not helping the person or team understand your intention, the general task, why the task is important, and constraints on the task.  Remember, the <strong>why</strong> is by far the most important part of that list.  If people don&rsquo;t understand <strong>why</strong> something is important then it&rsquo;s almost impossible for them to do a good job.  One of your top jobs, as a leader, is to help people understand the <strong>why</strong>.</p>
<p>Developing this motivation within people is dramatically different from simply delegating tasks or telling people what to do.  Managers can delegate tasks all day, but leaders can help people understand the tasks in context, and develop within their people a sense of ownership and caring about the tasks.  Leaders then step back and give their teams the room to perform.</p>
<p>If, for some reason, the task is not completed within the specified constraints, the person working on it will feel internally bad.  Since a good leader will have helped the person understand the purpose of the task (the <strong>why</strong>), and would have developed the intrinsic motivation within the person to complete the task, that person&rsquo;s disappointment in themselves is generally more powerful than any punishment some misguided manager could have delivered.</p>
<p>The same argument is true for accountability.  Holding people accountable is rarely necessary, since people who understand the intent, the general task, <strong>why</strong> it&rsquo;s important, the constraints, and have freedom to figure out the <strong>how</strong>, will be accountable to themselves for completing the task.  The accountability is constant (since it&rsquo;s internal) and far more effective than something imposed upon them.  If external accountability is the only reason the person is working on the task, what happens when that external accountability is momentarily removed or lacking entirely?  There are times to impose accountability externally, but they aren&rsquo;t common.</p>

<h1 id="what-to-do" class="anchor-link"><a href="#what-to-do">What to do?</a></h1>
<p>If you want people to feel personally accountable for something (in other words, to feel ownership) you have to actually give them creative freedom to own the solution to the problem.  This means focusing on communicating a few general things to people:</p>
<ul>
<li>
<p>Context (describe the current situation)</p>
</li>
<li>
<p>Goal (<strong>what</strong> you want accomplished and <strong>why</strong> it matters)</p>
</li>
<li>
<p>Constraints (what are the boundaries of the solution)</p>
</li>
</ul>
<p>Then ask people for their suggestions on how to achieve the goal given the constraints.</p>
<p>In other words, whereas a manager might tell people <strong>what</strong> to do and <strong>how</strong> to do it, a leader will effectively communicate <strong>where</strong> to go, <strong>why</strong> it&rsquo;s important, and let the people figure out <strong>how</strong> to get there.</p>
<p>Communicating your intent and why the goal is important is probably the most difficult part, and a lot of aspiring leaders fail here because they deviate and start telling people how they want to goal accomplished.  I might have to cover this in another post, but it&rsquo;s critical to stick to framing your actual goal and why the goal matters.  Do not go into operational details unless it&rsquo;s to communicate constraints.  Let your people solve the problem.</p>
<p>This process is more complicated than I outlined here, and even those three general bullet points for communication can be expanded upon and are not complete, but that&rsquo;s the basic idea.</p>
<p>Just tell your team your intent and why the goal is important and let them surprise you with how they decide to solve the problem.  If their solution somehow doesn&rsquo;t work, that means you as a leader failed to fully communicate the goal or the constraints on the solution space, so just take responsibility for the miscommunication, revise, and try again.</p>
<p>It&rsquo;s amazing what a creative and well-briefed team can come up with as a solution to a seemingly-impossible business problem, and as a leader it&rsquo;s important to be secure in your position and supportive of their solution.  Remember, their collective brains are more powerful than your individual one.</p>

<h1 id="ps" class="anchor-link"><a href="#ps">P.S.</a></h1>
<p>Questions not answered in this post (in no particular order):</p>
<ul>
<li>
<p>What if their solution meets all the constraints but isn&rsquo;t the way you would solve the problem?</p>
</li>
<li>
<p>How do you know if a leader is effective?</p>
</li>
<li>
<p>At one point does communicating constraints become telling someone <strong>how</strong> to do something?</p>
</li>
<li>
<p>Which steps or items are missing from the communication bullet points?</p>
</li>
<li>
<p>If a leader is secure does that mean they always accept the suggestions of the team?</p>
</li>
</ul>
<p>I&rsquo;ll likely cover these in a future post.</p>
 ]]></content:encoded></item><item><title>Culture Red Flags: Who is *They*?</title><link>https://adamdrake.com/culture-red-flags-who-is-they.html</link><pubDate>Sun, 03 Jul 2016 00:00:00 +0000</pubDate><guid>https://adamdrake.com/culture-red-flags-who-is-they.html</guid><description>&lt;p>Over the years I&amp;rsquo;ve advised many companies on how to improve their leadership capabilities in order to cultivate a more effective corporate culture and thereby achieve growth. One thing which is absolutely necessary for a company to thrive is for the culture to support collaboration and a sense of shared purpose. You need unit cohesion. You need the shared feeling that we are all one group, with one purpose, currently making progress towards one goal which supports that purpose.&lt;/p></description><content:encoded><![CDATA[ <p>Over the years I&rsquo;ve advised many companies on how to improve their leadership capabilities in order to cultivate a more effective corporate culture and thereby achieve growth.  One thing which is absolutely necessary for a company to thrive is for the culture to support collaboration and a sense of shared purpose.  You need unit cohesion.  You need the shared feeling that we are all one group, with one purpose, currently making progress towards one goal which supports that purpose.</p>
<p>When leadership is ineffective, however, things don&rsquo;t usually work out that way.</p>
<p>When leadership is ineffective, there is fragmentation in priorities, a lot of confusion, and and some measure of frustration.  Since people aren&rsquo;t clear on the actual goal or on your intent, they start doing what they think is best, which may not be the same as what another group thinks is best, and the sense of shared identity is lost.  Groups start to become distant and apathetic at best, though more often they become openly adversarial.</p>
<p>The example I&rsquo;ve often seen comes in excuses for insufficient growth in companies with a strong Sales and Technology focus.</p>
<p>The Sales team complains that they aren&rsquo;t able to meet growth targets because the Technology team doesn&rsquo;t build anything new to sell, and hasn&rsquo;t for a long time (usually longer than the current Sales head has been there).  If the Sales team only had better products then they&rsquo;d be able to sell them and the company would be doing well.  When I talk to people in Sales, I get the response that <em>they</em> (the Technology team) aren&rsquo;t doing a good job.</p>
<p>The Technology team of course defends the things they have built, and typically responds that the Sales team is simply ineffective.  When I talk to people in these teams they will <em>almost always</em> use the pronoun <em>THEY</em> to refer to what has, unfortunately, become the opposing team.  When I talk to people in Technology, I get the response that <em>they</em> (the Sales team) aren&rsquo;t doing a good job.</p>
<p>In reality the underlying issue is ineffective leadership at many levels.  The CEO is not leading the Sales and Tech leaders well, and they in turn are not leading their teams well either.  The use of the word <em>they</em> to refer to any subgroup of an organization while making excuses is an automatic red flag for me because it reveals ineffective leadership, which doesn&rsquo;t encourage a sense of ownership or responsibility, which leads to dehumanization and bickering internally, and this is where the word <em>they</em> comes into use.</p>
<p>The fix for this, like many things, is relatively straightforward.  Start asking: Who is <em>THEY</em>?  The answer should always be <em>our X</em> where X is some other subgroup in the company.</p>
<p>As a similar example, often someone is reporting that a decision has been made, and the person will often say that <em>They</em> decided or <em>Sales</em> decided or <em>Tech</em> decided.  This is basically never true and shows a cultural unwillingness to address problems and facts.  When something is decided, it&rsquo;s almost always decided by an individual.  Unanimous decisions in sizable organizations are not common.  Again, the same rule applies, you can simply ask for a name.  Who decided?  Which person?  What is their name?</p>
<p>Dehumanizing and creating distance through language is possibly as old as human communication itself.  Do not let the people and teams in your organization dehumanize each other.  You need them to cooperate and work toward a common goal.  It&rsquo;s your job as a leader to make that happen, and one of the ways to do that is to ensure that unintentional dehumanization via language is not tolerated.</p>
<p>So when you hear <em>they</em> and some verb, it&rsquo;s your job to ask who this <em>they</em> actually is and use that as a moment to reinforce the fact that we&rsquo;re all one team working to achieve one goal.</p>
<p>Note I assumed above that, as a leader, you clearly communicated your intent to the team along with the associated constraints, but going into more detail on that is a topic for another post.</p>
 ]]></content:encoded></item><item><title>What is Your Current Salary?</title><link>https://adamdrake.com/what-is-your-current-salary.html</link><pubDate>Thu, 05 May 2016 00:00:00 +0000</pubDate><guid>https://adamdrake.com/what-is-your-current-salary.html</guid><description>&lt;p>I&amp;rsquo;ve probably hired hundreds of people in my career and I also do a
fair bit of mentoring for new technology professionals, especially new
Data Scientists and Data Engineers, Software engineers, and similar
roles. One thing that often comes up is looking for new jobs and how
to go about that process. For more junior candidates especially, you
are at risk of getting asked a very dangerous question; What is your
current salary? It&amp;rsquo;s a horrible question, and should make you pause
for a moment and consider if you really want to work for the kind of
company that would ask it.&lt;/p></description><content:encoded><![CDATA[ <p>I&rsquo;ve probably hired hundreds of people in my career and I also do a
fair bit of mentoring for new technology professionals, especially new
Data Scientists and Data Engineers, Software engineers, and similar
roles.  One thing that often comes up is looking for new jobs and how
to go about that process.  For more junior candidates especially, you
are at risk of getting asked a very dangerous question; What is your
current salary?  It&rsquo;s a horrible question, and should make you pause
for a moment and consider if you really want to work for the kind of
company that would ask it.</p>

<h1 id="know-your-worth" class="anchor-link"><a href="#know-your-worth">Know your worth.</a></h1>
<p>One thing I always advise people, before they start talking with
new employers, is to know their worth on the open market.  Market
salaries are your most important piece of information in any job
search.  Companies spend obscene amounts of money buying salary data
so they can have a general idea of what they&rsquo;ll have to pay to acquire and retain talent.
They already know this information, in great detail, and if you choose
not to come prepared with this information as well then they almost
certainly will take advantage of you.</p>
<p>If you are sensitive about
talking to friends in similar roles at similar companies about
salary data, simply ask for ranges.  If you don&rsquo;t have friends doing
similar work at similar companies then you need to address a more
basic problem, the fact that you don&rsquo;t have a professional network.
Perhaps I&rsquo;ll write about this at a later time.  You can also look
online as there are many websites which post salary data by occupation
and sometimes even on a per-company basis.  There is no excuse for not
knowing this before you start looking and in fact you should know it
at all times.</p>
<p>Always know your worth and set that as your desired
salary.  Never settle for what you <em>think</em> you&rsquo;re worth, but rather demand
what the market will support (or more if you can prove you bring a greater than average market value).</p>

<h1 id="anything-you-say-can-and-will-be-used-against-you" class="anchor-link"><a href="#anything-you-say-can-and-will-be-used-against-you">Anything you say can and will be used against you.</a></h1>
<p>Sometimes during the recruiting process it can be helpful to know a candidates salary, but it&rsquo;s more of a passing curiosity than a hard requirement.  When a potential employer asks about your current salary in a persistent or inflexible way, it is almost
certain they plan to use that information against you.  The reason is
that most companies who are going to offer a fair market salary (or
ideally some percentage over the median market salary) will already
have a budget for the position and will simply make the offer.  The
only reason they would need to know your current salary is if they are
either paying below market and are trying to screen you out, or if
they are willing to pay market salaries but want to pay you less if
they think you&rsquo;ll take it.  The only solution is to outright refuse to
provide any information on your current compensation.</p>
<p>Many HR people
or recruiters will try a lot of deceptive tactics to get you to
disclose your current salary, like saying they have talked with other
people in the company doing similar jobs so they have some example
salaries but if you tell them your salary they can make sure you get a
fair offer.  This is a lie and a trap.  A fair offer is median market
or more and they don&rsquo;t need to know anything about your salary or the
salary of anyone else in your current company in order to make that
offer.  Remember, they <strong>already</strong> purchased the salary data and/or
know about market rates. Don&rsquo;t let them trick you.</p>

<h1 id="why-do-they-do-this" class="anchor-link"><a href="#why-do-they-do-this">Why do they do this?</a></h1>
<p>To cheat you out of money.  <em>Having a budget limitation</em> or <em>not
wasting your time</em> is no excuse since they can just simply be
honest about the maximum they&rsquo;re willing to pay.  The
position is already budgeted, remember?</p>
<p>People typically don&rsquo;t leave
jobs unless they&rsquo;re getting about a 20% raise from their current
salary.  Companies know this so they will ask for your current salary
and then make an offer that is around 20% higher than that
regardless of the market rate for your role.  From the company
perspective they are saving money so they are happy to rip you off.</p>
<p>That being said, if they&rsquo;re giving you a 20% raise and it&rsquo;s still
under market then you need to take responsibility for your own career
path and consider if the company and role you currently have is worth the discount against your market value.  See <em>Know your worth</em> above.</p>

<h1 id="how-do-you-respond" class="anchor-link"><a href="#how-do-you-respond">How do you respond?</a></h1>
<p>Be honest.  Tell the person that you are aware of your market rates
and you are sure that the company will provide you with a fair offer.</p>
<p>Another point to mention is that it&rsquo;s not relevant what you&rsquo;re
leaving, but what you&rsquo;re going towards.  People change jobs
for different reasons, and depending on the stage of their career it
may be worthwhile to take a pay cut for a fun challenge or pay raise for more cash but less fulfillment in other areas.  The
compensation you&rsquo;re leaving does not necessarily matter when it comes
to the compensation you&rsquo;d be willing to accept.</p>
<p>Most companies will
drop the topic at this point or tell you that they can&rsquo;t proceed
without you disclosing a number to them.  This is either a bluff or
they&rsquo;re serious and you don&rsquo;t want to work for a company like that
anyway.</p>

<h1 id="what-if-you-are-currently-paid-above-market" class="anchor-link"><a href="#what-if-you-are-currently-paid-above-market">What if you are currently paid above market?</a></h1>
<p>This can work to your advantage.  Be honest about the fact that you know you&rsquo;re being paid well above market, but that you like the role, company, culture, products, or whatever other reasons are causing you to consider making a move and for a lower salary.  I almost never advocate such a change for someone early in their career, but some opportunities could call for it.</p>

<h1 id="what-if-they-keep-pressing" class="anchor-link"><a href="#what-if-they-keep-pressing">What if they keep pressing?</a></h1>
<p>Again, be honest.  Tell them you are uncomfortable with their
pressure and you have already explained your perspective.  Add that
since they aren&rsquo;t respecting your boundaries you are not as able to
trust them since they are clearly the only side which will benefit
from discussing that topic.  Be firm.  Redirect the conversation to
cultural topics at a company which would continue pressing for such
information.  Make them explain to you why they have a good working
culture yet press employees to put themselves in disadvantageous
positions.  Tell them you aren&rsquo;t sure you want to continue with the process due to concerns about the culture.</p>
<p>You always maintain the power to walk away.</p>
<p>If they&rsquo;re talking with you
and you&rsquo;re a tech person then they need you a lot more than you need
them.  Don&rsquo;t forget that.</p>
<p>Many thanks to <a href="https://www.linkedin.com/in/eugeneyan">Eugene Yan</a> for his extensive feedback and perspectives on this post.</p>
 ]]></content:encoded></item><item><title>A Hackish System Command Service in Go</title><link>https://adamdrake.com/a-hackish-system-command-service-in-go.html</link><pubDate>Sun, 27 Sep 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/a-hackish-system-command-service-in-go.html</guid><description>&lt;p>When building data products, often the end result is either a recurring report or an API which allows for an interface with other services. In these cases, the product might be run by a cron job, or even manually, depending on the situation. When the product is part of (more frequently, at the end of) a larger data processing pipeline, this can become inefficient or problematic since steps earlier in the pipeline can cause the product to supply incorrect information or fail altogether.&lt;/p></description><content:encoded><![CDATA[ <p>When building data products, often the end result is either a recurring report or an API which allows for an interface with other services.  In these cases, the product might be run by a cron job, or even manually, depending on the situation.  When the product is part of (more frequently, at the end of) a larger data processing pipeline, this can become inefficient or problematic since steps earlier in the pipeline can cause the product to supply incorrect information or fail altogether.</p>
<p>To get around this problem it is often desirable to have previous steps in the data processing pipeline directly trigger the data product to run.  This ensures that earlier steps of the pipeline have completed successfully and also eliminates the need for buffer time before the cron job starts.  A way this coupling is often accomplished is via an HTTP endpoint which can be hit by some calling entity, thus triggering the processing job to start.</p>
<p>When the cron job is already running, building such an HTTP endpoint can be very straightforward since you need only run a local command on the system in question (responding with HTTP code 200, OK) and then while the command is running any subsequent requests can provide an HTTP 503 (Service Unavailable) response.</p>
<p>With that in mind, here is a small example in Go which accomplishes the task.  It will listen on some port for requests to a <code>/start</code> endpoint.  When that URL is accessed the command will be run in a separate goroutine, and any requests which come in while the command is running will receive a 503 response.  After the command completes and errors are handled the system is available and can be restarted again.</p>
<p>This is just a very rough outline and has some nasty things (e.g., global variables, security problems) but it provides the necessary endpoint and does what is needed with minimal effort.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Go" data-lang="Go"><span style="display:flex;"><span><span style="color:#f92672">package</span> <span style="color:#a6e22e">main</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;net/http&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#e6db74">&#34;os/exec&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> (
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">command</span> = <span style="color:#e6db74">&#34;commandTorun&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">args</span>    = <span style="color:#e6db74">&#34;argumentsForTheCommand&#34;</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">port</span>    = <span style="color:#e6db74">&#34;:8080&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">var</span> <span style="color:#a6e22e">jobRunning</span> = <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">runJob</span>() {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">jobRunning</span> = <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">exec</span>.<span style="color:#a6e22e">Command</span>(<span style="color:#a6e22e">command</span>, <span style="color:#a6e22e">args</span>).<span style="color:#a6e22e">Run</span>()
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">// Error was returned from system command.  Do something.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">jobRunning</span> = <span style="color:#66d9ef">false</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">jobStartEndpoint</span>(<span style="color:#a6e22e">w</span> <span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">ResponseWriter</span>, <span style="color:#a6e22e">r</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">Request</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">jobRunning</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">w</span>.<span style="color:#a6e22e">WriteHeader</span>(<span style="color:#ae81ff">503</span>)
</span></span><span style="display:flex;"><span>	} <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">go</span> <span style="color:#a6e22e">runJob</span>()
</span></span><span style="display:flex;"><span>		<span style="color:#a6e22e">w</span>.<span style="color:#a6e22e">WriteHeader</span>(<span style="color:#ae81ff">200</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">func</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">HandleFunc</span>(<span style="color:#e6db74">&#34;/start&#34;</span>, <span style="color:#a6e22e">jobStartEndpoint</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">http</span>.<span style="color:#a6e22e">ListenAndServe</span>(<span style="color:#a6e22e">port</span>, <span style="color:#66d9ef">nil</span>)
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div> ]]></content:encoded></item><item><title>Are your Functions Total?</title><link>https://adamdrake.com/are-your-functions-total.html</link><pubDate>Mon, 07 Sep 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/are-your-functions-total.html</guid><description>&lt;p>In recent years, and for a variety of reasons, functional programming has become an increasingly popular topic. Languages like Haskell, Scala, Clojure, and others, have had huge gains in popularity and consequently there have been many large-scale projects written in some of these languages. There has also been increasing pressure to move programming more towards the rigor of mathematics, something which I strongly support.&lt;/p>
&lt;p>One thing which could get more attention in the context of functional programming is the concept of &lt;a href="https://en.wikipedia.org/wiki/Total_functional_programming">Total Functional Programming&lt;/a>, which uses the concepts of &lt;strong>total functions&lt;/strong> combined with specific types of recursion in order to guarantee that all your programs terminate. Astute readers will note that this means, since the &lt;a href="https://en.wikipedia.org/wiki/Halting_problem">Halting Problem&lt;/a> is not decidable over Turing machines, that a Total Functional Programming language is not &lt;a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing Complete&lt;/a>. In practical use, this is not an undesirable property and in fact systems written in Turing complete languages are often restricted to be Turing incomplete by, for example, adding termination conditions to programs so that they do not run indefinitely. If you&amp;rsquo;ve ever been working on some kind of numerical program and added something like &lt;code>if loopCounter &amp;gt; limit then return&lt;/code> in order to stop a loop which has sufficiently converged, you have done exactly this.&lt;/p></description><content:encoded><![CDATA[ <p>In recent years, and for a variety of reasons, functional programming has become an increasingly popular topic.  Languages like Haskell, Scala, Clojure, and others, have had huge gains in popularity and consequently there have been many large-scale projects written in some of these languages.  There has also been increasing pressure to move programming more towards the rigor of mathematics, something which I strongly support.</p>
<p>One thing which could get more attention in the context of functional programming is the concept of <a href="https://en.wikipedia.org/wiki/Total_functional_programming">Total Functional Programming</a>, which uses the concepts of <strong>total functions</strong> combined with specific types of recursion in order to guarantee that all your programs terminate.  Astute readers will note that this means, since the <a href="https://en.wikipedia.org/wiki/Halting_problem">Halting Problem</a> is not decidable over Turing machines, that a Total Functional Programming language is not <a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing Complete</a>.  In practical use, this is not an undesirable property and in fact systems written in Turing complete languages are often restricted to be Turing incomplete by, for example, adding termination conditions to programs so that they do not run indefinitely.  If you&rsquo;ve ever been working on some kind of numerical program and added something like <code>if loopCounter &gt; limit then return</code> in order to stop a loop which has sufficiently converged, you have done exactly this.</p>
<p>Another benefit of Total Functional Programing arises due to the <a href="https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry-Howard Isomorphism</a>, which tells us that programs are representations of mathematical proofs, and therefore if we had a Turing complete language in which these programs (proofs) did not terminate then we would have significant logical inconsistencies.  In the total functional programming context, these consistencies are avoided.  This can have some nice implications from the theoretical computer science perspective.</p>
<p>In practical terms though, the benefits of Total Functional Programming, or at least making sure that functions are always total, is that software is more likely to be correct, easier to reason about, and because its construction will be more rigorous we can assume that the results will be of a higher quality.  This is especially important in certain classes of systems, but as these tools are becoming more available and known to more developers it makes sense to use them where appropriate.  Total functional programming comprises two design aspects, total functions and limited recursion.</p>

<h1 id="total-functions" class="anchor-link"><a href="#total-functions">Total functions</a></h1>
<p>A <strong>total function</strong> is a function which is defined for all elements of its domain.  This is in contrast to a <strong>partial function</strong> which is defined only on a subset of its domain.  As an example, division as an operation is not total because it is not defined for $0 \in \mathbb{R}$.  However, the division function can be made total by specifying a return value for 0.</p>
<p>The <a href="https://wiki.haskell.org">Haskell wiki</a> has a page specifically devoted to <a href="https://wiki.haskell.org/Avoiding_partial_functions">avoiding partial functions</a> which is worth a read.</p>
<p>The benefit to keeping your functions total where possible (and it&rsquo;s almost always possible) is that you can eliminate the problem of functions returning values for which there is no proper definition or handling, because the function is defined on all possible values in its domain.  In strong and statically typed languages, this allows for the compilers to provide lots of extra support in developing error-free programs since you can have the type checker confirm your functions are not doing to end up in some undefined or error state.  The Haskell wiki is helpful when it comes to further examples of non-total functions:</p>
<p>A good example of this is <code>head</code>. You shouldn&rsquo;t use this function or write functions like it. The problem is in the type, it says <code>[a] -&gt; a</code> which is actually impossible as far as total functions are concerned. Why? Because you might have an empty list! Instead, a more honest type that lets you write a total function would be <code>[a] -&gt; Maybe a</code>. This makes the possibility of not getting a result more explicit and keeps your functions total.</p>
<p>Another way, besides adding further definitions for elements in your domain for which your function is not defined, would be to exclude those elements from the domain of your functions altogether and to have this exclusion be enforced by the type system.  This is possible with <a href="https://en.wikipedia.org/wiki/Refinement_(computing)#Refinement_types">Refinement Types</a>, which are essentially just types paired with some type of predicate that causes a compile-time error when not satisfied.  Note, refinement types are related to <a href="https://en.wikipedia.org/wiki/Liskov_substitution_principle">Behavioral Subtyping</a> (Liskov Substitution Principle, the L in <a href="https://en.wikipedia.org/wiki/SOLID_(object-oriented_design)">SOLID</a>).  For the example of the division operator, we could simply exclude 0 as a valid element from the domain of our function.  This is straightforward, as you can see in this example using Liquid Haskell:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75715e">{-@ divide :: Int -&gt; {v: Int | v != 0 } -&gt; Int @-}</span>
</span></span></code></pre></div><p>Simply by making all your functions total, you make huge amounts of progress along the path of more stable and correct programs.  So do it.</p>
<p>
<img class="enclosure" src="/static/images/benStiller_doit.jpg" alt="Starsky and Hutch meme &lsquo;Do it!&rsquo;"  />
</p>

<h1 id="restricted-recursion" class="anchor-link"><a href="#restricted-recursion">Restricted recursion</a></h1>
<p>This point is a bit more subtle, but necessary in order to achieve guaranteed termination of programs.  In order for this termination to occur, we must ensure that there is no infinite recursion.  There are a few ways to go about this, the simplest of which is probably <strong>substructural recursion</strong>, which is simply writing functions which only recurse on a subset of the data structure on which it operates (that is, only using <a href="https://en.wikipedia.org/wiki/Primitive_recursive_function">primitive recursive</a> functions).  So in the case of a list, the recursion will always occur on a subset of the original list.  As an example, if you were summing the even elements of a list then you could do it in the following way (in Haskell):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Haskell" data-lang="Haskell"><span style="display:flex;"><span><span style="color:#a6e22e">sumEven</span> <span style="color:#f92672">::</span> [<span style="color:#66d9ef">Int</span>] <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">Int</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">sumEven</span> <span style="color:#66d9ef">[]</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">sumEven</span> (x<span style="color:#66d9ef">:</span>xs)
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">|</span> even x <span style="color:#f92672">=</span> x <span style="color:#f92672">+</span> sumEven xs
</span></span><span style="display:flex;"><span>	<span style="color:#f92672">|</span> otherwise <span style="color:#f92672">=</span> sumEven xs
</span></span></code></pre></div><p>Note also that the way you&rsquo;d implement this in idiomatic Haskell would probably be to simply use :code:<code>sumEven = sum $ filter even</code>, which in the end comes down to a right fold:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Haskell" data-lang="Haskell"><span style="display:flex;"><span><span style="color:#a6e22e">sumEven&#39;</span> <span style="color:#f92672">::</span> [<span style="color:#66d9ef">Int</span>] <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">Int</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">sumEven&#39;</span> <span style="color:#f92672">=</span> foldr (<span style="color:#f92672">+</span>) <span style="color:#ae81ff">0</span> <span style="color:#f92672">.</span> filter even
</span></span></code></pre></div><p>And also note that the implementation of <code>foldr</code> in the <a href="https://hackage.haskell.org/package/base-4.8.1.0/docs/src/GHC.Base.html#foldr">Haskell Prelude</a> uses the standard form of substructural recursion with a helper function, traditionally called <code>go</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Haskell" data-lang="Haskell"><span style="display:flex;"><span><span style="color:#a6e22e">foldr</span> k z <span style="color:#f92672">=</span> go
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">where</span>
</span></span><span style="display:flex;"><span>		go <span style="color:#66d9ef">[]</span>     <span style="color:#f92672">=</span> z
</span></span><span style="display:flex;"><span>		go (y<span style="color:#66d9ef">:</span>ys) <span style="color:#f92672">=</span> y `k` go ys
</span></span></code></pre></div><p>Note also that the <code>foldr</code> implementation is tail recursive while our original <code>sumEven</code> implementation is not.</p>
<p>
<img class="enclosure" src="/static/images/xkcd_tailRecursion.png" alt="XKCD comic &lsquo;Functional&rsquo;"  />
<br>
<em>XKCD: <a href="https://www.xkcd.com/1270/">https://www.xkcd.com/1270/</a></em></p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>With only these two techniques, we can make use of the benefits of total functional programming.  Compile-time checking that functions will never encounter any arguments for which they aren&rsquo;t defined, and confirmation that all computations are terminating, can bring huge amounts of safety and reliability to software.  These tools and techniques exist widely and are easy to use in all languages, so there&rsquo;s really no reason not to make use of them wherever you can.  It will completely eliminate runtime errors of that sort.  Are your functions total?  If not, why not?</p>
 ]]></content:encoded></item><item><title>Hooked: How to Build Habit-Forming Products</title><link>https://adamdrake.com/hooked-how-to-build-habit-forming-products.html</link><pubDate>Wed, 02 Sep 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/hooked-how-to-build-habit-forming-products.html</guid><description>&lt;p>I recently finished a book called &lt;a href="https://www.nirandfar.com/hooked/">Hooked: How to Build Habit-Forming Products&lt;/a> by Nir Eyal. The book overall expresses a nice framework for considering products and services, whether or not they should be habit-forming in the first place, and if so how to go about making that happen. The framework is very useful in that it allows for organizations to have a common language they can use to speak about their product and how they should modify or improve it. Below are my notes on a per-chapter basis, and I may follow this with another post summarizing my thoughts on the book and considerations for companies who need to add recurring users, reduce churn, and other common things.&lt;/p></description><content:encoded><![CDATA[ <p>I recently finished a book called <a href="https://www.nirandfar.com/hooked/">Hooked: How to Build Habit-Forming Products</a> by Nir Eyal.  The book overall expresses a nice framework for considering products and services, whether or not they should be habit-forming in the first place, and if so how to go about making that happen.  The framework is very useful in that it allows for organizations to have a common language they can use to speak about their product and how they should modify or improve it.  Below are my notes on a per-chapter basis, and I may follow this with another post summarizing my thoughts on the book and considerations for companies who need to add recurring users, reduce churn, and other common things.</p>

<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>The key idea is to be first to mind (e.g., Google).</p>
<p>To have an effect on frequency, a tech product must be attached to internal triggers.</p>
<p>Link the product to daily routines and emotions.</p>
<p>
<img class="enclosure" src="/static/images/hookedCycle.jpg" alt="The Hook Model"  />
</p>
<p>Triggers can be internal or external.  The goal is to start with external ones and progress to internal.</p>
<p>It&rsquo;s important to make it easy to perform actions.  Usability design is a big part of this step.</p>
<p>Variable rewards come as a result of actions.  There should be the possibility of a reward, but not the guarantee.</p>
<p>Investments are required as the final step.  Users must put something into the product or service.  These investments can be grouped into time, data, effort, social capital, or money.  The investment should improve the product or service through the next cycle.  Some examples could be inviting friends, stating preferences, building virtual assets, or learning to use new features.</p>
<p>Habits are undertaken with little or no conscious thought.</p>

<h1 id="chapter-1---the-habit-zone" class="anchor-link"><a href="#chapter-1---the-habit-zone">Chapter 1 - The Habit Zone</a></h1>
<p>Companies selling infrequently-used products do not require habitual users.  Companies with rare interactions are better off acquiring customers via marketing budget.</p>
<p>The point is to help companies who incite user action via habits, not companies who compel customer actions via other means.</p>
<p>Habits are good because they increase Customer Lifetime Value, provide pricing flexibility because customers become less price sensitive, and can reinforce a free-to-play or freemium model.</p>
<p>When people have habits, they involve their social circle.</p>
<p>Viral cycle time: The time required for one user to invite another user.</p>
<p>Habits enhance competitive advantage because people are unlikely to change their habits and therefore unlikely to change providers of the habitual product or service.</p>
<p>Consider habits as a strategic decision.  Amazon shows ads for competitors on their site because they want users to go to Amazon when they want a product.  This forms user habits and Amazon makes money on the transaction as well.</p>
<p><strong>Consumers prefer retailers who provide comparisons.</strong> (Thirfts, Valerie, and Haendol: Information Availability and Consumer Preference, Journal of Consumer Psychology, 2003, 149-59)</p>
<p>Is your product a vitamin or a painkiller?  Vitamins do not solve an obvious pain point and appeal to emotional rather than functional needs.  Painkillers solve an obvious need, relieving a specific pain, and they have quantifiable markets.</p>
<p>Habits are not in themselves addictions.  Additions are by definition self-destructive in nature.</p>
<p>Summary:</p>
<p>Not every business requires habitual engagement.</p>

<h2 id="questions" class="anchor-link"><a href="#questions">Questions</a></h2>
<ul>
<li>
<p>What habits does your business model require?</p>
</li>
<li>
<p>How do users currently solve that problem and why must it be solved in the first place?</p>
</li>
<li>
<p>How frequently do you expect users to engage with the product?</p>
</li>
<li>
<p>What user behavior do you want to make into a habit?</p>
</li>
</ul>

<h1 id="chapter-2---trigger" class="anchor-link"><a href="#chapter-2---trigger">Chapter 2 - Trigger</a></h1>
<p>Habits start with external triggers, which are embedded with information which tells the users what to do next.</p>

<h2 id="external-triggers" class="anchor-link"><a href="#external-triggers">External triggers</a></h2>
<ul>
<li>
<p>Paid Triggers: advertising, SEM.  Use paid triggers for acquisition and use other triggers to bring users back because paid triggers can become to expensive (if users interact with the product regularly).</p>
</li>
<li>
<p>Earned Triggers: good PR, viral videos, featured app store placement.  Awareness from earned triggers is typically short-lived and therefore companies who use them must work to always keep the product in the limelight.</p>
</li>
<li>
<p>Relationship Triggers: Word of mouth, sharing, etc.</p>
</li>
<li>
<p>Owned Triggers: These consume space in the user&rsquo;s environment.  E.g., app icon on the home screen, app update notification.  Owned triggers prompt repeat engagement until a habit is formed.  <strong>Without owned triggers and tacit permission it&rsquo;s difficult to change user behavior.</strong></p>
</li>
</ul>

<h2 id="internal-triggers" class="anchor-link"><a href="#internal-triggers">Internal triggers</a></h2>
<p>These manifest automatically in your mind.  Connecting internal triggers to the product is the overall goal.</p>
<p>Emotions, particularly negative ones, are powerful internal triggers.  Boredom, loneliness, frustration, anxiety are good examples.</p>
<p>Studies have linked depressive symptoms with email usage, video watching, gaming, and chatting online.</p>
<p>When building your product for triggers, the ultimate goal of the habit-forming product is to ease the user&rsquo;s pain by creating an association so the user identifies the product with removing the pain.</p>
<blockquote>
<p>&ldquo;We often think the internet enables you to do new things&hellip;But people just want to do the same things they&rsquo;ve always done.&rdquo;
&ndash; Evan Williams</p>
</blockquote>
<p>Declared preferences are what users say they want.</p>
<p>Revealed preferences are what users actually want.</p>
<p>Instagram photos you see in Facebook are a relationship external trigger.</p>

<h2 id="questions-1" class="anchor-link"><a href="#questions-1">Questions</a></h2>
<ul>
<li>
<p>Who is your intended user?</p>
</li>
<li>
<p>What are they doing right before the habit?</p>
</li>
<li>
<p>What are three possible internal triggers?</p>
</li>
<li>
<p>Which internal trigger is most frequent?</p>
</li>
<li>
<p>Every time a [internal/external trigger] then the user [first action of habit].</p>
</li>
<li>
<p>Consider places or times the user is in when the desired habit could be build.  What might be places and times to send an external trigger?</p>
</li>
<li>
<p>How can you couple an external trigger as closely as possible to when the user&rsquo;s internal trigger fires?</p>
</li>
<li>
<p>Think of three conventional external triggers, then three crazy or impossible ones.</p>
</li>
</ul>

<h1 id="chapter-3---action" class="anchor-link"><a href="#chapter-3---action">Chapter 3 - Action</a></h1>
<p>To initiate action, doing must be easier than thinking.</p>
<p>Three ingredients to initiate a behavior:</p>
<ul>
<li>
<p>User must have sufficient motivation.</p>
</li>
<li>
<p>User must have the ability to complete the desired action.</p>
</li>
<li>
<p>The trigger must be present to activate the behavior.</p>
</li>
</ul>
<p>A trigger cues an action, motivation is the energy for the action. (see Dr. Edward Deci, Professor of Psychology at University of Rochester)</p>
<p>Fogs argues there are three core motivators:</p>
<ul>
<li>
<p>Seek pleasure, avoid pain.</p>
</li>
<li>
<p>Seek hope, avoid fear.</p>
</li>
<li>
<p>Seek social acceptance, avoid rejection.</p>
</li>
</ul>
<p>From Something Really New: Three Simple Steps to Creating Truly Innovative Products (by Hauptly):</p>
<ul>
<li>
<p>Understand why people use some product or service.</p>
</li>
<li>
<p>Lay out steps they must take to get a job done.</p>
</li>
<li>
<p>Start removing steps until you have the simplest possible process.</p>
</li>
</ul>
<blockquote>
<p>Take a human desire, preferably one that has been around for a really long time&hellip;Identify that desire and use modern technology to take out steps.
&ndash; Evan Williams (co-founder of Twitter and Blogger)</p>
</blockquote>
<p>Fogg Six Elements of Simplicity:</p>
<ul>
<li>
<p>Time: How long it takes to complete an action.</p>
</li>
<li>
<p>Money: Final cost of taking an action.</p>
</li>
<li>
<p>Physical Effort: Labor involved in taking an action.</p>
</li>
<li>
<p>Brain Cycles: Level of mental effort and focus involved in taking an action.</p>
</li>
<li>
<p>Social Deviance: How accepted is the behavior by others?</p>
</li>
<li>
<p>Non-routine: How much does the action disrupt existing routines?</p>
</li>
</ul>
<p>On the question of starting with motivation or ability, <strong>ALWAYS</strong> choose ability.  Ease of use is the most important thing.  If people are motivated but don&rsquo;t have the ability, then the product is useless.</p>
<p>Cognitive biases are more important than rational economics.</p>
<p>Scarcity Effect: Use this to drive action and sense of urgency.  Show available stock if less than X units, for example.</p>
<p>Framing Effect: Higher costs for a product provide the user with a better sense of enjoyment.</p>
<p>Anchoring Effect: Consider one brand on sale with a higher price-per-unit cost.</p>
<p>Endowed Progress Effect: Punch card with 8 spots versus one with 10 spots and two which are pre-punched.  People receiving the 10 spot card (with two pre-punched) started with a sense of progress and therefore had an 82% higher completion rate.  There is increased motivation as people believe they are nearing completion of a goal.  This effect can be useful as part of an on-boarding process.</p>

<h2 id="questions-2" class="anchor-link"><a href="#questions-2">Questions</a></h2>
<ul>
<li>
<p>Go through the path a user takes after a trigger.  How many steps does it take?  How does it compare with other competing or non-competing products and services for ease of use?</p>
</li>
<li>
<p>Which resources are limiting user&rsquo;s ability to accomplish tasks that become habits?  Time, brain cycles, money, social deviance, physical effort, non-routine?</p>
</li>
<li>
<p>Find three testable ways to make intended tasks easier to complete.</p>
</li>
<li>
<p>How might you apply heuristics to make habit-forming actions more likely?</p>
</li>
</ul>

<h1 id="chapter-4---variable-reward" class="anchor-link"><a href="#chapter-4---variable-reward">Chapter 4 - Variable Reward</a></h1>
<p>The nucleus accumbens doesn&rsquo;t activate on receiving a reward, but on the anticipation of receiving a reward.  In other words, it&rsquo;s not the reward but the need to alleviate the craving for a reward which is motivating.</p>
<p>Skinners pigeons pressed the levers more times when the pellet was given after a random number of presses. (did they, on average, have to press more times in order to receive a pellet though?)</p>
<p>Three types of variable rewards:</p>
<ul>
<li>
<p><strong>Tribe</strong> - Social media is anticipation of acceptance by the tribe.</p>
</li>
<li>
<p><strong>Hunt</strong> - Persistence hunting was used before weapons and may explain some of our product interactions.  Computer gambling and slot machines are a good example of a hunt reward.  Twitter and Pinterest may function in the same way.</p>
</li>
<li>
<p><strong>Self</strong> - Pursuing a task to completion can influence people to continue many behaviors.  Consider jigsaw puzzles.  Rewards of the self are intrinsic.</p>
</li>
</ul>
<p>The self-determination theory of Deci and Richard Ryan espouses that people desire, among other things, to gain a sense of competency.  Adding an element of master to this goal makes the pursuit all the more exciting.</p>
<p>Examples of this sense of competency and completion could be video games (e.g., World of Warcraft), email (reducing the number of messages in the inbox as a goal), or places like Codeacademy.</p>
<p>Rewards must fit into the narrative of why the product is used and align with the user&rsquo;s internal motivations and triggers.</p>
<p>Companies that successfully change behaviors present users with an implicit choice between their old way of doing things and a new, more convenient way of doing things.</p>
<p>Experiences with finite variability become predictable and therefore less engaging for users.</p>
<p>Variable rewards must satisfy users&rsquo; needs while leaving them wanting to reengage, usually via the tribe, hunt, or self.  Email uses all three in that uncertainty over who is sending the message and what it contains, or opportunities/threats to possessions or livelihood combined with social obligation to respond to be seen as agreeable and the uncertain nature and motivation to control it cover all the types.</p>
<p>When autonomy is threatened we feel constrained by lack of choices and often rebel against a new behavior.  Psychologists call this reactance.  Maintaining a sense of user autonomy is necessary for repeat engagement.</p>
<p>Experiences that maintain user interest by sustaining variability with use are better because people don&rsquo;t get bored and variable rewards are better than consistent ones from a psychological perspective.</p>

<h2 id="do-this-now" class="anchor-link"><a href="#do-this-now">Do this now</a></h2>
<ul>
<li>
<p>Talk with five customers in open-ended interactions in order to find out what they find enjoyable or encouraging about using the product.  Are there any moments of delight or surprise?  Is there anything they find particularly satisfying about using the product?</p>
</li>
<li>
<p>Review the steps required for a customer to use the product or service habitually.  What outcome (reward) alleviates the user&rsquo;s pain?  Is the reward fulfilling, yet leaves the user wanting more interaction with the product?</p>
</li>
<li>
<p>Brainstorm three ways your product might heighten users&rsquo; search for variable rewards using rewards of the tribe, hunt, and self.</p>
</li>
</ul>

<h1 id="chapter-5---investment" class="anchor-link"><a href="#chapter-5---investment">Chapter 5 - Investment</a></h1>
<p>To change or form a habit, we need frequency and a change in attitude or perception about the habit.</p>
<p><strong>Escalation of commitment</strong> is the idea that the more users invest time and effort into a product or service, the more they value it.  In fact, there is ample evidence to show that labor leads to love.</p>
<p>The IKEA effect (Ariely): The phenomenon wherein people place greater value on things simply because they invested in their own creation.</p>
<p>We seek to be consistent with our past behaviors.</p>
<p>Small investments can lead to big changes in future behaviors (e.g., Tiny Habits).</p>
<p><strong>Cognitive dissonance</strong> is avoided because we change our perception of reality.  Consider the fable of the fox that cannot reach the grapes and decices therefore that they must be sour.</p>
<p>The previous three things together have an influence on future actions.</p>
<p>Rationalization is a powerful thing.  This effort must be worthwhile simply because I&rsquo;m making it, and I&rsquo;m not stupid, so I wouldn&rsquo;t be investing effort in something which isn&rsquo;t worthwhile.</p>
<p>Unlike the Action step in Chapter 3, Investment is about long-term rewards instead of immediate gratification.</p>
<p>The investment phase counterintuitively involves friction, <strong>but</strong> this friction always comes <strong>after</strong> the variable reward.</p>
<p>The main idea with Investment is to leverage a user&rsquo;s understanding that the product or service will get better through personal use and through their investment.</p>
<p>The investment phase is the time to load the next trigger.  E.g., interactions with Pinterest give the site tacit permission to contact the user regarding updates to pins or conversations.  The same goes for Instagram.</p>

<h2 id="do-this-now-1" class="anchor-link"><a href="#do-this-now-1">Do this now</a></h2>
<ul>
<li>
<p>Review your flow.  What bit of work are users doing which increases the likelihood of returning?</p>
</li>
<li>
<p>Brainstorm three ways to add small investments to the product in order to load the next trigger, store value as data, content, followers, reputation, and skill, and to identify how long it takes for a loaded trigger to reengage your users.  How can you reduce this delay in order to reduce cycle time?</p>
</li>
</ul>

<h1 id="chapter-6---summary" class="anchor-link"><a href="#chapter-6---summary">Chapter 6 - Summary</a></h1>
<p>What do your users really want (internal trigger)?</p>
<p>What brings users to your service (external trigger)?</p>
<p>What is the simplest action users can take in anticipation of a reward and how can you simplify the product to make this action easier (action)?</p>
<p>Are users fulfilled by the reward and yet left wanting more (variable reward)?</p>
<p>What bit of work do users invest in the product?  Does it load the next trigger and store value to improve the product with use?  (investment)</p>
<p>Ethics of the model can be determined by understanding whether you would use the product and whether or not the product will help users materially improve their lives.</p>
<p>Using these two questions, you can group yourself into the set of facilitators, peddlers, entertainers, or dealers.</p>
<p>Facilitators use their own product and believe it can materially help improve the lives of others.</p>
<p>Peddlers don&rsquo;t use their product but still believe it can help others.</p>
<p>Entertainers use their product but don&rsquo;t believe it materially helps others.</p>
<p>Dealers neither use the product, nor believe it helps others.</p>
<p>Consider where you fall.  How does that make you feel?  Ask yourself if you&rsquo;re proud of the way you influence the behavior of others.</p>

<h1 id="chapter-7---case-study-bible-app" class="anchor-link"><a href="#chapter-7---case-study-bible-app">Chapter 7 - Case Study: Bible App</a></h1>
<p>No notes.</p>

<h1 id="chapter-8---habit-testing-and-where-to-look-for-habit-forming-opportunities" class="anchor-link"><a href="#chapter-8---habit-testing-and-where-to-look-for-habit-forming-opportunities">Chapter 8 - Habit Testing and Where to Look for Habit-Forming Opportunities</a></h1>
<p>No notes.</p>
 ]]></content:encoded></item><item><title>A Quick Overview on the Kaggle Competition for Avito</title><link>https://adamdrake.com/a-quick-overview-on-the-kaggle-competition-for-avito.html</link><pubDate>Fri, 31 Jul 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/a-quick-overview-on-the-kaggle-competition-for-avito.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>I didn&amp;rsquo;t have much time for this competition, so didn&amp;rsquo;t invest much into feature engineering, creating ensembles or other things. As I participated in the &lt;a href="https://www.kaggle.com/c/avazu-ctr-prediction">Avazu competition&lt;/a> as well, which included the use of &lt;a href="https://www.kaggle.com/c/avazu-ctr-prediction/forums/t/10927/beat-the-benchmark-with-less-than-1mb-of-memory">tinrtgu&amp;rsquo;s now-famous code&lt;/a>, I decided to use the same approach here.&lt;/p>
&lt;h1 id="background" class="anchor-link">&lt;a href="#background">Background&lt;/a>&lt;/h1>
&lt;p>The overall goal of the competition is to analyze user behavior in order to generate a model for recommending ads to be shown in front of users, with the success metric being whether or not the user clicks on the ad. There is already a lot of work on this topic, so there is no need to rebuild everything from scratch.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>I didn&rsquo;t have much time for this competition, so didn&rsquo;t invest much into feature engineering, creating ensembles or other things.  As I participated in the <a href="https://www.kaggle.com/c/avazu-ctr-prediction">Avazu competition</a> as well, which included the use of <a href="https://www.kaggle.com/c/avazu-ctr-prediction/forums/t/10927/beat-the-benchmark-with-less-than-1mb-of-memory">tinrtgu&rsquo;s now-famous code</a>, I decided to use the same approach here.</p>

<h1 id="background" class="anchor-link"><a href="#background">Background</a></h1>
<p>The overall goal of the competition is to analyze user behavior in order to generate a model for recommending ads to be shown in front of users, with the success metric being whether or not the user clicks on the ad.  There is already a lot of work on this topic, so there is no need to rebuild everything from scratch.</p>
<p>If you haven&rsquo;t read the paper from Google on <a href="./static/ad-click-prediction-a-view-from-the-trenches.pdf">FTRL for ad prediction</a> and their view <em>from the trenches</em> then I can really recommend that as a first step.  They deal with all the topics we find in application, like sparsity, constraints on hardware, constraints on processing times, and so on.  For anyone who has also developed <a href="https://en.wikipedia.org/wiki/Real-time_bidding">real-time bidding</a> systems for <a href="https://en.wikipedia.org/wiki/Demand-side_platform">demand-side platforms</a> or <a href="https://en.wikipedia.org/wiki/Supply-side_platform">supply-side platforms</a> or other ad prediction systems this will probably be very familiar.</p>
<p>The data provided by Avito for the competition consisted of a sequence of views, including information on the user, ads they had seen, any possible requests to contact the seller, and so on.  The data size didn&rsquo;t present any particular challenges if you use online methods as I did, as the main data file of search information is about 10GB uncompressed and contains approximately 400 million records.  If you want to look further into ways to speed up the learning process, check out <a href="https://researcher.watson.ibm.com/researcher/files/us-dpwoodru/chw.pdf">Sublinear Optimization for Machine Learning</a> by Clarkson et. al.</p>

<h1 id="implementation" class="anchor-link"><a href="#implementation">Implementation</a></h1>
<p>The implementation was fairly quick as the solution is a known one for which Python code already exists.  As is often the case, Abishek <a href="https://www.kaggle.com/c/avito-context-ad-clicks/forums/t/14516/beating-the-benchmark">posted a solution</a> to beat the benchmark.  This solution took some time to run since it depends on NumPy and Pandas, which precludes my typical usage of <a href="">PyPy</a> for Python code needing a bit more performance.  It is easy to get around this with some decoupling, so I split the parts depending on NumPy and Pandas into a separate file thus enabling PyPy to be used for the performance-intensive code and the other code to be run separately.</p>
<p>The main code, which can be run by PyPy, consists of defining an ftrl object in addition to a couple of methods for fitting, predicting, and updating.  Nothing crazy.</p>

<h1 id="building-a-test-set" class="anchor-link"><a href="#building-a-test-set">Building a test set</a></h1>
<p>If you want to assemble a test set to benchmark against locally, the following method seems to correlate very well with the score on the public leader board.</p>
<p>From the <a href="https://www.kaggle.com/c/avito-context-ad-clicks/forums/t/15367/proper-validation-set/86077#post86077">avito competition</a> :</p>
<ol>
<li>
<p>Take the minimum date that occurs in the test set (May 12?).</p>
</li>
<li>
<p>Take all LAST sessions for each user that happens after that date (or sample it). The last session is the one with highest date for each user.</p>
</li>
</ol>
<p>This problem has a time component, so sampling from other periods of time won&rsquo;t do, since it is expected that ads change over time. Randomly sampling wont do, since it will get a bigger proportion of users that has many sessions. If we take anything but the last (or n last) sessions from user we will leave the user future in the training set, so cv wont match because of overfit. Bottom line: In the data page it says that they take the last session for each user that happens after may 12. So we just need to do the same (as close as it gets)!</p>

<h1 id="comments-from-another-competitor" class="anchor-link"><a href="#comments-from-another-competitor">Comments from another competitor</a></h1>
<p>Andrew Ostapets, who placed 9th in competition had the following to say on the approach:</p>
<blockquote>
<p>My single ftrl model with basic features: AdID, UserID, IPID, Position, Price, â€¦ + the second- and the third-order interactions between some of this features + scores similarity between SearchQuery and Title and SearchParams and Params. It gets Public LB score below 0.044.</p>
<p>Adding to this model only one new feature <code>PositionFactor</code> from my teammate Alexander. It gave the incredible increments and the model scored ~ 0.0418 on Public LB.</p>
<p><code>PositionFactor = hash( [Position 1_place:ObjectType 2_place:ObjectType 6_place:ObjectType 7_place:ObjectType 8_place:ObjectType])</code> , where <code>Position</code> is the position of the given context ad in search result page. <code>k_place:ObjectType</code> is the position and type others ads in search result page (if there are data about them).</p>
<p>Alexander&rsquo;s models vw+xgb and vw+rf give him ~ 0.0424 on Public LB</p>
<p>After tuning hyperparameters and finding the weights for linear combination of our solutions we achieved 0.04137 on Public LB.</p>
</blockquote>

<h1 id="from-a-5th-place-finisher" class="anchor-link"><a href="#from-a-5th-place-finisher">From a 5th place finisher</a></h1>
<p>Gilberto Titericz Junior was 5th place and used this method as described by Dmitry Efimov:</p>
<blockquote>
<p>I used something similar in the Avazu contest, if you are interested, you can check my presentation <em>(link no longer available)</em> about the solution (there are some slides about Batch FTRL). The principle is to sort combined dataset (train and test) by some fields and apply the FTRL algorithm. Then it will work in the following way: the algorithm is trained on the first batch from the train set and make prediction on the first batch from the test set. Then it starts training on the second batch from the train set starting from coefficients from the first batch and so on.</p>
</blockquote>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>This was an interesting and fun competition, and a good proving ground for new ideas and approaches.  I wrote up an implementation in Go which I may package as a library and put on GitHub at some point.  Until then, here is a forked gist from <a href="https://github.com/ceshine">ceshine</a> of the implementation from another competition:</p>
<!-- raw HTML omitted -->
 ]]></content:encoded></item><item><title>Transitioning to a Data-Driven Organization</title><link>https://adamdrake.com/transitioning-to-a-data-driven-organization.html</link><pubDate>Sun, 12 Jul 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/transitioning-to-a-data-driven-organization.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>I gave a talk at the CDO Summit in Singapore on 18 June and thought it may be worthwhile to address some of the points and provide additional detail on the &lt;a href="https://speakerdeck.com/adamdrake/transformational-data-programs">slides I used&lt;/a>.&lt;/p>
&lt;p>Sections below are listed by slide content and provide extra explanation.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h1 id="kardashev-scale" class="anchor-link">&lt;a href="#kardashev-scale">Kardashev Scale&lt;/a>&lt;/h1>
&lt;p>This is simply applying the &lt;a href="https://en.wikipedia.org/wiki/Kardashev_scale">Kardashev Scale&lt;/a> of technological advancement to the advancement of data usage in organizations. For more detail see the article I wrote on &lt;a href="https://adamdrake.com/the-kardashev-scale-of-data-maturity.html">the Kardashev Scale of Data Maturity&lt;/a>.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>I gave a talk at the CDO Summit in Singapore on 18 June and thought it may be worthwhile to address some of the points and provide additional detail on the <a href="https://speakerdeck.com/adamdrake/transformational-data-programs">slides I used</a>.</p>
<p>Sections below are listed by slide content and provide extra explanation.</p>
<!-- raw HTML omitted -->

<h1 id="kardashev-scale" class="anchor-link"><a href="#kardashev-scale">Kardashev Scale</a></h1>
<p>This is simply applying the <a href="https://en.wikipedia.org/wiki/Kardashev_scale">Kardashev Scale</a> of technological advancement to the advancement of data usage in organizations.  For more detail see the article I wrote on <a href="/the-kardashev-scale-of-data-maturity.html">the Kardashev Scale of Data Maturity</a>.</p>

<h1 id="culture" class="anchor-link"><a href="#culture">Culture</a></h1>
<p>The main point of the talk is that no matter the data maturity of the organization, and no matter what kind of data strategy you have developed, the culture surrounding data (and the company culture more broadly) will be the deciding factor in whether or not the organization continues to progress in the usage of data.  To use the phrase often attributed to Peter Drucker:</p>
<blockquote>
<p><strong>&hellip;culture eats strategy for breakfast</strong></p>
</blockquote>
<p>Consider what this means for your organization.  Does it have the right culture?  If not, your data strategy probably isn&rsquo;t worth much.</p>

<h1 id="defend-forecasts-against-actuals" class="anchor-link"><a href="#defend-forecasts-against-actuals">Defend forecasts against actuals</a></h1>
<p>This topic is one that crushes the hearts of many people, and the question &ldquo;When was the last time you had to defend forecasts against actuals?&rdquo; got quite a few laughs and smiles at the conference.  The main point is that you can use that question as a proxy for the data maturity in an organization.</p>
<p>Do people expect the forecasts to be absolutely correct?  Is there ever discussion or acceptance of error bars around forecasts?  Forecasts are, after all, nothing but a guess, so they should be treated as such.  If your organization is having intense debates or asking for extensive justification about why any forecasts differ from actuals, then the culture in the organization simply <strong>is not ready</strong> to advance in terms of data usage.  Yes, certain things in businesses can be forecasted more accurately than others, and yes businesses with a long history of stable trends may be able to forecast accurately, but that doesn&rsquo;t change the fact that a forecast will necessarily have some kind of error.  Unless your business has those kinds of ultra-stable histories, having pointless debates when forecasts are within error bounds is downright toxic.  If you need to produce some kind of forecast to satisfy investors or other people, it&rsquo;s best to make an educated guess based on what kinds of business developments you expect in the pipeline, but that&rsquo;s definitely not a Data Science problem, it&rsquo;s a BI/FP&amp;A problem.</p>
<p>Some businesses deserve credit for trying to get around this problem with approaches like rolling forecasts (e.g. quarterly) which are always updated.  This resolves the problem in a great way because there is no budgeting at that point, only the rolling quarterly forecasts.  See <a href="https://www.amazon.com/Beyond-Budgeting-Managers-Annual-Performance/dp/1578518660">Beyond Budgeting</a> for more details.</p>

<h1 id="the-problem-with-painting-a-picture-of-data" class="anchor-link"><a href="#the-problem-with-painting-a-picture-of-data">The problem with painting a picture of data</a></h1>
<p>There were quite a few presenters at the conference who claimed that one of the primary functions of a CDO is to paint a picture of the data, to be a data champion, to help people understand all the great things which can be done with data, and so on.  While this is somewhat true, and may be very much the case in some industries, I&rsquo;ve found that the bigger problem is one of inflated expectations.  In other words, the picture has already been painted and it&rsquo;s very different than the reality.</p>
<p>This is extremely difficult to address, especially since a natural reaction of some non-technical people is to assume that the CDO or person trying to temper expectations is actually incompetent.  If your organization is going through data or technical leaders one after the other, the issue of overly-inflated expectations from CXOs or board members may be the root cause.</p>
<p>The underlying issue is that people who don&rsquo;t really know much about the details of implementing data programs and transforming organizations to use data more effectively are being <strong>bombarded</strong> with messaging from vendors and other non-technical people which states that (1) the company&rsquo;s data is worth a ton of money and that (2) the vendor can help the company to extract the value from this data in a very short time.</p>
<p>Often, the first point is wrong.  Sometimes data simply is not valuable.  However, the second point is almost always wrong.  Most vendors cannot help you solve your data problems since the problems are usually cultural issues which a vendor cannot change, or technical in a way that&rsquo;s specific to your organization and how it has developed over time.  The typical outcome from non-technical people talking with vendors is that the technical people in the organization will be frustrated because they must again tell non-technical people that what the vendor has promised as possible really isn&rsquo;t.  This causes a non-technical person to lose trust in technical colleagues, everyone to lose trust in the vendors, and results in a sour mood all around.</p>
<p>My suggestion is that non-technical people <strong>do not talk to vendors and do not forward them on to technical staff</strong>.  One job of technical staff is to stay abreast of the solutions available, and the only reason the vendors are talking to non-technical people is because non-technical people sign the checks or because non-technical people don&rsquo;t have the knowledge to fully understand the problem, therefore being easier to deceive.  It&rsquo;s better to just save everyone the trouble and frustration and not start those conversations in the first place.</p>
<p>A huge amount of time in the data space is wasted on trying to reduce other people&rsquo;s inflated expectations.  Please don&rsquo;t contribute to this by painting unrealistic pictures of data and its usefulness.</p>

<h1 id="the-devil-is-in-the-details" class="anchor-link"><a href="#the-devil-is-in-the-details">The devil is in the details</a></h1>
<p>As mentioned above, there are vendors selling all manner of solutions, most of which are not appropriate for your business.  The details about whether or not a solution will work for your business is the responsibility of the technical people in the business and should be treated as such.</p>
<p>I&rsquo;ve seen many businesses get sidetracked on projects, some of which have gone so far over time and over budget that the business has gone bankrupt, simply because a non-technical person was making decisions about technical products or projects.  This is often due to being promised things by a vendor.</p>
<p>I have personally been involved in the cleanup and aftermath of a non-technical Director of Product telling a technical team that they must use Hadoop to solve a certain problem because the business needs to work with <em>Big Data</em>.  The result was a 60 node cluster which was used for, among other things, processing a 360kb (yes, kilobytes) job.</p>
<p>In short, just because a vendor is telling you what you want to hear, doesn&rsquo;t make it true, and non-technical people dictating technical details of projects is a huge red flag.</p>

<h1 id="dont-sell-to-people-who-arent-buying" class="anchor-link"><a href="#dont-sell-to-people-who-arent-buying">Don&rsquo;t sell to people who aren&rsquo;t buying</a></h1>
<p>Taking a larger view of the whole topic for a moment, what is sometimes happening to data leaders in organizations is that they are trying to sell a topic or a dream to people who aren&rsquo;t interested in buying.  If someone isn&rsquo;t open-minded about the potential of data in your organization, and you have to paint an unrealistic picture in order to convince them, then you&rsquo;re contributing to the problems mentioned above.  In addition, you&rsquo;re also wasting your own time and energy and doing harm to the organization.</p>
<p>If you feel like you&rsquo;re having to sell to people who aren&rsquo;t buying, your best bet is to leave and go to an organization which values your abilities.  There are plenty of organizations who understand they need to advance their data capabilities, and it won&rsquo;t be you trying to sell that story to them, but them trying to sell you on why they provide you with the best opportunity to use and grow your data expertise.</p>

<h1 id="kardashev-scale-data" class="anchor-link"><a href="#kardashev-scale-data">Kardashev Scale (data)</a></h1>
<p>This references <a href="/the-kardashev-scale-of-data-maturity.html">the Kardashev Scale of Data Maturity</a> post which I wrote previously.</p>

<h1 id="from-type-2-to-type-3" class="anchor-link"><a href="#from-type-2-to-type-3">From Type 2 to Type 3</a></h1>
<p>This is an overview of a previous post I wrote on moving from <a href="/moving-from-type-2-to-type-3-data-organizations.html">Type 2 to Type 3 data organizations</a>.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>The CDO role should focus on real problems in the business (e.g., fraud detection, recommender systems, data quality, etc.) and not get bogged down in useless debates about forecasts versus actuals and so on.  There can be a BI or FP&amp;A team who handle those topics, and the policies and procedures for baseline business reporting are already settled business.  It&rsquo;s simply a matter of execution.  You probably don&rsquo;t need a CDO for that, and if you bring one in thinking that they will be a magic bullet then everyone will be frustrated.  Even worse, the CDO will probably become the whipping boy for any data problems of any kind.  Simply having a CDO <strong>does not</strong> eliminate data problems in an organization, it only puts the organization on a path to minimizing data problems and starting to have more data focus in products and services.</p>
<p>In the end, the focus must be on people more the processes (hello <a href="https://agilemanifesto.org">Agile Manifesto</a>) and there must be an understanding that cultural transformation and enablement of people to use data more effectively in their daily work is far more valuable to the business and its long-term health than some <em>quick wins</em> gained from addressing the <em>low-hanging fruit</em>.  The difficult part is that such changes are hard to measure and therefore may rarely, if ever, get the credit they deserve.</p>
<p>Good luck.</p>
 ]]></content:encoded></item><item><title>Makespan Minimization for Unrelated Parallel Machines with Maintenance Windows</title><link>https://adamdrake.com/makespan-minimization-for-unrelated-parallel-machines-with-maintenance-windows.html</link><pubDate>Wed, 27 May 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/makespan-minimization-for-unrelated-parallel-machines-with-maintenance-windows.html</guid><description>&lt;p>It&amp;rsquo;s a bit late, but last year during the Christmas break, &lt;a href="https://kaggle.com">Kaggle&lt;/a> had a &lt;a href="https://www.kaggle.com/c/helping-santas-helpers">very interesting competition&lt;/a> for the season. The story was that the toy list at Santa&amp;rsquo;s workshop was long, and elves had to make all the toys, with some constraints on their productivity rating and rest intervals. This is an adaptation of the classic problem of minimizing makespan, though with additional constraints. A good leaderboard position could be achieved using offline methods since the entire list of toys was supplied in advance, but as usual I pursued online solutions for fun and speed.&lt;/p></description><content:encoded><![CDATA[ <p>It&rsquo;s a bit late, but last year during the Christmas break, <a href="https://kaggle.com">Kaggle</a> had a <a href="https://www.kaggle.com/c/helping-santas-helpers">very interesting competition</a> for the season.  The story was that the toy list at Santa&rsquo;s workshop was long, and elves had to make all the toys, with some constraints on their productivity rating and rest intervals.  This is an adaptation of the classic problem of minimizing makespan, though with additional constraints.  A good leaderboard position could be achieved using offline methods since the entire list of toys was supplied in advance, but as usual I pursued online solutions for fun and speed.</p>
<p>The problem they described can be reformulated as online makespan optimization for unrelated parallel machines with maintenance windows.  For the moment we&rsquo;ll just consider some basic approaches in the offline case, and I may write something else in the future which covers more online methods.</p>
<p>The inspiration for the proofs below and notation, as well as a broader overview of these topics, is found in lecture notes from a class Albert and Souza gave on Combinatorial Algorithms at Humboldt-UniversitÃ¤t zu Berlin Institut fÃ¼r Informatik.</p>

<h1 id="problem-statement" class="anchor-link"><a href="#problem-statement">Problem statement</a></h1>
<p>Let&rsquo;s start by formalizing the problem a bit so we have a clear understanding of what&rsquo;s happening.</p>
<p>Assume we have a set of machines $M := \{1, \ldots, m\}$ and a set of jobs $J := \{1, \ldots, n\}$ where job $j \in J$ on machine $i \in M$ requires $p_{ij}$ time units for processing.  Further, let $J_i$ be the set of all jobs processed on machine $i$ and $c_j$ be the time at which job $j$ is completed.  Now define the <em>load</em> on machine $i$ as $\ell_i := \sum_{j \in J_i} p_{ij}$.  Also note the starting time of machine $i$ before the start of job $j$ as $s_j$.  The <em>makespan</em> is then equivalent to the maximum load $\ell_{max} = c_j = max_{i \in M} \ell_i$.</p>
<p>Our basic objective is to find an assignment of jobs such that the makespan is minimized.</p>
<p>Furthermore, assume that that we must produce items <em>without preemption</em>, which means once an item has begun production on a given machine that it must continue until completion on the same machine.</p>
<p>In addition to this, the competition also had further constraints on intervals in which machines could operate, and their productivity bonuses (or penalties) for operating at different times.  We&rsquo;ll get to those later.</p>
<p>Also note that an algorithm is an $\alpha$-approximation for a problem if and only if for every instance of the problem the algorithm produces a solution which is within a factor $\alpha$ of the optimal solution.  In our context we are dealing with minimization problems, so $\alpha \ge 1$ means that the solution found by the algorithm is at most $\alpha$ times the optimal solution.</p>
<p>For now, let&rsquo;s consider the most basic formulation of the problem in the offline environment where we are presented with the complete job list.</p>

<h1 id="base-case-identical-parallel-machines" class="anchor-link"><a href="#base-case-identical-parallel-machines">Base case: Identical Parallel Machines</a></h1>
<p>In this case, the machines are identical so the production cost/time of an item is the same regardless of which machine produces the item.  This basic formulation is known to be NP-Hard, even for two machines.  We can examine two approaches to this problem, the basic List Scheduling heuristic and next the Sorted List Scheduling/Least Processing Time (LPT) heuristic.</p>

<h2 id="list-scheduling" class="anchor-link"><a href="#list-scheduling">List Scheduling</a></h2>
<p>This is approach is straightforward.  Take the set of jobs $J$ in any order, and for each job $j \in J$ allocate the job to the machine $i \in M$ which has the smallest load $\ell_i$.</p>
<p>THEOREM: The List Scheduling algorithm is a 2-approximation for makespan scheduling on identical parallel machines.</p>
<p>PROOF: Let $T_{OPT}$ be the optimal makespan for a given instance of the problem.  We can show that $s_j \le T_{OPT}$ for all $j \in J$.  The implication then is that $c_j = s_j + p_j \le T_{OPT} + p_j \le 2 \cdot T_{OPT}$ for all $j \in J$ since it is necessarily true that for all $j \in J$ we have that $p_j \le T_{OPT}$.</p>
<p>By way of contradiction, assume there exists some $s_j \gt T_{OPT}$.  Then the load on machine $i$ before the assignment of job $j$ is $\ell_i \gt T_{OPT}$ for all $i \in M$.  Then all jobs $J^\prime \subseteq J$ scheduled before $j$ by the algorithm have total processing time $\sum_{j^\prime \in J^\prime}p_{j^\prime} \gt m \cdot T_{OPT}$.  However, since the optimum schedule finishes all jobs $J$ at time $T_{OPT}$ we knows that $\sum_{j \in J} p_j \le m \cdot T_{OPT}$, a contradiction leading to the conclusion that the List Scheduling algorithm must start all jobs such that for all $j \in J$ we have $s_j \le T_{OPT}.$  $\blacksquare$</p>

<h2 id="sorted-list-scheduling" class="anchor-link"><a href="#sorted-list-scheduling">Sorted List Scheduling</a></h2>
<p>This algorithms is similar to the one above, except that instead of simply taking the set of jobs $J$ in any order, we sort them in decreasing order by length.</p>
<p>THEOREM: The Sorted List Scheduling algorithm is a $3/2$-approximation for makespan scheduling on identical parallel machines.</p>
<p>PROOF: Let $T_{OPT}$ be the optimal makespan for a given instance of the problem.  Then partition the jobs into a set of <em>large</em> jobs $J_L = \{j \in J \colon p_j \gt \frac{T_{OPT}}{2} \}$ and a set of <em>small</em> jobs $J_S = J - J_L$.  Now notice that $|J_L| \le m$.  Assume by way of contradiction that there are more than $m$ such jobs, then in any schedule (including the optimal one) there must be at least two such jobs scheduled on the same machine.  Since the length a large job is more than $\frac{T_{OPT}}{2}$ this contradicts that $T_{OPT}$ is the optimal makespan.</p>
<p>Since there are at most $m$ large jobs and the algorithm schedules them first and on individual machines, we know that $\forall j \in J_L, c_j \le T_{OPT}$.  Therefore, if a job completes later than $T_{OPT}$ it must be a small job with length at most $\frac{T_{OPT}}{2}$.  Since all jobs start not later than $T_{OPT}$ we have that $\forall j \in J_S, c_j \le T_{OPT} + p_j \le \frac{3}{2} \cdot T_{OPT}$.  $\blacksquare$</p>

<h1 id="extended-case-unrelated-parallel-machines" class="anchor-link"><a href="#extended-case-unrelated-parallel-machines">Extended case: Unrelated Parallel Machines</a></h1>
<p>This case is the same as before, except that machines may not have the same rates of production.  This means that a given job $j$ the processing time may be different depending on which machine processes the job, and $p_{ij}$ denotes the processing time for job $j$ on machine $i$.</p>
<p>The basic approach for this case is to relax the integer programming constraints to linear ones, use binary search to find a smallest feasible solution to the linear program, and then round to obtain the integer programming solution.</p>
<p>The range for the binary search is established by first greedily scheduling each job on the machine with the smallest load $\ell_i$.  If $\alpha$ is the makespan of such a schedule, then the range for binary search is $[ \frac{\alpha}{m}, \alpha ]$.</p>
<p>Though this approach is more complicated, it can be shown that this is also a 2-approximation for the problem of makespan minimization on unrelated parallel machines.</p>
<p>The above examples are appropriate for the offline version of the problem where the list of items for production is known in advance, but does not touch at all upon the online case where the makespan must be optimized in a more streaming fashion.</p>

<h1 id="additional-problem-constraints" class="anchor-link"><a href="#additional-problem-constraints">Additional problem constraints</a></h1>
<p>In the competition as designed, there were more constraints on the problem, notably that elves can only work during certain hours, with penalties incurred for time spend working outside these ours and increases in productivity for time spent working within those hours.  This can be considered equivalent to the concept of maintenance windows for machines.</p>

<h1 id="the-winning-solution" class="anchor-link"><a href="#the-winning-solution">The winning solution</a></h1>
<p>The winners of the competition posted <a href="https://www.kaggle.com/c/helping-santas-helpers/discussion/12441">posted a writeup</a> <a href="https://storage.googleapis.com/kaggle-forum-message-attachments/63756/1971/writeup.pdf">(PDF)</a> of their solution with lots of depth and explanation.  They used a combination of techniques in addition to some observations about the data.  Definitely recommend reading for further details.</p>
 ]]></content:encoded></item><item><title>On Two-Sided Markets</title><link>https://adamdrake.com/on-two-sided-markets.html</link><pubDate>Tue, 03 Mar 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/on-two-sided-markets.html</guid><description>&lt;p>Many technology companies can be viewed in the context of a two-sided marketplace (TSM), a special case of a multi-sided marketplace (MSM). This view has interesting implications for the dynamics of the business in addition to how product strategy and prioritization is decided. Having worked for over 15 years in TSM environments from Online Travel, to Affiliate Marketing at Zanox, mobile ad network madvertise, and many years in Financial Services, I thought it might be useful to provide a conceptual overview of the markets, dynamics, and implications. Since TSMs are so ubiquitous among internet economy success stories, we can also learn a lot from the likes of Google, eBay, Airbnb, Etsy, Kickstarter, oDesk, iTunes, Netflix, Spotify, Facebook, and others.&lt;/p></description><content:encoded><![CDATA[ <p>Many technology companies can be viewed in the context of a two-sided marketplace (TSM), a special case of a multi-sided marketplace (MSM).  This view has interesting implications for the dynamics of the business in addition to how product strategy and prioritization is decided.  Having worked for over 15 years in TSM environments from Online Travel, to Affiliate Marketing at Zanox, mobile ad network madvertise, and many years in Financial Services, I thought it might be useful to provide a conceptual overview of the markets, dynamics, and implications.  Since TSMs are so ubiquitous among internet economy success stories, we can also learn a lot from the likes of Google, eBay, Airbnb, Etsy, Kickstarter, oDesk, iTunes, Netflix, Spotify, Facebook, and others.</p>

<h1 id="what-is-a-tsm" class="anchor-link"><a href="#what-is-a-tsm">What is a TSM?</a></h1>
<p>Any time you have two parties (often called buyer and seller) who are connected by some intermediary (often called a platform) you have a TSM.  They are everywhere and due to their growth dynamics via network effects and the rise of a more connected and technologically-driven society, TSMs are especially powerful and high-potential businesses.</p>
<p>Some of these TSMs, since their content is organized and supplied partially or completely by hand are not exactly TSMs but rather <em>curated marketplaces</em> (CMs).  Netflix is a good example of this because movie studios do not provide the supply themselves, but rather Netflix does it as a result of commercial license agreements.  Often, the goal of a CM is to add tooling and maturity to the point where it can become a successful TSM.  This allows for even more efficient growth of buyer and seller groups and lower operating costs for the platform.</p>

<h1 id="the-care-and-feeding-of-tsms" class="anchor-link"><a href="#the-care-and-feeding-of-tsms">The Care and Feeding of TSMs</a></h1>
<p>When a TSM is first established, there is a classic chicken and egg problem.  You need buyers to have a USP for sellers and vice versa, so which comes first?  There are various ways to solve this problem.  We will not address that here, since the growth dynamics after this initial stage are most important for us.  When a TSM is first formed, it can rapidly rise to a dominant position, and the natural equilibrium state of the market is either a complete monopoly on the service provided or a shared platform arrangement with multiple options.</p>

<h1 id="monopoly-approach" class="anchor-link"><a href="#monopoly-approach">Monopoly Approach</a></h1>
<p>The dominant/monopoly approach requires a few things in order to be successful.  First, it only works in markets where multi-homing costs, meaning the cost of participating in multiple platforms, is high for buyers and sellers.  This makes sense, because if it were easy to use multiple platforms then buyers and sellers would constantly participate in multiple platforms.</p>
<p>In addition to high multi-homing costs, there must also be strong and positive effects for buyers and sellers for participating in the market.  More buyers must attract more sellers and vice versa, forming a very strong positive feedback loop leading to the rapid growth of the market.</p>
<p>In relation to that, there must also be limited ability to differentiate.  In other words, the market environment must be restrictive enough that it would not make sense to build additional platforms.</p>
<p>Clearly in the Online Travel space, the monopoly approach is not sufficient, primarily due to relatively low multi-homing costs, usually around billing information.  As a buyer, using multiple platforms just isn&rsquo;t very difficult.</p>
<p>In addition, a TSM which looks to be tending toward the monopoly situation is higher in risk due to the winner-take-all nature of that environment.  The risk is high for many, and the reward is only high if you are the dominant player.</p>

<h1 id="open-platform-approach" class="anchor-link"><a href="#open-platform-approach">Open Platform Approach</a></h1>
<p>This option is different from the one above, largely due to underlying commoditization of many aspects of the platform.  Credit cards are a good example here, with multiple large players (Visa, MasterCard, American Express, Discover, etc.) in the space.  The reason is that multi-homing costs are extremely low and ability to differentiate is high (points, cash back, limits, and so on).</p>
<p>This is similar to the situation in Online Travel, where the underlying products are often interchangeable.  Flights are a good example of this, as people are typically more sensitive to price than other things about a flight.  The multi-homing costs of using multiple platforms are effectively zero, mostly just the time required to supply your billing and contact details to purchase tickets.  Pricing is a critical component of TSMs as one side is often subsidized at the expense of the other, and we will now discuss the implications of having a subsidized side of the market.</p>

<h1 id="monetizing-two-sided-markets" class="anchor-link"><a href="#monetizing-two-sided-markets">Monetizing Two-Sided Markets</a></h1>
<p>The saying goes that you can&rsquo;t serve two masters, but in a TSM that&rsquo;s exactly the goal.  Buyers and sellers both expect to benefit from participation in the market, and this often comes in the form of subsidized participation for one side.  For example, when I was working with madvertise Mobile Advertising, a mobile ad network (which is a TSM between app developers and advertisers), the subsidized participant was the app developer.  The level of subsidy was sometimes significant and for a while we even had 1 million Euros set aside which we spent on revenue sharing with app developers, solely for the purpose of attracting more supply into the TSM.  In the online travel space, it&rsquo;s the traveler who is the subsidized end of the TSM.  Do you know of any online travel site which requires the user to pay in order to buy a ticket?</p>
<p>In addition to one side being a subsidized participant, it&rsquo;s also normal that the same side is extremely price sensitive.  If they do not like the cost, they will simply change platforms, which is easy because multi-homing cost is effectively nil.  Since price sensitivity is such a large factor in the subsidized end of a TSM, this could cause one market to have lower prices which would lead to users changing markets, and a price war to erupt.  This leads to the question of the difference between what buyers are willing to pay, sellers are willing to accept, and the fundamental topic of any TSM: <em>liquidity</em>.</p>

<h1 id="the-most-important-thing" class="anchor-link"><a href="#the-most-important-thing">The Most Important Thing</a></h1>
<p>Now that we&rsquo;ve built up a bit of background, we can get the real meat of the dynamics of a TSM.  In the context of a TSM, liquidity is the ability to efficiently match supply and demand with limited impact to the underlying price.  In the online travel space, increased ability to buy a ticket for a given route at any time, without the transaction influencing the price of the ticket, implies higher liquidity in the market.  Liquidity is the defining success metric of a TSM, and is the reason buyers and sellers participate in a TSM in the first place.  If you couldn&rsquo;t buy or sell what you wanted, or you could only do so with extreme swings in price, the market wouldn&rsquo;t be very useful for you.</p>
<p>Keeping in mind that liquidity is the cornerstone of a TSM, and the subsidized end of the market is so extremely price sensitive, we can think about what more or less liquidity in a TSM would look like and how this liquidity changes the underlying price of the goods in the TSM.</p>
<p>Since sellers have a minimum price they are willing to accept for their good, and buyers want to pay as little as possible (recall they are the subsidized end of our TSM), the effect of increased liquidity is actually that the sale price becomes closer to the seller&rsquo;s minimum acceptable price.  In other words, margins for sellers go down to the point where it just barely makes financial sense for them to continue to operate.  You could think of this as a kind of equilibrium price for the good in the TSM.  There is really no way around this, other than for sellers to differentiate themselves, something hard to accomplish in a somewhat commoditized market, or for sellers to attempt to bypass the TSM entirely and form direct relationships with buyers.  This latter situation, commonly referred to as <em>disintermediation</em> is to some extent a risk for all TSMs that do not continue to provide maximum possible liquidity.</p>
<p>In addition to the shrinking margin result that can arise in the absence of supplier differentiation, another effect of increased liquidity in TSMs is how prices react in changes to supply of goods and what the distribution of prices looks like from a long-term perspective.  If you consider that sellers are competing with each other for buyers (which they always do because we never have perfect liquidity) then that means that sellers are forced to drop their prices in order to stay competitive (because the subsidized party in our TSM is extremely price sensitive).  This is a kind of race to the bottom, with the result being that prices quickly reach their equilibrium state, which is the lowest price sellers are willing to accept.  However, the process of reaching this baseline price is in direct proportion to the amount of liquidity in the market.  In other words, the more liquidity the market has, the more uniform the prices become and the faster all prices adjust to a single sellers changing their price.</p>
<p>So if you want to have a highly-advanced TSM, that means you need as much liquidity as possible, which you can measure by how tightly prices for the same good are clustered in addition to how fast prices adjust.  To use a concrete example in online travel, if every ticket for the same route costs more or less the same, and a change in price from one airline or OTA causes very fast price matching among others, the market is highly liquid.</p>
<p>So high liquidity means tightly-clustered prices and fast adjustments to price changes.  Low liquidity means dispersed prices and slow adjustments to price changes.</p>

<h1 id="what-does-it-all-mean" class="anchor-link"><a href="#what-does-it-all-mean">What does it all mean?</a></h1>
<p>In order to build a successful TSM, and increase liquidity as much as possible, the TSM must provide the tooling and environment in the marketplace to support buyers and sellers in finding the best matches.  There are many examples of product improvements along these lines, and they generally involve providing increased information to both sides.  This information efficiency, the cornerstone of the Efficient Market Hypothesis is closely related to liquidity, which we are trying to maximize.</p>
<p>Regardless of which approaches are taken in order to increase liquidity in the TSM, we must have some ways of measuring progress.  This could be something as simple as looking at the price fluctuations for the same good in combination with how tightly clustered prices are for comparable items.  This will reflect directly on the amount of liquidity in the market, and depending on what the distribution of prices looks like it could be a very revealing KPI for the business.  Perhaps the only one which really matters in a TSM.</p>
 ]]></content:encoded></item><item><title>Moving from Type 2 to Type 3 Data Organizations</title><link>https://adamdrake.com/moving-from-type-2-to-type-3-data-organizations.html</link><pubDate>Sun, 15 Feb 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/moving-from-type-2-to-type-3-data-organizations.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>In the previous post on the Kardashev scale for data organizations we discussed the three general types and their characteristics, but didn&amp;rsquo;t dive deeply into how to make the move from Type 2 to Type 3 (the move from Type 1 to Type 2 doesn&amp;rsquo;t really require much explanation).&lt;/p>
&lt;p>The move from Type 2 to Type 3 requires more focus on data and how it integrates into the product (including developing totally new products) and a departure from focusing on the data organization as a service unit. It also implies that the infrastructure and tools are in place for people to look into data on operational metrics themselves and that they do not require the expertise of a dedicated BI group.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>In the previous post on the Kardashev scale for data organizations we discussed the three general types and their characteristics, but didn&rsquo;t dive deeply into how to make the move from Type 2 to Type 3 (the move from Type 1 to Type 2 doesn&rsquo;t really require much explanation).</p>
<p>The move from Type 2 to Type 3 requires more focus on data and how it integrates into the product (including developing totally new products) and a departure from focusing on the data organization as a service unit.  It also implies that the infrastructure and tools are in place for people to look into data on operational metrics themselves and that they do not require the expertise of a dedicated BI group.</p>
<p>All of these changes require the appetite within the organization in addition to people who are willing to be distributed within the organization in an effort to help educate and enable non-technical people to use data and tooling effectively.  I mostly discuss the organizational and people side of this problem as the technical side is a much easier problem to solve and has much clearer criteria for success.</p>

<h1 id="think-distributed" class="anchor-link"><a href="#think-distributed">Think distributed</a></h1>
<p>As organizations grow, assuming they want to maintain fast growth and flexibility, the desire to completely control anything centrally should decrease.  Instead, organizations should decentralize where possible, leading to semi-autonomous groups all working towards the same goal.  This approach also helps people to maintain a sense of independence and responsibility in addition to the growth and focus benefits.  Since the previous centralized approach is no longer viable for sufficiently large organizations progressing along the Type 2 to Type 3 spectrum, the approach to how data is used within the organization must also become decentralized.</p>
<p>The extreme end of this of course would be that every employee is also a data scientist, but since this is obviously impractical the focus becomes on building basic data literacy within the organization and commoditizing basic data needs while freeing up specialists to work on more valuable topics.  The goal of the enablement effort is that every employee has the possibility to do basic data collection and analysis in addition to having the critical thinking skills required to interpret and think about data problems effectively.</p>
<p>In order to do this, it is critical that disparate teams have the specialist support they need.  This means that the centralized data function should be distributed to the extent possible, and begin to engage in an education and awareness campaign with the broader organization.  The goal of this campaign must be to change the perception on data from a Central Services approach to something for which everyone is responsible and capable of handling.</p>
<p>It was not so long ago that organizations went through the progression of single typist, to centralized group of typists, to distributed typists, to everyone in the organization being responsible for their own typing.  Imagine the reaction if any modern organization still maintained a centralized typing staff.  Should a sufficiently advanced organization with a strictly centralized Data team be viewed any differently?</p>

<h1 id="winning-hearts-and-minds" class="anchor-link"><a href="#winning-hearts-and-minds">Winning hearts and minds</a></h1>
<p>In theory, the organization will have evolved to a point where there is a large appetite for using data more effectively.  However, this is often coupled with a desire for people to minimize the work that they are doing alone.  In other words, they want all the benefits of increased data usage and literacy but without having to do any additional work themselves.  This is a difficult challenge because progress along the Type 2 to Type 3 spectrum requires that individuals in the organization are able to access and analyze data independently.  This does not actually add to their workload as they might think, but rather decreases the time they spend waiting for results and therefore improves their ability to make decisions.  So even though people may think they will have more work to do, they will likely end up more productive than they were previously due to few delays and context switches.</p>
<p>Helping people become more data literate requires a huge amount of persistence from those actually doing the teaching and enabling.  They are at the front line of the effort, and therefore must approach the problem with compassion, patience, and a non-adversarial attitude.  In the end it&rsquo;s about building relationships with teams and helping them become more independent users of data in their daily work.</p>
<p>In order to build these relationships it is best to have data specialists embedded within the teams of the organization in order to provide support throughout the process, to reduce the latency between issues arising and being resolved, and to eliminate any remaining perception within the company that there is a centralized data function to which they can delegate any collection or analysis they do not want to do themselves.</p>

<h1 id="identify-requirements" class="anchor-link"><a href="#identify-requirements">Identify requirements</a></h1>
<p>The first step in the winning of hearts and minds is to simply have productive discussions with the team in which the data specialist is embedded.  It is always important to first understand the problem teams want to solve and what kinds of decisions they need to make before discussing any particulars of data which could be collected or analyzed.  Throughout this process of discovery it is also critical to provide different perspectives on data usage wherever possible.  Things like helping people understand how to use the right kind of data for the right kind of decision begin in this phase and continue throughout all interactions.</p>
<p>A favorite example of mine that should be addressed during this phase is the Data-Decision Frequency Gap.  People are often of the opinion that more data will allow them to make better decisions, but due to things like noise in the data, and cognitive biases in humans (which are <em>very</em> extensively documented) it is known that providing more data than is needed to make a decision may lead to worse outcomes than if the data was not available at all.  Simply helping people understand that there is no requirement to receive data at a frequency higher than they will make decisions, and all of the associated reasoning for that, is one example of a topic which can be very helpful in improving data literacy and usage.</p>

<h1 id="automate-where-practical" class="anchor-link"><a href="#automate-where-practical">Automate where practical</a></h1>
<p>Once the discussions have produced basic requirements in terms of what kinds of decisions need to be made and what kind of data is needed to support those decisions, it is helpful to automate the collection and processing of the data.  Much of this is too complicated and unnecessary for non-technical people, but is an absolutely required step in moving data specialists away from the service-based role common in early and mid-stage Type 2 organizations.</p>
<p>In addition to automating the required collection and processing of the data, it is highly likely that there were other tasks for which data specialists were previously responsible that have not been discussed in the requirements analysis.  These tasks can be stopped, thus freeing up additional time for data specialists to work on more relevant and beneficial things.</p>
<p>The result of this step should be that anything which was previously required by the team before the data specialist was embedded and was still deemed required after the initial discussions has been automated, and work on any other data collection analysis activities now understood to be unnecessary have been stopped.  This should result in a dramatic reduction in recurring workload, thus allowing the data specialist to provide support and education to the team.  The goal should ultimately be that basic ad hoc and exploratory data questions can be answered by people individually, but this requires additional tools and help from the data specialist.</p>

<h1 id="tooling-and-support" class="anchor-link"><a href="#tooling-and-support">Tooling and support</a></h1>
<p>Now that the team understands what they need, and they have automated processes for things done in the past, the data specialist can help educate the team on tooling and provide ongoing support.  The ongoing support responsibilities should lessen over time as the team becomes more data literate, but may never disappear entirely.</p>
<p>This effort is largely focused on helping people in the team become proficient in accessing the data in which they are interested and in helping train them how to do common reporting tasks which take up most of their time.  The majority of all work in non-technical teams (and arguably much in technical data teams as well) is some twist on taking a set of data, grouping it in some way, and doing some kind of aggregations, typically over some time interval.  Assuming the data is not excessively large or complicated, this is very simple to do in a standard relational database.  The knowledge of SQL required to accomplish these kinds of tasks is very limited and can be learned by non-technical people in a relatively short time.  Having this knowledge allows them to dramatically increase their self-sufficiency for common reporting tasks, and also provides them with the power to engage in basic exploratory analysis directly on the data.  By not having to rely on others to answer questions for them, people can reap enormous benefits with just a little time invested.</p>
<p>With the above in mind, education at this stage should be on basic SQL needed to address the problems the team wants to solve in addition to any education needed for dashboard creation tools which may be used.  Depending on the company culture, there may be resistance from some about learning SQL, typically combined with the claim that they are not technical people and therefore should not need to learn technical things.  Leaving aside to the moment the question of whether or not the organization would want to continue working with someone opposed to learning new things, that position just doesn&rsquo;t make sense.  In a similar way to the typists example mentioned previously, in order for organizations to advance in the way data is used there must be basic capability in most of the people to work with data.  Helping people understand that basic SQL is not so difficult and that they will have huge benefits in independence and productivity by knowing it may help to encourage them, but some will always resist.  Do not focus effort on helping these people.  You can&rsquo;t push a string.  The best hope is that seeing their peers who have learned be more productive and capable will encourage them in to improve their basic data skills.</p>

<h1 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h1>
<p>After going through the process above, the result should be teams that understand basic principles for how to collect and analyze the data they need to make decisions in the course of their work.  There should no longer be massive reliance on a centralized data team, although more advanced data problems will naturally require specialists.  The overall data literacy and capabilities of the organization should have advanced significantly as a result of the process, with associated reduction in ad hoc requests to data specialists and time data specialists spend on recurring reporting tasks.</p>
<p>All of these things support the transition towards a Type 3 data organization, and help build the momentum for the transition by freeing up time of data specialists.  These specialists are then able to spend more time working on advanced data topics, including building prototypes and products for external customers in addition to further improving the depth and breadth of their own technical knowledge.</p>
<p>With enough persistence, the data literacy within an organization can be improved considerably.  When combined with improved tooling and infrastructure, the ability of people to understand and make decisions about the business can rapidly become a competitive advantage.  This process, more than anything currently being discussed in the industry (Big Data, Cloud Computing, etc.) is what has the promise to rapidly accelerate the pace of innovation in modern organizations.  It&rsquo;s not about the technology, it&rsquo;s about the people.</p>
 ]]></content:encoded></item><item><title>On Schemas</title><link>https://adamdrake.com/on-schemas.html</link><pubDate>Sun, 15 Feb 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/on-schemas.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>Over the last few years, some people have come to see schemas of any type as a legacy hinderance which should generally be ignored, and much of the NoSQL fervor that gained momentum around 2010 was related to this. The promise was that not having schemas would set you free and that you would become more productive, agile, your application would be faster, and all kinds of other things. Some of this may have been true for web applications or APIs backed by a single data store, in a relatively small company or team, but it&amp;rsquo;s an entirely different matter when talking about distributed data processing systems.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>Over the last few years, some people have come to see schemas of any type as a legacy hinderance which should generally be ignored, and much of the NoSQL fervor that gained momentum around 2010 was related to this.  The promise was that not having schemas would set you free and that you would become more productive, agile, your application would be faster, and all kinds of other things.  Some of this may have been true for web applications or APIs backed by a single data store, in a relatively small company or team, but it&rsquo;s an entirely different matter when talking about distributed data processing systems.</p>
<p>In reality, schemas serve a very necessary function when systems need to start talking to each other as schemas define a clear contract between systems.  This allows for distributed data processing systems to grow in a reasonable way, reduces errors throughout the data pipeline, and can provide far more flexibility and development speed than if the messages between systems had no schema at all.  Additionally, this is critical when you don&rsquo;t have complete knowledge of which consumers will actually be using your service.  Whether you call it API documentation, service description, or you have a solid interface definition with Protocol Buffers or Avro, schemas are absolutely necessary for data in motion.</p>

<h1 id="everything-has-a-structure-anyway" class="anchor-link"><a href="#everything-has-a-structure-anyway">Everything has a structure anyway</a></h1>
<p>If you are pushing data between systems, in the vast majority of cases the data has some kind of structure.  There are certain classes of unstructured data, like video, audio, or images, but typically at least the metadata about them is structured.  Given this fact, when any two systems want to communicate they must be able to move the data around by speaking the same language, and this language is the schema.</p>
<p>If you don&rsquo;t have a schema on the message itself, what ends up happening is that the producer has the schema embedded implicitly in its codebase (in order to verify it&rsquo;s sending correct and complete messages) and the receiver of the message also has the schema implicitly embedded in its codebase (also to check for correctness and completeness).  This is bad enough, but when other receivers are added the situation gets even worse as each receiver must implement its own implicit schema in the codebase.  The result being that instead of simply making the schema explicit and shared among all senders and receivers, the schema is implicit and possibly inconsistent across the distributed system.</p>

<h1 id="enter-message-schemas" class="anchor-link"><a href="#enter-message-schemas">Enter message schemas</a></h1>
<p>When we talk about message schemas we are in a different context than a schema for a database table.  The reason being that for applications that want to communicate with the database, each one must implement the schema (this part is the same) but in the case of databases there is often no simple ways to extend or modify the schema without disruption for clients.  You could argue that views achieve this, but we are talking about the situation where the underlying table structure needs to change.</p>
<p>The interruptions to clients can be significant, but are often things like downtime of the database, or slowness due to changing fields in a table with lots of data, or other things.  For example, consider the way that Percona, a high-performance and high-availability version of MySQL, addresses the problem of adding columns to tables (i.e., changing the schema) with the <a href="https://www.percona.com/doc/percona-toolkit/2.1/pt-online-schema-change.html">pt-online-schema-change</a> tool:</p>
<blockquote>
<p>pt-online-schema-change works by creating an empty copy of the table to alter, modifying it as desired, and then copying rows from the original table into the new table. When the copy is complete, it moves away the original table and replaces it with the new one. By default, it also drops the original table.</p>
</blockquote>
<p>There are additional concerns when the table you want to change contains foreign keys, but that&rsquo;s even more operationally complex.  These difficulties with database schemas can be avoided in message schemas implemented with Protocol Buffers, Avro, and other message serialization formats.  The reason for this is that with Protocol Buffers for example, when best practices are followed a producer can extend the schema with additional optional fields at any time, with no impact on the downstream consumers whatsoever.  This is a huge difference, because adding a column to a database table can be a potentially dangerous process by comparison.</p>

<h1 id="schemas-and-distributed-systems" class="anchor-link"><a href="#schemas-and-distributed-systems">Schemas and distributed systems</a></h1>
<p>As systems grow larger, with more producers and consumers, protections on message correctness become even more important.  There are just simply more ways to form an incorrect message than a correct one, and unless you want to implement a lot of this correctness checking by hand, and spend a lot of time sorting out errors due to malformed messages, it makes sense to have schemas on all messages.  This line of reasoning is typically countered with the position that having schemas on messages will reduce flexibility for developers and cause dependencies.  There are two reasons that the statement is incorrect.</p>
<p>First, if a producer is producing messages and a consumer is consuming those messages then that producer and consumer have a dependency regardless of whether or not there is a schema on the message.  The two components simply cannot function properly without each other, so pretending there isn&rsquo;t some inherent dependency there can lead to poor design decisions, especially in systems with strong volume, frequency, or latency requirements.</p>
<p>Second, the flexibility argument shows a lack of understanding as the message schemas are different from schemas in a database.  The reason for this is that, as mentioned, the message schemas can be easily extended as needed to support product goals and this extension can be done independently of other producers or consumers.  Other producers can still produce with the same old schema and older consumers can still consume using the old version of the schema.  Any new fields simply won&rsquo;t be accessible to the consumers until they update to use the new schema version.</p>

<h1 id="json-does-not-count" class="anchor-link"><a href="#json-does-not-count">JSON does not count</a></h1>
<p>There are many people who argue that having the messages in JSON format is good enough and even preferable to other formats as the message are human-readable.  It is true that they are human readable, but I don&rsquo;t see that as a big enough benefit.  The number of times your message are read by humans is absolutely dwarfed by how often they are processed by machines.</p>
<p>Additionally, JSON simply is not descriptive enough in terms of field types to provide a good definition of messages.  Is that numeric field an integer or a float?  Are you implementing a lot of checking on the producer or consumer to make sure the message fields are of the correct type, length, and so on?  If so, your approach to schemas needs improvement.  If you cannot ensure basic data quality and consistency, your distributed system will inevitably encounter more problems than necessary, and distributed data processing systems have enough complexity as it is.</p>

<h1 id="have-no-fear" class="anchor-link"><a href="#have-no-fear">Have no fear</a></h1>
<p>The bad reputation of schemas in the last years is very unfortunate as they are a critical components of any well-functioning distributed system.  I have a general requirement when building distributed systems that all data in motion must have a schema, because the simple fact is that it has some structure when it is produced, and it lands somewhere with some structure, so having many components in between, each of which could possibly corrupt the data, doesn&rsquo;t make any sense.  Without clear contracts between message producers and consumers, the implicit schemas in every codebase become unmanageable, error prone, and impossible to update effectively, leading to severe degradation in development speed and overall system quality and stability.  This doesn&rsquo;t typically show up early in the development of a distributed system, or in small teams or codebases, or those with very few components, but since the complexity of a distributed system increases at a multiple much larger than the increase in components it becomes a critical problem.</p>
<p>Message schemas are not a bad thing (nor are database schemas when properly implemented) so use them wisely and reap the benefits of increased interoperability, stability, and extensibility of your distributed data processing system.</p>
 ]]></content:encoded></item><item><title>The Kardashev Scale of Data Maturity</title><link>https://adamdrake.com/the-kardashev-scale-of-data-maturity.html</link><pubDate>Mon, 12 Jan 2015 00:00:00 +0000</pubDate><guid>https://adamdrake.com/the-kardashev-scale-of-data-maturity.html</guid><description>&lt;h1 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h1>
&lt;p>For those who have read or seen much science fiction, you have probably encountered the &lt;a href="https://en.wikipedia.org/wiki/Kardashev_scale">Kardashev Scale&lt;/a> at some point. This is a general grouping of how advanced a civilization is based on the ways it utilizes energy. At the risk of reiterating what&amp;rsquo;s already on Wikipedia:&lt;/p>
&lt;blockquote>
&lt;p>The Kardashev scale is a method of measuring a civilization&amp;rsquo;s level of technological advancement, based on the amount of energy a civilization is able to utilize. The scale has three designated categories called Type I, II, and III. A Type I civilization uses all available resources impinging on its home planet, Type II harnesses all the energy of its star, and Type III of its galaxy.&lt;/p></description><content:encoded><![CDATA[ 
<h1 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h1>
<p>For those who have read or seen much science fiction, you have probably encountered the <a href="https://en.wikipedia.org/wiki/Kardashev_scale">Kardashev Scale</a> at some point.  This is a general grouping of how advanced a civilization is based on the ways it utilizes energy.  At the risk of reiterating what&rsquo;s already on Wikipedia:</p>
<blockquote>
<p>The Kardashev scale is a method of measuring a civilization&rsquo;s level of technological advancement, based on the amount of energy a civilization is able to utilize. The scale has three designated categories called Type I, II, and III. A Type I civilization uses all available resources impinging on its home planet, Type II harnesses all the energy of its star, and Type III of its galaxy.</p>
</blockquote>
<p>This classification may be interesting for civilizations, but it can also be applied to companies and how they use data.  Below I provide a general outline of what such a scale could look like, based on my experiences.</p>

<h1 id="type-1" class="anchor-link"><a href="#type-1">Type 1</a></h1>
<p>This type of company uses data for essential needs, effectively covering legal and tax requirements.  There usually aren&rsquo;t any dedicated data roles in such a setting beyond basic bookkeeping or accounting.  A company at this stage can operate within the required legal boundaries, but does not use data for understanding current or future products, services, or business operations.  In the case of a small business using cash based accounting, they can effectively satisfy these requirements using their bank statements.  Most sole proprietorships and many small businesses fall into this category.</p>

<h1 id="type-2" class="anchor-link"><a href="#type-2">Type 2</a></h1>
<p>Type 2 organizations are where things start to become more interesting.  Companies of this type have a strong focus on operational reporting and while some specific data skills are required, they are typically surrounding accounting, controlling, financial reporting, and similar areas.  Capabilities of the organization are typically limited to understanding past business operations (inherited from Type 1) but the ability to answer questions about current business operations is sometimes limited.</p>
<p>The collection and analysis of data is still heavily manual at this stage, although some areas of automation may have taken hold.  There is typically a Business Intelligence, reporting, or similar team that may use spreadsheets or possibly relational databases in order to answer questions posed by the business.  There is little or no technology and tooling in place which allows others in the business to explore data themselves.  The reporting tasks are largely reactionary, with the exception of periodic reporting requests like quarterly financials for board meetings, weekly reports for the product organization, and similar things.</p>
<p>At this stage there is little or no significant and widespread use of data as a product in itself, especially since the manual nature of the reporting tasks would make such a product difficult to support and scale.  There may be an increased focus on producing dashboards for management, even though what they are calling dashboards are likely to be overly complicated and provide limited real effectiveness when it comes to actually making decisions.</p>
<p>There is an increasing focus, and often more of an obsession, with metrics and KPIs as businesses progress through this type.  The reason is that the business is confounding data and usable information.  It ignores or is unaware of the fact that the data volumes and varieties are growing faster than the abilities of people to draw useful conclusions from simply examining all possible data sources.  This often results in little trust in the data, so all of the collection and analysis activities are for naught as managers actually making decisions continue to trust their intuition more than the data.  This is their fault in fact, because they are demanding data that isn&rsquo;t useful for the decisions in the first place.</p>
<p>This stage incurs <strong>significant</strong> operational cost, as it usually is accompanied by some kind of data warehouse (DWH), although often in name only, and therefore may require a significant IT effort to design and support.  In the later stages of this type the DWH becomes a constraint as it does not support the rapidly-changing business and product requirements.  The DWH will still function for ongoing reporting but will likely be of limited use for product metrics.  This creates an additional rift between the DWH team, the Business Intelligence team, and the rest of the organization, as everyone blames everyone else for lack of timely, accurate, and usable data.</p>
<p>In addition to operational overhead in terms of systems, there is also typically large fragmentation in the data landscape at this stage, with ineffective silos, often containing data relating to the same operational metrics.  This results in endless discussion and arguments about which data is correct, and also incurs additional operational cost due to having multiple copies of the same data around.  This situation is often the result of not modifying the data infrastructure when performance problems arise.  This is typically in the context of trying to perform reporting or analysis on an operational data store, which causes problems due to load.  This results in portions of the data (or the whole data store) being replicated to another place for reporting purposes.  This replica invariably ends up also becoming the back-end for some product, and the process continues leading to silos within silos and a massive web of data dependencies.  To make matters worse, the data typically undergoes transformation at each split/level and due to replications often in place this means that data changes upstream may cause massive discrepancies as the changed data trickles downstream.  What may be worse is when the changed data never flows downstream at all, which is often worse as it leaves the overall system in an inconsistent state.</p>
<p>Overall this stage is the most common one companies inhabit, and most companies get stuck here.  This results in a great deal of frustration and friction within the organization, especially between a BI/reporting team and the rest of the company as they are often seen as a poorly-performing bottleneck.  Conversely the BI/reporting team is often very demotivated by the manual and repetitive nature of the work, and the fact that their efforts are often in vain due to the tendency to favor intuition over conclusions supported by data.  In the end, the company is expending <em>enormous</em> amounts of effort to try to analyze data and use it for decisions, but they simply haven&rsquo;t moved on from the finance/reporting-based data practices.  Their heart is in the right place, success requires a different approach and perhaps most importantly dedicated leadership and expertise on transitioning an organization from Type 2 to Type 3.</p>

<h1 id="type-3" class="anchor-link"><a href="#type-3">Type 3</a></h1>
<p>For companies of this type, data is being used to inform the future actions of the company.  The company likely has a Chief Data Officer or similar role, this person is involved at the highest levels of the organization, and data is seen as a first-class citizen within the company.  People are using the data and systems to answer questions like what should we build, which ways can we package data as a product to users or customers, what is predicted value of some metric or KPI for the next months, and similar.  Emphasis is on predictive and prescriptive rather than descriptive analytics because the latter has typically been fully automated and is democratized to the point where historical and relevant information is available to all employees on demand.  In other words, accurate historical data has been commoditized.</p>
<p>In organizations of this type, the BI/reporting team focuses more on <strong>decision support</strong> instead of simply handling data requests, and is transitioning to more of a Data Science function.  Decision support means that the team is involved from early stages and provides analytics expertise to solve a business problem or question instead of simply providing raw data (which is never really the goal of the person requesting the data anyway).  Reporting and ad hoc requests previously handled by the BI team are now part of a self-service platform so any employee can analyze the data, and everything supporting the self-service platform is automated (collection, storage, preprocessing).</p>
<p>The self-service platform is typically not a traditional data warehouse with a fixed schema and there is less effort on supporting data infrastructure used solely for reporting purposes.  Data products start to be built which incorporate a small collection and analysis layer integrated into the current data infrastructure, a central component doing some kind of analytics or modeling, and a thin API to be used by the rest of the product portfolio or by customers directly.  In the case of external customers this can be an entirely separate revenue stream or product line of data products specifically, and in the case of internal customers this can allow for divisions or functions to build their own systems that utilize data for the right purposes.  In this way, the development of data products can also be distributed.</p>
<p>The business starts to trust the data and use it to inform future decisions, and will typically defer to the data even in cases where it runs counter to intuition (human factors should always provide a sanity check of course).  Additionally, as the organization starts to progress further along the Type 3 spectrum, the development of products becomes even more distributed to the point that disparate teams, divisions, or units are incorporating data into their current product portfolio or building entirely new products on top of the data sources now available to them.  There is still likely to be a centralized data team or teams which handles some architecture topics, provides guidance and best practices, and can act as internal consultants to the divisions, but at the far end of this spectrum much of the pure product development happens in a distributed fashion.</p>

<h1 id="summary" class="anchor-link"><a href="#summary">Summary</a></h1>
<p>Similar in the way Kardashev described human civilizations progressing along a continuum based on energy usage, we can think of organizations progressing along a continuum based on their data usage.  To make the transitions between different types, organizations require strategic commitment from the top as the culture surrounding data usage and the future of data will dominate any decisions or initiatives made at the middle-management layer.  Data and how it&rsquo;s used is simply too personal of a topic to find success without support from the top.</p>
<p>It should also be noted that organizations hoping to make these transitions must accept that change is often uncertain and typically not as easy as everyone hopes.  As long as continuous progress is being made, and the general direction is clear, senior leaders can maintain support for the efforts and help carry the company into the data-driven organization they want it to become.</p>
<p>
<img class="enclosure" src="/static/images/nevergiveup_neversurrender.jpg" alt="Tim Allen as Commander Taggart in Galaxy Quest with quote &lsquo;Never give up. Never surrender.&rsquo;"  />
</p>
 ]]></content:encoded></item><item><title>The Goal and the Theory of Constraints</title><link>https://adamdrake.com/the-goal-and-the-theory-of-constraints.html</link><pubDate>Thu, 25 Dec 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/the-goal-and-the-theory-of-constraints.html</guid><description>&lt;h3 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h3>
&lt;p>I was recently having a conversation about metrics and KPIs in a company, with the aim of finding out the things important to the company and ultimately designing an &lt;a href="https://en.wikipedia.org/wiki/Loss_function">objective function&lt;/a> for the business. This objective function is then used to determine which factors are important for the success of the business and therefore can result in the design of a closed-loop &lt;a href="https://en.wikipedia.org/wiki/Control_system">control system&lt;/a> that can serve as a way to run and optimize the business. In the course of this conversation, the other person asked me if I had read &lt;a href="https://en.wikipedia.org/wiki/The_Goal_%28novel%29">The Goal&lt;/a>, and I replied that I had not. They recommended it because it covers topics like the purpose of a business, how to find things to optimize, and what kind of process can be used for such optimization.&lt;/p></description><content:encoded><![CDATA[ 
<h3 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h3>
<p>I was recently having a conversation about metrics and KPIs in a company, with the aim of finding out the things important to the company and ultimately designing an <a href="https://en.wikipedia.org/wiki/Loss_function">objective function</a> for the business.  This objective function is then used to determine which factors are important for the success of the business and therefore can result in the design of a closed-loop <a href="https://en.wikipedia.org/wiki/Control_system">control system</a> that can serve as a way to run and optimize the business.  In the course of this conversation, the other person asked me if I had read <a href="https://en.wikipedia.org/wiki/The_Goal_%28novel%29">The Goal</a>, and I replied that I had not.  They recommended it because it covers topics like the purpose of a business, how to find things to optimize, and what kind of process can be used for such optimization.</p>
<p>Given my interest in such topics, I went directly to Amazon and ordered a copy of <em>The Goal</em> and the related book titled *<em>What Is This Thing Called Theory of Constraints</em>.  When reading a book like <em>The Goal</em> it is important to keep the book in context.  After all, it was released 30 years ago and times have changed since then.  For its time though, I&rsquo;m sure it was disruptive to standard management thinking.</p>

<h3 id="what-is-the-theory-of-constraints" class="anchor-link"><a href="#what-is-the-theory-of-constraints">What is the Theory of Constraints</a></h3>
<p>Wikipedia describes the book as a management-oriented novel with a focus on describing the Theory of Constraints, bottlenecks, and how to alleviate them.  There is also a thread running through the book emphasizing the importance of the <a href="https://en.wikipedia.org/wiki/Socratic_method">Socratic method</a> in problem solving and discussion, a method which I have also found to be useful throughout my career.  Most business-focused books I read tend to take far too long to emphasize the point, which is why I typically find a summary to be more useful than reading the whole book.  While there are a few exceptions to this, <strong>The Goal</strong> at nearly 400 pages is not one of them.  The process outlined in the book is relatively straightforward.</p>
<ol>
<li>
<p>Identify the most problematic constraint(s)</p>
</li>
<li>
<p>Make decisions and take actions that allow the constraint(s) operate more effectively</p>
</li>
<li>
<p>Keep those decisions top priority</p>
</li>
<li>
<p>Find further ways to increase throughput at the constraint(s)</p>
</li>
<li>
<p>When the biggest constraint has been eliminated, start the process over again with the new highest priority constraint.  Also, don&rsquo;t let historical process or procedure become a blocker as constraints are removed.</p>
</li>
</ol>
<p>Depending on your background, this overall approach may be nothing new at all.  For people coming from a distributed systems background or stream processing background, this is almost exactly the process used to optimize the throughput of a stream-based data processing system.  The system will only be able to process data as quickly as the slowest component, so constantly profiling to find the slowest component and then focusing effort on improving that is standard procedure.  After all, the system is only as fast as the slowest component, so focusing effort anywhere else simply does not make sense unless you&rsquo;re in the mode of completely changing the system architecture.</p>
<p>The Theory of Constraints could simply be described as the process of repeatedly identify the thing that&rsquo;s slowing you down, and making it faster.  While this is a sound approach to optimizing business, data processing pipelines, and other things, I don&rsquo;t think it requires 400 pages to adequately explain.</p>

<h3 id="what-about-kanban-scrum-toyota-production-system" class="anchor-link"><a href="#what-about-kanban-scrum-toyota-production-system">What about Kanban, Scrum, Toyota Production System?</a></h3>
<p>At the time <strong>The Goal</strong> was released, and certainly in the time since then, there were and are many other methods for production management and process optimization.  In addition to intuitive approaches that had been developed over longer timescales, there were also the more rigorous approaches of <a href="https://en.wikipedia.org/wiki/Statistical_process_control">statistical process control</a> which had been around since the 1950s.  The fact that plenty of other systems exist, some of which with more rigorous evidence of success, isn&rsquo;t discussed in <strong>The Goal</strong> but does receive some focus in the book <strong>What Is This Thing Called Theory Of Constraints</strong>.  This book provides a much more compact introduction to the Theory of Constraints than <strong>The Goal</strong>, but sadly is largely padded with some articles from the now-defunct Journal of Theory of Constraints.  It also seems to be selling sessions and seminars offered by the author&rsquo;s company.</p>

<h3 id="an-aside-on-measurement" class="anchor-link"><a href="#an-aside-on-measurement">An Aside on Measurement</a></h3>
<p>One thing that is noted repeatedly in <em>The Goal</em> but doesn&rsquo;t receive enough attention is the problem of what is being measured and why.  Specifically, the problem of performance being measured against metrics that are not relevant to the business.  In the book, this takes the shape of people being measured against efficiency metrics for particular components instead of overall revenue metrics for the business, and therefore possibly being penalized for what appears on paper to be a decrease in efficiency but regardless results in an increase in sales.  This kind of dissonance is something I have personally encountered many times in my career, usually in the context of a supervisory board or board of directors that enforces goals or metrics for executives which are totally detached from the success of the business.</p>
<p>A recent article in <a href="https://hbr.org/2015/01/where-boards-fall-short">Harvard Business Review</a> entitled <em>Where Boards Fall Short</em> specifically addresses the topic of board members not understanding the business and therefore giving direction and applying pressure to executives to achieve short-term financial goals instead of long-term business success.</p>
<blockquote>
<p>A mere 34% of the 772 directors surveyed by McKinsey in 2013 agreed that the boards on which they served fully comprehended their companiesâ€™ strategies. Only 22% said their boards were completely aware of how their firms created value, and just 16% claimed that their boards had a strong understanding of the dynamics of their firmsâ€™ industries.</p>
</blockquote>
<p>It&rsquo;s bad enough of course if your board doesn&rsquo;t understand how the company&rsquo;s industry works, but it&rsquo;s worse when that lack of understanding is translated into an emphasis on simple short-term financial metrics.</p>
<blockquote>
<p>More recently, in March 2014, McKinsey and the Canada Pension Plan Investment Board (CPPIB) asked 604 C-suite executives and directors around the world which source of pressure was most responsible for their organizationsâ€™ overemphasis on short-term financial results and underemphasis on long-term value creation. The most frequent response, cited by 47% of those surveyed, was the companyâ€™s board.</p>
</blockquote>
<p>As a data professional, a big part of the job is helping companies and boards to understand business dynamics, how to collect data on those dynamics, and what kinds of incentives make sense in order to encourage the kind of growth the company needs.  If senior executives or boards are focused on irrelevant metrics, or do not have an understanding of the business and therefore focus on only financial metrics, then everything else is put to the side to the detriment of long-term business success.  Measurement and how people are incentivized is a topic for another post, and definitely could have received more emphasis in <em>The Goal</em>.  After all, it doesn&rsquo;t matter if you improve the right things only for management to fire you because they don&rsquo;t understand the business anyway.</p>

<h3 id="summary" class="anchor-link"><a href="#summary">Summary</a></h3>
<p><strong>The Goal</strong> is a good book to read, provided you do not have a background in other management or process approaches, or any background in queueing theory or designing high-performance data pipelines.  If you already have experience in those areas, the ideas in <strong>The Goal</strong> may seem quaint and dry to you, and the book will seem too long, involved, and slow in explaining things with which you are already familiar.  The process overall is a sensible one, and should be studied in the context of other methods like JIT, TPS, Kanban, and so on.</p>
<p>The overall lessons in the book are good ones, though it should be noted that the topic of properly defining and analyzing metrics for the business gets a lighter treatment than it should.  For that reason, I would also recommend reading something like <a href="https://leananalyticsbook.com/">Lean Analytics</a> by Croll and Yoskovitz to get a feel for how analytics inside a company can look.  The approaches there can help guide the implementation of effective analytics and measurement programs inside companies, and hopefully can also provide ideas for helping management understand how to measure the things that matter.  In a world where most boards do not understand how the business works or what kind dynamics indicate business growth, no good deed goes unpunished.</p>
 ]]></content:encoded></item><item><title>Stop Collecting So Much Data</title><link>https://adamdrake.com/stop-collecting-so-much-data.html</link><pubDate>Sun, 14 Sep 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/stop-collecting-so-much-data.html</guid><description>&lt;p>In many discussions with people in the industry, the topic of how much data is collected or processed often arises. Although it&amp;rsquo;s useful for getting a feeling for the scale of data challenges at a company, as a metric for the skills or effectiveness of a data organization it&amp;rsquo;s a pretty useless topic. However, even when the topic is raised in the context of getting a feel for data challenges at a company, that only makes sense if all the data are necessary for solving problems. However, that is usually not the case and I propose that blindly collecting all possible data is an anti-pattern and bad for data programs generally. Assuming it&amp;rsquo;s not necessary for a valid reason, like reproducibility of results, collecting all possible data can indicate that the underlying problem has not been properly identified, or that proper data governance is not in place to guide the process of collecting data.&lt;/p></description><content:encoded><![CDATA[ <p>In many discussions with people in the industry, the topic of how much data is collected or processed often arises.  Although it&rsquo;s useful for getting a feeling for the scale of data challenges at a company, as a metric for the skills or effectiveness of a data organization it&rsquo;s a pretty useless topic.  However, even when the topic is raised in the context of getting a feel for data challenges at a company, that only makes sense if all the data are necessary for solving problems.  However, that is usually not the case and I propose that blindly collecting all possible data is an anti-pattern and bad for data programs generally.  Assuming it&rsquo;s not necessary for a valid reason, like reproducibility of results, collecting all possible data can indicate that the underlying problem has not been properly identified, or that proper data governance is not in place to guide the process of collecting data.</p>

<h3 id="do-you-really-know-the-problem" class="anchor-link"><a href="#do-you-really-know-the-problem">Do you really know the problem?</a></h3>
<p>If you&rsquo;re just collecting everything because you haven&rsquo;t yet identified the problem which you would like to solve, that&rsquo;s fine as long as you know you aren&rsquo;t solving any problems yet.  Perhaps you&rsquo;re interested in doing some exploratory data analysis in order to help identify a concrete problem.  If you think you&rsquo;re solving a problem by collecting all possible data, it&rsquo;s much more likely that you are creating a storage and risk nightmare.  Contrary to the popular exclamations in the <em>Big Data (tm)</em> community, storing and managing all of that data costs a lot of time, money, and energy.  Although it&rsquo;s becoming ever cheaper to store data, the cognitive and organizational overhead of managing all of it is of course going up.</p>
<p>In other words, unless you are doing exploratory work or have a good reason, consider the habit of collecting all possible data to indicate that you haven&rsquo;t really identified a problem to solve yet.  You can make the argument that collecting all possible data now will allow you to effectively solve problems you think of in the future, but as mentioned this collection incurs costs and should be considered in light of data governance within your organization.  You do have proper <a href="/on-data-governance.html">data governance</a> in place, right?</p>

<h3 id="you-cant-lose-what-you-dont-have" class="anchor-link"><a href="#you-cant-lose-what-you-dont-have">You can&rsquo;t lose what you don&rsquo;t have</a></h3>
<p>As mentioned in the governance article, another angle from which to view excess collection as an anti-pattern is to consider that with increased data collected and stored comes increased risk of the data being disclosed, leaked, released to a court, or other unfortunate outcomes.  The more you collect, the more you risk losing.  This can be doubly bad if you are collecting user data, since your users or customers are depending on you to make ethical decisions on how data is collected and stored.  If you&rsquo;re simply collecting tons of data for potential future use, and you don&rsquo;t have a good reason right now, you could be doing a disservice to your customers.  Additionally, you are exposing your employees and shareholders to unnecessary risks.</p>

<h3 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h3>
<p>Before you start collecting everything in sight, relax for a moment and think.  Have you actually identified the problem you would like to solve?  If not, are you collecting more data than you need in order to perform your exploratory analysis?  If so, are you exposing your users or company to increased risk due to possible leaks of data you didn&rsquo;t need in the first place?  Just a few things to think about when considering what to collect and what to do with it.</p>
 ]]></content:encoded></item><item><title>On Data Governance</title><link>https://adamdrake.com/on-data-governance.html</link><pubDate>Sun, 07 Sep 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/on-data-governance.html</guid><description>&lt;h3 id="overview" class="anchor-link">&lt;a href="#overview">Overview&lt;/a>&lt;/h3>
&lt;p>The short version, is that Data Governance is all of the business concerns surrounding data. This means things like data quality, management, risks, and similar non-technical things. It&amp;rsquo;s comprised of the kind of concerns that business people would typically have surrounding data, although the quality topic is critically important for machine learning practitioners. For our purposes, I&amp;rsquo;ll group the concerns generally into quality, management, and risks. Each of those things can be pursued very deeply, but we need only an overview in order to make some key points.&lt;/p></description><content:encoded><![CDATA[ 
<h3 id="overview" class="anchor-link"><a href="#overview">Overview</a></h3>
<p>The short version, is that Data Governance is all of the business concerns surrounding data.  This means things like data quality, management, risks, and similar non-technical things.  It&rsquo;s comprised of the kind of concerns that business people would typically have surrounding data, although the quality topic is critically important for machine learning practitioners.  For our purposes, I&rsquo;ll group the concerns generally into quality, management, and risks.  Each of those things can be pursued very deeply, but we need only an overview in order to make some key points.</p>

<h3 id="quality" class="anchor-link"><a href="#quality">Quality</a></h3>
<p>The quality of data starts at collection, and although it may be a contrarian or controversial point I maintain that all high-quality data needs to have a schema, even in transit.  This means that things like sending around data in any kind of string format where serializing and deserializing is not enforced by a type system is counter-productive when it comes to having high-quality data.  If data does not have a schema on collection, it is up to the entire software engineering organization to pass around data in consistent and reliable formats.  Since this is not feasible, a schema is required.  Besides, if your data has no schema, have you really evaluated the underlying problems and the data needed to solve those problems or are you just trying to collect everything in the hopes that someday it will be useful?  That is a common anti-pattern and simply collecting all data should be avoided.</p>

<h3 id="management" class="anchor-link"><a href="#management">Management</a></h3>
<p>Data management topics are arguably the most important of all.  Consider the impact of data spread in different places, or of people waiting for data access they need in order to work effectively.  These are just two of the many concerns in the are of data management, but they&rsquo;re often the two biggest Data Management problems that most companies face.  In the case of data being in disparate places, this is the commonly-noted <em>data silo</em> problem that plagues many organizations.  It often stems from the so-called <em>Conway&rsquo;s Law</em> which effectively states that any organization producing any technical system will invariably produce a system that reflects the communication structure within the organization.  This means that it&rsquo;s very common for groups to replicate data for the sole purpose of further processing.  Sometimes this is needed for scalability purposes, but oftentimes it&rsquo;s simply a matter of overcoming an organizational problem with a technical solution (albeit not a very good one).  The result is that data is locked away in silos, and oftentimes it&rsquo;s the same data.</p>
<p>The additional problem is that since organizations have multiple teams developing information products that should be using the same data source, but are using different sources, there are discrepancies in the results of these information products.  This results in massive additional cost for the organization due to less trust from customers, lost development time from hunting down esoteric bugs between systems processing similar data, and the unquantifiable loss resulting from reduced morale of employees who feel like they are working on a dysfunctional system.  In reality, the system isn&rsquo;t dysfunctional and could be improved greatly by simply eliminating redundant data sources.  For data to be used well in an organization, the management of the data is perhaps the biggest burden.  This is a post-collection and pre-product topic, so the bulk of data problems reside here.</p>

<h3 id="risks" class="anchor-link"><a href="#risks">Risks</a></h3>
<p>Some of the more subtle risks have already been mentioned, but more obvious ones include things like data that can be subpoenaed in the event of legal action.  If unnecessary data is maintained by the organization, this data constitutes a risk in legal cases because it can be used to prove or discover actions with penalties not beneficial to the company.</p>
<p>In a similar light, there is the possibility that there could be some kind of data breach where data is unintentionally exposed to the public.  In this case, as in the legal example, having unnecessary data is a risk to the company and its customers.  If there is more customer data stored than needed to operate the business and its products, then this data is also at risk of being stolen or leaked.</p>
<p>There are also risks for low-quality data, and this goes along with the Data Management topic above.  Low-quality data causes numerous problems for organizations including the aforementioned decrease in customer trust, reduction in employee morale, and lost development time, but it additionally can result in adoption of flawed strategies or initiatives.  If the low-quality data is used to support business decisions then the consequences of those bad decisions can be directly attributed to the bad data used to make them.</p>

<h3 id="summary" class="anchor-link"><a href="#summary">Summary</a></h3>
<p>This is just a brief overview of some of the general topics encountered when considering data governance within an organization.  Ultimately, the reasons for implementing more effective data governance are usually to further strategic goals of the company in terms of products or services, or reduce surface area for various kinds of data risk.  Without some basic data governance in place, the challenges of using data effectively in an organization are often too great to overcome, resulting in frustration and failed efforts to become data-driven.</p>
 ]]></content:encoded></item><item><title>On Salary Negotiations</title><link>https://adamdrake.com/on-salary-negotiations.html</link><pubDate>Fri, 05 Sep 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/on-salary-negotiations.html</guid><description>&lt;p>Salary negotiations are often presented from the perspective of a potential employee, but I rarely read anything regarding strategies for companies who want to do their best to hire a particular candidate. As someone not formally trained in HR, my opinions on the topic have been developed strictly through my experiences. If you&amp;rsquo;re an HR expert and think I&amp;rsquo;m crazy then I ask you contact me and help me improve my perspective.&lt;/p></description><content:encoded><![CDATA[ <p>Salary negotiations are often presented from the perspective of a potential employee, but I rarely read anything regarding strategies for companies who want to do their best to hire a particular candidate.  As someone not formally trained in HR, my opinions on the topic have been developed strictly through my experiences.  If you&rsquo;re an HR expert and think I&rsquo;m crazy then I ask you contact me and help me improve my perspective.</p>
<p>The main problem from the salary perspective is how much has been budgeted for the position, if it&rsquo;s been budgeted at all, how much the company thinks is far and how much the candidate feels is fair.  There are other issues like salary structure within the organization and frameworks for computing salaries, but in this case I&rsquo;m only covering organizations that are flexible in terms of salary.  Obviously, in the case of government entities or other organizations with fixed rank and grade salary scales, this whole topic is moot.</p>
<p>So the question is, what&rsquo;s the best way for an organization with a flexible salary structure to make an offer which ensures they have the highest likelihood to get the candidates they want?</p>
<p>The answer isn&rsquo;t that hard, and the approach I use is to simply offer the highest counter-offer which I am willing to accept.</p>
<p>Consider for a moment the implications of alternate approaches.  If you try to get away paying a candidate the lowest salary they are willing to accept, you decrease the chances you will be able to recruit them and you also decrease the chances they will stay for a long time.  In many companies, without very strong leadership, it&rsquo;s hard to push through large salary changes, so it&rsquo;s very likely that someone&rsquo;s salary won&rsquo;t change much during the term of their employment.  If a person is being paid less than their market value, they&rsquo;ll simply leave sooner or later.  In my experience, people tend to leave when opportunities for salary increases get to around 15% or 20%.  If the company environment is bad, people will leave even if they take a cut in salary, but leaving for a pay cut is a symptom of a very different organizational problem.</p>
<p>So what is the risk to the organization when taking this different approach to salaries?  Well, higher staff costs is the most quantifiable risk and the item with this approach that Finance or a CFO would define as a problem.  However, there is also the benefit that (all other things being equal) with more favorable salaries comes lower churn, and churn has many negative impacts on the company besides the cost of refilling the position.  The morale impacts are not really measurable in direct financial terms, but it&rsquo;s definitely harmful.  Additionally, the employees who can easily make a change and get paid more are often the most talented, so you suffer the problems of churn and morale combined with losing the employees most capable of commanding a higher salary.</p>
<p>The argument against this approach is that you don&rsquo;t want to retain people who are only there for a salary.  This is true, but if people aren&rsquo;t getting paid what they could earn elsewhere in the market then the company isn&rsquo;t being fair either.  If the company can&rsquo;t afford to pay market salary to its employees, this is a leadership failure from which the company needs to recover or the company must offer some form of intrinsic motivation that makes up for the lower salary structure.  Non-profit organizations are a good example of an exception to the market salary rule.  For companies that can&rsquo;t afford to pay market salaries, but want to, possible options are something like layoffs with fair severance or other arrangements in order to lower or maintain overall staff costs and raise salaries for the remaining employees to a fair level.</p>
<p>So the short version is, one way to handle the salary topic from a hiring perspective is to simply start by offering the highest counter-offer you are willing to accept.  This is often a higher offer than the candidates expectations, but if not then there is simply not an overlap in compensation needs.</p>
 ]]></content:encoded></item><item><title>Using Twitter as a Stream Processing Source</title><link>https://adamdrake.com/using-twitter-as-a-stream-processing-source.html</link><pubDate>Wed, 11 Jun 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/using-twitter-as-a-stream-processing-source.html</guid><description>&lt;p>Recently, I was providing a lecture on stream processing and planned to use the Twitter streaming API as an example. To provide a framework for the attendees, I created the one below. It has been tested with Python 3.4 but as it does not include testing or other things it should only be used as an example.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> threading &lt;span style="color:#f92672">import&lt;/span> Thread
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> collections &lt;span style="color:#f92672">import&lt;/span> deque
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> twython &lt;span style="color:#f92672">import&lt;/span> TwythonStreamer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> requests.exceptions &lt;span style="color:#f92672">import&lt;/span> ChunkedEncodingError
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>For the imports, we need them for the following reasons:&lt;/p></description><content:encoded><![CDATA[ <p>Recently, I was providing a lecture on stream processing and planned to use the Twitter streaming API as an example.  To provide a framework for the attendees, I created the one below.  It has been tested with Python 3.4 but as it does not include testing or other things it should only be used as an example.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> threading <span style="color:#f92672">import</span> Thread
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> deque
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> twython <span style="color:#f92672">import</span> TwythonStreamer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> requests.exceptions <span style="color:#f92672">import</span> ChunkedEncodingError
</span></span></code></pre></div><p>For the imports, we need them for the following reasons:</p>
<p>Thread as the consumer of the Twitter stream will run in a separate thread.</p>
<p>We use a double-ended queue (deque) as a lock-free way to move messages from one thread to another.  Most operations on the deque are lock-free/atomic, and we will use <code>append()</code> and <code>popleft()</code> in this case and for that reason.</p>
<p><code>TwythonStreamer</code> is a Twitter Streaming API class from the twython library (<code>pip install twython</code> if you don&rsquo;t have it).</p>
<p>The <code>ChunkedEncodingError</code> exception is used to handle the case when the API responds with the wrong number of bytes, which it is known to do.  In case that happens, we just call the stream consumer again with the same deque.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">TwitterStream</span>(TwythonStreamer):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, consumer_key, consumer_secret, token, token_secret, tqueue):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>tweet_queue <span style="color:#f92672">=</span> tqueue
</span></span><span style="display:flex;"><span>        super(TwitterStream, self)<span style="color:#f92672">.</span>__init__(consumer_key, consumer_secret, token, token_secret)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_success</span>(self, data):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#39;text&#39;</span> <span style="color:#f92672">in</span> data:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>tweet_queue<span style="color:#f92672">.</span>append(data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">on_error</span>(self, status_code, data):
</span></span><span style="display:flex;"><span>        print(status_code)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Want to stop trying to get data because of the error?</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Uncomment the next line!</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># self.disconnect()</span>
</span></span></code></pre></div><p>The <code>TwitterStream</code> class extends the <code>TwythonStreamer</code> class and provides information on what to do when a tweet is received and on errors.  In this case, when the tweet is received we append it to the deque and on errors we simply print.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stream_tweets</span>(tweets_queue):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Input your credentials below</span>
</span></span><span style="display:flex;"><span>    consumer_key <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    consumer_secret <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    token <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    token_secret <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        stream <span style="color:#f92672">=</span> TwitterStream(consumer_key, consumer_secret, token, token_secret, tweets_queue)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># You can filter on keywords, or simply draw from the sample stream</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#stream.statuses.filter(track=&#39;twitter&#39;, language=&#39;en&#39;)</span>
</span></span><span style="display:flex;"><span>        stream<span style="color:#f92672">.</span>statuses<span style="color:#f92672">.</span>sample(language<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;en&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> ChunkedEncodingError:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Sometimes the API sends back one byte less than expected which results in an exception in the</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># current version of the requests library</span>
</span></span><span style="display:flex;"><span>        stream_tweets(tweet_queue)
</span></span></code></pre></div><p>This is the function that does most of the work, connecting to the streaming API, starting to sample from it, and handling the <code>ChunkedEncodingError</code> exceptions mentioned earlier.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">process_tweets</span>(tweets_queue):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> len(tweets_queue) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">#  Do something with the tweets</span>
</span></span><span style="display:flex;"><span>            print(tweets_queue<span style="color:#f92672">.</span>popleft())
</span></span></code></pre></div><p>The process_tweets function is a small helper function that (inefficiently) loops over the deque and processes the contents element-wise.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    tweet_queue <span style="color:#f92672">=</span> deque()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    tweet_stream <span style="color:#f92672">=</span> Thread(target<span style="color:#f92672">=</span>stream_tweets, args<span style="color:#f92672">=</span>(tweet_queue,), daemon<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    tweet_stream<span style="color:#f92672">.</span>start()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    process_tweets(tweet_queue)
</span></span></code></pre></div><p>Here we tie everything together by constructing the deque, starting the thread for the stream which will append to the deque, and the process tweet function that will handle the tweets.</p>
<p>So that was an easy skeleton for playing around with streams from Twitter, you can find the code in the <a href="https://github.com/adamdrake/twitterstreamtemplate">twitterstreamtemplate</a> repository on GitHub.</p>
 ]]></content:encoded></item><item><title>Notes on The Anatomy of Courage</title><link>https://adamdrake.com/notes-on-the-anatomy-of-courage.html</link><pubDate>Wed, 07 May 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/notes-on-the-anatomy-of-courage.html</guid><description>&lt;p>Just a quick summary as I don&amp;rsquo;t really have detailed notes for this book.&lt;/p>
&lt;p>&lt;strong>The Anatomy of Courage&lt;/strong> is a quick read, and is interspersed with anecdotal accounts from Moran&amp;rsquo;s time as a doctor in the trenches in World War 1. The interesting part about books such as this is the applicability of the ideas contained therein to the workplace. The book says &amp;ldquo;Courage is will-power, whereof no man has an unlimited stock&amp;hellip;&amp;rdquo; In other words, for this book courage can be considered the will to continue an action in the face of danger or other difficulties. That general examination allows for the conclusions of the book to be applied to parts of life other than warfare.&lt;/p></description><content:encoded><![CDATA[ <p>Just a quick summary as I don&rsquo;t really have detailed notes for this book.</p>
<p><strong>The Anatomy of Courage</strong> is a quick read, and is interspersed with anecdotal accounts from Moran&rsquo;s time as a doctor in the trenches in World War 1.  The interesting part about books such as this is the applicability of the ideas contained therein to the workplace.  The book says &ldquo;Courage is will-power, whereof no man has an unlimited stock&hellip;&rdquo;  In other words, for this book courage can be considered the will to continue an action in the face of danger or other difficulties.  That general examination allows for the conclusions of the book to be applied to parts of life other than warfare.</p>
<p>The first part, <em>The Discovery of Fear</em> is a brief overview on the causes of fear and how they contribute to the degradation of courage.  This includes the power of the imagination for influencing positive or negative emotions, cowardice (which is not simply fear or avoiding that which makes you afraid), and how moods can have a variety of effects on emotional stability and performance.  It&rsquo;s more or less about the effects of personal and unit morale on performance.</p>
<p>Section two covers a variety of ways in which courage, the will to continue fighting, is expended.  These include things like lack of rest, exposure to the elements or harsh conditions, isolation at sea, and so on.  There is special attention paid to the acts of pilots, who at that time were still a relatively new part of modern warfare and who in some ways have additional concerns due to not only the risk of losing their lives due to enemy actions, but also due to poor reliability of their equipment.  It also covers the demotivating effects of monotony and constant exposure to death.  The last part is debatable as a negative factor in maintaining courage, as many Eastern philosophical schools (e.g., Buddhism) and ancient Geek and Roman schools (e.g., Stoicism) encourage frequent consideration of death and negative things as a way to appreciate what you have.</p>
<p>The third section, <em>The Care and Management of Fear</em>, deals with exactly that.  It considers what can be done about reducing fear and maintaining courage in areas of Selection, Discipline, The Support of Numbers, and Leadership.  Of these, I would conclude Leadership to be the most important, as selection of people, maintaining and encouraging of discipline, and having proper numbers of people in place is the responsibility of any leader.</p>
<p>Overall the book has some good parallels to challenges in the workplace.  Although they are not of the life-and-death variety experienced in the trenches of World War 1, some of the basic human tendencies in stress management are similar in both environments.  Additionally, there are sections peppered throughout the book on what to look for when someone has lost the will to continue fighting, and how that is a very dangerous situation not just for the individual but also for their unit.  In the workplace, this would translate to someone giving up on their job, perhaps starting to look for another one, dragging down the morale of the team, but not quitting.</p>
 ]]></content:encoded></item><item><title>Notes on John Maxwell's Five Levels of Leadership</title><link>https://adamdrake.com/notes-on-john-maxwells-five-levels-of-leadership.html</link><pubDate>Mon, 31 Mar 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/notes-on-john-maxwells-five-levels-of-leadership.html</guid><description>&lt;p>Leadership is influence.&lt;/p>
&lt;p>Note: when you talk about your vision with people, they see you through the lens of these levels. So the person who sees you in level 1 will not absorb or be motivated by the vision in the same way as someone who sees you in level 4.&lt;/p>
&lt;h3 id="level-1-rights" class="anchor-link">&lt;a href="#level-1-rights">Level 1: Rights&lt;/a>&lt;/h3>
&lt;p>You get the position and the title. Basically nothing here besides imparted authority. People follow you because it&amp;rsquo;s their job, or they must for some reason. The upside is you get to start working on yourself. The people will give you the least amount of their energy, effort, and mind.&lt;/p></description><content:encoded><![CDATA[ <p>Leadership is influence.</p>
<p>Note: when you talk about your vision with people, they see you through the lens of these levels.  So the person who sees you in level 1 will not absorb or be motivated by the vision in the same way as someone who sees you in level 4.</p>

<h3 id="level-1-rights" class="anchor-link"><a href="#level-1-rights">Level 1: Rights</a></h3>
<p>You get the position and the title.  Basically nothing here besides imparted authority.  People follow you because it&rsquo;s their job, or they must for some reason.  The upside is you get to start working on yourself.  The people will give you the least amount of their energy, effort, and mind.</p>

<h3 id="level-2-relationships" class="anchor-link"><a href="#level-2-relationships">Level 2: Relationships</a></h3>
<p>A leader at this level is effective because they build relationships with people in their team and they are likable.</p>
<p>At this level you have rapport with your people, everyone generally likes each other.  The leader is generally likable and is seen as constructive.</p>
<p>Relationships with people are the foundation of leadership and you cannot have a relationship with people that are antagonized or irritated by you.</p>
<p>People on this level do 3 things well:</p>
<ul>
<li>
<p>Listen</p>
</li>
<li>
<p>Observe</p>
</li>
<li>
<p>Learn</p>
</li>
</ul>
<p>In the process of doing those 3 things, the leaders have an attitude of servitude.  They exist to serve their people.</p>

<h3 id="level-3-results" class="anchor-link"><a href="#level-3-results">Level 3: Results</a></h3>
<p>At this level, the effectiveness of leaders is measured by what they can produce and how they help the bottom line.  They produce by examples of how to be effective and productive.</p>
<p>Be a tour guide, not a travel agent.</p>
<p>Leaders here gain credibility from their teams by fleshing out and modeling for the people around them the things that they want to see and need to produce.  By these acts they start to attract people who want to produce like they do.</p>
<blockquote>
<p>We attract who we are, not what we want.</p>
</blockquote>
<p>At this level, who you are as a leader is who you attract on your team.  Much problem solving is taken care of here.</p>
<p>Managers try to solve problems, but leaders try to create momentum.  Leaders know you can solve 80% of problems with momentum.  A train traveling at 100kph will smash through a 2m thick concrete block with ease, but if you put a 2cm block in front of the wheels when it&rsquo;s stopped it won&rsquo;t even be able to get moving (or will have a hard time doing so).</p>

<h3 id="level-4-developing-people" class="anchor-link"><a href="#level-4-developing-people">Level 4: Developing People</a></h3>
<p>This level is all about people development.  The most appreciable asset you have in an organization is the people in that organization.  You commit yourself to developing the people, and you grow the company by growing the people.</p>
<p>Three thoughts on developing people:</p>
<ul>
<li>
<p>The key to developing good people is recruitment.  The better people you bring in, the more you can do with them.  Eighty percent of your success of equipping people to be successful is on the front door when you decide whom to hire.</p>
</li>
<li>
<p>Positioning.  Put the people you recruit in the right places.  Successful people always position themselves well.  People are successful because they have found their sweet spot.  Successful leaders discover what other people are good at.  Successful people position themselves well, but successful leaders position other people well too.</p>
</li>
<li>
<p>Equipping people.  Development and training.  The 5 step equipping process</p>
<ul>
<li>
<p>I do it</p>
</li>
<li>
<p>I do it and you&rsquo;re with me</p>
</li>
<li>
<p>You do it and I&rsquo;m with you</p>
</li>
<li>
<p>You do it</p>
</li>
<li>
<p>You do it and somebody&rsquo;s with you (CRITICAL STEP - you never really equip somebody until they can equip somebody else)</p>
</li>
</ul>
</li>
</ul>

<h3 id="level-5-respect" class="anchor-link"><a href="#level-5-respect">Level 5: Respect</a></h3>
<p>This is the pinnacle level.  You&rsquo;ve done so well by so many for so long that people just absolutely follow you.  They follow you because of who you are, the qualities of have, and what you&rsquo;ve done.</p>
<p>The <a href="https://www.youtube.com/watch?v=aPwXeg8ThWI">full video</a> is on YouTube.</p>
 ]]></content:encoded></item><item><title>Notes on Learning to Eat Soup with a Knife</title><link>https://adamdrake.com/notes-on-learning-to-eat-soup-with-a-knife.html</link><pubDate>Sat, 29 Mar 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/notes-on-learning-to-eat-soup-with-a-knife.html</guid><description>&lt;h3 id="chapter-1" class="anchor-link">&lt;a href="#chapter-1">Chapter 1&lt;/a>&lt;/h3>
&lt;p>What is a &amp;ldquo;Learning Organization?&amp;rdquo;&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Does it promote suggestions from lower ranks and from operational areas (i.e. people &amp;ldquo;on the ground&amp;rdquo;)?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Are subordinates encouraged to question superiors and policies?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Does the organization regularly question its basic assumptions?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Are executives and other management routinely in close contact with operational people and open to their suggestions?&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>The three key elements to &lt;em>The Learning Challenge&lt;/em> of Sullivan and Harper from the book &lt;strong>Hope is Not a Method&lt;/strong>:&lt;/p></description><content:encoded><![CDATA[ 
<h3 id="chapter-1" class="anchor-link"><a href="#chapter-1">Chapter 1</a></h3>
<p>What is a &ldquo;Learning Organization?&rdquo;</p>
<ul>
<li>
<p>Does it promote suggestions from lower ranks and from operational areas (i.e. people &ldquo;on the ground&rdquo;)?</p>
</li>
<li>
<p>Are subordinates encouraged to question superiors and policies?</p>
</li>
<li>
<p>Does the organization regularly question its basic assumptions?</p>
</li>
<li>
<p>Are executives and other management routinely in close contact with operational people and open to their suggestions?</p>
</li>
</ul>
<p>The three key elements to <em>The Learning Challenge</em> of Sullivan and Harper from the book <strong>Hope is Not a Method</strong>:</p>
<ul>
<li>
<p>The right culture</p>
</li>
<li>
<p>The knowledge itself</p>
</li>
<li>
<p>Access to the knowledge</p>
</li>
</ul>

<h3 id="chapter-2" class="anchor-link"><a href="#chapter-2">Chapter 2</a></h3>
<blockquote>
<p>Insurgents start with nothing but a cause and grow to strength, while counter-insurgents start with everything but a cause and gradually decline in strength and grow to weakness.
&ndash; Frank Kitson, <strong>Low Intensity Operations: Subversion, Intensity, and Peacekeeping</strong>, pg. 29</p>
</blockquote>
<blockquote>
<p>The printing press is the greatest weapon in the armory of the modern commander.
&ndash; T.E. Lawrence</p>
</blockquote>

<h3 id="chapter-5" class="anchor-link"><a href="#chapter-5">Chapter 5</a></h3>
<p>(page 90)
The methodology of General Sir Gerald Templar as described by John Cloake:</p>
<ul>
<li>
<p>Get the priorities right.</p>
</li>
<li>
<p>Get the instructions right.</p>
</li>
<li>
<p>Get the organization right.</p>
</li>
<li>
<p>Get the right people into the organization.</p>
</li>
<li>
<p>Get the right spirit into the people.</p>
</li>
<li>
<p>Leave them to get on with it.</p>
</li>
</ul>

<h3 id="chapter-6" class="anchor-link"><a href="#chapter-6">Chapter 6</a></h3>
<p>The old guard in the Army didn&rsquo;t care at all about the successes of the CIA and the US Army Special Forces with arming and training villages (see example of Buon Enao).  Instead, they were very dismissive of the capabilities of these kinds of soldiers.  The quote from General Harold K. Johnson in his <em>Senior Officer Oral History Project</em> debriefing is particularly telling, and sounds like every successful Data Science or Engineering team I&rsquo;ve ever led (page 128).</p>
<blockquote>
<p>Well, the Special Forces that were available at the time President Kennedy latched on to them as a new gimmick, were what I would describe as consisting primarily of fugitives from responsibility.  These were people that somehow or other tended to be nonconformist, couldn&rsquo;t quite get along in a straight military system, and found a haven where their actions were not scrutinized too carefully, and where they came under only sporadic or intermittent observation from the regular chain of command. . . . Perhaps there is a desirability for this highly specialized effort, but I continue to really question it as such.</p>
</blockquote>

<h3 id="chapter-7" class="anchor-link"><a href="#chapter-7">Chapter 7</a></h3>
<p>(page 158)
Regarding the ability of the Regional Forces/Popular Forces to become capable and take over operations:</p>
<blockquote>
<p>The Vietnamese like being part of an organization which cares, and they respond well and bravely . . . There are sufficient men who will fight if they know the system is competent and cares
&ndash; Lewy, <strong>American in Vietnam</strong>, 117</p>
</blockquote>
<p>In other words, local groups who may seem incapable will be motivated to do their best and work against all odds if they believe and trust that the organization of which they are a part knows what it&rsquo;s doing and cares about their well-being.  As soon as an organization loses this trust from its people, there is little hope.</p>
<p>(page 162)
From a memo from Robert McNamara to President Johnson on 14 October 1966, indicating his growing doubts about any military solution in Vietnam:</p>
<blockquote>
<p>The large-unit operations war, which we know best how to fight and where we have had our successes, is largely irrelevant to pacification as long as we do not lose it . . . Success in pacification depends on the interrelated functions of providing physical security, destroying the VC apparatus, motivating the people to cooperate, and establishing responsive local government.  An obviously necessary but not sufficient requirement for success of the RD (ed. <em>Rural Development</em>) cadre and police is vigorously conducted and adequately prolonged clearing operations by military troops who will <em>stay</em> in the area, who behave themselves decently, and who show respect for the people.</p>
</blockquote>
<p>If you don&rsquo;t have a group of middle-management on the ground, willing to fight for the people on the ground, and willing to continue to do so, all hope is lost.  However, it is stated in the book that the Joint Chiefs of Staff profoundly disagreed and instead favored an increase in the bombing of North Vietnam and further commitment of US troops.  This again demonstrates the lack of capability and micro-management inherent in organizations where the high-level directors believe they have more or superior knowledge to those who are actually doing the work.</p>

<h3 id="chapter-9" class="anchor-link"><a href="#chapter-9">Chapter 9</a></h3>
<p>Richard Downie&rsquo;s six recommendations for facilitating doctrinal change:</p>
<ul>
<li>
<p>Institutionalize doctrinal development as a continually evolving set of theoretical guidelines.</p>
</li>
<li>
<p>Establish a systemic assessment process to ensure the validity of current doctrinral operation assumptions.</p>
</li>
<li>
<p>Develop an efficient process to gain organizational consensus on emerging doctrines.</p>
</li>
<li>
<p>Establish a systemic process through which to rapidly transmit and disseminate doctrine to units in the field.</p>
</li>
<li>
<p>Welcome the civilian leadership&rsquo;s inquiries concerning military capability and appropriateness of doctrine as useful challenges for the military institution.</p>
</li>
<li>
<p>Doctrine as a focus of inquiry concerning military effectiveness for potential threats and challenges.</p>
</li>
</ul>
<p>&ndash; Richard Downie, <strong>Learning from Conflict</strong>, 261-265</p>
 ]]></content:encoded></item><item><title>Notes on The Mission, the Men, and Me</title><link>https://adamdrake.com/notes-on-the-mission-the-men-and-me.html</link><pubDate>Sat, 29 Mar 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/notes-on-the-mission-the-men-and-me.html</guid><description>&lt;h3 id="part-1" class="anchor-link">&lt;a href="#part-1">Part 1&lt;/a>&lt;/h3>
&lt;p>Don&amp;rsquo;t get treed by a Chiuahua. That is, don&amp;rsquo;t make snap decisions before you have collected and processed a sufficient amount of information to decide. When it&amp;rsquo;s not possible to decide, develop the situation.&lt;/p>
&lt;p>Humor your imagination.&lt;/p>
&lt;h3 id="part-2" class="anchor-link">&lt;a href="#part-2">Part 2&lt;/a>&lt;/h3>
&lt;p>The mind goes through 3 phases during learning and planning. Saturate, incubate, illuminate. They occur more or less in order, but your mind continuously cycles through each phase. Incubation-induced sleep loss is common though sleep is needed in order to maintain optimal chances of illumination (page 70).&lt;/p></description><content:encoded><![CDATA[ 
<h3 id="part-1" class="anchor-link"><a href="#part-1">Part 1</a></h3>
<p>Don&rsquo;t get treed by a Chiuahua.  That is, don&rsquo;t make snap decisions before you have collected and processed a sufficient amount of information to decide.  When it&rsquo;s not possible to decide, develop the situation.</p>
<p>Humor your imagination.</p>

<h3 id="part-2" class="anchor-link"><a href="#part-2">Part 2</a></h3>
<p>The mind goes through 3 phases during learning and planning.  Saturate, incubate, illuminate.  They occur more or less in order, but your mind continuously cycles through each phase.  Incubation-induced sleep loss is common though sleep is needed in order to maintain optimal chances of illumination (page 70).</p>
<p>The military&rsquo;s insistence on &ldquo;zero-defect operations&rdquo; caused massive amounts of effort to be used in order to develop plans for every possible contingency.  This risk averse behavior resulted in operational and logistics requirements so enormous that no politician would be willing to stage such a large presence in any other country.  Therefore, the risk aversion prohibited most operations from ever proceeding in the first place (page 76).</p>
<p>When in doubt, develop the situation.</p>
<p>The only failure is a failure to try.</p>
<p>Always listen to the guy on the ground.</p>

<h3 id="part-3" class="anchor-link"><a href="#part-3">Part 3</a></h3>
<p>Imagine everyone&rsquo;s potential as the guy on the ground</p>
<p>On video teleconference (VTC): It has the selling point that it increases situational awareness.  However, this is a false sense of situational awareness as it is more accurately just more information.  It is not necessarily more useful information.  Consider a management dashboard that is monitored by the C-level executives in a company.  This may provide more information, but without sufficient context and without deeper situational awareness, which must be gained by people in operational positions, that dashboard will encourage the executives to make more decisions and to be more committed to those decisions.  By simply having more information, they think they are more equipped to make decisions when in reality they should be speaking with the operational people who are actually qualified to make such decisions.  Management does not know better, regardless of how many dashboards they have (page 154).</p>
<p>Imagine how to seek out the guy on the ground</p>

<h3 id="part-4" class="anchor-link"><a href="#part-4">Part 4</a></h3>
<p>It&rsquo;s not reality unless it&rsquo;s shared</p>
<blockquote>
<p>How would large organizations such as the military organize if they didn&rsquo;t know how they were supposed to be organized? (page 217)</p>
</blockquote>
<p>In companies, why are salespeople not inside of the engineering teams that are building the products which they are selling?  Why is it necessary to rely on multiple levels of indirection (product owners, product marketing, etc.) which only make the salespeople less informed and likely diminish their chances of success in selling the product?  To properly sell a product you must believe in it and you must know it through and through.  Every level of abstraction between the engineering team and the sales person or account manager actually talking to the client means the salesperson understands the product less and has less of a say in what gets built.  Put sales and account managers into engineering teams, experiment with the idea of getting rid of product owners but keep a scrum master or other administrator in the team.  Since it is often senior engineers that do most of the requirements analysis and also participate in stakeholder management, this could be more efficient.</p>
<blockquote>
<p>The Chinese symbol for crisis is &lsquo;danger-opportunity&rsquo;, which roughly translates to &lsquo;without the danger the cannot arise the opportunity.&rsquo;&quot; (page 266)</p>
</blockquote>
<p>I was skeptical about this one, and a quick search shows that <a href="https://en.wikipedia.org/wiki/Chinese_word_for_%22crisis%22">Wikipedia</a> indicates that danger-opportunity is not necessarily correct.</p>
 ]]></content:encoded></item><item><title>CSAP - Collect, Store, Analyze, Productize</title><link>https://adamdrake.com/csap-collect-store-analyze-productize.html</link><pubDate>Sat, 25 Jan 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/csap-collect-store-analyze-productize.html</guid><description>&lt;h3 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h3>
&lt;p>Compared with many disciplines and areas, Data Science is extremely new and the scope of a Data Science team inside an organization is still a matter of debate. Since Data Science is an amalgamation of many different areas and specialties, including mathematics, computer science, statistics, machine learning, business, economics, and others, there so far hasn&amp;rsquo;t been many clear frameworks or organizational structures to support a Data Science group. Regardless of the implementation details, a company looking to improve its overall standing from a data perspective will want a specialist group who focuses on how data is collected, stored, analyzed, and productized (CSAP).&lt;/p></description><content:encoded><![CDATA[ 
<h3 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h3>
<p>Compared with many disciplines and areas, Data Science is extremely new and the scope of a Data Science team inside an organization is still a matter of debate.  Since Data Science is an amalgamation of many different areas and specialties, including mathematics, computer science, statistics, machine learning, business, economics, and others, there so far hasn&rsquo;t been many clear frameworks or organizational structures to support a Data Science group.  Regardless of the implementation details, a company looking to improve its overall standing from a data perspective will want a specialist group who focuses on how data is collected, stored, analyzed, and productized (CSAP).</p>
<p>There are two main problems with this, the first being that companies often donâ€™t know where to put such a group from an organizational perspective, and the second is that in the absence of a Chief Data Officer (which many companies now have) it can be difficult for executives to understand and implement the overall strategy and mission of such a team in relation to the four main focus areas.</p>
<p>Both of these problems can, for different reasons, result in badly missed expectations, a lot of frustration, and wasted time.  In forming a data strategy and missions to go along with it, it helps to fit the activities of a Data Science group into some sort of general structure.  In order to assist companies with this, I use the following framework to describe what concerns a Data Science group, which can then be used to derive strategy and mission.</p>

<h3 id="part-0-ethical-and-legal-concerns" class="anchor-link"><a href="#part-0-ethical-and-legal-concerns">Part 0: Ethical and legal concerns</a></h3>
<p>Any time the discussion is about methods for data collection or analysis, it is first important to identify and account for as many data privacy issues as possible.  The phrase &ldquo;Privacy by Design&rdquo; arises here and is fitting for the requirements of data processing systems and Data Science groups.  This concept is critical from an ethical perspective, and from a legal one as well.  The EU and USA are both working to improve the data regulatory environment, but in many cases they don&rsquo;t go far enough.  Expect data privacy laws to become more strict to reflect increasing business and consumer demand for better minimum legal protections.</p>
<p>When considering what data to collect, a good general principle is to start by collecting everything that is available and then exclude whatever data is ethically or legally objectionable.  In cases where more detailed data is required, like a complete IP address for fraud detection purposes, perhaps it can be stored only temporarily.  This is where limitations on data lifetime come into play.  A good compromise could be something like keeping an IP address for some hours or days in order to do most of the required fraud detection work, but then discarding that data in order to achieve the greater privacy goals.  Data should also be anonymised in order to eliminate ethical or legal problems with collecting and storying potentially sensitive data.</p>
<p>Another options is decreasing the level of detail, or resolution, of the data.  In the IP address case, perhaps the complete IP address is not required, but rather only part of it.  This allowed the data to be pseudo-anonymous, which is much more beneficial for users.  Of course, being pseudo-anonymous in the sense of being one in a group of 10 million is much different from being seen as one in a group of 2, but every little bit helps.</p>
<p>The EU data privacy directive in particular started with all user data being classified as personal, but they have since gone more in the direction of accepting pseudo-anonymity.  This must be balanced by the &ldquo;mosaic effect&rdquo; as mentioned above.  Individual pieces of data may not be useful to identify you, but collecting vast amounts of seemingly useless data can be very accurate in identifying a natural person.</p>

<h3 id="collect" class="anchor-link"><a href="#collect">Collect</a></h3>
<p>There are many questions that arise when analyzing data collection options and effectiveness.  All data that is stored, analyzed, or productized arises from this step and there are some important questions that should be asked.</p>

<h4 id="methods-and-sources" class="anchor-link"><a href="#methods-and-sources">Methods and sources</a></h4>
<p>The sources of data are ideally mostly from internally-controlled sources like a customer using your web application.  In this case you have total control over what is measured and collected, and you can start to measure new things or stop measuring existing things as you like.</p>
<p>There is also the option to use externally-controlled data sources like companies who aggregate data about people, including your customers.  There can be quite a bit of risk with this option, since you could be basing a product or service on data that you don&rsquo;t have under your control.  External data sources are nice to use to augment internal sources, but be aware of the risk of making critical products or services dependent on external data.  A good example of the downsides can be seen in the way many companies suffered as Twitter changed their API in the last few years.</p>
<p>The goal of the methods and sources area is to get an overview of the current options for internal and external data sources, and potentially identify any additional data sources that are not being used by the company.</p>

<h4 id="data-format-and-speed" class="anchor-link"><a href="#data-format-and-speed">Data format and speed</a></h4>
<p>Once the sources are identified, it&rsquo;s important to examine the format and speed with which these sources deliver data.  Does the data come by CSV files sent hourly or nightly?  Is the data provided by a direct connection to a real-time feed?  The answers to these questions have large consequences on the ways that the data can and cannot be used.</p>

<h4 id="data-quality-standards" class="anchor-link"><a href="#data-quality-standards">Data quality standards</a></h4>
<p>When the data arrives from a source, does it require a lot of further processing in order to be usable?  How strong are the guarantees for things like the uniqueness of user IDs and other constraints or are there no guarantees an ID will even be present?  Is missing data handled in consistent and logical ways or does the system do strange things like silently generate missing data?</p>
<p>Having been in situations where I&rsquo;ve had to deal with the undesirable answers to the above questions, I learned the hard way that I should have asked those questions earlier.  If you build a data processing system on top of inconsistent data then it&rsquo;s just garbage in, garbage out.</p>
<p>The goal of course should be that the data is clean, requires minimal or no additional processing before use, that all reasonable constraints are present and enforced, and that missing data is not dealt with in unexpected ways.</p>

<h4 id="completeness-of-data-from-a-source" class="anchor-link"><a href="#completeness-of-data-from-a-source">Completeness of data from a source</a></h4>
<p>When a source is being used for collection, it may provide 10 valuable pieces of data, but only 9 are ever collected.  There could be new ways to obtain more data from the same source, and those ways should be explored.  If you had to send an advertisement to a mobile device, would you rather only know the request came from an Android device, or would it be helpful to also know that the request came from within 100 meters of a supermarket?  Additional data is usually helpful, but not always provided by default since many systems were not designed to make data products the end result.</p>

<h3 id="store" class="anchor-link"><a href="#store">Store</a></h3>
<p>Once the data is being collected, the question of how to store it must be addressed.  As before, there are many consequences of the decisions at this step since you can only build products on data that is available in storage.</p>

<h4 id="what-is-the-capacity-in-terms-of-volume-and-speed" class="anchor-link"><a href="#what-is-the-capacity-in-terms-of-volume-and-speed">What is the capacity in terms of volume and speed?</a></h4>
<p>The first question is whether or not the storage system or systems can actually handle the volume of data and the speed with which the data is produced.  A very large but slow storage system may be better, or a small but extremely fast storage system may be better, all depending on company and product demands.</p>
<p>The storage question is usually handled by simple files on disk, relational databases, non-relational databases, or in-memory systems.  In the past these were all relatively distinct categories, but there are now systems that are hybrids between two or more of those categories.</p>
<p>An additional concern is if there will be any intermediate storage or messaging systems.  For time-critical processing, it is often useful to have a high-speed system that handles a small time window of data, say hours or weeks, and then a secondary slower and larger system in which all historical data is archived.  Both can be used, but one will not satisfy the requirements of the other and hence both are often required.  The main issue is, can the storage system handle the data?</p>

<h4 id="future-data-and-product-strategy" class="anchor-link"><a href="#future-data-and-product-strategy">Future data and product strategy</a></h4>
<p>The storage systems should support the direction in which the company is going.  For example, if the company is trying to have better responsiveness when processing new data then building systems that only work effectively in a batch processing framework is not a good choice.  Even if such systems are most well-known by the employees of the company.</p>
<p>A good example is something like payments to publishers in an advertising context.  If the payment system is built on sequential batch jobs, then it will only be possible to pay someone once that sequence of jobs has completed.  If the company has an overall strategy to reduce payout times, a contradiction is reached because the data processing system is simply not capable of that, which limits further improvement in customer service.</p>

<h4 id="what-kind-of-retention-guidelines-are-in-place" class="anchor-link"><a href="#what-kind-of-retention-guidelines-are-in-place">What kind of retention guidelines are in place?</a></h4>
<p>While the volume and speed considerations in the first section were more about the requirements of customers and products, this is more about the internal requirements of the company.  If the company has committed to retaining 5 years of customer history, it&rsquo;s important that the data systems can support that goal.  This brings up topics like compression and storage formats, horizontal scalability of storage systems, and so on.  A good strategy is of course to maximize vertical scalability with things like compression and then to move on to horizontal scalability with things like sharding and clustering of databases and storage and processing systems like Hadoop.</p>

<h3 id="analyze" class="anchor-link"><a href="#analyze">Analyze</a></h3>
<p>After the proper collection and storage questions have been answered, data is flowing in, and being stored for further use, the analysis-related topics must be addressed.  These include questions like what kind of analysis results could be produced?  Do we have the capability to do batch and real-time analysis?  If not, why not?  Will any such limitations that be overly burdensome in terms of which products can be designed and built?  Is there missing data that would be useful or necessary for an effective analysis?  If so, return to the collection topic.  Additionally, performance and accuracy concerns arise here as well due to the ability of many algorithms to dramatically improve both.  Often the algorithm can do more to improve the analysis speed than any investments in bigger or more servers, or new data analysis frameworks like Hadoop.</p>

<h3 id="productize" class="anchor-link"><a href="#productize">Productize</a></h3>
<p>What kinds of problems does the customer (internal or external) have?
What kinds of problems can be solved with the data we have?
What is the overlap, if any?
Does the technology architecture support independent data products that can be worked on and deployed only by the DS team, or is there significant support from other departments (e.g., Engineering, Operations) required?</p>
 ]]></content:encoded></item><item><title>Data Science and Organizational Structure</title><link>https://adamdrake.com/data-science-and-organizational-structure.html</link><pubDate>Sat, 25 Jan 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/data-science-and-organizational-structure.html</guid><description>&lt;h3 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h3>
&lt;p>When a company wants to make data one of the prime focuses of the business, often the first problem that arises is how to fit a Data Science team into the current organizational structure. Similar problems have risen in the past with Business Intelligence/Business Analytics, and other disciplines, but the reason that Data Science presents a different problem is because it is a superset of previous areas in terms of technical and business scope. Since a Data Science group is concerned with so many areas of the business, and many levels of technical and product detail, itâ€™s not always straightforward to arrange a Data Science team within the existing organizational structure.&lt;/p></description><content:encoded><![CDATA[ 
<h3 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h3>
<p>When a company wants to make data one of the prime focuses of the business, often the first problem that arises is how to fit a Data Science team into the current organizational structure.  Similar problems have risen in the past with Business Intelligence/Business Analytics, and other disciplines, but the reason that Data Science presents a different problem is because it is a superset of previous areas in terms of technical and business scope.  Since a Data Science group is concerned with so many areas of the business, and many levels of technical and product detail, itâ€™s not always straightforward to arrange a Data Science team within the existing organizational structure.</p>

<h3 id="what-does-a-data-science-group-do" class="anchor-link"><a href="#what-does-a-data-science-group-do">What does a Data Science group do?</a></h3>
<p>In order to find the best place for the group, the first priority is to understand what it will actually do in the organization.  What is the specific mandate from the board?  From the CEO?  Questions on overall scope and company strategy are an absolute prerequisite.  Assuming the company has an overall strategy to use data more effectively and not just some short-term product goals, the Data Science team should be focused on concerns across departments and hierarchies.  This could include things like building forecasting or customer churn models for Sales, helping HR optimize recruiting, helping Marketing or Sales better target potential customers, or building new recommendation systems into the product.</p>
<p>Within the scope of individual product or service offerings, a Data Science team is concerned with many levels of detail, from the presentation of data and user interface (note: user interfaces are not always technical) all the way down to the efficiency with which the data is stored in the back-end systems.</p>
<p>This broad scope, and deep reach, has the potential to create massive benefits for a company, and also the potential for a lot of internal politics and conflict.  If the group is not well-positioned and the mandate of the board members absolutely clear, the result can be increased politics and lack of effectiveness in the broader organization.  In order to be successful, a Data Science group needs independence, support, and wide authority to operate where and how needed.</p>

<h3 id="where-could-data-science-fit" class="anchor-link"><a href="#where-could-data-science-fit">Where could Data Science fit?</a></h3>
<p>A Data Science group is ideally a neutral and top-level part of the organization.  This positioning will reduce structural alliances or preferences to any other group and maximise the changes for success.  All parts of the company should be options for improvement as the company begins to develop a culture of using data properly for all aspects of the business.  This means improving current products and services and also finding new revenue sources from existing data.  In order to be effective, a Data Science team needs access to essentially all data the company has and make any suggestions about how to act, and this requires a mandate and support from the absolute highest levels of the company.</p>
<p>As with the creation of any new department or group within an organization, at any level, there is potential for causing the current political climate of the organization to deteriorate.  This varies greatly by company, but is often compounded by the fact that a Data Science group may become not only the source of data products but also the best source of information about the company.  Some people could seek to capitalize and exploit this, and such motives are something that the board and top executive should keep in mind.  From an operational perspective, this data access and analysis capability can also devolve into a stream of neverending ad-hoc data requests, which has the potential to distract the team and keep it focused on daily operational work instead of more strategic data goals.  This sort of reporting work is better accomplished by a BI department, or possibly a Finance and Controlling group.</p>

<h4 id="chief-data-officer-reporting-directly-to-the-board-of-directors" class="anchor-link"><a href="#chief-data-officer-reporting-directly-to-the-board-of-directors">Chief Data Officer reporting directly to the Board of Directors</a></h4>
<p>The best solution is to have a top-level Chief Data Officer position, that perhaps reports directly to a senior board member.  Without this, neutrality is automatically compromised since having the group under any other department implicitly makes it a tool of that department.  This can be intentional due to politics and management, or unintentional and due to the simple fact that being embedded in one department makes people more aware of the problems faced by that particular department.  Having a top-level and neutral role avoids intentional or unintentional favoritism and allows for the desired broad benefits to the company to materialize.  The Chief Data Officer role is not a new one.  It has existed for over a decade at places like Facebook, Yahoo, CitiGroup, and even in government as cities in the US like San Francisco, Chicago, Philadelphia, Baltimore, and New York all have Chief Data Officers.  Even the US Army has a Chief Data Officer.  Private companies, strangely enough, are lagging behind government entities in creating the role.</p>

<h4 id="chief-data-officer-reporting-to-highest-ranking-executive" class="anchor-link"><a href="#chief-data-officer-reporting-to-highest-ranking-executive">Chief Data Officer reporting to highest-ranking executive</a></h4>
<p>Aside from reporting directly to the Board, the next best option is for the Chief Data Officer to report directly to the CEO (in cases where other executives report to the CEO) or to the CTO/CIO (in cases where all executives are equivalent and report to a higher board).  This still preserves some measure of neutrality, and allows the person to provide the organization with broad advice and results.  There can be problems that arise in the case that there are separate executives for the Product and Technology groups.  Since a Data Science team will need to work unhindered in both areas, there is potential for conflict.</p>

<h4 id="direct-report-to-head-of-technology-or-product" class="anchor-link"><a href="#direct-report-to-head-of-technology-or-product">Direct report to head of Technology or Product</a></h4>
<p>It is possible for a Data Science group to be part of the Engineering or Product departments, as the group will naturally work very closely with both of those areas.  Engineering regarding implementation of data products in production systems and Product in developing and prioritizing new data products, improving their knowledge of the customer, and collaborating on how data products fit into the overall product roadmap.  This has the potential for the conflicts mentioned previously, but itâ€™s still better than some other options.</p>

<h4 id="worst-case-scenario-direct-report-to-head-of-sales-or-marketing" class="anchor-link"><a href="#worst-case-scenario-direct-report-to-head-of-sales-or-marketing">Worst-case scenario: Direct report to head of Sales or Marketing</a></h4>
<p>This is the least-desirable situation.  In this scenario the Data Science group is separated from the Product and Engineering teams, meaning they are too far away from the entire product development process.  Additionally, it is often the case that the reason the Data Science group ends up inside of Sales or Marketing is because the head of Sales or Marketing is the biggest data champion in the company due to the fact they see they have a lot to gain from better knowledge and usage of their data.  Things like identifying customers who are likely to churn, improving target lists for new sales, and so on are certainly within the realm of what a Data Science team should be doing, but those arenâ€™t the only things they should be doing.  The risk of having a Data Science team inside the Sales or Marketing group is that they become servants of only that group and the company loses out on the broader benefits of having a skilled Data Science team, like improvements to products, internal processes across departments, and so on.</p>

<h3 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h3>
<p>Having a Data Science group is of course a great benefit to many companies, but where to place the group to maximize the benefits and chances of success is another matter.  The most important requirement is of course that the group is as neutral as possible, and has as much freedom to operate as possible.  This means ideally positioning the group directly under the Board of Directors, with additional options being directly under the sole executive (e.g., CEO) or another executive department (CIO/CTO).  An acceptable but limiting arrangement could be positioning inside the Engineering or Product departments, with the least desirable outcome being positioning in an area like Sales or Marketing.</p>
 ]]></content:encoded></item><item><title>Command-line Tools can be 235x Faster than your Hadoop Cluster</title><link>https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html</link><pubDate>Sat, 18 Jan 2014 00:00:00 +0000</pubDate><guid>https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html</guid><description>&lt;h3 id="introduction" class="anchor-link">&lt;a href="#introduction">Introduction&lt;/a>&lt;/h3>
&lt;p>As I was browsing the web and catching up on some sites I visit periodically, I found a cool article from &lt;a href="https://tomhayden3.com/2013/12/27/chess-mr-job/">Tom Hayden&lt;/a> about using &lt;a href="https://aws.amazon.com/elasticmapreduce/">Amazon Elastic Map Reduce&lt;/a> (EMR) and &lt;a href="https://github.com/Yelp/mrjob">mrjob&lt;/a> in order to compute some statistics on win/loss ratios for chess games he downloaded from the &lt;a href="https://www.top-5000.nl/pgn.htm">millionbase archive&lt;/a>, and generally have fun with EMR. Since the data volume was only about 1.75GB containing around 2 million chess games, I was skeptical of using Hadoop for the task, but I can understand his goal of learning and having fun with mrjob and EMR. Since the problem is basically just to look at the result lines of each file and aggregate the different results, it seems ideally suited to stream processing with shell commands. I tried this out, and for the same amount of data I was able to use my laptop to get the results in about 12 seconds (processing speed of about 270MB/sec), while the Hadoop processing took about 26 minutes (processing speed of about 1.14MB/sec).&lt;/p></description><content:encoded><![CDATA[ 
<h3 id="introduction" class="anchor-link"><a href="#introduction">Introduction</a></h3>
<p>As I was browsing the web and catching up on some sites I visit periodically, I found a cool article from <a href="https://tomhayden3.com/2013/12/27/chess-mr-job/">Tom Hayden</a> about using <a href="https://aws.amazon.com/elasticmapreduce/">Amazon Elastic Map Reduce</a> (EMR) and <a href="https://github.com/Yelp/mrjob">mrjob</a> in order to compute some statistics on win/loss ratios for chess games he downloaded from the <a href="https://www.top-5000.nl/pgn.htm">millionbase archive</a>, and generally have fun with EMR.  Since the data volume was only about 1.75GB containing around 2 million chess games, I was skeptical of using Hadoop for the task, but I can understand his goal of learning and having fun with mrjob and EMR.  Since the problem is basically just to look at the result lines of each file and aggregate the different results, it seems ideally suited to stream processing with shell commands.  I tried this out, and for the same amount of data I was able to use my laptop to get the results in about 12 seconds (processing speed of about 270MB/sec), while the Hadoop processing took about 26 minutes (processing speed of about 1.14MB/sec).</p>
<p>After reporting that the time required to process the data with 7 c1.medium machine in the cluster took 26 minutes, Tom remarks</p>
<blockquote>
<p>This is probably better than it would take to run serially on my machine but probably not as good as if I did some kind of clever multi-threaded application locally.</p>
</blockquote>
<p>This is absolutely correct, although even serial processing may beat 26 minutes.  Although Tom was doing the project for fun, often people use Hadoop and other so-called <em>Big Data (tm)</em> tools for real-world processing and analysis jobs that can be done faster with simpler tools and different techniques.</p>
<p>One especially under-used approach for data processing is using standard shell tools and commands.  The benefits of this approach can be massive, since creating a data pipeline out of shell commands means that all the processing steps can be done in parallel.  This is basically like having your own <a href="https://storm-project.net/">Storm</a> cluster on your local machine.  Even the concepts of Spouts, Bolts, and Sinks transfer to shell pipes and the commands between them.  You can pretty easily construct a stream processing pipeline with basic commands that will have extremely good performance compared to many modern <em>Big Data (tm)</em> tools.</p>
<p>An additional point is the batch versus streaming analysis approach.  Tom mentions in the beginning of the piece that after loading 10000 games and doing the analysis locally, that he gets a bit short on memory.  This is because all game data is loaded into RAM for the analysis.  However, considering the problem for a bit, it can be easily solved with streaming analysis that requires basically no memory at all.  The resulting stream processing pipeline we will create will be over 235 times faster than the Hadoop implementation and use virtually no memory.</p>

<h3 id="learn-about-the-data" class="anchor-link"><a href="#learn-about-the-data">Learn about the data</a></h3>
<p>The first step in the pipeline is to get the data out of the PGN files.  Since I had no idea what kind of format this was, I checked it out on <a href="https://en.wikipedia.org/wiki/Portable_Game_Notation">Wikipedia</a>.</p>
<pre tabindex="0"><code>[Event &#34;F/S Return Match&#34;]
[Site &#34;Belgrade, Serbia Yugoslavia|JUG&#34;]
[Date &#34;1992.11.04&#34;]
[Round &#34;29&#34;]
[White &#34;Fischer, Robert J.&#34;]
[Black &#34;Spassky, Boris V.&#34;]
[Result &#34;1/2-1/2&#34;]
(moves from the game follow...)
</code></pre><p>We are only interested in the results of the game, which only have 3 real outcomes.  The 1-0 case means that white won, the 0-1 case means that black won, and the 1/2-1/2 case means the game was a draw.  There is also a <em>-</em> case meaning the game is ongoing or cannot be scored, but we ignore that for our purposes.</p>

<h3 id="acquire-sample-data" class="anchor-link"><a href="#acquire-sample-data">Acquire sample data</a></h3>
<p>The first thing to do is get a lot of game data.  This proved more difficult than I thought it would be, but after some looking around online I found a git repository on GitHub from <a href="https://github.com/rozim/ChessData">rozim</a> that had plenty of games.  I used this to compile a set of 3.46GB of data, which is about twice what Tom used in his test.  The next step is to get all that data into our pipeline.</p>

<h3 id="build-a-processing-pipeline" class="anchor-link"><a href="#build-a-processing-pipeline">Build a processing pipeline</a></h3>
<p><em>If you are following along and timing your processing, don&rsquo;t forget to clear your OS page cache as otherwise you won&rsquo;t get valid processing times.</em></p>
<p>Shell commands are great for data processing pipelines because you get parallelism for free.  For proof, try a simple example in your terminal.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sleep <span style="color:#ae81ff">3</span> | echo <span style="color:#e6db74">&#34;Hello world.&#34;</span>
</span></span></code></pre></div><p>Intuitively it may seem that the above will sleep for 3 seconds and then print <code>Hello world</code> but in fact both steps are done at the same time.  This basic fact is what can offer such great speedups for simple non-IO-bound processing systems capable of running on a single machine.</p>
<p>Before starting the analysis pipeline, it is good to get a reference for how fast it could be and for this we can simply dump the data to <code>/dev/null</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat *.pgn &gt; /dev/null
</span></span></code></pre></div><p>In this case, it takes about 13 seconds to go through the 3.46GB, which is about 272MB/sec.  This would be a kind of upper-bound on how quickly data could be processed on this system due to IO constraints.</p>
<p>Now we can start on the analysis pipeline, the first step of which is using <code>cat</code> to generate the stream of data.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat *.pgn
</span></span></code></pre></div><p>Since only the result lines in the files are interesting, we can simply scan through all the data files, and pick out the lines containing &lsquo;Results&rsquo; with <code>grep</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat *.pgn | grep <span style="color:#e6db74">&#34;Result&#34;</span>
</span></span></code></pre></div><p>This will give us only the <code>Result</code> lines from the files.  Now if we want, we can simply use the <code>sort</code> and <code>uniq</code> commands in order to get a list of all the unique items in the file along with their counts.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat *.pgn | grep <span style="color:#e6db74">&#34;Result&#34;</span> | sort | uniq -c
</span></span></code></pre></div><p>This is a very straightforward analysis pipeline, and gives us the results in about 70 seconds.  While we can certainly do better, assuming linear scaling this would have taken the Hadoop cluster approximately 52 minutes to process.</p>
<p>In order to reduce the speed further, we can take out the <code>sort | uniq</code> steps from the pipeline, and replace them with AWK, which is a wonderful tool/language for event-based data processing.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cat *.pgn | grep <span style="color:#e6db74">&#34;Result&#34;</span> | awk <span style="color:#e6db74">&#39;{ split($0, a, &#34;-&#34;); res = substr(a[1], length(a[1]), 1); if (res == 1) white++; if (res == 0) black++; if (res == 2) draw++;} END { print white+black+draw, white, black, draw }&#39;</span>
</span></span></code></pre></div><p>This will take each result record, split it on the hyphen, and take the character immediately to the left, which will be a 0 in the case of a win for black, a 1 in the case of a win for white, or a 2 in the case of a draw.  Note that <code>$0</code> is a built-in variable that represents the entire record.</p>
<p>This reduces the running time to approximately 65 seconds, and since we&rsquo;re processing twice as much data this is a speedup of around 47 times.</p>
<p>So even at this point we already have a speedup of around 47 with a naive local solution.  Additionally, the memory usage is effectively zero since the only data stored is the actual counts, and incrementing 3 integers is almost free in memory space terms.  However, looking at <code>htop</code> while this is running shows that <code>grep</code> is currently the bottleneck with full usage of a single CPU core.</p>

<h3 id="parallelize-the-bottlenecks" class="anchor-link"><a href="#parallelize-the-bottlenecks">Parallelize the bottlenecks</a></h3>
<p>This problem of unused cores can be fixed with the wonderful <code>xargs</code> command, which will allow us to parallelize the <code>grep</code>.  Since <code>xargs</code> expects input in a certain way, it is safer and easier to use <code>find</code> with the <code>-print0</code> argument in order to make sure that each file name being passed to <code>xargs</code> is null-terminated.  The corresponding <code>-0</code> tells <code>xargs</code> to expected null-terminated input.  Additionally, the <code>-n</code> how many inputs to give each process and the <code>-P</code> indicates the number of processes to run in parallel.  Also important to be aware of is that such a parallel pipeline doesn&rsquo;t guarantee delivery order, but this isn&rsquo;t a problem if you are used to dealing with distributed processing systems.  The <code>-F</code> for <code>grep</code> indicates that we are only matching on fixed strings and not doing any fancy regex, and can offer a small speedup, which I did not notice in my testing.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>find . -type f -name <span style="color:#e6db74">&#39;*.pgn&#39;</span> -print0 | xargs -0 -n1 -P4 grep -F <span style="color:#e6db74">&#34;Result&#34;</span> | gawk <span style="color:#e6db74">&#39;{ split($0, a, &#34;-&#34;); res = substr(a[1], length(a[1]), 1); if (res == 1) white++; if (res == 0) black++; if (res == 2) draw++;} END { print NR, white, black, draw }&#39;</span>
</span></span></code></pre></div><p>This results in a run time of about 38 seconds, which is an additional 40% or so reduction in processing time from parallelizing the <code>grep</code> step in our pipeline.  This gets us up to approximately 77 times faster than the Hadoop implementation.</p>
<p>Although we have improved the performance dramatically by parallelizing the <code>grep</code> step in our pipeline, we can actually remove this entirely by having <code>awk</code> filter the input records (lines in this case) and only operate on those containing the string &ldquo;Result&rdquo;.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>find . -type f -name <span style="color:#e6db74">&#39;*.pgn&#39;</span> -print0 | xargs -0 -n1 -P4 awk <span style="color:#e6db74">&#39;/Result/ { split($0, a, &#34;-&#34;); res = substr(a[1], length(a[1]), 1); if (res == 1) white++; if (res == 0) black++; if (res == 2) draw++;} END { print white+black+draw, white, black, draw }&#39;</span>
</span></span></code></pre></div><p>You may think that would be the correct solution, but this will output the results of <strong>each</strong> file individually, when we want to aggregate them all together.  The resulting correct implementation is conceptually very similar to what the MapReduce implementation would be.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>find . -type f -name <span style="color:#e6db74">&#39;*.pgn&#39;</span> -print0 | xargs -0 -n4 -P4 awk <span style="color:#e6db74">&#39;/Result/ { split($0, a, &#34;-&#34;); res = substr(a[1], length(a[1]), 1); if (res == 1) white++; if (res == 0) black++; if (res == 2) draw++ } END { print white+black+draw, white, black, draw }&#39;</span> | awk <span style="color:#e6db74">&#39;{games += $1; white += $2; black += $3; draw += $4; } END { print games, white, black, draw }&#39;</span>
</span></span></code></pre></div><p>By adding the second awk step at the end, we obtain the aggregated game information as desired.</p>
<p>This further improves the speed dramatically, achieving a running time of about 18 seconds, or about 174 times faster than the Hadoop implementation.</p>
<p>However, we can make it a bit faster still by using <a href="https://invisible-island.net/mawk/mawk.html">mawk</a>, which is often a drop-in replacement for <code>gawk</code> and can offer better performance.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>find . -type f -name <span style="color:#e6db74">&#39;*.pgn&#39;</span> -print0 | xargs -0 -n4 -P4 mawk <span style="color:#e6db74">&#39;/Result/ { split($0, a, &#34;-&#34;); res = substr(a[1], length(a[1]), 1); if (res == 1) white++; if (res == 0) black++; if (res == 2) draw++ } END { print white+black+draw, white, black, draw }&#39;</span> | mawk <span style="color:#e6db74">&#39;{games += $1; white += $2; black += $3; draw += $4; } END { print games, white, black, draw }&#39;</span>
</span></span></code></pre></div><p>This <code>find | xargs mawk | mawk</code> pipeline gets us down to a runtime of about 12 seconds, or about 270MB/sec, which is around 235 times faster than the Hadoop implementation.</p>

<h3 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h3>
<p>Hopefully this has illustrated some points about using and abusing tools like Hadoop for data processing tasks that can better be accomplished on a single machine with simple shell commands and tools.  If you have a huge amount of data or really need distributed processing, then tools like Hadoop may be required, but more often than not these days I see Hadoop used where a traditional relational database or other solutions would be far better in terms of performance, cost of implementation, and ongoing maintenance.</p>
 ]]></content:encoded></item><item><title>Real-Time Bidding, First and Second-Price Auctions, and Transparency</title><link>https://adamdrake.com/real-time-bidding-first-and-second-price-auctions-and-transparency.html</link><pubDate>Sat, 19 May 2012 00:00:00 +0000</pubDate><guid>https://adamdrake.com/real-time-bidding-first-and-second-price-auctions-and-transparency.html</guid><description>&lt;p>There has been some debate recently on &lt;a href="https://www.adexchanger.com">AdExchanger&lt;/a> about the benefits
of first price versus second price auctions. Esco Strong, the Director
of Display Marketplace Strategy for &lt;a href="https://advertising.microsoft.com">Microsoft Advertising&lt;/a> &lt;a href="https://www.adexchanger.com/data-driven-thinking/second-guessing-the-second-price-auction-model/">wrote an
article&lt;/a> that basically said second price auctions didn&amp;rsquo;t work well for
single unit RTB auctions and we should get rid of them:&lt;/p>
&lt;blockquote>
&lt;p>Comparatively, first-price auctions are competitions where there is
no reduction in clearing price for the auction winner; instead, the
winner simply acquires the good they have won by paying the price of
their bid. The dynamics of this type of marketplace would become
much more straightforward and predictable, enabling more parties to
participate and experience stable results, as well as manage their
businesses to a of set expectations that won&amp;rsquo;t require constant
revision.&lt;/p></description><content:encoded><![CDATA[ <p>There has been some debate recently on <a href="https://www.adexchanger.com">AdExchanger</a> about the benefits
of first price versus second price auctions. Esco Strong, the Director
of Display Marketplace Strategy for <a href="https://advertising.microsoft.com">Microsoft Advertising</a> <a href="https://www.adexchanger.com/data-driven-thinking/second-guessing-the-second-price-auction-model/">wrote an
article</a> that basically said second price auctions didn&rsquo;t work well for
single unit RTB auctions and we should get rid of them:</p>
<blockquote>
<p>Comparatively, first-price auctions are competitions where there is
no reduction in clearing price for the auction winner; instead, the
winner simply acquires the good they have won by paying the price of
their bid. The dynamics of this type of marketplace would become
much more straightforward and predictable, enabling more parties to
participate and experience stable results, as well as manage their
businesses to a of set expectations that won&rsquo;t require constant
revision.</p>
</blockquote>
<p>Then Jonathan Wolf, Chief Buying Officer for <a href="https://criteo.com">Criteo</a>, <a href="https://www.adexchanger.com/the-sell-sider/incentivizing-low-bidding/">wrote a
response</a> that disputed the claims made by Esco Strong:</p>
<blockquote>
<p>While I am and remain a fan of Esco, and his piece was elegantly
argued, I strongly disagree with it. As I see it, there are two
options in building a long-term business: by pricing transparently,
or by taking unfair advantage of your customers. Only the first
seems sustainable to me.</p>
</blockquote>
<p>He then went on to touch on some topics relating to first and second
price auction mechanisms with some input from the Business Intelligence
group at Criteo. The problem with Esco Strong&rsquo;s original article is that
it shows a strong lack of understanding on some critical basics of
auction theory and mechanism design. Things like the Bayes-Nash
Equilibrium, Revenue Equivalence Theorem, and construction of optimal
floor prices were not really mentioned for some reason. So, what are you
to do if you want to design an auction mechanism to participate in the
RTB space? I&rsquo;m glad you asked. The short answer is to use a sealed bid,
second price auction with a revenue-optimal reserve price. This kind of
auction is nothing new and has been around since Myerson&rsquo;s crucial 1981
paper <a href="https://www.cs.princeton.edu/courses/archive/spr09/cos444/papers/myerson81.pdf">Optimal Auction Design</a>.</p>

<h3 id="revenue-equivalence-theorem" class="anchor-link"><a href="#revenue-equivalence-theorem">Revenue Equivalence Theorem</a></h3>
<p>Let&rsquo;s say you want to sell something and you need to know which auction
mechanism will provide you with the move revenue. There is a result in
Auction Theory dating back to Vickery in 1961 (that Myerson generalized)
that says if the auction has the following criteria:</p>
<ol>
<li>
<p>The bidder with the highest signal/valuation/whatever wins the
auction.</p>
</li>
<li>
<p>The bidder with the lowest signal/valuation/whatever expects zero
surplus (i.e., they win nothing).</p>
</li>
<li>
<p>All the bidders are risk-neutral.</p>
</li>
<li>
<p>All bids are drawn from a strictly increasing and atomless
distribution.</p>
</li>
</ol>
<p>then your choice of auction mechanism will not have an impact on your
revenue as the seller. As long as those conditions are met then your
choice of mechanism is not relevant to your overall revenue. <em>Bid
Shading and Revenue Volatility</em> So, why bother with any debate about
first versus second-price auctions if the revenue to the seller is
equivalent? Well, because there are some problems with using a
first-price auction. First of all, bidders don&rsquo;t have any reason to bid
their true value and instead are more motivated to engage in <a href="https://en.wikipedia.org/wiki/Bid_shading">bid
shading</a>, which just means bidding slightly less than you think the
item will sell for. This kind of bidding strategy leads to more
volatility in revenue for the seller, even though the long-term revenues
would be equivalent by the Revenue Equivalence Theorem. Most of the
people in the Finance and Controlling departments don&rsquo;t really like
increased volatility in the revenue, so it&rsquo;s not so cool for them or
anyone else involved on the business side to have to deal with it.
Additionally, if you are on the buy side then you have to do all kinds
of trickery and magic in order to figure out what the true market price
is. It&rsquo;s a waste of time and energy and it doesn&rsquo;t make anybody happy.</p>

<h3 id="price-discrimination" class="anchor-link"><a href="#price-discrimination">Price Discrimination</a></h3>
<p>One thing that was touched on by Jonathan
Wolf was the use of what he called <em>dynamic pricing</em>, which is just a
different way of saying <em>price discrimination</em>. In theory, <a href="https://en.wikipedia.org/wiki/Price_discrimination">price
discrimination</a> comes into play when you have a market for goods, the
goods cannot be transferred easily or at all after being sold, and there
is either only one place to get the goods or a few limited sources. In
this way it is possible to charge different buyers different prices for
the same item. There are different kinds of price discrimination that we
encounter in our every day lives. For example, the concept of buying in
bulk in order to pay a lower cost per unit is a standard example of
so-called <em>second degree price discrimination</em>. If you have a monopoly
on certain publishers and you are entering that inventory into an RTB
system and you also have really fantastic data analysis skills, then you
can take advantage of monopolistic effects and do things like <em>first
degree price discrimination</em>, which basically means you charge the buyer
exactly what highest price that they&rsquo;re willing to pay. However, price
discrimination may not be advisable as a long-term business strategy as
the eventual result is that people would rather do business somewhere
else than deal with your games. This leads to a discussion on . . .</p>

<h3 id="transparency-and-accountability" class="anchor-link"><a href="#transparency-and-accountability">Transparency and Accountability</a></h3>
<p>Most of my experience comes from the
financial services industry, and almost all of that was in doing
consulting work for mutual funds and investment advisors in the US. This
industry is heavily regulated (although it needs more if you ask me) and
many of these regulations are designed to provide transparency and
accountability. We will need the same two things in the RTB space as
computational advertising evolves. Any company that is going to provide
an RTB system for others to participate in should be as clear as
possible about how their auction system works, the design of the
mechanism, how any conflicts of interest are handled, and so on. A lot
can be learned here from the transparency and accountability rules of
the finance space. The more transparent you are with regard to your RTB
system, the more comfortable people will be participating. When I was at
the <a href="https://www.adtrader-conference.com/en/">AdTrader Conference</a> in Hamburg last month, one of the things I
discussed with quite a few attendees was concern about and desire for
transparency in RTB systems. I can tell you all that any sort of <em>black
box</em> implementation just isn&rsquo;t going to cut it. I spoke with people from
all sides who were skeptical about participation in such an exchange.
You will have to be open and transparent about your systems (to extent
possible) if you want people to buy in and be comfortable doing business
with you. This is not some new groundbreaking business philosophy, but
some companies will be tempted to take advantage of the newness and lack
of understanding about RTB systems in order to try to make a quick buck.
You probably wouldn&rsquo;t buy or sell stocks on an exchange that didn&rsquo;t provide
transparent pricing information. So why would you try
to sell people on a black box RTB auction system?</p>

<h3 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h3>
<p>So, the key takeaway here is that even though first-price and second-price
auctions generate equivalent revenue for sellers, first-price auctions
come with a lot of baggage that doesn&rsquo;t make sense to deal with. If
you&rsquo;re a buyer, then first-price auctions are a pain because you have to
employ strategies for true price determination/bid shading, and it just
adds complication. Additionally, if you are designing an RTB system,
transparency and accountability are the name of the game. Be honest
about how things work and the peace of mind your participants have will
be rewarded with loyalty.</p>
 ]]></content:encoded></item><item><title>MAC Addresses, UDIDs, and Privacy</title><link>https://adamdrake.com/mac-addresses-udids-and-privacy.html</link><pubDate>Fri, 06 Apr 2012 00:00:00 +0000</pubDate><guid>https://adamdrake.com/mac-addresses-udids-and-privacy.html</guid><description>&lt;p>There has been quite a bit of fuss in the days since Apple started
rejecting apps that make use of the UDID. The deprecation was announced
months ago, but the rejection started without warning and was a surprise
to some. Firms that had been planning for the change typically already
had multiple secondary solutions in place, many of which rely on using
the Media Access Control (MAC) address from the &lt;a href="https://en.wikipedia.org/wiki/Wireless_network_interface_controller">wireless network
interface controller&lt;/a> (wireless NIC) on the device. There have since
been complaints that this is just as much of a privacy problem as using
the UDID that Apple banned access to (keep in mind, they still have
access to it), but these complaints demonstrate a lack of understanding
on what a MAC address is, why it exists, and most notably the fact that
it is transmitted in a plainly-readable form that can be viewed by every
other device on any network to which you are connected.&lt;/p></description><content:encoded><![CDATA[ <p>There has been quite a bit of fuss in the days since Apple started
rejecting apps that make use of the UDID. The deprecation was announced
months ago, but the rejection started without warning and was a surprise
to some. Firms that had been planning for the change typically already
had multiple secondary solutions in place, many of which rely on using
the Media Access Control (MAC) address from the <a href="https://en.wikipedia.org/wiki/Wireless_network_interface_controller">wireless network
interface controller</a> (wireless NIC) on the device. There have since
been complaints that this is just as much of a privacy problem as using
the UDID that Apple banned access to (keep in mind, they still have
access to it), but these complaints demonstrate a lack of understanding
on what a MAC address is, why it exists, and most notably the fact that
it is transmitted in a plainly-readable form that can be viewed by every
other device on any network to which you are connected.</p>

<h3 id="some-background-on-mac-addresses" class="anchor-link"><a href="#some-background-on-mac-addresses">Some background on MAC addresses</a></h3>
<p>MAC stands for <a href="https://en.wikipedia.org/wiki/Media_access_control">Media Access Control</a>, and it is a
special identifier that is assigned by the manufacturer to every NIC
inside electronic devices. In theory, every NIC in every device has a
unique MAC address assigned to it. This has been the case for decades,
so there is nothing new or revolutionary going on here. If you have a
laptop with an ethernet NIC (where you plug in a cable to get on a
network) and a wireless NIC (so that you can access wireless networks),
and a Bluetooth controller (for keyboards, mice, etc.) then your laptop
will have three distinct MAC addresses, one for each NIC. These MAC
addresses are used to route the information from your device to other
devices or points on the network. The MAC address is somewhat like a
return address written on a letter, and due to its importance for
network communication, it isn&rsquo;t going anywhere any time soon. Any time
you send any information over the network, say to access a web page,
check your email, or any other task, this information is broken up into
tiny chunks, and each chunk contains information about where it came
from and where it&rsquo;s going. Maybe a more concrete example would better
illustrate how this works.</p>
<p>Say you want to mail a big book to a friend. If you used the same method
to send the book that your electronic device uses to surf the web, then
you wouldn&rsquo;t just send one big book in one big box. What your
computer/iPhone/whatever does is splits the book into stacks of say, 20
pages. Then it puts each stack of pages into its own envelope and writes
your friend&rsquo;s address and the return address (yours), so that your
friend knows where the letter came from. It also writes a number on each
envelope so that your friend can reassemble the pages inside the
envelopes in the correct order and make sure that they received all the
envelopes required to reconstruct the complete book. People are not
shocked by the fact that anyone who happens to see one of the envelopes
will also see the addressing information that you wrote on them.</p>
<p>This process works just the same when electronic devices communicate.
The difference is that the address of the sender and recipient are not a
name, street, city, and country. They are other identifiers, one of
which is the MAC address of your NIC. In general these pieces of
information can be seen by everyone who is on the same network as you,
and in some cases even people outside your network. In order words, if
you are surfing the web on your phone using a wireless network in a
coffee shop, then everyone else who is connected to that wireless network
can see your MAC address, and you can see theirs too. It&rsquo;s 100%,
completely, public. It is not encrypted, anonymized, or otherwise
abstracted. The MAC address from your device is broadcasted as clear as
if you wrote it on a huge piece of paper and held it above your head.
Everyone could easily read it, and they&rsquo;d think you were crazy if you
yelled at them for doing so. They would probably already think you were
crazy for writing a MAC address on a huge piece of paper and holding it
over your head, but you get my point.</p>

<h3 id="the-privacy-problem" class="anchor-link"><a href="#the-privacy-problem">The Privacy Problem</a></h3>
<p>So then the question becomes, is making use of information someone has
publicized actually a privacy problem? I am guessing that most people
who are raising the privacy issue in relation to the usage MAC addresses
don&rsquo;t realize that the MAC address is being constantly broadcast by
their device any time they are doing anything on any network. User
privacy is important, and that&rsquo;s why I fully advocate that companies
making use of the MAC address should anonymize it first. By doing so
they are voluntarily protecting the user.</p>
<p>From the opposite perspective, there is no way to easily disable or
change a MAC address. You can pretend to have a different one, called
<a href="https://en.wikipedia.org/wiki/MAC_spoofing">MAC Spoofing</a>, but it isn&rsquo;t always easy or possible to do so. In that
sense, anyone who is using a device connected to some network doesn&rsquo;t
really have a choice in regards to the visibility of their MAC address.
The MAC address exists and has for decades, it&rsquo;s pretty much required in
order for most devices to communicate, and there is nothing you can
easily do to get rid of it. In that sense, using the MAC address as a
device identifier poses the same problems as the UDID.</p>
<p>The big problem here is something that is very common when technology
and privacy intersect. People don&rsquo;t understand the details of how the
technology works, and for the most part they don&rsquo;t really care. This
causes people to use features that probably aren&rsquo;t good for their
privacy even though they shouldn&rsquo;t. This ignorance also causes them to
freak out about things that don&rsquo;t really have as much of an impact on
their privacy, because they don&rsquo;t understand the technology and this
lack of understanding results in fear. They will go along happily using
their iPhone, checking in with Foursquare, which is cross-posted to
their Facebook (or they check in with Facebook directly), and they tweet
pictures with Instagram, and they think nothing of doing all of this. In
reality, they are giving away an amazing amount of information about who
they are, where they are, and what they are doing.</p>
<p>For example, if you are checking in with Facebook or Foursquare then
people know where you are and where you aren&rsquo;t. If you have personal
photos on your (likely public) Facebook profile then someone can easily
just go to wherever you are (since you checked in), wait for you to come
out (since they have your photo), and follow you around. They could
follow you home, wait until you leave again, see that you have checked
in at work, and proceed to steal all your possessions. People are
voluntarily sharing all these things, this data that could be formed
into a very real threat, and people seem to be perfectly comfortable
with that. Why? You could make the argument that people are comfortable
sharing so much information because they are choosing to do so, but
that&rsquo;s not really a good argument if the choice is not a well-informed
one. I would advise people to visit the <a href="https://www.eff.org">Electronic Frontier Foundation</a>
(EFF), which has a specific page set up for <a href="https://www.eff.org/issues/social-networks">social network privacy
and security</a>. As is often the case, the privacy argument all comes
down to user education. They never knew anything about MAC addresses,
and now they&rsquo;re unhappy that there is some unique token that is tied to
their device. They just didn&rsquo;t know that it&rsquo;s been this way all along.</p>

<h3 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h3>
<p>So using UDIDs is not possible anymore, and that isn&rsquo;t a bad thing. Many
companies have switched to alternative methods, including using an
anonymized version of the MAC address. The MAC address is a necessary
part of communication between networked devices and is readable by all
devices on the same network (and always has been), so taking the step to
anonymize it (which every company should) is actually a step up for user
privacy.</p>
<p>You don&rsquo;t get to drive a car without license plates, you don&rsquo;t get to
send letters without writing an address on them, and you don&rsquo;t really
get to connect electronic devices to a network without a MAC address.
You do get to choose if you will drive, write letters, or surf the web,
and in these situations the user still does have the choice to opt-out.
Whether or not they feel the risks outweigh the benefits is something
only they can decide, but that decision should be an informed one. In
the meantime, companies making use of the MAC address should keep in
mind user privacy concerns, should always hash the MAC address so they
are not accessing the original, and should take all possible steps to
facilitate privacy and transparency for users.</p>
 ]]></content:encoded></item><item><title>UDID is Gone. So What?</title><link>https://adamdrake.com/udid-is-gone.-so-what.html</link><pubDate>Sat, 31 Mar 2012 00:00:00 +0000</pubDate><guid>https://adamdrake.com/udid-is-gone.-so-what.html</guid><description>&lt;p>The last week has seen quite a bit of commotion in the mobile world as
Apple has started enforcing their long-awaited deprecation of the use of
the UDID. Honestly, I&amp;rsquo;m not sure what all the fuss is about. This change
was announced by Apple last summer, so everyone has had nearly a year to
prepare for it. The general set of questions I&amp;rsquo;ve seen on the topic can
be reduced to the following.&lt;/p></description><content:encoded><![CDATA[ <p>The last week has seen quite a bit of commotion in the mobile world as
Apple has started enforcing their long-awaited deprecation of the use of
the UDID. Honestly, I&rsquo;m not sure what all the fuss is about. This change
was announced by Apple last summer, so everyone has had nearly a year to
prepare for it. The general set of questions I&rsquo;ve seen on the topic can
be reduced to the following.</p>

<h3 id="why-did-apple-do-this" class="anchor-link"><a href="#why-did-apple-do-this">Why did Apple do this?</a></h3>
<p>Most people would simply state the the reason is related to privacy
concerns, but I think that&rsquo;s the short and easy answer. Before we can go
deeper into this question we need to consider how the UDID is typically
used by app developers and mobile advertising firms.</p>
<p>The problem with using the UDID is that, as the name implies, it is an
identifier that is unique to the device. In that sense you can think
about it like a license plate number on a car. The industry
best-practice for dealing with the UDID is to anonymize it before it
gets sent anywhere. So let&rsquo;s just say at this point that if you are
using the UDID and you aren&rsquo;t anonymizing it first, you&rsquo;re part of the
problem. Having an anonymized UDID basically akin to having some encoded
version of a license plate number from a car. This encoding is one-way
so even if you have the encoded version of the UDID, that doesn&rsquo;t mean
that you can just reverse the process to obtain the UDID itself. This
process is called hashing and the <a href="https://en.wikipedia.org/wiki/MD5">MD5</a> and <a href="https://en.wikipedia.org/wiki/SHA-1">SHA-1</a> algorithms are the
ones most commonly used for this.</p>
<p>So what does having this anonymized identifier get you as an app
developer? Namely it allows you to see how many people have downloaded
you app, how it is being used, and various other kinds of analytics that
you may be interested in. For example, perhaps you would like to know
how often people have deleted and then re-installed your app. You can
find this out by sending the anonymized UDID every time your application
is launched. There are plenty of useful things you can measure using
this identifier from an app developer&rsquo;s perspective.</p>
<p>The other large group that makes use of the UDID is mobile advertising
firms. One obvious use for the identifier is something like frequency
capping, which is just an industry term for making sure you don&rsquo;t see
the same ad over and over again. I think everyone is happy not to be
bothered by the same ad, especially if it isn&rsquo;t even relevant. Another
use for the UDID is for services like conversion tracking. Say you are
an advertiser and you want to run advertisements for your new app. You
also would like to know how often people are clicking on your ad, and
how often people who click on your ad are actually downloading the app,
and how many of those people are actually running the app, and so forth.
This kind of information can be obtained using the UDID. The UDID can
also be used to do so-called targeted advertising, which basically looks
at the devices who fit into some group and makes some guesses about
other devices. In other words, users who have app A and app B installed
tend to be more likely to click on advertisements for app C. This allows
for better targeting of ads and provides more efficient allocation of
resources for advertisers and more relevant advertising for users.</p>
<p>Now that the groundwork has been laid on UDIDs, how they&rsquo;re used, and
why they&rsquo;re used, we can begin to have a discussion about privacy
issues.</p>
<p>I cannot pretend to know what went on in the debates leading up to the
decision to deprecate the UDID, but here is the basic idea as I see it.
Many developers were not anonymizing the UDID before making use of it,
and this is bad no matter how you slice it. Secondly, people tend to be
uncomfortable with the idea of &ldquo;being tracked&rdquo; and don&rsquo;t have a firm
concept of what that always means. For example, if you know an
anonymized version of my license plate number, and you can&rsquo;t see
original license plate numbers, then you really don&rsquo;t have any useful
information about me. If you see my anonymized license plate in
different places on different days then you&rsquo;ll be able to re-recognize
me, but that doesn&rsquo;t mean you know who I am or where I live. Lastly, the
UDID is something that is hardware based and therefore can&rsquo;t really be
changed or deleted from the device. In other words, it&rsquo;s too permanent.
All that being said, Apple didn&rsquo;t want to be seen as making it easy for
people to &ldquo;be tracked.&rdquo; I don&rsquo;t blame them for that, but deprecating the
UDID doesn&rsquo;t change anything, as we&rsquo;ll see.</p>

<h3 id="potential-replacements" class="anchor-link"><a href="#potential-replacements">Potential Replacements</a></h3>
<p>Okay, so apparently the gospel says that using the UDID is bad. What
happens next then? Well there are quite a few proposed solutions, some
of which are below in no particular order.</p>
<ul>
<li>
<p><a href="https://github.com/ylechelle/OpenUDID">OpenUDID</a> is a solution that came out last year and generates a
unique token for the device that is stored in the UIPasteboard and
consequently is available to all apps. In this way it still becomes a
unique identifier for the device, which doesn&rsquo;t solve any of the
privacy problems mentioned earlier. There is some opt-out
functionality present, but the fact remains that it&rsquo;s still one
identifier that goes back to one device.</p>
</li>
<li>
<p><a href="https://code.google.com/archive/p/odinmobile/wikis/ODIN1.wiki">ODIN-1</a> uses the <a href="https://en.wikipedia.org/wiki/MAC_address">Media Access Control</a> (MAC) address from the
wireless network chip inside the device in order to generate a unique
token for the device. In this way it is really no different than
using the UDID as it is still a hardware-based identification system
and therefore is difficult to change.</p>
</li>
<li>
<p>SecureUDID is an effort by Crashlytics to produce their own
UDID replacement. Apparently there is a <a href="https://techcrunch.com/2012/03/27/secureudid-is-an-open-source-solution-to-the-apple-udid-problem/">bit of a scuffle</a> between
the SecureUDID people and the OpenUDID people over who contributed to
which technology and when. In the end, the result is that you still
have a token that you can use to differentiate between devices, but
the problem is that the token is generated on a per-domain basis. In
other words, a publisher of multiple apps will be able to use the
same token in all their apps, but another publisher will not be able
to see the same token. If you are an ad network and you process ad
requests from multiple apps, then you will not be able to tell that
two requests from different apps actually came from the same device
except under very specific circumstances. In the end, this solution
is a non-starter in cases where you need to be able to identify the
same device across apps from different publishers.</p>
</li>
</ul>
<p>There are other solutions out there, but the last one brings us to the
key issue in the matter. The only way for the ecosystem to perpetuate is
with one unique identifier per device, and that&rsquo;s the point that is at
odds with the privacy argument. The reason that there are so many apps
available for iOS devices is because that can be a profitable endeavor.
The app developer will try to make money by selling their app for some
price, or by having some in-app advertising that generates revenue for
them. This is why apps are free. If Apple started rejecting every app
that was able to identify a device uniquely, people would be forced to
develop for other platforms, and that would be horrible for Apple.
Imagine having an iPhone or an iPad without any apps. So Apple has to
walk a fine line now by addressing concerns of privacy advocates and
also addressing concerns of those who make a living by developing apps
on their platform.</p>

<h3 id="what-next" class="anchor-link"><a href="#what-next">What next?</a></h3>
<p>I think most people in the industry will move towards using the
anonymized MAC address. This is the easiest change to make and the one
that is most likely to be done by most industry players. This also
allows for a device-specific identifier and therefore all of the
previous products and services that were using the UDID can convert to
using the MAC address without issue. The problem with this approach is
that it is fundamentally no different from using the UDID and therefore
likely to receive push-back from Apple at some point. In the end there
will (hopefully) be an industry-wide solution that provides the required
level of identification on a per-device basis, but is also something
that can be cleared by the user. I think that will be the best solution
for everyone involved.</p>
<p>Additionally, mobile websites and app developers should take additional
steps to clearly communicate to their users what kind of information is
being collected, why it being collected, how it will be handled, and so
forth. Additionally, opt-out capability is something that will need to
become the rule rather than the exception. This doesn&rsquo;t have to be
anything complicated, and could be as simple as app developers
displaying a Terms of Use window to the user when the app is run for the
first time. These terms should be very clear on anything related to data
collection, use, and storage, and allow the user to choose not to
provide any data at all. At that point it will be up to the
developer/publisher to decide if they want to allow the user to continue
to use the app or if they want to make the use contingent on the ability
to display ads. That&rsquo;s how they&rsquo;re making money from their trade.</p>

<h3 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion</a></h3>
<p>So the UDID is gone now. So what? This was announced months ago, and in
the end it doesn&rsquo;t really change anything. The need to uniquely identify
devices is greater than ever, and the number of apps in the iOS App
Store is rapidly growing (<a href="https://www.apple.com/iphone/built-in-apps/app-store.html">over 500,000 at the moment</a>). Apple won&rsquo;t
risk alienating their developers, who are an integral part of the reason
that people buy iOS devices in the first place (There&rsquo;s an App For
That(tm)). The goal then is to be as transparent as possible and move
toward solutions that allow users to opt out of data collection, even
though there should be no personally-identifiable information being
collected anyway. That will be the only solution to the problem of
balancing the need to uniquely identify a device and also respect the
privacy and desires of users. The downside may be that app developers
will only allow their apps to be used by those that opt in since they
need to put food on the table. Just like there is no free lunch, there
are no free apps.</p>
 ]]></content:encoded></item><item><title>On Big Data and Spurious Correlations</title><link>https://adamdrake.com/on-big-data-and-spurious-correlations.html</link><pubDate>Sat, 18 Feb 2012 00:00:00 +0000</pubDate><guid>https://adamdrake.com/on-big-data-and-spurious-correlations.html</guid><description>&lt;p>I didn&amp;rsquo;t have time to mention it last week, but even though I am happy
that the New York Times wrote an &lt;a href="https://www.nytimes.com/2012/02/12/sunday-review/big-datas-impact-in-the-world.html">article on big data&lt;/a>, I think the
most interesting part was at the end:&lt;/p>
&lt;blockquote>
&lt;p>Big Data has its perils, to be sure. With huge data sets and
fine-grained measurement, statisticians and computer scientists
note, there is increased risk of false discoveries. The trouble
with seeking a meaningful needle in massive haystacks of data, says
Trevor Hastie, a statistics professor at Stanford, is that many
bits of straw look like needles. Big Data also supplies more raw
material for statistical shenanigans and biased fact-finding
excursions. It offers a high-tech twist on an old trick: I know the
facts, now lets find em. That is, says Rebecca Goldin, a
mathematician at George Mason University, one of the most
pernicious uses of data.&lt;/p></description><content:encoded><![CDATA[ <p>I didn&rsquo;t have time to mention it last week, but even though I am happy
that the New York Times wrote an <a href="https://www.nytimes.com/2012/02/12/sunday-review/big-datas-impact-in-the-world.html">article on big data</a>, I think the
most interesting part was at the end:</p>
<blockquote>
<p>Big Data has its perils, to be sure. With huge data sets and
fine-grained measurement, statisticians and computer scientists
note, there is increased risk of false discoveries. The trouble
with seeking a meaningful needle in massive haystacks of data, says
Trevor Hastie, a statistics professor at Stanford, is that many
bits of straw look like needles. Big Data also supplies more raw
material for statistical shenanigans and biased fact-finding
excursions. It offers a high-tech twist on an old trick: I know the
facts, now lets find em. That is, says Rebecca Goldin, a
mathematician at George Mason University, one of the most
pernicious uses of data.</p>
</blockquote>
<p>The warning was embedded on the last page of a 3-page article, a mere 3
short paragraphs from the end. I understand that the piece was designed
to be rather lighthearted and to focus more on job opportunities that
are present in such a growing field, but more needs to be said about
this peril of analyzing very large sets of data.</p>
<p>Humans already have a long list of <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">cognitive biases</a>, which I call brain failures, that come
up in our daily lives. These brain failures have become increasingly
problematic along with the increase in access to information. Humans
love to find similarities between things, and those pattern recognition
skills are one thing that have allowed us to survive this long. If Ug
the caveman ate berries and then Ug got sick, he would assume that the
berries were the cause and therefore avoid them, thus potentially saving
him from illness and death. In this way, by natural selection, we have
evolved to become very sensitive to correlations that do not exist or
exist but do not have an effect on the situation under consideration.
This is especially apparent in the financial sector, where <a href="https://en.wikipedia.org/wiki/Spurious_relationship">spurious
relationships</a> abound. On the surface it can be pretty obvious that the
correlations are spurious, but that doesn&rsquo;t stop people from
demonstrating that they are supported by data.</p>
<p>For example, consider the
<a href="https://blogs.wsj.com/marketbeat/2010/01/28/super-bowl-indicator-says-stocks-to-rise/">Superbowl Indicator</a> which says that if an original NFL team wins the
Superbowl then stocks will rise in the coming year, and if not then they
will fall. This already sounds pretty ridiculous, but consider that it
also has a 79% accuracy rate. A perfect example of a spurious
correlation. There are other crazy correlative indicators of stock
market prices, like the <a href="https://www.investopedia.com/terms/s/sportsillustratedindicator.asp">Sports Illustrated Swimsuit Issue Indicator</a>,
which says that the stock market will have above-average returns in
years that an American model is on the cover of the Sports Illustrated
Swimsuit issue. The point is that as humans have the ability to amass
and analyze larger and larger sets of data, they will increasingly
discover correlations that are spurious, and data scientists or those
who work with &ldquo;Big Data&rdquo; should be very aware of this problem.</p>
<p>At this
point the discipline is still occupied by those with a strong scientific
and mathematical background and therefore already have some
critical-thinking-based immunity to spurious correlations from training
or past exposure, but as tools and techniques for data analysis become
more accessible to the average person the problem of succumbing to
spurious correlations will be more pronounced. I&rsquo;m not scolding the New
York Times for not putting that at the beginning of their article, but I
think it would be good to put more emphasis on the careful analytical
skills required in &ldquo;Big Data&rdquo; work.</p>
 ]]></content:encoded></item><item><title>What Mobile Advertising Needs</title><link>https://adamdrake.com/what-mobile-advertising-needs.html</link><pubDate>Sun, 01 Jan 2012 00:00:00 +0000</pubDate><guid>https://adamdrake.com/what-mobile-advertising-needs.html</guid><description>&lt;p>The advertising world is both feeding, and being fed a lot of hype about the current state and potential of mobile advertising. It&amp;rsquo;s no doubt that this form of marketing is unique in many ways, and offers opportunities not available via other forms of advertising. As an example, on mobile you can take advantage of information like a relatively precise knowledge of the location of the individual. Now, it is debatable whether such granular knowledge of a person&amp;rsquo;s location is a good, bad, or neutral thing, but the fact remains that this piece of information is something that simply has not been available to advertisers until recently. Additionally, advertising on mobile is almost guaranteed to be seen by the user due to both the nature of interaction with the device and additionally due to smaller screen sizes. Lastly, the time spent interacting with mobile devices is far greater than time spent with print media, so the percentage of advertising budgets spent on mobile should be proportionally higher, right?&lt;/p></description><content:encoded><![CDATA[ <p>The advertising world is both feeding, and being fed a lot of hype about the current state and potential of mobile advertising.  It&rsquo;s no doubt that this form of marketing is unique in many ways, and offers opportunities not available via other forms of advertising.  As an example, on mobile you can take advantage of information like a relatively precise knowledge of the location of the individual.  Now, it is debatable whether such granular knowledge of a person&rsquo;s location is a good, bad, or neutral thing, but the fact remains that this piece of information is something that simply has not been available to advertisers until recently.  Additionally, advertising on mobile is almost guaranteed to be seen by the user due to both the nature of interaction with the device and additionally due to smaller screen sizes.  Lastly, the time spent interacting with mobile devices is far greater than time spent with print media, so the percentage of advertising budgets spent on mobile should be proportionally higher, right?</p>
<p>In fact, time spent on mobile has been ahead of print for some time, and recent data from an <a href="https://www.emarketer.com/newsroom/index.php/consumers-spending-time-mobile-growth-time-online-slows/">eMarketer Study</a> shows that while time spend on mobile is 11.7%, mobile is only getting 1.6% of the advertising budgets out there.  So if the user attention is there, and the additional advertising options are there, where are the budgets?  The story that mobile companies are telling to investors and potential clients is that this is a fantastic growth opportunity because the budgets on mobile will catch up to where they should be proportionally, and this is a multi-billion dollar increase in revenues for the mobile industry.  However, there is a problem with this logic.  It makes critical assumptions about advertisers and agencies, where they want to spend their advertising budgets, and why.  It doesn&rsquo;t take into account the fact that before the spending is there, some way to demonstrate value will be required.  In short, if you can&rsquo;t prove the return on the money spend on mobile, the budgets simply will not materialize.  The big problem of mobile advertising and lack of budgets can be traced very simply back to issues with trust and transparency.  Solve those problems, and you will be greatly rewarded with all the budgets you can handle.</p>
<p>In order to build the necessary trust and transparency with clients, there are some areas where mobile companies need to catch up and improve.  However, before any product discussion can really happen, first the industry needs to decide who their boss is (hint: it&rsquo;s the advertisers and agencies, they have the budgets) and settle on consistent terminology.  Without these two things, the whole industry will struggle to gain ground due to fragmentation and the futile attempt to serve too many masters.</p>
<p>Believe it or not, the question of how to even define what constitutes a valid impression is still somewhat of an open one in the mobile space.  Do you define an impression as receiving a request for a creative from a publisher site?  Do you perform a test after the request has been answered with a creative to confirm that the creative was delivered?  What about a test to confirm that the user actually viewed the creative?  Not having these questions answered leads to fractured and company-dependent definitions and terms like page impression, ad impression, confirmed impression, etc.  So let&rsquo;s take the perspective of the advertiser or agency, who is supplying the budget, and consider which definition of impression maximizes the value obtained from their ad spend.</p>
<p>An <em>impression</em> should only be valid if you can prove that the creative has been delivered <em>and</em> you can prove that the creative was in a viewable area of the user&rsquo;s screen.  Additionally, you must confirm that the device can process JavaScript, otherwise it may not be a valid impression and additionally could lead to further problems verifying clicks or doing other processing.  If those criteria aren&rsquo;t met then you shouldn&rsquo;t get to count the impression for delivery or analytics purposes because it doesn&rsquo;t add value for the advertiser or agency.</p>
<p>Okay, so now there&rsquo;s a solid definition of impressions, what about clicks?  This is a complicated issue as well since the click usually gets registered on the publisher site, gets redirected a couple of times and may get passed through a third-party verification service, and at some point hits the landing page where the user is ultimately supposed to end up.  Additionally, the click fraud topic is alive and well here and could make up a series of articles all by itself.  Additionally, since mobile devices have small screens and humans have fingers with a variety of diameters, the issue of accidental clicks is something that shouldn&rsquo;t be ignored.</p>
<p>With that in mind, a <em>click</em> is only valid if the creative has been viewable by the user for more than 1 second.  This is a criteria that some have proposed in order to cut down on accidental clicks, and it sounds like a very reasonable requirement.  Additionally, Google has gone in a good direction for <a href="https://googlemobileads.blogspot.com/2012/12/combating-accidental-clicks-in-mobile.html">AdMob ads</a> that requires confirmation by the user that they actually want to click on the creative.  This should do a good job at almost completely eliminating accidental clicks.  This is a great increase for value provided to advertisers and agencies since they can be sure that the only clicks that count are ones where the user explicitly indicated their intention to view the ad.</p>
<p>These definitions can get us started on having a real conversation about the effectiveness of advertising on mobile.  The industry needs to settle on definitions like these in order to begin to provide the reporting and insight that advertisers and agencies want from campaigns.  Without strict definitions of what constitutes an impression and what constitutes a click, any subsequent analytics or reporting data don&rsquo;t really provide value to anyone.  At that point it&rsquo;s just a lot of noise in order to try to make various players in the value chain look like they&rsquo;re doing a great job.  To use the words of Marc Andreessen in an <a href="https://allthingsd.com/20121217/andreessen-and-mixpanel-call-for-an-end-to-bullshit-metrics/">AllThingsD interview</a>, it&rsquo;s important to stop measuring and using bullshit metrics.  The only way forward for an industry with so much potential is to adopt metrics that make sense for those who are injecting the cash into said industry, and that is the advertisers and agencies.</p>
 ]]></content:encoded></item><item><title>Don't Ship What Doesn't Work</title><link>https://adamdrake.com/dont-ship-what-doesnt-work.html</link><pubDate>Fri, 05 Aug 2011 00:00:00 +0000</pubDate><guid>https://adamdrake.com/dont-ship-what-doesnt-work.html</guid><description>&lt;p>If involved in workflow engineering, technology-related or otherwise, do
everyone a favor and don&amp;rsquo;t pass something to the next stage if the
previous stage isn&amp;rsquo;t done properly. Shigeru Miyamoto, the creator of
Mario and the Legend of Zelda knows this. Take his words to heart:&lt;/p>
&lt;blockquote>
&lt;p>A late game is only late until it ships. A bad game is bad until
the end of time.
&amp;ndash;Shigeru Miyamoto&lt;/p>
&lt;/blockquote>
&lt;p>If you pass a project on to the next stage of the workflow when it isn&amp;rsquo;t
perfect, eventually it will have to regress back and be repaired. Just
save everyone the effort and make it correct right now.&lt;/p></description><content:encoded><![CDATA[ <p>If involved in workflow engineering, technology-related or otherwise, do
everyone a favor and don&rsquo;t pass something to the next stage if the
previous stage isn&rsquo;t done properly. Shigeru Miyamoto, the creator of
Mario and the Legend of Zelda knows this. Take his words to heart:</p>
<blockquote>
<p>A late game is only late until it ships. A bad game is bad until
the end of time.
&ndash;Shigeru Miyamoto</p>
</blockquote>
<p>If you pass a project on to the next stage of the workflow when it isn&rsquo;t
perfect, eventually it will have to regress back and be repaired. Just
save everyone the effort and make it correct right now.</p>
 ]]></content:encoded></item><item><title>The Dismal Jobs Report, Economic Recovery, and Normalcy Bias</title><link>https://adamdrake.com/the-dismal-jobs-report-economic-recovery-and-normalcy-bias.html</link><pubDate>Sat, 16 Jul 2011 00:00:00 +0000</pubDate><guid>https://adamdrake.com/the-dismal-jobs-report-economic-recovery-and-normalcy-bias.html</guid><description>&lt;p>Well everyone
is reacting with shock and amazement at the negative June jobs report,
which showed that contrary to the 125,000 jobs that even the most
pessimistic economists expected to be added to the economy, the actual
number was in fact about 18,000. This isn&amp;rsquo;t surprising, as this recovery
will take a long time. In fact, it will take longer than most people
expect and that is due in part to something called Normalcy Bias.&lt;/p></description><content:encoded><![CDATA[ <p>Well everyone
is reacting with shock and amazement at the negative June jobs report,
which showed that contrary to the 125,000 jobs that even the most
pessimistic economists expected to be added to the economy, the actual
number was in fact about 18,000. This isn&rsquo;t surprising, as this recovery
will take a long time. In fact, it will take longer than most people
expect and that is due in part to something called Normalcy Bias.</p>
<p>Normalcy bias is a cognitive bias which
is of particular interest, given the global financial crash that
occurred in 2008 and the ensuing recovery. The normalcy bias is a mental
state that is entered into when faced with a disaster and leads to
underestimation of the possibility that a disaster will occur, in
addition to underestimating the possible effects of the disaster itself.</p>
<p>The result of the normalcy bias is inadequate preparation for disasters
because there is a propensity to believe that such a disaster has never
occurred and therefore such a disaster will never occur. In addition, it
makes coping with the disaster exceedingly difficult once it starts.</p>
<p>Lastly, and perhaps most importantly, the normalcy bias causes people to
interpret warnings as optimistically as possible by using ambiguities to
conclude that the situation is not as serious as it seems.</p>
<p>Consider the
<a href="https://www.marketwatch.com/story/stocks-tumble-on-weak-jobs-growth-2011-07-08">statement</a> from Bruce McCain, chief investment strategist at Key
Private Bank, who said</p>
<blockquote>
<p>It was obviously a shock, although in
retrospect, I don&rsquo;t think we should be inordinately surprised by the
report considering the weakness in the second quarter.</p>
</blockquote>
<p>This is a
textbook example of optimistic interpretation of information due to
normalcy bias.</p>
<p>Another good example of the normalcy bias was seen during
Hurricane Katrina. Even after mandatory evacuation orders were given,
and the situation in New Orleans had become dire, there were thousands
of people who refused to evacuate the city. Many people in New Orleans
lost their lives because of their inability to overcome the normalcy
bias. They were simply convinced that everything would be fine.</p>
<p>Overcoming the normalcy bias can be difficult, since there is a fine
line between identifying and planning for potential issues and having a
constant doomsday attitude. In addition, many financial disasters are
difficult to predict and therefore accepting and adapting to conditions
is more important than identifying potential problems and planning for
them. In the case of the economic recovery and the jobs report, normalcy
bias causes people to underestimate the severity of the issue, and
overestimate the speed with which a recovery will take place.</p>
<p>When the
normalcy bias is too prevalent, we get situations like the one that
unfolded today wherein people who think a recovery is in full swing are
hit square in the face with the stark realities of the situation.</p>
<p>The
recovery will take time. A long time. Don&rsquo;t succumb to the normalcy bias
and conclude that things will return to normal with surprising
expediency. Do all you can to benefit from the recovery as it occurs. In
the meantime make sure you are investing in yourself, specifically your
transferable skills, so that when the economy is in full swing again
you will be marketable to many employers.</p>
 ]]></content:encoded></item><item><title>Uncorrelated Does NOT Imply Independent</title><link>https://adamdrake.com/uncorrelated-does-not-imply-independent.html</link><pubDate>Tue, 21 Jun 2011 00:00:00 +0000</pubDate><guid>https://adamdrake.com/uncorrelated-does-not-imply-independent.html</guid><description>&lt;p>This is just an aside to describe a misconception that we have seen some
money managers make when describing their strategies or portfolios. When
you are discussing the correlation of your portfolio to another
portfolio or the market in general, the fact that your portfolio may be
fairly uncorrelated does not have anything to do with the independence
of your portfolio from a reference portfolio or the market in general.
In fact, even if the portfolio you have developed is completely
uncorrelated, it still probably isn&amp;rsquo;t independent. The &lt;a href="">Risk
Fundamentals&lt;/a> (link removed due to being broken as of 2018-06-13) website commits this error fairly egregiously:&lt;/p></description><content:encoded><![CDATA[ <p>This is just an aside to describe a misconception that we have seen some
money managers make when describing their strategies or portfolios. When
you are discussing the correlation of your portfolio to another
portfolio or the market in general, the fact that your portfolio may be
fairly uncorrelated does not have anything to do with the independence
of your portfolio from a reference portfolio or the market in general.
In fact, even if the portfolio you have developed is completely
uncorrelated, it still probably isn&rsquo;t independent. The <a href="">Risk
Fundamentals</a> (link removed due to being broken as of 2018-06-13) website commits this error fairly egregiously:</p>
<blockquote>
<p>However, if the performance of the two funds were uncorrelated
statistically independent  the standard deviation of a portfolio
comprised of the two funds would decline to 7.1% compared with 10%
for each of the individual funds.</p>
</blockquote>
<p>Again, uncorrelated does not in any way imply independence (also called
statistical independence). Here is a proof in case you don&rsquo;t want to
<a href="https://en.wikipedia.org/wiki/Normally_distributed_and_uncorrelated_does_not_imply_independent">look it up on Wikipedia</a>. In the symmetric case, suppose you have two
random variables, both normally distributed and perfectly uncorrelated.
Let $X$ be a normally distributed random variable with mean
0 and standard deviation 1. Let $W$ be a simple random
variable that is -1 with probability 1/2 and 1 with probability 1/2. Now
let $Y = WX$. Then $X$ and $Y$:</p>
<ul>
<li>Are uncorrelated</li>
<li>Have the same normal distribution</li>
<li>Are NOT independent</li>
</ul>

<h3 id="proof-that--x--and--y--are-uncorrelated" class="anchor-link"><a href="#proof-that--x--and--y--are-uncorrelated">Proof that <code>$ X $</code> and <code>$ Y $</code> are uncorrelated:</a></h3>
<p>To show this we need only demonstrate that their covariance is 0.
<code>$$ cov(X,Y) = E[XY]-E[X]E[Y] = E[XY] - 0 = E[E[XY \| W]] $$</code> Now
<code>$ W $</code> is very simple, so this conditional expectation can be
expressed easily. <code>$E[E[XY| W]]= E[X^2]Pr(W=1) + E[-X^2]Pr(W=-1) = 1\\\times\\\frac{1}{2} + -1\\\times\\\frac{1}{2} = 0$</code> Since their covariance is 0, they are uncorrelated. <strong>QED</strong></p>

<h3 id="proof-that-x-and-y-have-the-same-normal-distribution" class="anchor-link"><a href="#proof-that-x-and-y-have-the-same-normal-distribution">Proof that $X$ and $Y$ have the same normal distribution:</a></h3>
<p>To do this we can show that both random variables have
the same cumulative probability density function. $Pr(Y \le x) = E[Pr(Y \le x | W)] = Pr(X \le x)Pr(W=1) + Pr(-X \le
x)Pr(W=-1)$ Now since $X$ and $-X$ have
the same normal distribution, this just becomes $Pr(X \le
x)\times\frac{1}{2} + Pr(X \le x)\times\frac{1}{2} = Pr(X \le
x)$ Therefore $Pr(Y \le x) = Pr(X \le x)$.  <strong>QED</strong>.</p>

<h3 id="proof-that-x-and-y-are-not-independent" class="anchor-link"><a href="#proof-that-x-and-y-are-not-independent">Proof that $X$ and $Y$ are NOT independent:</a></h3>
<p>To see this consider the fact that $Pr(Y &gt; 1 | X =
\frac{1}{2}) = 0$. In other words, $Y$ being
greater than 1 is dependent on $X$ NOT being
$\frac{1}{2}$ and therefore, they are NOT independent.  <strong>QED</strong>.</p>
<p>As you can see, the fact that two things are uncorrelated does
not mean they are independent. If you are fund manager, investment
advisor, or any individual writing materials to be distributed to
investors or potential investors you should realize that every time you
say your portfolio is uncorrelated with and therefore independent of the
market, you&rsquo;re probably lying.</p>
 ]]></content:encoded></item><item><title>Thoughts on the Efficient Market Hypothesis</title><link>https://adamdrake.com/thoughts-on-the-efficient-market-hypothesis.html</link><pubDate>Tue, 14 Jun 2011 00:00:00 +0000</pubDate><guid>https://adamdrake.com/thoughts-on-the-efficient-market-hypothesis.html</guid><description>&lt;p>The Efficient Market
Hypothesis (EMH) is both important and often misunderstood. For our
purposes, the term &lt;em>efficient&lt;/em> is related to informational efficiency,
or how quickly information affects prices. In a way, the level of
informational efficiency in a market tells you what level of randomness
to expect and consequently if it is possible to outperform the market.
In its simplest form, the EMH states that market prices reflect
decisions made by participants who have acted rationally based on
information they possess. It is not required that all participants act
rationally at all times, but only that at any given time most
participants are acting rationally given the information they possess.
In order to clarify the impact of varying levels of information, the EMH
has been split into sub-types depending on what kind of information is
incorporated into the asset price. There are currently three forms of
the EMH: the Weak EMH, the Semi-strong EMH, and the Strong EMH.&lt;/p></description><content:encoded><![CDATA[ <p>The Efficient Market
Hypothesis (EMH) is both important and often misunderstood. For our
purposes, the term <em>efficient</em> is related to informational efficiency,
or how quickly information affects prices. In a way, the level of
informational efficiency in a market tells you what level of randomness
to expect and consequently if it is possible to outperform the market.
In its simplest form, the EMH states that market prices reflect
decisions made by participants who have acted rationally based on
information they possess. It is not required that all participants act
rationally at all times, but only that at any given time most
participants are acting rationally given the information they possess.
In order to clarify the impact of varying levels of information, the EMH
has been split into sub-types depending on what kind of information is
incorporated into the asset price. There are currently three forms of
the EMH: the Weak EMH, the Semi-strong EMH, and the Strong EMH.</p>
<p><strong>The Weak-form EMH</strong> stipulates that all past publicly-available information
has been accounted for in the price of an asset. It is often said that
such information is <em>priced in</em>. In this version of the EMH you can see
that if someone had new information that was not public then they could
use that information to buy or sell the stock before everyone else does
and obtain a profit. If this version of the EMH were true then there
would be numerous opportunities to outperform the market for any person
who had more information than other market participants. However, any
insider information you may obtain cannot legally be used for investment
purposes. The few people who choose not to abide by the law are
typically not enough to move the price and therefore the information
anomaly is not much of a concern. The key idea with this form of the EMH
is that past rates of return do not affect future rates of return. In
other words, rates of return for one time period are independent of
rates of return for another time period. This is an important
implication because it invalidates all forms of technical analysis
outright. Technical analysis is a method of identifying patterns in
pricing data in order to draw future conclusions about what will happen
next, but since the weak-form EMH says there are no patterns technical
analysis cannot provide any reliable information. There is a vast amount
of empirical support for this form of the EMH.</p>
<p><strong>The Semi-strong EMH</strong> takes the Weak EMH one step further and stipulates that not only is it
the case that all past publicly-available information is priced in to an
asset, but the price of the asset immediately corrects based on any new
publicly-available information. Because of this additional caveat, it is
impossible for investors to obtain above-market returns by acting on new
information. So on top of the concept of independent returns from the
Weak-form EMH which prevents past returns from having any effect on
future returns, we now have the additional restriction that any new
public information is effectively useless as the asset price adjust
instantaneously. The key difference between the Semi-strong EMH and the
Weak EMH is that the Semi-Strong-Form EMH also prevents someone from
consistently outperforming the market based on Fundamental Analysis in
addition to Technical Analysis.</p>
<p>In the <strong>Strong-form EMH</strong> all public
and private information is reflected in prices and it is impossible for
anyone to outperform the market. Since it is illegal to trade on insider
information, Strong-Form Efficiency is impossible to achieve. So what
does all this mean for performance? In a 100% efficient market, it is
impossible to outperform the market on purpose, but that doesn&rsquo;t mean
that it is impossible to outperform the market. Consider an example from
the Clustering Illusion, wherein it can be calculated that you
can expect 2,876 advisors in the US to beat the market for 5 consecutive
years on nothing but chance alone. They may advertise it as skill, and
they may genuinely believe it to be, but simply outperforming the market
for 5 consecutive years is something you expect 3.125% of advisors to
<em>always</em> do by chance. Now an important thing to consider is that with
the rise of algorithmic and high-frequency trading (HFT), markets become
increasingly efficient since machines can trade based on information
faster than humans. In this way, new information is processed and
reflected in the price of an asset faster than ever before. There have
been statements that the average holding period of securities is down to
11 seconds at some firms and while that number is an estimate, holding
periods are certainly decreasing. As holding periods decrease and
transactions in the markets increase the price action becomes more like
pure noise, i.e., totally unpredictable. That is precisely the purpose
of our market forecasts. We know that it is not possible to say with
certainty which way a stock price will move and therefore we produce
ranges wherein we believe the stock will close. This simply functions as
a <em>noise filter</em> of sorts. We don&rsquo;t claim to know what a stock will do,
only that we have a fairly good idea of what a stock is <em>unlikely</em> to
do. We know based on empirical data that a stock has approximately an
85% chance of closing within our range.</p>

<h2 id="summary" class="anchor-link"><a href="#summary">Summary</a></h2>
<p>The markets
are already fairly efficient/random and are becoming more efficient as
HFT becomes more prevalent. We predict that noise filtering in markets
to become increasingly important and for this reason we strive to
provide noise filtering algorithms that are as accurate as possible.</p>
 ]]></content:encoded></item><item><title>Market Commentary, Correlation, and Causation</title><link>https://adamdrake.com/market-commentary-correlation-and-causation.html</link><pubDate>Thu, 09 Jun 2011 00:00:00 +0000</pubDate><guid>https://adamdrake.com/market-commentary-correlation-and-causation.html</guid><description>&lt;p>Don&amp;rsquo;t be fooled, this isn&amp;rsquo;t market commentary. This is commentary about
market commentary. Many times when we come across market commentary, we
see horrible examples of confusing correlation and causation, the
logical fallacy of &lt;a href="https://en.wikipedia.org/wiki/Post_hoc_ergo_propter_hoc">post hoc ergo propter hoc&lt;/a> wherein event B is said
to be caused by event A simply because event B followed A. This fallacy
can be found in the vast majority of market commentary, and is
especially obvious on days where the market didn&amp;rsquo;t move appreciably, yet
there is someone claiming to know why the move occurred. Today is a good
example. The Dow Jones Industrial Average gained 75 points today, or
0.6%, which is well within normal market fluctuations. In other words,
nothing happened in the market today. However, that did not stop anyone
from trying to find an explanation for this nothingness. Over on &lt;a href="https://www.thestreet.com/story/11148120/1/stock-market-story-june-9.html">The
Street&lt;/a> they attributed the 0.6% gain to a narrowing trade deficit in
the last month, amongst other factors.&lt;/p></description><content:encoded><![CDATA[ <p>Don&rsquo;t be fooled, this isn&rsquo;t market commentary. This is commentary about
market commentary. Many times when we come across market commentary, we
see horrible examples of confusing correlation and causation, the
logical fallacy of <a href="https://en.wikipedia.org/wiki/Post_hoc_ergo_propter_hoc">post hoc ergo propter hoc</a> wherein event B is said
to be caused by event A simply because event B followed A. This fallacy
can be found in the vast majority of market commentary, and is
especially obvious on days where the market didn&rsquo;t move appreciably, yet
there is someone claiming to know why the move occurred. Today is a good
example. The Dow Jones Industrial Average gained 75 points today, or
0.6%, which is well within normal market fluctuations. In other words,
nothing happened in the market today. However, that did not stop anyone
from trying to find an explanation for this nothingness. Over on <a href="https://www.thestreet.com/story/11148120/1/stock-market-story-june-9.html">The
Street</a> they attributed the 0.6% gain to a narrowing trade deficit in
the last month, amongst other factors.</p>
<p>As a concrete example, consider your commute time to work and what a 0.6% variation in that would be.  According to a <a href="https://www.gallup.com/poll/28504/workers-average-commute-roundtrip-minutes-typical-day.aspx">2007 Gallup Poll</a>, the average American commutes 46 minutes to work, round trip, so assume 23 minutes each way. Well 23 minutes is 1,380 seconds and 0.6% of 1,380 seconds is 8.28 seconds. In other words, the movement of the stock market today is equivalent in magnitude to you arriving 8.28 seconds early for work. Would that even matter? Would you try to explain your punctuality? If so, do you think anyone would believe that you correctly accounted for all the factors that led to your arrival 8.28 seconds earlier than normal?</p>
<p>This is what happens every time the market doesn&rsquo;t move much and people write commentary about why it did what it did. Remember that just because there was a slight change in the trade deficit, and today the market closed up 0.6%, that does not mean those two facts are related. Correlation does not equal causation, and the post hoc ergo propter hoc fallacy is rampant.</p>
 ]]></content:encoded></item><item><title>On Technical Analysis, Fractals, and Stock Prices</title><link>https://adamdrake.com/on-technical-analysis-fractals-and-stock-prices.html</link><pubDate>Sun, 05 Jun 2011 00:00:00 +0000</pubDate><guid>https://adamdrake.com/on-technical-analysis-fractals-and-stock-prices.html</guid><description>&lt;p>I&amp;rsquo;ve been thinking recently about fractal geometry with applications to
finance, and I talked to an acquaintance who informed me that he watches
the &amp;ldquo;fractals&amp;rdquo; on his charts when trading. This prompted me to do some
research into how technical analysts use &amp;ldquo;fractals&amp;rdquo; and see what kind of
information such an indicator provides. There are many issues with using
fractal behavior as a technical indicator, namely that the way the term
is used in technical analysis doesn&amp;rsquo;t sound like it has anything to do
with fractals at all. According to &lt;a href="https://www.investopedia.com/terms/f/fractal.asp">Investopedia&lt;/a>, in technical
analysis a fractal is defined as&lt;/p></description><content:encoded><![CDATA[ <p>I&rsquo;ve been thinking recently about fractal geometry with applications to
finance, and I talked to an acquaintance who informed me that he watches
the &ldquo;fractals&rdquo; on his charts when trading. This prompted me to do some
research into how technical analysts use &ldquo;fractals&rdquo; and see what kind of
information such an indicator provides. There are many issues with using
fractal behavior as a technical indicator, namely that the way the term
is used in technical analysis doesn&rsquo;t sound like it has anything to do
with fractals at all. According to <a href="https://www.investopedia.com/terms/f/fractal.asp">Investopedia</a>, in technical
analysis a fractal is defined as</p>
<blockquote>
<p>A type of pattern used in technical analysis to predict a reversal
in the current trend. A fractal pattern consists of five bars and is
identified when the price meets the following characteristics:
&gt;1. A shift from a downtrend to an uptrend occurs when the lowest bar
is located in the middle of the pattern and two bars with
successively higher lows are positioned around it.
&gt;1. A shift from an uptrend to a downtrend occurs when the highest
bar is located in the middle of the pattern and two bars with
successively lower highs are positioned around it.</p>
</blockquote>
<p>In other words, a <em>fractal</em> in the technical analysis community is just
a pattern where there is a localized minimum or maximum in 5 contiguous
time steps of the price series. I think somebody just decided to call it
a fractal because it sounds cool and scientific.</p>
<p>Now considering the
fact that price action moves around all the time, there is no way that
this <em>fractal</em> construct of technical analysis provides any useful
information. Fractals in this sense simply cannot be useful because such
phenomena will occur all the time. So if these <em>fractals</em> in technical
analysis aren&rsquo;t real, what about the real ones? The answer is that a
fractal is just something in which all parts resemble the whole. No
matter how much you zoom in or how much you zoom out everything stays
more or less the same.</p>
<p>The classic example of fractal patterns are
shorelines. The view from space is similar to the view from an aircraft
which is similar to the view from a lower-flying glider, and so on.
Another familiar example is fauna. A tree has a trunk with branches, and
each branch has its own branches. In other words, every branch from a
tree is like a miniature tree itself. This kind of behavior is also seen
in financial markets. Without any scale on the chart, it is impossible
to know what period of time the chart represents. Below are two charts
for IBM closing prices without any scales. The filename for the image
says which one is which. Can you tell the time period covered by either
chart?</p>
<p>
<img class="enclosure" src="/static/images/ibm_monthly_1980010120100101.png" alt="IBM plot 1"  />
</p>
<p>
<img class="enclosure" src="/static/images/ibm_daily_2010010120110101.png" alt="IBM plot 2"  />
</p>
<p>Here is the R code for the plots above,
which contain the dates. Even knowing the two dates involved it would be
impossible for you to tell which is which had I not included plot
titles.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>ibm10year <span style="color:#f92672">=</span> <span style="color:#a6e22e">getYahooData</span>(<span style="color:#e6db74">&#34;IBM&#34;</span>, <span style="color:#ae81ff">19800101</span>, <span style="color:#ae81ff">20100101</span>, adjust<span style="color:#f92672">=</span><span style="color:#66d9ef">FALSE</span>, freq<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;monthly&#34;</span>, type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;price&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(<span style="color:#a6e22e">seq</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#a6e22e">length</span>(ibm10year<span style="color:#f92672">$</span>Close)), <span style="color:#a6e22e">as.data.frame</span>(ibm10year<span style="color:#f92672">$</span>Close)<span style="color:#f92672">$</span>Close, main<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;IBM Plot 1&#34;</span>, axes<span style="color:#f92672">=</span><span style="color:#66d9ef">FALSE</span>, type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l&#39;</span>, frame.plot<span style="color:#f92672">=</span><span style="color:#66d9ef">TRUE</span>, xlab<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Time&#34;</span>, ylab<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Price&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ibmshort <span style="color:#f92672">=</span> <span style="color:#a6e22e">getYahooData</span>(<span style="color:#e6db74">&#34;IBM&#34;</span>, <span style="color:#ae81ff">20100101</span>, <span style="color:#ae81ff">20110101</span>, freq<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;daily&#34;</span>, type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;price&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(<span style="color:#a6e22e">seq</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#a6e22e">length</span>(ibmshort<span style="color:#f92672">$</span>Close)), <span style="color:#a6e22e">as.data.frame</span>(ibmshort<span style="color:#f92672">$</span>Close)<span style="color:#f92672">$</span>Close, main<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;IBM Plot 2&#34;</span>, axes<span style="color:#f92672">=</span><span style="color:#66d9ef">FALSE</span>, type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l&#39;</span>, frame.plot<span style="color:#f92672">=</span><span style="color:#66d9ef">TRUE</span>, xlab<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Time&#34;</span>, ylab<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Price&#34;</span>)
</span></span></code></pre></div><p>Now lets apply this correct concept of a fractal, or object that is
self-similar on all scales, to financial instruments. One way that
fractals are measured or categorized is by their Hurst exponent
$H$. It is a description of the long-term memory of a time
series, so if $0 &lt; H &lt; 0.5$ you can conclude that the
series has negative autocorrelation. This means that a decrease will
typically be followed by an increase. This is equivalent to a
mean-reversion pattern.</p>
<p>If $0.5 &lt; H &lt; 1$ you can say that
there is a positive autocorrelation, which indicates that an increase
will be followed by an increase and similarly for decreases. This would
be a trend-following pattern.</p>
<p>Finally, if $H = 0.5$ then
the series is completely random, meaning that a stock is equally likely
to go up or down regardless of what happened the instant prior.</p>
<p>Lets
look at a few different data sets to determine their corresponding Hurst
Exponents. We will start off with an example of a random sequence of
8000 numbers, normally distributed, so that we can see what we expect
from random fractal behavior.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">rm</span>(list <span style="color:#f92672">=</span> <span style="color:#a6e22e">ls</span>(all <span style="color:#f92672">=</span> <span style="color:#66d9ef">TRUE</span>))
</span></span><span style="display:flex;"><span>randseq <span style="color:#f92672">=</span> <span style="color:#a6e22e">cumsum</span>(<span style="color:#a6e22e">rnorm</span>(<span style="color:#ae81ff">8000</span>))
</span></span><span style="display:flex;"><span>N <span style="color:#f92672">=</span> <span style="color:#a6e22e">length</span>(randseq)
</span></span><span style="display:flex;"><span>randreturn <span style="color:#f92672">=</span> randseq[2<span style="color:#f92672">:</span>N]<span style="color:#f92672">/</span>randseq[1<span style="color:#f92672">:</span>(N<span style="color:#ae81ff">-1</span>)]<span style="color:#ae81ff">-1</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(<span style="color:#a6e22e">hurstSpec</span>(randreturn, method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;standard&#34;</span>, sdf.method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;multitaper&#34;</span>))
</span></span></code></pre></div><p>
<img class="enclosure" src="/static/images/hurst_exp_random.png" alt="Random Hurst exponent"  />
</p>
<p>In this case you see a Hurst Exponent H = 0.503, which is
what we expect since we generated the sequence randomly and H = 0.5
corresponds to random behavior. Now let&rsquo;s look at a plot for IBM from
01/01/1980 to last Friday, 6/3/2011, that&rsquo;s over 31 years of returns.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">rm</span>(list <span style="color:#f92672">=</span> <span style="color:#a6e22e">ls</span>(all <span style="color:#f92672">=</span> <span style="color:#66d9ef">TRUE</span>))
</span></span><span style="display:flex;"><span>ibm80 <span style="color:#f92672">=</span> <span style="color:#a6e22e">getReturns</span>(<span style="color:#e6db74">&#34;IBM&#34;</span>, freq<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;day&#34;</span>, start<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;1980-01-01&#34;</span>, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2011-06-03&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(<span style="color:#a6e22e">hurstSpec</span>(ibm80<span style="color:#f92672">$</span>R, method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;standard&#34;</span>, sdf.method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;multitaper&#34;</span>))
</span></span></code></pre></div><p>
<img class="enclosure" src="/static/images/hurst_exp_ibm_1980010120110603.png" alt="Hurst exponent for IBM over 31 years"  />
</p>
<p>Here we have a Hurst Exponent of H = 0.487, which again
points to price fluctuations being random. So on a scale of just over 31
years, there cannot be any reliable trading indicator. This fact does
not bode well for technical analysis. Perhaps it is a scale issue and
smaller time periods will reveal more patterns, you say? Well, fractals
by definition are self-similar and so time scales are irrelevant.</p>
<p>However, I know people will not be convinced on theory alone so here is
a plot of IBM from 01/01/2006 to last Friday, 06/03/2011, just over 5
years of data.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">rm</span>(list <span style="color:#f92672">=</span> <span style="color:#a6e22e">ls</span>(all <span style="color:#f92672">=</span> <span style="color:#66d9ef">TRUE</span>))
</span></span><span style="display:flex;"><span>ibm06 <span style="color:#f92672">=</span> <span style="color:#a6e22e">getReturns</span>(<span style="color:#e6db74">&#34;IBM&#34;</span>, freq<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;day&#34;</span>, start<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2006-01-01&#34;</span>, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2011-06-03&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(<span style="color:#a6e22e">hurstSpec</span>(ibm06<span style="color:#f92672">$</span>R, method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;standard&#34;</span>, sdf.method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;multitaper&#34;</span>))
</span></span></code></pre></div><p>
<img class="enclosure" src="/static/images/hurst_exp_ibm_2006010120010603.png" alt="Hurst exponent for IBM over 5 years"  />
</p>
<p>This gives a Hurst Exponent of H = 0.499, which is actually
closer to pure randomness then the deliberately random sequence we
constructed earlier. Even starting from 01/01/11, the Hurst Exponent is
still 0.465, very close to 0.5. Having the same Hurst Exponent at all
time scales is precisely what is expected from something that is fractal
in nature.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">rm</span>(list <span style="color:#f92672">=</span> <span style="color:#a6e22e">ls</span>(all <span style="color:#f92672">=</span> <span style="color:#66d9ef">TRUE</span>))
</span></span><span style="display:flex;"><span>ibm06 <span style="color:#f92672">=</span> <span style="color:#a6e22e">getReturns</span>(<span style="color:#e6db74">&#34;IBM&#34;</span>, freq<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;day&#34;</span>, start<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2011-01-01&#34;</span>, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2011-06-03&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(<span style="color:#a6e22e">hurstSpec</span>(ibm06<span style="color:#f92672">$</span>R, method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;standard&#34;</span>, sdf.method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;multitaper&#34;</span>))
</span></span></code></pre></div><p>
<img class="enclosure" src="/static/images/hurst_exp_ibm_2011010120110603.png" alt="Hurst exponent for IBM over 6 months"  />
</p>
<p>If we go down to behavior over the last three months, from
03/01/11-06/03/11, the result is similar with a Hurst Exponent of 0.509.
Again, this shows almost perfect randomness.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">rm</span>(list <span style="color:#f92672">=</span> <span style="color:#a6e22e">ls</span>(all <span style="color:#f92672">=</span> <span style="color:#66d9ef">TRUE</span>))
</span></span><span style="display:flex;"><span>ibm06 <span style="color:#f92672">=</span> <span style="color:#a6e22e">getReturns</span>(<span style="color:#e6db74">&#34;IBM&#34;</span>, freq<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;day&#34;</span>, start<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2011-03-01&#34;</span>, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;2011-06-03&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">plot</span>(<span style="color:#a6e22e">hurstSpec</span>(ibm06<span style="color:#f92672">$</span>R, method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;standard&#34;</span>, sdf.method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;multitaper&#34;</span>))
</span></span></code></pre></div><p>
<img class="enclosure" src="/static/images/hurst_exp_ibm2011030120110603.png" alt="Hurst exponent for IBM over three months"  />
</p>
<p>As you can see, the true definition of fractal does hold
when considering stock prices. The Hurst Exponent, a measure of how
movements in a fractal pattern are related to each other stays
relatively constant and very close to 0.5, which indicates that there is
no discernible pattern in the data. We have shown that no predictability
exists for our example, IBM, in ranges from 31 years down to 3 months.</p>
<p>As you can imagine, since the price movement is fractal in nature, we
can zoom in as much as we like and the results will be the same.
Finally, the 5 steps in a time series that form a <em>fractal</em> in technical
analysis provide no usable information since there is no possible
way to predict with accuracy when prices will move and what direction
they will move in. If you&rsquo;re trading based on technical analysis
indicators such as these, you may want to reconsider your strategy.</p>
 ]]></content:encoded></item><item><title>Computing Ornstein-Uhlenbeck Process Trajectories in R</title><link>https://adamdrake.com/computing-ornstein-uhlenbeck-process-trajectories-in-r.html</link><pubDate>Tue, 31 May 2011 00:00:00 +0000</pubDate><guid>https://adamdrake.com/computing-ornstein-uhlenbeck-process-trajectories-in-r.html</guid><description>&lt;p>Compared to the Ruby version, computing this in R is much easier due to
the built-in stochastic differential equation simulator. Assuming you
have R installed, make sure you also install the sde package. Here is
all the initial work that cleans up everything from your workspace, sets
the initial value of the process, the end-point, how granular you want
the simulation to be, and how many trajectories you want.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-R" data-lang="R">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">rm&lt;/span>(list &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">ls&lt;/span>(all &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">TRUE&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x0 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">50&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>end_point &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">200&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>discretization_factor &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">100&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>total_steps &lt;span style="color:#f92672">=&lt;/span> end_point &lt;span style="color:#f92672">*&lt;/span> discretization_factor
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#Use the same seed for multiple trajectories if (number_trajectories &amp;gt; 1)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>number_trajectories &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">set.seed&lt;/span>(&lt;span style="color:#a6e22e">rnorm&lt;/span>(&lt;span style="color:#ae81ff">1&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we have a 0 drift parameter and a standard deviation of 1, followed
by the simulation and plot of the process.&lt;/p></description><content:encoded><![CDATA[ <p>Compared to the Ruby version, computing this in R is much easier due to
the built-in stochastic differential equation simulator. Assuming you
have R installed, make sure you also install the sde package. Here is
all the initial work that cleans up everything from your workspace, sets
the initial value of the process, the end-point, how granular you want
the simulation to be, and how many trajectories you want.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span><span style="color:#a6e22e">rm</span>(list <span style="color:#f92672">=</span> <span style="color:#a6e22e">ls</span>(all <span style="color:#f92672">=</span> <span style="color:#66d9ef">TRUE</span>))
</span></span><span style="display:flex;"><span>x0 <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span>end_point <span style="color:#f92672">=</span> <span style="color:#ae81ff">200</span>
</span></span><span style="display:flex;"><span>discretization_factor <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>total_steps <span style="color:#f92672">=</span> end_point <span style="color:#f92672">*</span> discretization_factor
</span></span><span style="display:flex;"><span><span style="color:#75715e">#Use the same seed for multiple trajectories if (number_trajectories &gt; 1)</span>
</span></span><span style="display:flex;"><span>number_trajectories <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">set.seed</span>(<span style="color:#a6e22e">rnorm</span>(<span style="color:#ae81ff">1</span>))
</span></span></code></pre></div><p>Here we have a 0 drift parameter and a standard deviation of 1, followed
by the simulation and plot of the process.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-R" data-lang="R"><span style="display:flex;"><span>d <span style="color:#f92672">=</span> <span style="color:#a6e22e">expression</span>(<span style="color:#ae81ff">0</span> <span style="color:#f92672">*</span> x)
</span></span><span style="display:flex;"><span>s <span style="color:#f92672">=</span> <span style="color:#a6e22e">expression</span>(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> <span style="color:#a6e22e">sde.sim</span>(M<span style="color:#f92672">=</span>number_trajectories, X0<span style="color:#f92672">=</span>x0, T<span style="color:#f92672">=</span>end_point, N<span style="color:#f92672">=</span>total_steps, drift<span style="color:#f92672">=</span>d, sigma<span style="color:#f92672">=</span>s) <span style="color:#a6e22e">plot</span>(X,main<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Price Action&#34;</span>, xlab<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Trading Period&#34;</span>, ylab<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Price&#34;</span>)
</span></span></code></pre></div><p>Here is an image of one of the trajectories created by the code.</p>
<p>
<img class="enclosure" src="/static/images/ousim_r_1_trajectory.png" alt="single trajectory"  />
</p>
<p>Making the small change in the code and switching
<code>number_trajectories = 1</code> to <code>number_trajectories = 3</code> causes the
simulator to produce a very convenient plot with all three trajectories.
You could do some averaging or filtering with them if you wanted to.
Below is an image of three trajectories.</p>
<p>
<img class="enclosure" src="/static/images/ousim_r_3_trajectories.png" alt="three trajectories"  />
</p>
<p>As you can see, doing such simulations with R is very quick and easy. In fact, I think I may displace Ruby as my default language for such tasks.</p>
 ]]></content:encoded></item><item><title>Computing Ornstein-Uhlenbeck Process Trajectories in Ruby</title><link>https://adamdrake.com/computing-ornstein-uhlenbeck-process-trajectories-in-ruby.html</link><pubDate>Tue, 31 May 2011 00:00:00 +0000</pubDate><guid>https://adamdrake.com/computing-ornstein-uhlenbeck-process-trajectories-in-ruby.html</guid><description>&lt;p>This code is adapted from some Matlab code I found that simulates the OU
process exactly. I had to code up a quick Gaussian random number
generator in Ruby because I didn&amp;rsquo;t find a method to handle that. As
noted in the comments I used the Box-Muller Transformation but if lots
of random numbers are required the Ziggurat Algorithm could be used
instead.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ruby" data-lang="ruby">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#!/usr/bin/env ruby&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">include&lt;/span> &lt;span style="color:#66d9ef">Math&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> require &lt;span style="color:#e6db74">&amp;#39;rubygems&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> require &lt;span style="color:#e6db74">&amp;#39;gnuplot&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#Gaussian random number generator using the Box-Muller Transformation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#If this is too slow it can be replaced with the Ziggurat Algorithm&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">randn&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> z1 &lt;span style="color:#f92672">=&lt;/span> rand
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> z2 &lt;span style="color:#f92672">=&lt;/span> rand
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rand_normal &lt;span style="color:#f92672">=&lt;/span> sqrt(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">*&lt;/span>log(z1))&lt;span style="color:#f92672">*&lt;/span>sin(&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#66d9ef">PI&lt;/span>&lt;span style="color:#f92672">*&lt;/span>z2)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> rand_normal&lt;span style="color:#f92672">.&lt;/span>to_f
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">end&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#Enter the parameters for the simulation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> steps &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">400&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#start_time = 0 #simulation start time&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">#end_time = 400 #simuation end time&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dt &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">01&lt;/span> &lt;span style="color:#75715e">#time step&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tau &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#75715e">#relaxation time&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> c &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#75715e">#diffusion constant&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x0 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">[]&lt;/span> &lt;span style="color:#75715e">#initial value for stochastic variable x&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mu &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#75715e">#mean of stochatic process x&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y0 &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">[]&lt;/span> &lt;span style="color:#75715e">#initial value for integral x &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> start_dist &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#75715e">#start of OU pdf &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> end_dist &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span> &lt;span style="color:#75715e">#end of OU pdf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> time &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">..&lt;/span>steps)&lt;span style="color:#f92672">.&lt;/span>step(dt)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x&lt;span style="color:#f92672">[&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">=&lt;/span> x0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y&lt;span style="color:#f92672">[&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">=&lt;/span> y0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> time&lt;span style="color:#f92672">.&lt;/span>each &lt;span style="color:#66d9ef">do&lt;/span> &lt;span style="color:#f92672">|&lt;/span>t&lt;span style="color:#f92672">|&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#f92672">=&lt;/span> i &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> r1 &lt;span style="color:#f92672">=&lt;/span> randn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> r2 &lt;span style="color:#f92672">=&lt;/span> randn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> puts x&lt;span style="color:#f92672">[&lt;/span>i&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> x&lt;span style="color:#f92672">[&lt;/span>i&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">=&lt;/span> x&lt;span style="color:#f92672">[&lt;/span>i&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">*&lt;/span> exp(&lt;span style="color:#f92672">-&lt;/span>dt&lt;span style="color:#f92672">/&lt;/span>tau) &lt;span style="color:#f92672">+&lt;/span> sqrt((c&lt;span style="color:#f92672">*&lt;/span>tau&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">5&lt;/span>)&lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">-&lt;/span>(exp(&lt;span style="color:#f92672">-&lt;/span>dt&lt;span style="color:#f92672">/&lt;/span>tau))&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>))&lt;span style="color:#f92672">*&lt;/span>r1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y&lt;span style="color:#f92672">[&lt;/span>i&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">=&lt;/span> y&lt;span style="color:#f92672">[&lt;/span>i&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">+&lt;/span> x&lt;span style="color:#f92672">[&lt;/span>i&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">]*&lt;/span>tau&lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">-&lt;/span>exp(&lt;span style="color:#f92672">-&lt;/span>dt&lt;span style="color:#f92672">/&lt;/span>tau))&lt;span style="color:#f92672">+&lt;/span>sqrt((c&lt;span style="color:#f92672">*&lt;/span>tau&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>&lt;span style="color:#f92672">*&lt;/span>(dt&lt;span style="color:#f92672">/&lt;/span>tau&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">*&lt;/span> \
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> (&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">-&lt;/span>exp(&lt;span style="color:#f92672">-&lt;/span>dt&lt;span style="color:#f92672">/&lt;/span>tau))&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">5&lt;/span>&lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">-&lt;/span>exp(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">*&lt;/span>dt&lt;span style="color:#f92672">/&lt;/span>tau))))&lt;span style="color:#f92672">-&lt;/span>((&lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">5&lt;/span>&lt;span style="color:#f92672">*&lt;/span>c&lt;span style="color:#f92672">*&lt;/span>tau&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">*&lt;/span> \
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> (&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">-&lt;/span>exp(&lt;span style="color:#f92672">-&lt;/span>dt&lt;span style="color:#f92672">/&lt;/span>tau))&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">/&lt;/span>((c&lt;span style="color:#f92672">*&lt;/span>tau&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">-&lt;/span>exp(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">*&lt;/span>dt&lt;span style="color:#f92672">/&lt;/span>tau))))&lt;span style="color:#f92672">*&lt;/span>r2&lt;span style="color:#f92672">+&lt;/span> \
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ((&lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">.&lt;/span>&lt;span style="color:#ae81ff">5&lt;/span>&lt;span style="color:#f92672">*&lt;/span>c&lt;span style="color:#f92672">*&lt;/span>tau&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">-&lt;/span>exp(&lt;span style="color:#f92672">-&lt;/span>dt&lt;span style="color:#f92672">/&lt;/span>tau))&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>(sqrt((c&lt;span style="color:#f92672">*&lt;/span>tau&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">*&lt;/span> \
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> (&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">-&lt;/span>(exp(&lt;span style="color:#f92672">-&lt;/span>dt&lt;span style="color:#f92672">/&lt;/span>tau))&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)))&lt;span style="color:#f92672">*&lt;/span>r1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">end&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> k &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> j &lt;span style="color:#f92672">=&lt;/span> (start_dist&lt;span style="color:#f92672">..&lt;/span>end_dist)&lt;span style="color:#f92672">.&lt;/span>step(dt)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> p &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#f92672">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> j&lt;span style="color:#f92672">.&lt;/span>each &lt;span style="color:#66d9ef">do&lt;/span> &lt;span style="color:#f92672">|&lt;/span>l&lt;span style="color:#f92672">|&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> k &lt;span style="color:#f92672">=&lt;/span> k &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> p&lt;span style="color:#f92672">[&lt;/span>k&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">=&lt;/span> sqrt((&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">/&lt;/span>tau)&lt;span style="color:#f92672">/&lt;/span>(&lt;span style="color:#66d9ef">PI&lt;/span>&lt;span style="color:#f92672">*&lt;/span>c))&lt;span style="color:#f92672">*&lt;/span>exp(&lt;span style="color:#f92672">-&lt;/span>(&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">/&lt;/span>tau)&lt;span style="color:#f92672">*&lt;/span>(l&lt;span style="color:#f92672">-&lt;/span>mu)&lt;span style="color:#f92672">**&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">/&lt;/span>(c))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">end&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>That&amp;rsquo;s it. Not too difficult to compute with Ruby, but I also did another version in R. I&amp;rsquo;ll post about that shortly.&lt;/p></description><content:encoded><![CDATA[ <p>This code is adapted from some Matlab code I found that simulates the OU
process exactly. I had to code up a quick Gaussian random number
generator in Ruby because I didn&rsquo;t find a method to handle that. As
noted in the comments I used the Box-Muller Transformation but if lots
of random numbers are required the Ziggurat Algorithm could be used
instead.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ruby" data-lang="ruby"><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#!/usr/bin/env ruby</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">include</span> <span style="color:#66d9ef">Math</span>
</span></span><span style="display:flex;"><span>  require <span style="color:#e6db74">&#39;rubygems&#39;</span>
</span></span><span style="display:flex;"><span>  require <span style="color:#e6db74">&#39;gnuplot&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#Gaussian random number generator using the Box-Muller Transformation</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#If this is too slow it can be replaced with the Ziggurat Algorithm</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">randn</span>
</span></span><span style="display:flex;"><span>    z1 <span style="color:#f92672">=</span> rand
</span></span><span style="display:flex;"><span>    z2 <span style="color:#f92672">=</span> rand
</span></span><span style="display:flex;"><span>    rand_normal <span style="color:#f92672">=</span> sqrt(<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span><span style="color:#f92672">*</span>log(z1))<span style="color:#f92672">*</span>sin(<span style="color:#ae81ff">2</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span><span style="color:#f92672">*</span><span style="color:#66d9ef">PI</span><span style="color:#f92672">*</span>z2)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> rand_normal<span style="color:#f92672">.</span>to_f
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">end</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#Enter the parameters for the simulation</span>
</span></span><span style="display:flex;"><span>  steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">400</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#start_time = 0          #simulation start time</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">#end_time = 400          #simuation end time</span>
</span></span><span style="display:flex;"><span>  dt <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">01</span>            <span style="color:#75715e">#time step</span>
</span></span><span style="display:flex;"><span>  tau <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">1</span>            <span style="color:#75715e">#relaxation time</span>
</span></span><span style="display:flex;"><span>  c <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span>                <span style="color:#75715e">#diffusion constant</span>
</span></span><span style="display:flex;"><span>  x0 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>  x <span style="color:#f92672">=</span> <span style="color:#f92672">[]</span>               <span style="color:#75715e">#initial value for stochastic variable x</span>
</span></span><span style="display:flex;"><span>  mu <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span>               <span style="color:#75715e">#mean of stochatic process x</span>
</span></span><span style="display:flex;"><span>  y0 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>  y <span style="color:#f92672">=</span> <span style="color:#f92672">[]</span>               <span style="color:#75715e">#initial value for integral x </span>
</span></span><span style="display:flex;"><span>  start_dist <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">2</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span>    <span style="color:#75715e">#start of OU pdf </span>
</span></span><span style="display:flex;"><span>  end_dist <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">.</span><span style="color:#ae81ff">0</span>       <span style="color:#75715e">#end of OU pdf</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  time <span style="color:#f92672">=</span> (<span style="color:#ae81ff">0</span><span style="color:#f92672">..</span>steps)<span style="color:#f92672">.</span>step(dt)
</span></span><span style="display:flex;"><span>  i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>  x<span style="color:#f92672">[</span><span style="color:#ae81ff">0</span><span style="color:#f92672">]</span> <span style="color:#f92672">=</span> x0 
</span></span><span style="display:flex;"><span>  y<span style="color:#f92672">[</span><span style="color:#ae81ff">0</span><span style="color:#f92672">]</span> <span style="color:#f92672">=</span> y0
</span></span><span style="display:flex;"><span>  time<span style="color:#f92672">.</span>each <span style="color:#66d9ef">do</span> <span style="color:#f92672">|</span>t<span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span>    i <span style="color:#f92672">=</span> i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span> 
</span></span><span style="display:flex;"><span>    r1 <span style="color:#f92672">=</span> randn
</span></span><span style="display:flex;"><span>    r2 <span style="color:#f92672">=</span> randn
</span></span><span style="display:flex;"><span>  puts x<span style="color:#f92672">[</span>i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    x<span style="color:#f92672">[</span>i<span style="color:#f92672">]</span> <span style="color:#f92672">=</span> x<span style="color:#f92672">[</span>i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#f92672">]</span> <span style="color:#f92672">*</span> exp(<span style="color:#f92672">-</span>dt<span style="color:#f92672">/</span>tau) <span style="color:#f92672">+</span> sqrt((c<span style="color:#f92672">*</span>tau<span style="color:#f92672">*</span><span style="color:#ae81ff">0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">5</span>)<span style="color:#f92672">*</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>(exp(<span style="color:#f92672">-</span>dt<span style="color:#f92672">/</span>tau))<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>))<span style="color:#f92672">*</span>r1
</span></span><span style="display:flex;"><span>    y<span style="color:#f92672">[</span>i<span style="color:#f92672">]</span> <span style="color:#f92672">=</span> y<span style="color:#f92672">[</span>i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#f92672">]</span> <span style="color:#f92672">+</span> x<span style="color:#f92672">[</span>i<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#f92672">]*</span>tau<span style="color:#f92672">*</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>exp(<span style="color:#f92672">-</span>dt<span style="color:#f92672">/</span>tau))<span style="color:#f92672">+</span>sqrt((c<span style="color:#f92672">*</span>tau<span style="color:#f92672">**</span><span style="color:#ae81ff">3</span><span style="color:#f92672">*</span>(dt<span style="color:#f92672">/</span>tau<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span> \
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>exp(<span style="color:#f92672">-</span>dt<span style="color:#f92672">/</span>tau))<span style="color:#f92672">+</span><span style="color:#ae81ff">0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">5</span><span style="color:#f92672">*</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>exp(<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>dt<span style="color:#f92672">/</span>tau))))<span style="color:#f92672">-</span>((<span style="color:#ae81ff">0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">5</span><span style="color:#f92672">*</span>c<span style="color:#f92672">*</span>tau<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">*</span> \
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>exp(<span style="color:#f92672">-</span>dt<span style="color:#f92672">/</span>tau))<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span><span style="color:#f92672">/</span>((c<span style="color:#f92672">*</span>tau<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">*</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>exp(<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>dt<span style="color:#f92672">/</span>tau))))<span style="color:#f92672">*</span>r2<span style="color:#f92672">+</span> \
</span></span><span style="display:flex;"><span>      ((<span style="color:#ae81ff">0</span><span style="color:#f92672">.</span><span style="color:#ae81ff">5</span><span style="color:#f92672">*</span>c<span style="color:#f92672">*</span>tau<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">*</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>exp(<span style="color:#f92672">-</span>dt<span style="color:#f92672">/</span>tau))<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">/</span>(sqrt((c<span style="color:#f92672">*</span>tau<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">*</span> \
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>(exp(<span style="color:#f92672">-</span>dt<span style="color:#f92672">/</span>tau))<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)))<span style="color:#f92672">*</span>r1
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">end</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  k <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>  j <span style="color:#f92672">=</span> (start_dist<span style="color:#f92672">..</span>end_dist)<span style="color:#f92672">.</span>step(dt)
</span></span><span style="display:flex;"><span>  p <span style="color:#f92672">=</span> <span style="color:#f92672">[]</span>
</span></span><span style="display:flex;"><span>  j<span style="color:#f92672">.</span>each <span style="color:#66d9ef">do</span> <span style="color:#f92672">|</span>l<span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span>      k <span style="color:#f92672">=</span> k <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>      p<span style="color:#f92672">[</span>k<span style="color:#f92672">]</span> <span style="color:#f92672">=</span> sqrt((<span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>tau)<span style="color:#f92672">/</span>(<span style="color:#66d9ef">PI</span><span style="color:#f92672">*</span>c))<span style="color:#f92672">*</span>exp(<span style="color:#f92672">-</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>tau)<span style="color:#f92672">*</span>(l<span style="color:#f92672">-</span>mu)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span><span style="color:#f92672">/</span>(c)) 
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">end</span>
</span></span></code></pre></div><p>That&rsquo;s it. Not too difficult to compute with Ruby, but I also did another version in R. I&rsquo;ll post about that shortly.</p>
 ]]></content:encoded></item></channel></rss>